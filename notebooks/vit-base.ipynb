{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit(model_name):\n",
    "    if model_name == 'tiny': model = timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=4)\n",
    "    if model_name == 'small': model = timm.create_model('vit_small_patch16_224', pretrained=False, num_classes=4)\n",
    "    if model_name == 'base': model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=4)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='/home/ubuntu/Parkinson-Project/non-keyframes/energy_images', transform=transform)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8) \n",
    "validation_size = int(total_size * 0.1) \n",
    "test_size = total_size - train_size - validation_size\n",
    "generator = torch.Generator().manual_seed(0) \n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size], generator=generator)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'vit-base-130-epochs-early-stopping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (patch_drop): Identity()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_type = 'base'\n",
    "model = create_vit(model_type)\n",
    "\n",
    "# Model summary to check architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1, Loss: 1.437828, Accuracy: 6.25%\n",
      "Batch 2, Loss: 3.431281, Accuracy: 17.97%\n",
      "Batch 3, Loss: 2.019404, Accuracy: 27.08%\n",
      "Batch 4, Loss: 2.985187, Accuracy: 25.78%\n",
      "Batch 5, Loss: 1.336606, Accuracy: 26.56%\n",
      "Batch 6, Loss: 1.512536, Accuracy: 25.26%\n",
      "Batch 7, Loss: 1.692100, Accuracy: 26.34%\n",
      "Batch 8, Loss: 2.097736, Accuracy: 26.76%\n",
      "Batch 9, Loss: 1.854435, Accuracy: 27.43%\n",
      "Batch 10, Loss: 1.259159, Accuracy: 28.44%\n",
      "Batch 11, Loss: 1.480032, Accuracy: 28.69%\n",
      "Batch 12, Loss: 1.197533, Accuracy: 28.91%\n",
      "Batch 13, Loss: 1.384947, Accuracy: 29.93%\n",
      "Batch 14, Loss: 1.278703, Accuracy: 30.47%\n",
      "Batch 15, Loss: 1.459901, Accuracy: 30.42%\n",
      "Batch 16, Loss: 1.416520, Accuracy: 30.37%\n",
      "Batch 17, Loss: 1.434119, Accuracy: 30.15%\n",
      "Batch 18, Loss: 1.385262, Accuracy: 30.12%\n",
      "Batch 19, Loss: 1.311515, Accuracy: 30.67%\n",
      "Batch 20, Loss: 1.319456, Accuracy: 30.94%\n",
      "Batch 21, Loss: 1.367072, Accuracy: 31.03%\n",
      "Batch 22, Loss: 1.361068, Accuracy: 31.25%\n",
      "Batch 23, Loss: 1.324246, Accuracy: 31.39%\n",
      "Batch 24, Loss: 1.251820, Accuracy: 31.77%\n",
      "Batch 25, Loss: 1.301458, Accuracy: 31.56%\n",
      "Batch 26, Loss: 1.121968, Accuracy: 31.91%\n",
      "Batch 27, Loss: 1.440815, Accuracy: 31.60%\n",
      "Batch 28, Loss: 1.330882, Accuracy: 31.58%\n",
      "Batch 29, Loss: 1.139212, Accuracy: 32.00%\n",
      "Batch 30, Loss: 1.259799, Accuracy: 31.98%\n",
      "Batch 31, Loss: 1.286980, Accuracy: 31.55%\n",
      "Batch 32, Loss: 1.346523, Accuracy: 31.54%\n",
      "Batch 33, Loss: 1.310361, Accuracy: 31.16%\n",
      "Batch 34, Loss: 1.255709, Accuracy: 31.11%\n",
      "Batch 35, Loss: 1.302199, Accuracy: 30.94%\n",
      "Batch 36, Loss: 1.288913, Accuracy: 30.99%\n",
      "Batch 37, Loss: 1.395554, Accuracy: 30.95%\n",
      "Batch 38, Loss: 1.157739, Accuracy: 31.09%\n",
      "Batch 39, Loss: 1.331763, Accuracy: 30.97%\n",
      "Batch 40, Loss: 1.442235, Accuracy: 30.90%\n",
      "Batch 41, Loss: 1.451243, Accuracy: 30.72%\n",
      "Batch 42, Loss: 1.360536, Accuracy: 30.77%\n",
      "Batch 43, Loss: 1.209977, Accuracy: 30.89%\n",
      "Batch 44, Loss: 1.281512, Accuracy: 30.79%\n",
      "Batch 45, Loss: 1.247405, Accuracy: 31.01%\n",
      "Batch 46, Loss: 1.260598, Accuracy: 31.01%\n",
      "Batch 47, Loss: 1.296210, Accuracy: 30.92%\n",
      "Batch 48, Loss: 1.256235, Accuracy: 30.99%\n",
      "Batch 49, Loss: 1.292931, Accuracy: 31.19%\n",
      "Batch 50, Loss: 1.287399, Accuracy: 31.31%\n",
      "Batch 51, Loss: 1.225309, Accuracy: 31.28%\n",
      "Batch 52, Loss: 1.310038, Accuracy: 31.46%\n",
      "Batch 53, Loss: 1.210195, Accuracy: 31.66%\n",
      "Batch 54, Loss: 1.283762, Accuracy: 31.68%\n",
      "Batch 55, Loss: 1.537485, Accuracy: 31.59%\n",
      "Batch 56, Loss: 1.330210, Accuracy: 31.50%\n",
      "Batch 57, Loss: 1.252395, Accuracy: 31.63%\n",
      "Batch 58, Loss: 1.360704, Accuracy: 31.44%\n",
      "Batch 59, Loss: 1.216177, Accuracy: 31.65%\n",
      "Batch 60, Loss: 1.200403, Accuracy: 31.93%\n",
      "Batch 61, Loss: 1.208350, Accuracy: 31.92%\n",
      "Batch 62, Loss: 1.233776, Accuracy: 32.11%\n",
      "Batch 63, Loss: 1.306600, Accuracy: 32.27%\n",
      "Batch 64, Loss: 1.352089, Accuracy: 32.25%\n",
      "Batch 65, Loss: 1.299532, Accuracy: 32.31%\n",
      "Batch 66, Loss: 1.271635, Accuracy: 32.32%\n",
      "Batch 67, Loss: 1.313871, Accuracy: 32.35%\n",
      "Batch 68, Loss: 1.315124, Accuracy: 32.31%\n",
      "Batch 69, Loss: 1.371996, Accuracy: 32.20%\n",
      "Batch 70, Loss: 1.272269, Accuracy: 32.19%\n",
      "Batch 71, Loss: 1.236936, Accuracy: 32.37%\n",
      "Batch 72, Loss: 1.238571, Accuracy: 32.51%\n",
      "Batch 73, Loss: 1.320895, Accuracy: 32.47%\n",
      "Batch 74, Loss: 1.275049, Accuracy: 32.47%\n",
      "Batch 75, Loss: 1.263582, Accuracy: 32.58%\n",
      "Batch 76, Loss: 1.367886, Accuracy: 32.46%\n",
      "Batch 77, Loss: 1.376333, Accuracy: 32.37%\n",
      "Batch 78, Loss: 1.284415, Accuracy: 32.39%\n",
      "Batch 79, Loss: 1.284345, Accuracy: 32.42%\n",
      "Batch 80, Loss: 1.213954, Accuracy: 32.60%\n",
      "Batch 81, Loss: 1.291260, Accuracy: 32.64%\n",
      "Batch 82, Loss: 1.267628, Accuracy: 32.66%\n",
      "Batch 83, Loss: 1.386055, Accuracy: 32.68%\n",
      "Batch 84, Loss: 1.320166, Accuracy: 32.59%\n",
      "Batch 85, Loss: 1.239814, Accuracy: 32.70%\n",
      "Batch 86, Loss: 1.277420, Accuracy: 32.87%\n",
      "Batch 87, Loss: 1.226892, Accuracy: 32.79%\n",
      "Batch 88, Loss: 1.240579, Accuracy: 32.83%\n",
      "Batch 89, Loss: 1.274437, Accuracy: 32.79%\n",
      "Batch 90, Loss: 1.151584, Accuracy: 32.86%\n",
      "Batch 91, Loss: 1.230539, Accuracy: 32.92%\n",
      "Batch 92, Loss: 1.103494, Accuracy: 33.00%\n",
      "Batch 93, Loss: 1.208775, Accuracy: 33.08%\n",
      "Batch 94, Loss: 1.200832, Accuracy: 33.14%\n",
      "Batch 95, Loss: 1.429731, Accuracy: 33.04%\n",
      "Batch 96, Loss: 1.282264, Accuracy: 33.11%\n",
      "Batch 97, Loss: 1.269573, Accuracy: 33.18%\n",
      "Batch 98, Loss: 1.202451, Accuracy: 33.16%\n",
      "Batch 99, Loss: 1.215505, Accuracy: 33.16%\n",
      "Batch 100, Loss: 1.253885, Accuracy: 33.20%\n",
      "Batch 101, Loss: 1.235850, Accuracy: 33.20%\n",
      "Batch 102, Loss: 1.206529, Accuracy: 33.23%\n",
      "Batch 103, Loss: 1.270538, Accuracy: 33.16%\n",
      "Batch 104, Loss: 1.183658, Accuracy: 33.29%\n",
      "Batch 105, Loss: 1.345071, Accuracy: 33.24%\n",
      "Batch 106, Loss: 1.255211, Accuracy: 33.33%\n",
      "Batch 107, Loss: 1.393159, Accuracy: 33.28%\n",
      "Batch 108, Loss: 1.247410, Accuracy: 33.36%\n",
      "Batch 109, Loss: 1.261919, Accuracy: 33.31%\n",
      "Batch 110, Loss: 1.286029, Accuracy: 33.30%\n",
      "Batch 111, Loss: 1.297138, Accuracy: 33.18%\n",
      "Batch 112, Loss: 1.334546, Accuracy: 33.12%\n",
      "Batch 113, Loss: 1.248283, Accuracy: 33.12%\n",
      "Batch 114, Loss: 1.320181, Accuracy: 33.06%\n",
      "Batch 115, Loss: 1.233811, Accuracy: 33.15%\n",
      "Batch 116, Loss: 1.262249, Accuracy: 33.24%\n",
      "Batch 117, Loss: 1.245194, Accuracy: 33.28%\n",
      "Batch 118, Loss: 1.234928, Accuracy: 33.26%\n",
      "Batch 119, Loss: 1.347830, Accuracy: 33.21%\n",
      "Batch 120, Loss: 1.370327, Accuracy: 33.24%\n",
      "Batch 121, Loss: 1.294212, Accuracy: 33.29%\n",
      "Batch 122, Loss: 1.317731, Accuracy: 33.30%\n",
      "Batch 123, Loss: 1.269896, Accuracy: 33.33%\n",
      "Batch 124, Loss: 1.368433, Accuracy: 33.27%\n",
      "Batch 125, Loss: 1.230790, Accuracy: 33.29%\n",
      "Batch 126, Loss: 1.256966, Accuracy: 33.25%\n",
      "Batch 127, Loss: 1.151651, Accuracy: 33.30%\n",
      "Batch 128, Loss: 1.225721, Accuracy: 33.30%\n",
      "Batch 129, Loss: 1.226631, Accuracy: 33.36%\n",
      "Batch 130, Loss: 1.206504, Accuracy: 33.43%\n",
      "Batch 131, Loss: 1.215818, Accuracy: 33.43%\n",
      "Batch 132, Loss: 1.239963, Accuracy: 33.49%\n",
      "Batch 133, Loss: 1.191170, Accuracy: 33.59%\n",
      "Batch 134, Loss: 1.218664, Accuracy: 33.68%\n",
      "Batch 135, Loss: 1.388554, Accuracy: 33.72%\n",
      "Batch 136, Loss: 1.343895, Accuracy: 33.74%\n",
      "Batch 137, Loss: 1.135990, Accuracy: 33.87%\n",
      "Batch 138, Loss: 1.181224, Accuracy: 34.02%\n",
      "Batch 139, Loss: 1.239830, Accuracy: 34.04%\n",
      "Batch 140, Loss: 1.092491, Accuracy: 34.21%\n",
      "Batch 141, Loss: 1.083295, Accuracy: 34.28%\n",
      "Batch 142, Loss: 1.214488, Accuracy: 34.36%\n",
      "Batch 143, Loss: 1.135208, Accuracy: 34.47%\n",
      "Batch 144, Loss: 1.088859, Accuracy: 34.60%\n",
      "Batch 145, Loss: 1.099856, Accuracy: 34.77%\n",
      "Batch 146, Loss: 1.152652, Accuracy: 34.90%\n",
      "Batch 147, Loss: 1.085415, Accuracy: 35.06%\n",
      "Batch 148, Loss: 1.217850, Accuracy: 35.10%\n",
      "Batch 149, Loss: 1.109812, Accuracy: 35.20%\n",
      "Batch 150, Loss: 1.310037, Accuracy: 35.27%\n",
      "Batch 151, Loss: 1.108987, Accuracy: 35.36%\n",
      "Batch 152, Loss: 0.948229, Accuracy: 35.50%\n",
      "Batch 153, Loss: 1.091113, Accuracy: 35.56%\n",
      "Batch 154, Loss: 1.133278, Accuracy: 35.63%\n",
      "Batch 155, Loss: 1.309700, Accuracy: 35.66%\n",
      "Batch 156, Loss: 1.030571, Accuracy: 35.73%\n",
      "Batch 157, Loss: 1.166295, Accuracy: 35.78%\n",
      "Batch 158, Loss: 1.184948, Accuracy: 35.86%\n",
      "Batch 159, Loss: 1.376812, Accuracy: 35.86%\n",
      "Batch 160, Loss: 1.122851, Accuracy: 35.99%\n",
      "Batch 161, Loss: 1.176410, Accuracy: 36.02%\n",
      "Batch 162, Loss: 1.258102, Accuracy: 36.05%\n",
      "Batch 163, Loss: 1.240187, Accuracy: 36.10%\n",
      "Batch 164, Loss: 1.062532, Accuracy: 36.21%\n",
      "Batch 165, Loss: 1.211906, Accuracy: 36.27%\n",
      "Batch 166, Loss: 1.039810, Accuracy: 36.36%\n",
      "Batch 167, Loss: 1.065113, Accuracy: 36.42%\n",
      "Batch 168, Loss: 1.141198, Accuracy: 36.50%\n",
      "Batch 169, Loss: 1.130320, Accuracy: 36.56%\n",
      "Batch 170, Loss: 0.913019, Accuracy: 36.72%\n",
      "Batch 171, Loss: 1.271765, Accuracy: 36.77%\n",
      "Batch 172, Loss: 1.075165, Accuracy: 36.86%\n",
      "Batch 173, Loss: 1.206492, Accuracy: 37.01%\n",
      "Batch 174, Loss: 1.129382, Accuracy: 37.08%\n",
      "Batch 175, Loss: 1.042328, Accuracy: 37.23%\n",
      "Batch 176, Loss: 0.988732, Accuracy: 37.33%\n",
      "Batch 177, Loss: 1.041541, Accuracy: 37.46%\n",
      "Batch 178, Loss: 1.276944, Accuracy: 37.53%\n",
      "Batch 179, Loss: 1.120460, Accuracy: 37.63%\n",
      "Batch 180, Loss: 1.135619, Accuracy: 37.67%\n",
      "Batch 181, Loss: 1.004654, Accuracy: 37.79%\n",
      "Batch 182, Loss: 1.036345, Accuracy: 37.89%\n",
      "Batch 183, Loss: 1.077282, Accuracy: 37.97%\n",
      "Batch 184, Loss: 1.121105, Accuracy: 38.07%\n",
      "Batch 185, Loss: 1.192992, Accuracy: 38.11%\n",
      "Batch 186, Loss: 0.954363, Accuracy: 38.26%\n",
      "Batch 187, Loss: 0.958346, Accuracy: 38.42%\n",
      "Batch 188, Loss: 1.005534, Accuracy: 38.52%\n",
      "Batch 189, Loss: 0.980945, Accuracy: 38.60%\n",
      "Batch 190, Loss: 1.119776, Accuracy: 38.70%\n",
      "Batch 191, Loss: 1.135644, Accuracy: 38.74%\n",
      "Batch 192, Loss: 1.133004, Accuracy: 38.82%\n",
      "Batch 193, Loss: 0.955232, Accuracy: 38.97%\n",
      "Batch 194, Loss: 1.351205, Accuracy: 39.03%\n",
      "Batch 195, Loss: 0.975244, Accuracy: 39.13%\n",
      "Batch 196, Loss: 0.924986, Accuracy: 39.24%\n",
      "Batch 197, Loss: 1.178976, Accuracy: 39.32%\n",
      "Batch 198, Loss: 0.956732, Accuracy: 39.41%\n",
      "Batch 199, Loss: 1.028175, Accuracy: 39.51%\n",
      "Batch 200, Loss: 1.028008, Accuracy: 39.60%\n",
      "Batch 201, Loss: 0.872758, Accuracy: 39.72%\n",
      "Batch 202, Loss: 0.913056, Accuracy: 39.83%\n",
      "Batch 203, Loss: 1.009800, Accuracy: 39.92%\n",
      "Batch 204, Loss: 0.798620, Accuracy: 40.05%\n",
      "Batch 205, Loss: 1.054015, Accuracy: 40.09%\n",
      "Batch 206, Loss: 0.965011, Accuracy: 40.23%\n",
      "Batch 207, Loss: 0.948567, Accuracy: 40.34%\n",
      "Batch 208, Loss: 0.990671, Accuracy: 40.40%\n",
      "Batch 209, Loss: 1.026700, Accuracy: 40.48%\n",
      "Batch 210, Loss: 0.963673, Accuracy: 40.55%\n",
      "Batch 211, Loss: 1.046308, Accuracy: 40.63%\n",
      "Batch 212, Loss: 1.118596, Accuracy: 40.69%\n",
      "Batch 213, Loss: 1.247567, Accuracy: 40.73%\n",
      "Training - Epoch 1, Loss: 1.248866, Accuracy: 40.73%\n",
      "Validation Batch 1, Loss: 1.014987, Accuracy: 51.56%\n",
      "Validation Batch 2, Loss: 0.993839, Accuracy: 55.47%\n",
      "Validation Batch 3, Loss: 1.073499, Accuracy: 53.65%\n",
      "Validation Batch 4, Loss: 0.832408, Accuracy: 57.03%\n",
      "Validation Batch 5, Loss: 0.941578, Accuracy: 58.44%\n",
      "Validation Batch 6, Loss: 0.771591, Accuracy: 61.20%\n",
      "Validation Batch 7, Loss: 0.989647, Accuracy: 60.94%\n",
      "Validation Batch 8, Loss: 1.080889, Accuracy: 61.13%\n",
      "Validation Batch 9, Loss: 1.052090, Accuracy: 60.59%\n",
      "Validation Batch 10, Loss: 0.945190, Accuracy: 60.00%\n",
      "Validation Batch 11, Loss: 0.963577, Accuracy: 59.38%\n",
      "Validation Batch 12, Loss: 0.888016, Accuracy: 59.64%\n",
      "Validation Batch 13, Loss: 1.027739, Accuracy: 59.50%\n",
      "Validation Batch 14, Loss: 1.128121, Accuracy: 59.15%\n",
      "Validation Batch 15, Loss: 1.039774, Accuracy: 58.85%\n",
      "Validation Batch 16, Loss: 1.011165, Accuracy: 58.98%\n",
      "Validation Batch 17, Loss: 1.080166, Accuracy: 58.73%\n",
      "Validation Batch 18, Loss: 0.982433, Accuracy: 58.68%\n",
      "Validation Batch 19, Loss: 1.075424, Accuracy: 58.63%\n",
      "Validation Batch 20, Loss: 0.907879, Accuracy: 58.75%\n",
      "Validation Batch 21, Loss: 0.894103, Accuracy: 59.08%\n",
      "Validation Batch 22, Loss: 1.022488, Accuracy: 58.95%\n",
      "Validation Batch 23, Loss: 1.113599, Accuracy: 58.76%\n",
      "Validation Batch 24, Loss: 0.933662, Accuracy: 58.98%\n",
      "Validation Batch 25, Loss: 0.857019, Accuracy: 59.38%\n",
      "Validation Batch 26, Loss: 0.883301, Accuracy: 59.56%\n",
      "Validation Batch 27, Loss: 0.917653, Accuracy: 59.89%\n",
      "Validation - Epoch 1, Loss: 0.978587, Accuracy: 59.89%\n",
      "Patience—0\n",
      "Epoch 2\n",
      "Batch 1, Loss: 1.089520, Accuracy: 57.81%\n",
      "Batch 2, Loss: 0.986113, Accuracy: 60.94%\n",
      "Batch 3, Loss: 1.004812, Accuracy: 58.85%\n",
      "Batch 4, Loss: 0.942071, Accuracy: 60.16%\n",
      "Batch 5, Loss: 1.026561, Accuracy: 59.38%\n",
      "Batch 6, Loss: 0.951075, Accuracy: 59.38%\n",
      "Batch 7, Loss: 1.219988, Accuracy: 57.59%\n",
      "Batch 8, Loss: 1.099729, Accuracy: 57.03%\n",
      "Batch 9, Loss: 0.819315, Accuracy: 57.99%\n",
      "Batch 10, Loss: 0.896783, Accuracy: 58.44%\n",
      "Batch 11, Loss: 0.938112, Accuracy: 59.09%\n",
      "Batch 12, Loss: 1.102067, Accuracy: 57.94%\n",
      "Batch 13, Loss: 1.036636, Accuracy: 57.45%\n",
      "Batch 14, Loss: 0.798633, Accuracy: 58.15%\n",
      "Batch 15, Loss: 0.951911, Accuracy: 58.33%\n",
      "Batch 16, Loss: 0.986752, Accuracy: 58.59%\n",
      "Batch 17, Loss: 0.812994, Accuracy: 58.82%\n",
      "Batch 18, Loss: 0.886929, Accuracy: 59.20%\n",
      "Batch 19, Loss: 0.948091, Accuracy: 59.21%\n",
      "Batch 20, Loss: 1.043357, Accuracy: 59.53%\n",
      "Batch 21, Loss: 0.976528, Accuracy: 59.52%\n",
      "Batch 22, Loss: 0.859802, Accuracy: 59.66%\n",
      "Batch 23, Loss: 0.882227, Accuracy: 59.92%\n",
      "Batch 24, Loss: 1.047590, Accuracy: 59.70%\n",
      "Batch 25, Loss: 0.897893, Accuracy: 59.75%\n",
      "Batch 26, Loss: 0.945472, Accuracy: 59.80%\n",
      "Batch 27, Loss: 1.057676, Accuracy: 59.84%\n",
      "Batch 28, Loss: 1.050049, Accuracy: 59.71%\n",
      "Batch 29, Loss: 0.952910, Accuracy: 59.75%\n",
      "Batch 30, Loss: 0.859535, Accuracy: 60.10%\n",
      "Batch 31, Loss: 0.934246, Accuracy: 60.23%\n",
      "Batch 32, Loss: 0.842105, Accuracy: 60.40%\n",
      "Batch 33, Loss: 1.032699, Accuracy: 60.18%\n",
      "Batch 34, Loss: 1.003651, Accuracy: 60.02%\n",
      "Batch 35, Loss: 0.980331, Accuracy: 60.09%\n",
      "Batch 36, Loss: 0.955904, Accuracy: 60.07%\n",
      "Batch 37, Loss: 0.865529, Accuracy: 60.22%\n",
      "Batch 38, Loss: 1.095743, Accuracy: 60.16%\n",
      "Batch 39, Loss: 0.893142, Accuracy: 60.26%\n",
      "Batch 40, Loss: 1.038220, Accuracy: 60.20%\n",
      "Batch 41, Loss: 0.757749, Accuracy: 60.33%\n",
      "Batch 42, Loss: 0.789705, Accuracy: 60.34%\n",
      "Batch 43, Loss: 1.032183, Accuracy: 60.17%\n",
      "Batch 44, Loss: 1.004139, Accuracy: 60.09%\n",
      "Batch 45, Loss: 0.934557, Accuracy: 60.14%\n",
      "Batch 46, Loss: 0.777799, Accuracy: 60.39%\n",
      "Batch 47, Loss: 0.720376, Accuracy: 60.57%\n",
      "Batch 48, Loss: 0.892858, Accuracy: 60.64%\n",
      "Batch 49, Loss: 0.993623, Accuracy: 60.55%\n",
      "Batch 50, Loss: 0.985484, Accuracy: 60.56%\n",
      "Batch 51, Loss: 0.836491, Accuracy: 60.57%\n",
      "Batch 52, Loss: 0.899536, Accuracy: 60.67%\n",
      "Batch 53, Loss: 0.548257, Accuracy: 61.06%\n",
      "Batch 54, Loss: 0.858628, Accuracy: 61.00%\n",
      "Batch 55, Loss: 0.822960, Accuracy: 61.16%\n",
      "Batch 56, Loss: 1.159522, Accuracy: 61.02%\n",
      "Batch 57, Loss: 0.866792, Accuracy: 61.10%\n",
      "Batch 58, Loss: 0.774857, Accuracy: 61.23%\n",
      "Batch 59, Loss: 0.650061, Accuracy: 61.55%\n",
      "Batch 60, Loss: 0.884157, Accuracy: 61.64%\n",
      "Batch 61, Loss: 0.911063, Accuracy: 61.71%\n",
      "Batch 62, Loss: 0.785498, Accuracy: 61.87%\n",
      "Batch 63, Loss: 0.882302, Accuracy: 61.90%\n",
      "Batch 64, Loss: 0.953661, Accuracy: 61.89%\n",
      "Batch 65, Loss: 0.780430, Accuracy: 61.92%\n",
      "Batch 66, Loss: 0.832052, Accuracy: 62.00%\n",
      "Batch 67, Loss: 0.893611, Accuracy: 62.03%\n",
      "Batch 68, Loss: 0.678405, Accuracy: 62.18%\n",
      "Batch 69, Loss: 0.822445, Accuracy: 62.36%\n",
      "Batch 70, Loss: 0.824020, Accuracy: 62.43%\n",
      "Batch 71, Loss: 0.711124, Accuracy: 62.61%\n",
      "Batch 72, Loss: 0.806400, Accuracy: 62.74%\n",
      "Batch 73, Loss: 0.792044, Accuracy: 62.84%\n",
      "Batch 74, Loss: 0.829209, Accuracy: 62.86%\n",
      "Batch 75, Loss: 0.646620, Accuracy: 63.06%\n",
      "Batch 76, Loss: 0.951885, Accuracy: 63.10%\n",
      "Batch 77, Loss: 0.851219, Accuracy: 63.15%\n",
      "Batch 78, Loss: 0.685030, Accuracy: 63.26%\n",
      "Batch 79, Loss: 0.801943, Accuracy: 63.41%\n",
      "Batch 80, Loss: 0.818302, Accuracy: 63.55%\n",
      "Batch 81, Loss: 0.784150, Accuracy: 63.62%\n",
      "Batch 82, Loss: 0.862725, Accuracy: 63.57%\n",
      "Batch 83, Loss: 0.573745, Accuracy: 63.76%\n",
      "Batch 84, Loss: 0.813609, Accuracy: 63.75%\n",
      "Batch 85, Loss: 0.696884, Accuracy: 63.90%\n",
      "Batch 86, Loss: 0.549050, Accuracy: 64.06%\n",
      "Batch 87, Loss: 0.704246, Accuracy: 64.13%\n",
      "Batch 88, Loss: 0.817859, Accuracy: 64.13%\n",
      "Batch 89, Loss: 0.498764, Accuracy: 64.33%\n",
      "Batch 90, Loss: 0.850520, Accuracy: 64.29%\n",
      "Batch 91, Loss: 0.648670, Accuracy: 64.37%\n",
      "Batch 92, Loss: 0.884474, Accuracy: 64.40%\n",
      "Batch 93, Loss: 0.738591, Accuracy: 64.47%\n",
      "Batch 94, Loss: 0.748714, Accuracy: 64.53%\n",
      "Batch 95, Loss: 0.908244, Accuracy: 64.49%\n",
      "Batch 96, Loss: 0.726913, Accuracy: 64.53%\n",
      "Batch 97, Loss: 0.600464, Accuracy: 64.66%\n",
      "Batch 98, Loss: 0.850429, Accuracy: 64.65%\n",
      "Batch 99, Loss: 0.794745, Accuracy: 64.68%\n",
      "Batch 100, Loss: 0.818478, Accuracy: 64.69%\n",
      "Batch 101, Loss: 0.843699, Accuracy: 64.73%\n",
      "Batch 102, Loss: 0.637532, Accuracy: 64.86%\n",
      "Batch 103, Loss: 0.723926, Accuracy: 64.96%\n",
      "Batch 104, Loss: 0.618971, Accuracy: 65.08%\n",
      "Batch 105, Loss: 0.718155, Accuracy: 65.10%\n",
      "Batch 106, Loss: 0.612434, Accuracy: 65.21%\n",
      "Batch 107, Loss: 0.542481, Accuracy: 65.36%\n",
      "Batch 108, Loss: 1.002809, Accuracy: 65.32%\n",
      "Batch 109, Loss: 0.626226, Accuracy: 65.38%\n",
      "Batch 110, Loss: 0.618190, Accuracy: 65.45%\n",
      "Batch 111, Loss: 0.582323, Accuracy: 65.51%\n",
      "Batch 112, Loss: 0.600896, Accuracy: 65.61%\n",
      "Batch 113, Loss: 0.934143, Accuracy: 65.60%\n",
      "Batch 114, Loss: 0.531461, Accuracy: 65.73%\n",
      "Batch 115, Loss: 0.639848, Accuracy: 65.79%\n",
      "Batch 116, Loss: 0.581363, Accuracy: 65.88%\n",
      "Batch 117, Loss: 0.703922, Accuracy: 65.95%\n",
      "Batch 118, Loss: 0.705863, Accuracy: 66.01%\n",
      "Batch 119, Loss: 0.685406, Accuracy: 66.06%\n",
      "Batch 120, Loss: 0.527924, Accuracy: 66.20%\n",
      "Batch 121, Loss: 0.786189, Accuracy: 66.26%\n",
      "Batch 122, Loss: 0.724314, Accuracy: 66.33%\n",
      "Batch 123, Loss: 0.579807, Accuracy: 66.43%\n",
      "Batch 124, Loss: 0.417776, Accuracy: 66.57%\n",
      "Batch 125, Loss: 0.582151, Accuracy: 66.67%\n",
      "Batch 126, Loss: 0.834371, Accuracy: 66.72%\n",
      "Batch 127, Loss: 0.970575, Accuracy: 66.71%\n",
      "Batch 128, Loss: 0.617476, Accuracy: 66.75%\n",
      "Batch 129, Loss: 0.795469, Accuracy: 66.78%\n",
      "Batch 130, Loss: 0.508198, Accuracy: 66.90%\n",
      "Batch 131, Loss: 0.660192, Accuracy: 66.96%\n",
      "Batch 132, Loss: 0.756532, Accuracy: 67.01%\n",
      "Batch 133, Loss: 0.510789, Accuracy: 67.13%\n",
      "Batch 134, Loss: 0.846529, Accuracy: 67.13%\n",
      "Batch 135, Loss: 0.691484, Accuracy: 67.16%\n",
      "Batch 136, Loss: 0.605473, Accuracy: 67.29%\n",
      "Batch 137, Loss: 0.498056, Accuracy: 67.42%\n",
      "Batch 138, Loss: 0.513062, Accuracy: 67.50%\n",
      "Batch 139, Loss: 0.540969, Accuracy: 67.60%\n",
      "Batch 140, Loss: 0.398246, Accuracy: 67.75%\n",
      "Batch 141, Loss: 0.590560, Accuracy: 67.82%\n",
      "Batch 142, Loss: 0.616215, Accuracy: 67.89%\n",
      "Batch 143, Loss: 0.775827, Accuracy: 67.94%\n",
      "Batch 144, Loss: 0.414137, Accuracy: 68.07%\n",
      "Batch 145, Loss: 0.634718, Accuracy: 68.10%\n",
      "Batch 146, Loss: 0.609363, Accuracy: 68.17%\n",
      "Batch 147, Loss: 0.720423, Accuracy: 68.19%\n",
      "Batch 148, Loss: 0.616832, Accuracy: 68.24%\n",
      "Batch 149, Loss: 0.589819, Accuracy: 68.32%\n",
      "Batch 150, Loss: 0.698202, Accuracy: 68.38%\n",
      "Batch 151, Loss: 0.692010, Accuracy: 68.43%\n",
      "Batch 152, Loss: 0.625777, Accuracy: 68.44%\n",
      "Batch 153, Loss: 0.722446, Accuracy: 68.48%\n",
      "Batch 154, Loss: 0.714186, Accuracy: 68.50%\n",
      "Batch 155, Loss: 0.515112, Accuracy: 68.56%\n",
      "Batch 156, Loss: 0.632816, Accuracy: 68.59%\n",
      "Batch 157, Loss: 0.501414, Accuracy: 68.67%\n",
      "Batch 158, Loss: 0.597119, Accuracy: 68.72%\n",
      "Batch 159, Loss: 0.583220, Accuracy: 68.75%\n",
      "Batch 160, Loss: 0.627294, Accuracy: 68.81%\n",
      "Batch 161, Loss: 0.779038, Accuracy: 68.80%\n",
      "Batch 162, Loss: 0.581588, Accuracy: 68.85%\n",
      "Batch 163, Loss: 0.553426, Accuracy: 68.93%\n",
      "Batch 164, Loss: 0.725053, Accuracy: 68.95%\n",
      "Batch 165, Loss: 0.639493, Accuracy: 68.99%\n",
      "Batch 166, Loss: 0.755232, Accuracy: 68.96%\n",
      "Batch 167, Loss: 0.497157, Accuracy: 69.04%\n",
      "Batch 168, Loss: 0.494365, Accuracy: 69.08%\n",
      "Batch 169, Loss: 0.643173, Accuracy: 69.12%\n",
      "Batch 170, Loss: 0.625216, Accuracy: 69.15%\n",
      "Batch 171, Loss: 0.542269, Accuracy: 69.22%\n",
      "Batch 172, Loss: 0.635360, Accuracy: 69.29%\n",
      "Batch 173, Loss: 0.719706, Accuracy: 69.29%\n",
      "Batch 174, Loss: 0.773050, Accuracy: 69.30%\n",
      "Batch 175, Loss: 0.369730, Accuracy: 69.40%\n",
      "Batch 176, Loss: 0.608424, Accuracy: 69.46%\n",
      "Batch 177, Loss: 0.600736, Accuracy: 69.50%\n",
      "Batch 178, Loss: 0.617005, Accuracy: 69.52%\n",
      "Batch 179, Loss: 0.480394, Accuracy: 69.62%\n",
      "Batch 180, Loss: 0.466688, Accuracy: 69.68%\n",
      "Batch 181, Loss: 0.817095, Accuracy: 69.70%\n",
      "Batch 182, Loss: 0.792571, Accuracy: 69.71%\n",
      "Batch 183, Loss: 0.545772, Accuracy: 69.76%\n",
      "Batch 184, Loss: 0.515303, Accuracy: 69.81%\n",
      "Batch 185, Loss: 0.324869, Accuracy: 69.91%\n",
      "Batch 186, Loss: 0.415256, Accuracy: 69.99%\n",
      "Batch 187, Loss: 0.597685, Accuracy: 70.05%\n",
      "Batch 188, Loss: 0.611660, Accuracy: 70.08%\n",
      "Batch 189, Loss: 0.574959, Accuracy: 70.10%\n",
      "Batch 190, Loss: 0.591420, Accuracy: 70.12%\n",
      "Batch 191, Loss: 0.487220, Accuracy: 70.18%\n",
      "Batch 192, Loss: 0.745674, Accuracy: 70.18%\n",
      "Batch 193, Loss: 0.525677, Accuracy: 70.22%\n",
      "Batch 194, Loss: 0.477627, Accuracy: 70.29%\n",
      "Batch 195, Loss: 0.622342, Accuracy: 70.30%\n",
      "Batch 196, Loss: 0.685098, Accuracy: 70.33%\n",
      "Batch 197, Loss: 0.606980, Accuracy: 70.33%\n",
      "Batch 198, Loss: 0.478882, Accuracy: 70.38%\n",
      "Batch 199, Loss: 0.583766, Accuracy: 70.42%\n",
      "Batch 200, Loss: 0.553700, Accuracy: 70.45%\n",
      "Batch 201, Loss: 0.608308, Accuracy: 70.45%\n",
      "Batch 202, Loss: 0.525006, Accuracy: 70.50%\n",
      "Batch 203, Loss: 0.634017, Accuracy: 70.55%\n",
      "Batch 204, Loss: 0.549576, Accuracy: 70.60%\n",
      "Batch 205, Loss: 0.428549, Accuracy: 70.68%\n",
      "Batch 206, Loss: 0.714197, Accuracy: 70.67%\n",
      "Batch 207, Loss: 0.427071, Accuracy: 70.71%\n",
      "Batch 208, Loss: 0.487117, Accuracy: 70.76%\n",
      "Batch 209, Loss: 0.352685, Accuracy: 70.83%\n",
      "Batch 210, Loss: 0.736051, Accuracy: 70.82%\n",
      "Batch 211, Loss: 0.529053, Accuracy: 70.88%\n",
      "Batch 212, Loss: 0.450143, Accuracy: 70.92%\n",
      "Batch 213, Loss: 0.591302, Accuracy: 70.92%\n",
      "Training - Epoch 2, Loss: 0.734636, Accuracy: 70.92%\n",
      "Validation Batch 1, Loss: 0.426730, Accuracy: 85.94%\n",
      "Validation Batch 2, Loss: 0.624689, Accuracy: 78.91%\n",
      "Validation Batch 3, Loss: 0.542494, Accuracy: 78.12%\n",
      "Validation Batch 4, Loss: 0.348464, Accuracy: 80.86%\n",
      "Validation Batch 5, Loss: 0.276741, Accuracy: 82.50%\n",
      "Validation Batch 6, Loss: 0.358958, Accuracy: 83.07%\n",
      "Validation Batch 7, Loss: 0.445658, Accuracy: 82.81%\n",
      "Validation Batch 8, Loss: 0.612178, Accuracy: 82.42%\n",
      "Validation Batch 9, Loss: 0.703767, Accuracy: 81.42%\n",
      "Validation Batch 10, Loss: 0.353633, Accuracy: 82.34%\n",
      "Validation Batch 11, Loss: 0.412221, Accuracy: 82.39%\n",
      "Validation Batch 12, Loss: 0.386291, Accuracy: 82.42%\n",
      "Validation Batch 13, Loss: 0.519866, Accuracy: 82.09%\n",
      "Validation Batch 14, Loss: 0.700102, Accuracy: 81.70%\n",
      "Validation Batch 15, Loss: 0.538568, Accuracy: 81.67%\n",
      "Validation Batch 16, Loss: 0.488665, Accuracy: 81.64%\n",
      "Validation Batch 17, Loss: 0.615891, Accuracy: 81.25%\n",
      "Validation Batch 18, Loss: 0.361781, Accuracy: 81.60%\n",
      "Validation Batch 19, Loss: 0.598119, Accuracy: 81.33%\n",
      "Validation Batch 20, Loss: 0.324613, Accuracy: 81.56%\n",
      "Validation Batch 21, Loss: 0.476333, Accuracy: 81.47%\n",
      "Validation Batch 22, Loss: 0.530941, Accuracy: 81.53%\n",
      "Validation Batch 23, Loss: 0.740613, Accuracy: 80.98%\n",
      "Validation Batch 24, Loss: 0.485393, Accuracy: 81.05%\n",
      "Validation Batch 25, Loss: 0.354941, Accuracy: 81.31%\n",
      "Validation Batch 26, Loss: 0.636257, Accuracy: 81.19%\n",
      "Validation Batch 27, Loss: 0.511265, Accuracy: 81.15%\n",
      "Validation - Epoch 2, Loss: 0.495377, Accuracy: 81.15%\n",
      "Patience—0\n",
      "Epoch 3\n",
      "Batch 1, Loss: 0.524758, Accuracy: 78.12%\n",
      "Batch 2, Loss: 0.409906, Accuracy: 82.03%\n",
      "Batch 3, Loss: 0.351319, Accuracy: 83.85%\n",
      "Batch 4, Loss: 0.526654, Accuracy: 83.20%\n",
      "Batch 5, Loss: 0.560095, Accuracy: 81.88%\n",
      "Batch 6, Loss: 0.478247, Accuracy: 82.55%\n",
      "Batch 7, Loss: 0.440453, Accuracy: 83.26%\n",
      "Batch 8, Loss: 0.647664, Accuracy: 82.62%\n",
      "Batch 9, Loss: 0.355829, Accuracy: 83.33%\n",
      "Batch 10, Loss: 0.460364, Accuracy: 83.59%\n",
      "Batch 11, Loss: 0.396944, Accuracy: 83.81%\n",
      "Batch 12, Loss: 0.745809, Accuracy: 83.20%\n",
      "Batch 13, Loss: 0.360329, Accuracy: 83.41%\n",
      "Batch 14, Loss: 0.465909, Accuracy: 83.48%\n",
      "Batch 15, Loss: 0.366116, Accuracy: 83.44%\n",
      "Batch 16, Loss: 0.258008, Accuracy: 83.98%\n",
      "Batch 17, Loss: 0.566768, Accuracy: 83.92%\n",
      "Batch 18, Loss: 0.360022, Accuracy: 84.20%\n",
      "Batch 19, Loss: 0.326976, Accuracy: 84.29%\n",
      "Batch 20, Loss: 0.355693, Accuracy: 84.38%\n",
      "Batch 21, Loss: 0.359456, Accuracy: 84.52%\n",
      "Batch 22, Loss: 0.421199, Accuracy: 84.45%\n",
      "Batch 23, Loss: 0.378908, Accuracy: 84.44%\n",
      "Batch 24, Loss: 0.414623, Accuracy: 84.38%\n",
      "Batch 25, Loss: 0.435473, Accuracy: 84.25%\n",
      "Batch 26, Loss: 0.555295, Accuracy: 83.89%\n",
      "Batch 27, Loss: 0.322914, Accuracy: 84.03%\n",
      "Batch 28, Loss: 0.368448, Accuracy: 84.10%\n",
      "Batch 29, Loss: 0.467983, Accuracy: 84.11%\n",
      "Batch 30, Loss: 0.433133, Accuracy: 84.11%\n",
      "Batch 31, Loss: 0.453708, Accuracy: 84.02%\n",
      "Batch 32, Loss: 0.565779, Accuracy: 83.94%\n",
      "Batch 33, Loss: 0.591496, Accuracy: 83.81%\n",
      "Batch 34, Loss: 0.408060, Accuracy: 83.92%\n",
      "Batch 35, Loss: 0.445553, Accuracy: 83.79%\n",
      "Batch 36, Loss: 0.367150, Accuracy: 83.90%\n",
      "Batch 37, Loss: 0.510818, Accuracy: 83.78%\n",
      "Batch 38, Loss: 0.345495, Accuracy: 83.96%\n",
      "Batch 39, Loss: 0.505271, Accuracy: 83.81%\n",
      "Batch 40, Loss: 0.586880, Accuracy: 83.75%\n",
      "Batch 41, Loss: 0.483452, Accuracy: 83.77%\n",
      "Batch 42, Loss: 0.418270, Accuracy: 83.85%\n",
      "Batch 43, Loss: 0.505456, Accuracy: 83.79%\n",
      "Batch 44, Loss: 0.424885, Accuracy: 83.84%\n",
      "Batch 45, Loss: 0.419292, Accuracy: 83.72%\n",
      "Batch 46, Loss: 0.428316, Accuracy: 83.70%\n",
      "Batch 47, Loss: 0.544852, Accuracy: 83.64%\n",
      "Batch 48, Loss: 0.547748, Accuracy: 83.50%\n",
      "Batch 49, Loss: 0.403906, Accuracy: 83.55%\n",
      "Batch 50, Loss: 0.432610, Accuracy: 83.56%\n",
      "Batch 51, Loss: 0.457774, Accuracy: 83.58%\n",
      "Batch 52, Loss: 0.560336, Accuracy: 83.50%\n",
      "Batch 53, Loss: 0.446674, Accuracy: 83.43%\n",
      "Batch 54, Loss: 0.517784, Accuracy: 83.39%\n",
      "Batch 55, Loss: 0.453558, Accuracy: 83.38%\n",
      "Batch 56, Loss: 0.373066, Accuracy: 83.37%\n",
      "Batch 57, Loss: 0.582762, Accuracy: 83.39%\n",
      "Batch 58, Loss: 0.422398, Accuracy: 83.49%\n",
      "Batch 59, Loss: 0.417753, Accuracy: 83.55%\n",
      "Batch 60, Loss: 0.429645, Accuracy: 83.57%\n",
      "Batch 61, Loss: 0.356768, Accuracy: 83.68%\n",
      "Batch 62, Loss: 0.427454, Accuracy: 83.74%\n",
      "Batch 63, Loss: 0.491638, Accuracy: 83.75%\n",
      "Batch 64, Loss: 0.342015, Accuracy: 83.79%\n",
      "Batch 65, Loss: 0.416924, Accuracy: 83.87%\n",
      "Batch 66, Loss: 0.376599, Accuracy: 83.95%\n",
      "Batch 67, Loss: 0.319796, Accuracy: 84.03%\n",
      "Batch 68, Loss: 0.324429, Accuracy: 84.08%\n",
      "Batch 69, Loss: 0.339599, Accuracy: 84.08%\n",
      "Batch 70, Loss: 0.288227, Accuracy: 84.13%\n",
      "Batch 71, Loss: 0.731714, Accuracy: 84.09%\n",
      "Batch 72, Loss: 0.795504, Accuracy: 83.88%\n",
      "Batch 73, Loss: 0.615909, Accuracy: 83.86%\n",
      "Batch 74, Loss: 0.359814, Accuracy: 83.91%\n",
      "Batch 75, Loss: 0.415835, Accuracy: 83.92%\n",
      "Batch 76, Loss: 0.382295, Accuracy: 83.96%\n",
      "Batch 77, Loss: 0.348236, Accuracy: 83.97%\n",
      "Batch 78, Loss: 0.536204, Accuracy: 83.89%\n",
      "Batch 79, Loss: 0.348055, Accuracy: 83.92%\n",
      "Batch 80, Loss: 0.610322, Accuracy: 83.87%\n",
      "Batch 81, Loss: 0.344431, Accuracy: 83.95%\n",
      "Batch 82, Loss: 0.568115, Accuracy: 83.88%\n",
      "Batch 83, Loss: 0.509338, Accuracy: 83.87%\n",
      "Batch 84, Loss: 0.370515, Accuracy: 83.91%\n",
      "Batch 85, Loss: 0.467426, Accuracy: 83.88%\n",
      "Batch 86, Loss: 0.373882, Accuracy: 83.94%\n",
      "Batch 87, Loss: 0.434844, Accuracy: 83.93%\n",
      "Batch 88, Loss: 0.689435, Accuracy: 83.84%\n",
      "Batch 89, Loss: 0.533184, Accuracy: 83.78%\n",
      "Batch 90, Loss: 0.315250, Accuracy: 83.75%\n",
      "Batch 91, Loss: 0.593821, Accuracy: 83.69%\n",
      "Batch 92, Loss: 0.551993, Accuracy: 83.66%\n",
      "Batch 93, Loss: 0.479689, Accuracy: 83.70%\n",
      "Batch 94, Loss: 0.466490, Accuracy: 83.66%\n",
      "Batch 95, Loss: 0.436335, Accuracy: 83.62%\n",
      "Batch 96, Loss: 0.547707, Accuracy: 83.63%\n",
      "Batch 97, Loss: 0.293589, Accuracy: 83.71%\n",
      "Batch 98, Loss: 0.282223, Accuracy: 83.79%\n",
      "Batch 99, Loss: 0.424377, Accuracy: 83.81%\n",
      "Batch 100, Loss: 0.396380, Accuracy: 83.84%\n",
      "Batch 101, Loss: 0.460251, Accuracy: 83.88%\n",
      "Batch 102, Loss: 0.378600, Accuracy: 83.90%\n",
      "Batch 103, Loss: 0.349074, Accuracy: 83.90%\n",
      "Batch 104, Loss: 0.319791, Accuracy: 83.92%\n",
      "Batch 105, Loss: 0.422075, Accuracy: 83.90%\n",
      "Batch 106, Loss: 0.267120, Accuracy: 83.98%\n",
      "Batch 107, Loss: 0.329951, Accuracy: 84.00%\n",
      "Batch 108, Loss: 0.278688, Accuracy: 84.06%\n",
      "Batch 109, Loss: 0.360441, Accuracy: 84.12%\n",
      "Batch 110, Loss: 0.255553, Accuracy: 84.16%\n",
      "Batch 111, Loss: 0.416195, Accuracy: 84.18%\n",
      "Batch 112, Loss: 0.382277, Accuracy: 84.21%\n",
      "Batch 113, Loss: 0.412125, Accuracy: 84.22%\n",
      "Batch 114, Loss: 0.247627, Accuracy: 84.29%\n",
      "Batch 115, Loss: 0.432683, Accuracy: 84.29%\n",
      "Batch 116, Loss: 0.465056, Accuracy: 84.27%\n",
      "Batch 117, Loss: 0.462409, Accuracy: 84.29%\n",
      "Batch 118, Loss: 0.369750, Accuracy: 84.31%\n",
      "Batch 119, Loss: 0.298803, Accuracy: 84.36%\n",
      "Batch 120, Loss: 0.347583, Accuracy: 84.40%\n",
      "Batch 121, Loss: 0.199750, Accuracy: 84.48%\n",
      "Batch 122, Loss: 0.363002, Accuracy: 84.53%\n",
      "Batch 123, Loss: 0.371251, Accuracy: 84.55%\n",
      "Batch 124, Loss: 0.420490, Accuracy: 84.55%\n",
      "Batch 125, Loss: 0.399105, Accuracy: 84.55%\n",
      "Batch 126, Loss: 0.386826, Accuracy: 84.57%\n",
      "Batch 127, Loss: 0.280090, Accuracy: 84.63%\n",
      "Batch 128, Loss: 0.435545, Accuracy: 84.63%\n",
      "Batch 129, Loss: 0.556035, Accuracy: 84.58%\n",
      "Batch 130, Loss: 0.528153, Accuracy: 84.52%\n",
      "Batch 131, Loss: 0.420755, Accuracy: 84.53%\n",
      "Batch 132, Loss: 0.304119, Accuracy: 84.58%\n",
      "Batch 133, Loss: 0.330838, Accuracy: 84.61%\n",
      "Batch 134, Loss: 0.520907, Accuracy: 84.57%\n",
      "Batch 135, Loss: 0.434286, Accuracy: 84.57%\n",
      "Batch 136, Loss: 0.331592, Accuracy: 84.57%\n",
      "Batch 137, Loss: 0.357829, Accuracy: 84.58%\n",
      "Batch 138, Loss: 0.779263, Accuracy: 84.54%\n",
      "Batch 139, Loss: 0.551951, Accuracy: 84.51%\n",
      "Batch 140, Loss: 0.357439, Accuracy: 84.50%\n",
      "Batch 141, Loss: 0.610063, Accuracy: 84.42%\n",
      "Batch 142, Loss: 0.426126, Accuracy: 84.42%\n",
      "Batch 143, Loss: 0.590018, Accuracy: 84.38%\n",
      "Batch 144, Loss: 0.307069, Accuracy: 84.41%\n",
      "Batch 145, Loss: 0.506249, Accuracy: 84.41%\n",
      "Batch 146, Loss: 0.525479, Accuracy: 84.38%\n",
      "Batch 147, Loss: 0.523805, Accuracy: 84.34%\n",
      "Batch 148, Loss: 0.381545, Accuracy: 84.33%\n",
      "Batch 149, Loss: 0.511390, Accuracy: 84.28%\n",
      "Batch 150, Loss: 0.321677, Accuracy: 84.31%\n",
      "Batch 151, Loss: 0.316334, Accuracy: 84.35%\n",
      "Batch 152, Loss: 0.388847, Accuracy: 84.34%\n",
      "Batch 153, Loss: 0.447423, Accuracy: 84.38%\n",
      "Batch 154, Loss: 0.218670, Accuracy: 84.43%\n",
      "Batch 155, Loss: 0.291023, Accuracy: 84.48%\n",
      "Batch 156, Loss: 0.368127, Accuracy: 84.50%\n",
      "Batch 157, Loss: 0.684705, Accuracy: 84.44%\n",
      "Batch 158, Loss: 0.447216, Accuracy: 84.43%\n",
      "Batch 159, Loss: 0.243282, Accuracy: 84.47%\n",
      "Batch 160, Loss: 0.366374, Accuracy: 84.49%\n",
      "Batch 161, Loss: 0.279451, Accuracy: 84.53%\n",
      "Batch 162, Loss: 0.497841, Accuracy: 84.51%\n",
      "Batch 163, Loss: 0.618318, Accuracy: 84.49%\n",
      "Batch 164, Loss: 0.399475, Accuracy: 84.51%\n",
      "Batch 165, Loss: 0.262382, Accuracy: 84.55%\n",
      "Batch 166, Loss: 0.354007, Accuracy: 84.56%\n",
      "Batch 167, Loss: 0.452687, Accuracy: 84.52%\n",
      "Batch 168, Loss: 0.379269, Accuracy: 84.54%\n",
      "Batch 169, Loss: 0.545355, Accuracy: 84.50%\n",
      "Batch 170, Loss: 0.448700, Accuracy: 84.50%\n",
      "Batch 171, Loss: 0.365352, Accuracy: 84.48%\n",
      "Batch 172, Loss: 0.297794, Accuracy: 84.50%\n",
      "Batch 173, Loss: 0.378887, Accuracy: 84.51%\n",
      "Batch 174, Loss: 0.506429, Accuracy: 84.48%\n",
      "Batch 175, Loss: 0.352310, Accuracy: 84.51%\n",
      "Batch 176, Loss: 0.298009, Accuracy: 84.55%\n",
      "Batch 177, Loss: 0.513573, Accuracy: 84.52%\n",
      "Batch 178, Loss: 0.247573, Accuracy: 84.55%\n",
      "Batch 179, Loss: 0.441272, Accuracy: 84.54%\n",
      "Batch 180, Loss: 0.382536, Accuracy: 84.53%\n",
      "Batch 181, Loss: 0.378310, Accuracy: 84.56%\n",
      "Batch 182, Loss: 0.296006, Accuracy: 84.57%\n",
      "Batch 183, Loss: 0.313522, Accuracy: 84.60%\n",
      "Batch 184, Loss: 0.377481, Accuracy: 84.59%\n",
      "Batch 185, Loss: 0.371393, Accuracy: 84.59%\n",
      "Batch 186, Loss: 0.454875, Accuracy: 84.58%\n",
      "Batch 187, Loss: 0.315943, Accuracy: 84.63%\n",
      "Batch 188, Loss: 0.327041, Accuracy: 84.67%\n",
      "Batch 189, Loss: 0.284235, Accuracy: 84.70%\n",
      "Batch 190, Loss: 0.492736, Accuracy: 84.67%\n",
      "Batch 191, Loss: 0.311129, Accuracy: 84.70%\n",
      "Batch 192, Loss: 0.337670, Accuracy: 84.73%\n",
      "Batch 193, Loss: 0.310711, Accuracy: 84.76%\n",
      "Batch 194, Loss: 0.440370, Accuracy: 84.75%\n",
      "Batch 195, Loss: 0.459488, Accuracy: 84.73%\n",
      "Batch 196, Loss: 0.291623, Accuracy: 84.75%\n",
      "Batch 197, Loss: 0.168806, Accuracy: 84.80%\n",
      "Batch 198, Loss: 0.206213, Accuracy: 84.84%\n",
      "Batch 199, Loss: 0.327090, Accuracy: 84.85%\n",
      "Batch 200, Loss: 0.397574, Accuracy: 84.88%\n",
      "Batch 201, Loss: 0.326102, Accuracy: 84.89%\n",
      "Batch 202, Loss: 0.262413, Accuracy: 84.92%\n",
      "Batch 203, Loss: 0.248237, Accuracy: 84.95%\n",
      "Batch 204, Loss: 0.285971, Accuracy: 84.97%\n",
      "Batch 205, Loss: 0.448757, Accuracy: 84.96%\n",
      "Batch 206, Loss: 0.105265, Accuracy: 85.03%\n",
      "Batch 207, Loss: 0.169415, Accuracy: 85.06%\n",
      "Batch 208, Loss: 0.318033, Accuracy: 85.09%\n",
      "Batch 209, Loss: 0.345000, Accuracy: 85.10%\n",
      "Batch 210, Loss: 0.440069, Accuracy: 85.08%\n",
      "Batch 211, Loss: 0.269414, Accuracy: 85.11%\n",
      "Batch 212, Loss: 0.277153, Accuracy: 85.13%\n",
      "Batch 213, Loss: 0.342465, Accuracy: 85.14%\n",
      "Training - Epoch 3, Loss: 0.412464, Accuracy: 85.14%\n",
      "Validation Batch 1, Loss: 0.284789, Accuracy: 90.62%\n",
      "Validation Batch 2, Loss: 0.527934, Accuracy: 86.72%\n",
      "Validation Batch 3, Loss: 0.313261, Accuracy: 87.50%\n",
      "Validation Batch 4, Loss: 0.197995, Accuracy: 89.45%\n",
      "Validation Batch 5, Loss: 0.223267, Accuracy: 90.00%\n",
      "Validation Batch 6, Loss: 0.199829, Accuracy: 90.10%\n",
      "Validation Batch 7, Loss: 0.301592, Accuracy: 89.73%\n",
      "Validation Batch 8, Loss: 0.433676, Accuracy: 89.26%\n",
      "Validation Batch 9, Loss: 0.425925, Accuracy: 88.89%\n",
      "Validation Batch 10, Loss: 0.403092, Accuracy: 88.59%\n",
      "Validation Batch 11, Loss: 0.365695, Accuracy: 88.49%\n",
      "Validation Batch 12, Loss: 0.474802, Accuracy: 88.15%\n",
      "Validation Batch 13, Loss: 0.344504, Accuracy: 87.98%\n",
      "Validation Batch 14, Loss: 0.423159, Accuracy: 87.83%\n",
      "Validation Batch 15, Loss: 0.341721, Accuracy: 87.81%\n",
      "Validation Batch 16, Loss: 0.218848, Accuracy: 88.18%\n",
      "Validation Batch 17, Loss: 0.516561, Accuracy: 87.87%\n",
      "Validation Batch 18, Loss: 0.251494, Accuracy: 87.93%\n",
      "Validation Batch 19, Loss: 0.434949, Accuracy: 87.75%\n",
      "Validation Batch 20, Loss: 0.130302, Accuracy: 88.05%\n",
      "Validation Batch 21, Loss: 0.323230, Accuracy: 87.95%\n",
      "Validation Batch 22, Loss: 0.392017, Accuracy: 87.64%\n",
      "Validation Batch 23, Loss: 0.514437, Accuracy: 87.09%\n",
      "Validation Batch 24, Loss: 0.405888, Accuracy: 87.11%\n",
      "Validation Batch 25, Loss: 0.250009, Accuracy: 87.25%\n",
      "Validation Batch 26, Loss: 0.648291, Accuracy: 86.90%\n",
      "Validation Batch 27, Loss: 0.475794, Accuracy: 86.73%\n",
      "Validation - Epoch 3, Loss: 0.363817, Accuracy: 86.73%\n",
      "Patience—0\n",
      "Epoch 4\n",
      "Batch 1, Loss: 0.238352, Accuracy: 92.19%\n",
      "Batch 2, Loss: 0.275900, Accuracy: 90.62%\n",
      "Batch 3, Loss: 0.412884, Accuracy: 88.54%\n",
      "Batch 4, Loss: 0.219304, Accuracy: 89.84%\n",
      "Batch 5, Loss: 0.322019, Accuracy: 89.69%\n",
      "Batch 6, Loss: 0.166370, Accuracy: 90.36%\n",
      "Batch 7, Loss: 0.305697, Accuracy: 89.29%\n",
      "Batch 8, Loss: 0.359169, Accuracy: 88.67%\n",
      "Batch 9, Loss: 0.312382, Accuracy: 88.89%\n",
      "Batch 10, Loss: 0.434921, Accuracy: 87.97%\n",
      "Batch 11, Loss: 0.193048, Accuracy: 88.35%\n",
      "Batch 12, Loss: 0.235540, Accuracy: 88.80%\n",
      "Batch 13, Loss: 0.140849, Accuracy: 89.30%\n",
      "Batch 14, Loss: 0.308992, Accuracy: 89.17%\n",
      "Batch 15, Loss: 0.243113, Accuracy: 89.27%\n",
      "Batch 16, Loss: 0.256395, Accuracy: 89.36%\n",
      "Batch 17, Loss: 0.243651, Accuracy: 89.25%\n",
      "Batch 18, Loss: 0.218925, Accuracy: 89.50%\n",
      "Batch 19, Loss: 0.200931, Accuracy: 89.64%\n",
      "Batch 20, Loss: 0.142532, Accuracy: 90.00%\n",
      "Batch 21, Loss: 0.188602, Accuracy: 90.10%\n",
      "Batch 22, Loss: 0.250675, Accuracy: 90.13%\n",
      "Batch 23, Loss: 0.183984, Accuracy: 90.35%\n",
      "Batch 24, Loss: 0.221130, Accuracy: 90.49%\n",
      "Batch 25, Loss: 0.369575, Accuracy: 90.44%\n",
      "Batch 26, Loss: 0.199419, Accuracy: 90.50%\n",
      "Batch 27, Loss: 0.238958, Accuracy: 90.62%\n",
      "Batch 28, Loss: 0.369061, Accuracy: 90.40%\n",
      "Batch 29, Loss: 0.274888, Accuracy: 90.36%\n",
      "Batch 30, Loss: 0.239102, Accuracy: 90.42%\n",
      "Batch 31, Loss: 0.183610, Accuracy: 90.42%\n",
      "Batch 32, Loss: 0.192689, Accuracy: 90.48%\n",
      "Batch 33, Loss: 0.312169, Accuracy: 90.39%\n",
      "Batch 34, Loss: 0.382948, Accuracy: 90.30%\n",
      "Batch 35, Loss: 0.305544, Accuracy: 90.27%\n",
      "Batch 36, Loss: 0.268584, Accuracy: 90.23%\n",
      "Batch 37, Loss: 0.317924, Accuracy: 90.12%\n",
      "Batch 38, Loss: 0.433023, Accuracy: 90.09%\n",
      "Batch 39, Loss: 0.284036, Accuracy: 90.06%\n",
      "Batch 40, Loss: 0.461755, Accuracy: 89.96%\n",
      "Batch 41, Loss: 0.213807, Accuracy: 89.98%\n",
      "Batch 42, Loss: 0.256820, Accuracy: 89.96%\n",
      "Batch 43, Loss: 0.278195, Accuracy: 89.86%\n",
      "Batch 44, Loss: 0.195885, Accuracy: 89.91%\n",
      "Batch 45, Loss: 0.359577, Accuracy: 89.86%\n",
      "Batch 46, Loss: 0.361991, Accuracy: 89.91%\n",
      "Batch 47, Loss: 0.235229, Accuracy: 90.03%\n",
      "Batch 48, Loss: 0.373933, Accuracy: 89.91%\n",
      "Batch 49, Loss: 0.272028, Accuracy: 89.89%\n",
      "Batch 50, Loss: 0.321471, Accuracy: 89.84%\n",
      "Batch 51, Loss: 0.345487, Accuracy: 89.80%\n",
      "Batch 52, Loss: 0.181415, Accuracy: 89.90%\n",
      "Batch 53, Loss: 0.144219, Accuracy: 89.98%\n",
      "Batch 54, Loss: 0.171349, Accuracy: 90.08%\n",
      "Batch 55, Loss: 0.265577, Accuracy: 90.06%\n",
      "Batch 56, Loss: 0.194539, Accuracy: 90.12%\n",
      "Batch 57, Loss: 0.156079, Accuracy: 90.21%\n",
      "Batch 58, Loss: 0.150646, Accuracy: 90.27%\n",
      "Batch 59, Loss: 0.232214, Accuracy: 90.28%\n",
      "Batch 60, Loss: 0.321170, Accuracy: 90.23%\n",
      "Batch 61, Loss: 0.557444, Accuracy: 90.14%\n",
      "Batch 62, Loss: 0.300475, Accuracy: 90.10%\n",
      "Batch 63, Loss: 0.177445, Accuracy: 90.15%\n",
      "Batch 64, Loss: 0.190379, Accuracy: 90.21%\n",
      "Batch 65, Loss: 0.223539, Accuracy: 90.24%\n",
      "Batch 66, Loss: 0.185321, Accuracy: 90.29%\n",
      "Batch 67, Loss: 0.193600, Accuracy: 90.35%\n",
      "Batch 68, Loss: 0.176725, Accuracy: 90.42%\n",
      "Batch 69, Loss: 0.175006, Accuracy: 90.49%\n",
      "Batch 70, Loss: 0.375735, Accuracy: 90.49%\n",
      "Batch 71, Loss: 0.262311, Accuracy: 90.49%\n",
      "Batch 72, Loss: 0.222379, Accuracy: 90.49%\n",
      "Batch 73, Loss: 0.191565, Accuracy: 90.56%\n",
      "Batch 74, Loss: 0.293975, Accuracy: 90.54%\n",
      "Batch 75, Loss: 0.227687, Accuracy: 90.58%\n",
      "Batch 76, Loss: 0.255903, Accuracy: 90.60%\n",
      "Batch 77, Loss: 0.325168, Accuracy: 90.58%\n",
      "Batch 78, Loss: 0.209730, Accuracy: 90.58%\n",
      "Batch 79, Loss: 0.199576, Accuracy: 90.64%\n",
      "Batch 80, Loss: 0.368335, Accuracy: 90.62%\n",
      "Batch 81, Loss: 0.202987, Accuracy: 90.68%\n",
      "Batch 82, Loss: 0.131048, Accuracy: 90.74%\n",
      "Batch 83, Loss: 0.089265, Accuracy: 90.83%\n",
      "Batch 84, Loss: 0.181637, Accuracy: 90.89%\n",
      "Batch 85, Loss: 0.188800, Accuracy: 90.92%\n",
      "Batch 86, Loss: 0.248439, Accuracy: 90.90%\n",
      "Batch 87, Loss: 0.215467, Accuracy: 90.86%\n",
      "Batch 88, Loss: 0.227332, Accuracy: 90.87%\n",
      "Batch 89, Loss: 0.268462, Accuracy: 90.85%\n",
      "Batch 90, Loss: 0.327805, Accuracy: 90.82%\n",
      "Batch 91, Loss: 0.301343, Accuracy: 90.81%\n",
      "Batch 92, Loss: 0.335928, Accuracy: 90.79%\n",
      "Batch 93, Loss: 0.169244, Accuracy: 90.84%\n",
      "Batch 94, Loss: 0.265743, Accuracy: 90.84%\n",
      "Batch 95, Loss: 0.268446, Accuracy: 90.86%\n",
      "Batch 96, Loss: 0.232245, Accuracy: 90.85%\n",
      "Batch 97, Loss: 0.334758, Accuracy: 90.82%\n",
      "Batch 98, Loss: 0.430668, Accuracy: 90.77%\n",
      "Batch 99, Loss: 0.365022, Accuracy: 90.72%\n",
      "Batch 100, Loss: 0.194958, Accuracy: 90.77%\n",
      "Batch 101, Loss: 0.202058, Accuracy: 90.83%\n",
      "Batch 102, Loss: 0.298215, Accuracy: 90.81%\n",
      "Batch 103, Loss: 0.210665, Accuracy: 90.84%\n",
      "Batch 104, Loss: 0.207149, Accuracy: 90.87%\n",
      "Batch 105, Loss: 0.096988, Accuracy: 90.92%\n",
      "Batch 106, Loss: 0.262398, Accuracy: 90.92%\n",
      "Batch 107, Loss: 0.296829, Accuracy: 90.87%\n",
      "Batch 108, Loss: 0.332695, Accuracy: 90.84%\n",
      "Batch 109, Loss: 0.405887, Accuracy: 90.80%\n",
      "Batch 110, Loss: 0.187994, Accuracy: 90.82%\n",
      "Batch 111, Loss: 0.183263, Accuracy: 90.84%\n",
      "Batch 112, Loss: 0.240404, Accuracy: 90.83%\n",
      "Batch 113, Loss: 0.364600, Accuracy: 90.79%\n",
      "Batch 114, Loss: 0.486112, Accuracy: 90.73%\n",
      "Batch 115, Loss: 0.276493, Accuracy: 90.69%\n",
      "Batch 116, Loss: 0.179649, Accuracy: 90.73%\n",
      "Batch 117, Loss: 0.286613, Accuracy: 90.73%\n",
      "Batch 118, Loss: 0.276989, Accuracy: 90.70%\n",
      "Batch 119, Loss: 0.187158, Accuracy: 90.73%\n",
      "Batch 120, Loss: 0.187777, Accuracy: 90.79%\n",
      "Batch 121, Loss: 0.240077, Accuracy: 90.79%\n",
      "Batch 122, Loss: 0.274916, Accuracy: 90.75%\n",
      "Batch 123, Loss: 0.193122, Accuracy: 90.78%\n",
      "Batch 124, Loss: 0.123567, Accuracy: 90.81%\n",
      "Batch 125, Loss: 0.173234, Accuracy: 90.84%\n",
      "Batch 126, Loss: 0.212043, Accuracy: 90.86%\n",
      "Batch 127, Loss: 0.261717, Accuracy: 90.87%\n",
      "Batch 128, Loss: 0.187363, Accuracy: 90.91%\n",
      "Batch 129, Loss: 0.448332, Accuracy: 90.86%\n",
      "Batch 130, Loss: 0.308458, Accuracy: 90.84%\n",
      "Batch 131, Loss: 0.067071, Accuracy: 90.91%\n",
      "Batch 132, Loss: 0.213188, Accuracy: 90.92%\n",
      "Batch 133, Loss: 0.241050, Accuracy: 90.92%\n",
      "Batch 134, Loss: 0.193103, Accuracy: 90.93%\n",
      "Batch 135, Loss: 0.167772, Accuracy: 90.94%\n",
      "Batch 136, Loss: 0.202326, Accuracy: 90.96%\n",
      "Batch 137, Loss: 0.066959, Accuracy: 91.01%\n",
      "Batch 138, Loss: 0.146722, Accuracy: 91.04%\n",
      "Batch 139, Loss: 0.210062, Accuracy: 91.05%\n",
      "Batch 140, Loss: 0.116468, Accuracy: 91.08%\n",
      "Batch 141, Loss: 0.233971, Accuracy: 91.07%\n",
      "Batch 142, Loss: 0.140887, Accuracy: 91.11%\n",
      "Batch 143, Loss: 0.251512, Accuracy: 91.09%\n",
      "Batch 144, Loss: 0.244504, Accuracy: 91.07%\n",
      "Batch 145, Loss: 0.053524, Accuracy: 91.13%\n",
      "Batch 146, Loss: 0.117834, Accuracy: 91.16%\n",
      "Batch 147, Loss: 0.296321, Accuracy: 91.16%\n",
      "Batch 148, Loss: 0.156600, Accuracy: 91.17%\n",
      "Batch 149, Loss: 0.245933, Accuracy: 91.18%\n",
      "Batch 150, Loss: 0.224895, Accuracy: 91.19%\n",
      "Batch 151, Loss: 0.185204, Accuracy: 91.21%\n",
      "Batch 152, Loss: 0.263493, Accuracy: 91.22%\n",
      "Batch 153, Loss: 0.186210, Accuracy: 91.23%\n",
      "Batch 154, Loss: 0.453328, Accuracy: 91.16%\n",
      "Batch 155, Loss: 0.095638, Accuracy: 91.19%\n",
      "Batch 156, Loss: 0.306115, Accuracy: 91.17%\n",
      "Batch 157, Loss: 0.206319, Accuracy: 91.19%\n",
      "Batch 158, Loss: 0.192737, Accuracy: 91.20%\n",
      "Batch 159, Loss: 0.113975, Accuracy: 91.23%\n",
      "Batch 160, Loss: 0.219573, Accuracy: 91.25%\n",
      "Batch 161, Loss: 0.287028, Accuracy: 91.26%\n",
      "Batch 162, Loss: 0.181917, Accuracy: 91.29%\n",
      "Batch 163, Loss: 0.221395, Accuracy: 91.31%\n",
      "Batch 164, Loss: 0.258363, Accuracy: 91.32%\n",
      "Batch 165, Loss: 0.101896, Accuracy: 91.34%\n",
      "Batch 166, Loss: 0.179840, Accuracy: 91.36%\n",
      "Batch 167, Loss: 0.159929, Accuracy: 91.36%\n",
      "Batch 168, Loss: 0.093361, Accuracy: 91.40%\n",
      "Batch 169, Loss: 0.190159, Accuracy: 91.40%\n",
      "Batch 170, Loss: 0.342707, Accuracy: 91.41%\n",
      "Batch 171, Loss: 0.282617, Accuracy: 91.41%\n",
      "Batch 172, Loss: 0.174846, Accuracy: 91.43%\n",
      "Batch 173, Loss: 0.230727, Accuracy: 91.46%\n",
      "Batch 174, Loss: 0.117929, Accuracy: 91.48%\n",
      "Batch 175, Loss: 0.159913, Accuracy: 91.51%\n",
      "Batch 176, Loss: 0.235064, Accuracy: 91.51%\n",
      "Batch 177, Loss: 0.075080, Accuracy: 91.55%\n",
      "Batch 178, Loss: 0.060151, Accuracy: 91.59%\n",
      "Batch 179, Loss: 0.201634, Accuracy: 91.59%\n",
      "Batch 180, Loss: 0.379737, Accuracy: 91.56%\n",
      "Batch 181, Loss: 0.212619, Accuracy: 91.56%\n",
      "Batch 182, Loss: 0.265833, Accuracy: 91.54%\n",
      "Batch 183, Loss: 0.132539, Accuracy: 91.57%\n",
      "Batch 184, Loss: 0.355975, Accuracy: 91.55%\n",
      "Batch 185, Loss: 0.250420, Accuracy: 91.55%\n",
      "Batch 186, Loss: 0.151345, Accuracy: 91.58%\n",
      "Batch 187, Loss: 0.149390, Accuracy: 91.60%\n",
      "Batch 188, Loss: 0.254537, Accuracy: 91.60%\n",
      "Batch 189, Loss: 0.316533, Accuracy: 91.58%\n",
      "Batch 190, Loss: 0.180219, Accuracy: 91.59%\n",
      "Batch 191, Loss: 0.184680, Accuracy: 91.60%\n",
      "Batch 192, Loss: 0.240381, Accuracy: 91.59%\n",
      "Batch 193, Loss: 0.242508, Accuracy: 91.59%\n",
      "Batch 194, Loss: 0.111395, Accuracy: 91.61%\n",
      "Batch 195, Loss: 0.144784, Accuracy: 91.62%\n",
      "Batch 196, Loss: 0.240477, Accuracy: 91.62%\n",
      "Batch 197, Loss: 0.110617, Accuracy: 91.66%\n",
      "Batch 198, Loss: 0.212820, Accuracy: 91.67%\n",
      "Batch 199, Loss: 0.086270, Accuracy: 91.69%\n",
      "Batch 200, Loss: 0.115973, Accuracy: 91.71%\n",
      "Batch 201, Loss: 0.218458, Accuracy: 91.72%\n",
      "Batch 202, Loss: 0.069137, Accuracy: 91.75%\n",
      "Batch 203, Loss: 0.053471, Accuracy: 91.79%\n",
      "Batch 204, Loss: 0.100420, Accuracy: 91.80%\n",
      "Batch 205, Loss: 0.216657, Accuracy: 91.81%\n",
      "Batch 206, Loss: 0.308316, Accuracy: 91.79%\n",
      "Batch 207, Loss: 0.152238, Accuracy: 91.79%\n",
      "Batch 208, Loss: 0.038096, Accuracy: 91.83%\n",
      "Batch 209, Loss: 0.113611, Accuracy: 91.86%\n",
      "Batch 210, Loss: 0.086757, Accuracy: 91.88%\n",
      "Batch 211, Loss: 0.288268, Accuracy: 91.87%\n",
      "Batch 212, Loss: 0.158184, Accuracy: 91.88%\n",
      "Batch 213, Loss: 0.224584, Accuracy: 91.88%\n",
      "Training - Epoch 4, Loss: 0.231737, Accuracy: 91.88%\n",
      "Validation Batch 1, Loss: 0.110777, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.289575, Accuracy: 94.53%\n",
      "Validation Batch 3, Loss: 0.196179, Accuracy: 93.75%\n",
      "Validation Batch 4, Loss: 0.219690, Accuracy: 93.36%\n",
      "Validation Batch 5, Loss: 0.121215, Accuracy: 93.75%\n",
      "Validation Batch 6, Loss: 0.025697, Accuracy: 94.79%\n",
      "Validation Batch 7, Loss: 0.141225, Accuracy: 94.87%\n",
      "Validation Batch 8, Loss: 0.183176, Accuracy: 94.73%\n",
      "Validation Batch 9, Loss: 0.198520, Accuracy: 94.62%\n",
      "Validation Batch 10, Loss: 0.121149, Accuracy: 94.69%\n",
      "Validation Batch 11, Loss: 0.158152, Accuracy: 94.60%\n",
      "Validation Batch 12, Loss: 0.205516, Accuracy: 94.66%\n",
      "Validation Batch 13, Loss: 0.228886, Accuracy: 94.59%\n",
      "Validation Batch 14, Loss: 0.251718, Accuracy: 94.64%\n",
      "Validation Batch 15, Loss: 0.144492, Accuracy: 94.69%\n",
      "Validation Batch 16, Loss: 0.131560, Accuracy: 94.63%\n",
      "Validation Batch 17, Loss: 0.119065, Accuracy: 94.76%\n",
      "Validation Batch 18, Loss: 0.098260, Accuracy: 94.97%\n",
      "Validation Batch 19, Loss: 0.329581, Accuracy: 94.90%\n",
      "Validation Batch 20, Loss: 0.106462, Accuracy: 94.92%\n",
      "Validation Batch 21, Loss: 0.247114, Accuracy: 94.79%\n",
      "Validation Batch 22, Loss: 0.136667, Accuracy: 94.67%\n",
      "Validation Batch 23, Loss: 0.173695, Accuracy: 94.70%\n",
      "Validation Batch 24, Loss: 0.162382, Accuracy: 94.53%\n",
      "Validation Batch 25, Loss: 0.111567, Accuracy: 94.62%\n",
      "Validation Batch 26, Loss: 0.377488, Accuracy: 94.29%\n",
      "Validation Batch 27, Loss: 0.204248, Accuracy: 94.25%\n",
      "Validation - Epoch 4, Loss: 0.177558, Accuracy: 94.25%\n",
      "Patience—0\n",
      "Epoch 5\n",
      "Batch 1, Loss: 0.110559, Accuracy: 95.31%\n",
      "Batch 2, Loss: 0.103730, Accuracy: 96.09%\n",
      "Batch 3, Loss: 0.109888, Accuracy: 96.35%\n",
      "Batch 4, Loss: 0.063456, Accuracy: 96.88%\n",
      "Batch 5, Loss: 0.156984, Accuracy: 96.88%\n",
      "Batch 6, Loss: 0.061232, Accuracy: 97.14%\n",
      "Batch 7, Loss: 0.030582, Accuracy: 97.54%\n",
      "Batch 8, Loss: 0.239401, Accuracy: 96.88%\n",
      "Batch 9, Loss: 0.293764, Accuracy: 96.35%\n",
      "Batch 10, Loss: 0.084738, Accuracy: 96.56%\n",
      "Batch 11, Loss: 0.078776, Accuracy: 96.73%\n",
      "Batch 12, Loss: 0.175176, Accuracy: 96.48%\n",
      "Batch 13, Loss: 0.056659, Accuracy: 96.75%\n",
      "Batch 14, Loss: 0.117381, Accuracy: 96.76%\n",
      "Batch 15, Loss: 0.223853, Accuracy: 96.25%\n",
      "Batch 16, Loss: 0.125171, Accuracy: 96.09%\n",
      "Batch 17, Loss: 0.056789, Accuracy: 96.23%\n",
      "Batch 18, Loss: 0.100792, Accuracy: 96.27%\n",
      "Batch 19, Loss: 0.055062, Accuracy: 96.38%\n",
      "Batch 20, Loss: 0.151216, Accuracy: 96.41%\n",
      "Batch 21, Loss: 0.070731, Accuracy: 96.50%\n",
      "Batch 22, Loss: 0.145457, Accuracy: 96.45%\n",
      "Batch 23, Loss: 0.172462, Accuracy: 96.33%\n",
      "Batch 24, Loss: 0.276661, Accuracy: 96.03%\n",
      "Batch 25, Loss: 0.036353, Accuracy: 96.19%\n",
      "Batch 26, Loss: 0.223883, Accuracy: 96.03%\n",
      "Batch 27, Loss: 0.170632, Accuracy: 95.95%\n",
      "Batch 28, Loss: 0.144981, Accuracy: 95.93%\n",
      "Batch 29, Loss: 0.015855, Accuracy: 96.07%\n",
      "Batch 30, Loss: 0.173378, Accuracy: 96.04%\n",
      "Batch 31, Loss: 0.025463, Accuracy: 96.17%\n",
      "Batch 32, Loss: 0.072386, Accuracy: 96.24%\n",
      "Batch 33, Loss: 0.312799, Accuracy: 96.16%\n",
      "Batch 34, Loss: 0.237127, Accuracy: 96.05%\n",
      "Batch 35, Loss: 0.335117, Accuracy: 95.85%\n",
      "Batch 36, Loss: 0.054729, Accuracy: 95.88%\n",
      "Batch 37, Loss: 0.171569, Accuracy: 95.73%\n",
      "Batch 38, Loss: 0.208944, Accuracy: 95.68%\n",
      "Batch 39, Loss: 0.106280, Accuracy: 95.71%\n",
      "Batch 40, Loss: 0.121509, Accuracy: 95.74%\n",
      "Batch 41, Loss: 0.137515, Accuracy: 95.73%\n",
      "Batch 42, Loss: 0.151321, Accuracy: 95.72%\n",
      "Batch 43, Loss: 0.150712, Accuracy: 95.71%\n",
      "Batch 44, Loss: 0.226445, Accuracy: 95.53%\n",
      "Batch 45, Loss: 0.151185, Accuracy: 95.56%\n",
      "Batch 46, Loss: 0.229487, Accuracy: 95.48%\n",
      "Batch 47, Loss: 0.130265, Accuracy: 95.48%\n",
      "Batch 48, Loss: 0.087435, Accuracy: 95.54%\n",
      "Batch 49, Loss: 0.146905, Accuracy: 95.50%\n",
      "Batch 50, Loss: 0.103953, Accuracy: 95.53%\n",
      "Batch 51, Loss: 0.032451, Accuracy: 95.62%\n",
      "Batch 52, Loss: 0.082276, Accuracy: 95.67%\n",
      "Batch 53, Loss: 0.056900, Accuracy: 95.73%\n",
      "Batch 54, Loss: 0.207807, Accuracy: 95.63%\n",
      "Batch 55, Loss: 0.086861, Accuracy: 95.60%\n",
      "Batch 56, Loss: 0.073575, Accuracy: 95.65%\n",
      "Batch 57, Loss: 0.199749, Accuracy: 95.61%\n",
      "Batch 58, Loss: 0.129101, Accuracy: 95.64%\n",
      "Batch 59, Loss: 0.075048, Accuracy: 95.66%\n",
      "Batch 60, Loss: 0.163847, Accuracy: 95.60%\n",
      "Batch 61, Loss: 0.158897, Accuracy: 95.57%\n",
      "Batch 62, Loss: 0.124107, Accuracy: 95.59%\n",
      "Batch 63, Loss: 0.092644, Accuracy: 95.63%\n",
      "Batch 64, Loss: 0.214927, Accuracy: 95.58%\n",
      "Batch 65, Loss: 0.314553, Accuracy: 95.53%\n",
      "Batch 66, Loss: 0.202807, Accuracy: 95.45%\n",
      "Batch 67, Loss: 0.135624, Accuracy: 95.48%\n",
      "Batch 68, Loss: 0.246170, Accuracy: 95.38%\n",
      "Batch 69, Loss: 0.258246, Accuracy: 95.27%\n",
      "Batch 70, Loss: 0.264185, Accuracy: 95.16%\n",
      "Batch 71, Loss: 0.178174, Accuracy: 95.11%\n",
      "Batch 72, Loss: 0.137560, Accuracy: 95.10%\n",
      "Batch 73, Loss: 0.126785, Accuracy: 95.10%\n",
      "Batch 74, Loss: 0.105412, Accuracy: 95.10%\n",
      "Batch 75, Loss: 0.230027, Accuracy: 95.06%\n",
      "Batch 76, Loss: 0.141988, Accuracy: 95.07%\n",
      "Batch 77, Loss: 0.094428, Accuracy: 95.09%\n",
      "Batch 78, Loss: 0.258068, Accuracy: 95.01%\n",
      "Batch 79, Loss: 0.142121, Accuracy: 95.02%\n",
      "Batch 80, Loss: 0.218325, Accuracy: 94.98%\n",
      "Batch 81, Loss: 0.104457, Accuracy: 95.02%\n",
      "Batch 82, Loss: 0.061909, Accuracy: 95.06%\n",
      "Batch 83, Loss: 0.141637, Accuracy: 95.07%\n",
      "Batch 84, Loss: 0.246670, Accuracy: 95.09%\n",
      "Batch 85, Loss: 0.176741, Accuracy: 95.07%\n",
      "Batch 86, Loss: 0.058610, Accuracy: 95.11%\n",
      "Batch 87, Loss: 0.142676, Accuracy: 95.15%\n",
      "Batch 88, Loss: 0.122940, Accuracy: 95.15%\n",
      "Batch 89, Loss: 0.030511, Accuracy: 95.21%\n",
      "Batch 90, Loss: 0.054205, Accuracy: 95.24%\n",
      "Batch 91, Loss: 0.455654, Accuracy: 95.14%\n",
      "Batch 92, Loss: 0.063917, Accuracy: 95.16%\n",
      "Batch 93, Loss: 0.130234, Accuracy: 95.14%\n",
      "Batch 94, Loss: 0.230896, Accuracy: 95.10%\n",
      "Batch 95, Loss: 0.113056, Accuracy: 95.10%\n",
      "Batch 96, Loss: 0.126605, Accuracy: 95.08%\n",
      "Batch 97, Loss: 0.251956, Accuracy: 95.07%\n",
      "Batch 98, Loss: 0.358232, Accuracy: 95.01%\n",
      "Batch 99, Loss: 0.113475, Accuracy: 95.01%\n",
      "Batch 100, Loss: 0.081951, Accuracy: 95.05%\n",
      "Batch 101, Loss: 0.203262, Accuracy: 95.03%\n",
      "Batch 102, Loss: 0.239820, Accuracy: 94.99%\n",
      "Batch 103, Loss: 0.183492, Accuracy: 94.99%\n",
      "Batch 104, Loss: 0.242642, Accuracy: 94.98%\n",
      "Batch 105, Loss: 0.135455, Accuracy: 95.00%\n",
      "Batch 106, Loss: 0.052554, Accuracy: 95.05%\n",
      "Batch 107, Loss: 0.233336, Accuracy: 95.02%\n",
      "Batch 108, Loss: 0.171805, Accuracy: 95.02%\n",
      "Batch 109, Loss: 0.184147, Accuracy: 95.00%\n",
      "Batch 110, Loss: 0.372790, Accuracy: 94.93%\n",
      "Batch 111, Loss: 0.259976, Accuracy: 94.88%\n",
      "Batch 112, Loss: 0.141636, Accuracy: 94.88%\n",
      "Batch 113, Loss: 0.235218, Accuracy: 94.87%\n",
      "Batch 114, Loss: 0.101075, Accuracy: 94.89%\n",
      "Batch 115, Loss: 0.170935, Accuracy: 94.90%\n",
      "Batch 116, Loss: 0.065098, Accuracy: 94.94%\n",
      "Batch 117, Loss: 0.077703, Accuracy: 94.97%\n",
      "Batch 118, Loss: 0.145781, Accuracy: 94.93%\n",
      "Batch 119, Loss: 0.183696, Accuracy: 94.91%\n",
      "Batch 120, Loss: 0.165793, Accuracy: 94.91%\n",
      "Batch 121, Loss: 0.177950, Accuracy: 94.90%\n",
      "Batch 122, Loss: 0.070567, Accuracy: 94.93%\n",
      "Batch 123, Loss: 0.092433, Accuracy: 94.93%\n",
      "Batch 124, Loss: 0.130152, Accuracy: 94.93%\n",
      "Batch 125, Loss: 0.191745, Accuracy: 94.92%\n",
      "Batch 126, Loss: 0.065161, Accuracy: 94.94%\n",
      "Batch 127, Loss: 0.037395, Accuracy: 94.97%\n",
      "Batch 128, Loss: 0.101033, Accuracy: 94.98%\n",
      "Batch 129, Loss: 0.097943, Accuracy: 95.00%\n",
      "Batch 130, Loss: 0.193133, Accuracy: 94.99%\n",
      "Batch 131, Loss: 0.129466, Accuracy: 94.99%\n",
      "Batch 132, Loss: 0.139162, Accuracy: 95.00%\n",
      "Batch 133, Loss: 0.154260, Accuracy: 94.98%\n",
      "Batch 134, Loss: 0.025314, Accuracy: 95.02%\n",
      "Batch 135, Loss: 0.166921, Accuracy: 95.01%\n",
      "Batch 136, Loss: 0.056746, Accuracy: 95.04%\n",
      "Batch 137, Loss: 0.124055, Accuracy: 95.03%\n",
      "Batch 138, Loss: 0.077780, Accuracy: 95.05%\n",
      "Batch 139, Loss: 0.238572, Accuracy: 95.02%\n",
      "Batch 140, Loss: 0.055861, Accuracy: 95.04%\n",
      "Batch 141, Loss: 0.105282, Accuracy: 95.07%\n",
      "Batch 142, Loss: 0.095905, Accuracy: 95.07%\n",
      "Batch 143, Loss: 0.145242, Accuracy: 95.07%\n",
      "Batch 144, Loss: 0.094295, Accuracy: 95.07%\n",
      "Batch 145, Loss: 0.193801, Accuracy: 95.08%\n",
      "Batch 146, Loss: 0.208058, Accuracy: 95.08%\n",
      "Batch 147, Loss: 0.202327, Accuracy: 95.08%\n",
      "Batch 148, Loss: 0.153145, Accuracy: 95.09%\n",
      "Batch 149, Loss: 0.069168, Accuracy: 95.10%\n",
      "Batch 150, Loss: 0.060558, Accuracy: 95.12%\n",
      "Batch 151, Loss: 0.178038, Accuracy: 95.14%\n",
      "Batch 152, Loss: 0.286603, Accuracy: 95.12%\n",
      "Batch 153, Loss: 0.119079, Accuracy: 95.13%\n",
      "Batch 154, Loss: 0.205696, Accuracy: 95.11%\n",
      "Batch 155, Loss: 0.175502, Accuracy: 95.10%\n",
      "Batch 156, Loss: 0.140211, Accuracy: 95.09%\n",
      "Batch 157, Loss: 0.207782, Accuracy: 95.08%\n",
      "Batch 158, Loss: 0.128058, Accuracy: 95.09%\n",
      "Batch 159, Loss: 0.161027, Accuracy: 95.07%\n",
      "Batch 160, Loss: 0.157662, Accuracy: 95.07%\n",
      "Batch 161, Loss: 0.227799, Accuracy: 95.03%\n",
      "Batch 162, Loss: 0.108950, Accuracy: 95.04%\n",
      "Batch 163, Loss: 0.130394, Accuracy: 95.03%\n",
      "Batch 164, Loss: 0.132231, Accuracy: 95.03%\n",
      "Batch 165, Loss: 0.048842, Accuracy: 95.05%\n",
      "Batch 166, Loss: 0.128815, Accuracy: 95.06%\n",
      "Batch 167, Loss: 0.148723, Accuracy: 95.04%\n",
      "Batch 168, Loss: 0.211440, Accuracy: 95.03%\n",
      "Batch 169, Loss: 0.105158, Accuracy: 95.05%\n",
      "Batch 170, Loss: 0.121783, Accuracy: 95.06%\n",
      "Batch 171, Loss: 0.155250, Accuracy: 95.06%\n",
      "Batch 172, Loss: 0.154027, Accuracy: 95.05%\n",
      "Batch 173, Loss: 0.223131, Accuracy: 95.03%\n",
      "Batch 174, Loss: 0.047203, Accuracy: 95.06%\n",
      "Batch 175, Loss: 0.188513, Accuracy: 95.06%\n",
      "Batch 176, Loss: 0.123965, Accuracy: 95.07%\n",
      "Batch 177, Loss: 0.084386, Accuracy: 95.08%\n",
      "Batch 178, Loss: 0.136786, Accuracy: 95.08%\n",
      "Batch 179, Loss: 0.167433, Accuracy: 95.08%\n",
      "Batch 180, Loss: 0.092653, Accuracy: 95.09%\n",
      "Batch 181, Loss: 0.135949, Accuracy: 95.09%\n",
      "Batch 182, Loss: 0.135409, Accuracy: 95.10%\n",
      "Batch 183, Loss: 0.203549, Accuracy: 95.07%\n",
      "Batch 184, Loss: 0.190153, Accuracy: 95.07%\n",
      "Batch 185, Loss: 0.071457, Accuracy: 95.08%\n",
      "Batch 186, Loss: 0.127445, Accuracy: 95.08%\n",
      "Batch 187, Loss: 0.212287, Accuracy: 95.06%\n",
      "Batch 188, Loss: 0.182834, Accuracy: 95.05%\n",
      "Batch 189, Loss: 0.065856, Accuracy: 95.06%\n",
      "Batch 190, Loss: 0.134845, Accuracy: 95.04%\n",
      "Batch 191, Loss: 0.074230, Accuracy: 95.05%\n",
      "Batch 192, Loss: 0.128667, Accuracy: 95.05%\n",
      "Batch 193, Loss: 0.048568, Accuracy: 95.07%\n",
      "Batch 194, Loss: 0.028801, Accuracy: 95.10%\n",
      "Batch 195, Loss: 0.156753, Accuracy: 95.09%\n",
      "Batch 196, Loss: 0.074211, Accuracy: 95.11%\n",
      "Batch 197, Loss: 0.140607, Accuracy: 95.10%\n",
      "Batch 198, Loss: 0.086301, Accuracy: 95.12%\n",
      "Batch 199, Loss: 0.121970, Accuracy: 95.12%\n",
      "Batch 200, Loss: 0.093862, Accuracy: 95.12%\n",
      "Batch 201, Loss: 0.016699, Accuracy: 95.15%\n",
      "Batch 202, Loss: 0.237805, Accuracy: 95.15%\n",
      "Batch 203, Loss: 0.145334, Accuracy: 95.15%\n",
      "Batch 204, Loss: 0.108557, Accuracy: 95.17%\n",
      "Batch 205, Loss: 0.063457, Accuracy: 95.18%\n",
      "Batch 206, Loss: 0.051335, Accuracy: 95.19%\n",
      "Batch 207, Loss: 0.113861, Accuracy: 95.20%\n",
      "Batch 208, Loss: 0.064232, Accuracy: 95.21%\n",
      "Batch 209, Loss: 0.105793, Accuracy: 95.20%\n",
      "Batch 210, Loss: 0.137291, Accuracy: 95.21%\n",
      "Batch 211, Loss: 0.095441, Accuracy: 95.21%\n",
      "Batch 212, Loss: 0.085902, Accuracy: 95.21%\n",
      "Batch 213, Loss: 0.108671, Accuracy: 95.21%\n",
      "Training - Epoch 5, Loss: 0.142116, Accuracy: 95.21%\n",
      "Validation Batch 1, Loss: 0.092250, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.174385, Accuracy: 95.31%\n",
      "Validation Batch 3, Loss: 0.118957, Accuracy: 95.31%\n",
      "Validation Batch 4, Loss: 0.100506, Accuracy: 95.70%\n",
      "Validation Batch 5, Loss: 0.131569, Accuracy: 95.62%\n",
      "Validation Batch 6, Loss: 0.016969, Accuracy: 96.35%\n",
      "Validation Batch 7, Loss: 0.106853, Accuracy: 96.65%\n",
      "Validation Batch 8, Loss: 0.245718, Accuracy: 96.09%\n",
      "Validation Batch 9, Loss: 0.273740, Accuracy: 95.49%\n",
      "Validation Batch 10, Loss: 0.103571, Accuracy: 95.47%\n",
      "Validation Batch 11, Loss: 0.034260, Accuracy: 95.88%\n",
      "Validation Batch 12, Loss: 0.201171, Accuracy: 95.96%\n",
      "Validation Batch 13, Loss: 0.088480, Accuracy: 96.03%\n",
      "Validation Batch 14, Loss: 0.185533, Accuracy: 95.87%\n",
      "Validation Batch 15, Loss: 0.224429, Accuracy: 95.42%\n",
      "Validation Batch 16, Loss: 0.083948, Accuracy: 95.51%\n",
      "Validation Batch 17, Loss: 0.204193, Accuracy: 95.50%\n",
      "Validation Batch 18, Loss: 0.046830, Accuracy: 95.66%\n",
      "Validation Batch 19, Loss: 0.080826, Accuracy: 95.64%\n",
      "Validation Batch 20, Loss: 0.024668, Accuracy: 95.86%\n",
      "Validation Batch 21, Loss: 0.067588, Accuracy: 95.83%\n",
      "Validation Batch 22, Loss: 0.104809, Accuracy: 95.95%\n",
      "Validation Batch 23, Loss: 0.223306, Accuracy: 95.72%\n",
      "Validation Batch 24, Loss: 0.196144, Accuracy: 95.70%\n",
      "Validation Batch 25, Loss: 0.045211, Accuracy: 95.81%\n",
      "Validation Batch 26, Loss: 0.128141, Accuracy: 95.85%\n",
      "Validation Batch 27, Loss: 0.079225, Accuracy: 95.89%\n",
      "Validation - Epoch 5, Loss: 0.125307, Accuracy: 95.89%\n",
      "Patience—0\n",
      "Epoch 6\n",
      "Batch 1, Loss: 0.101621, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.046163, Accuracy: 97.66%\n",
      "Batch 3, Loss: 0.030411, Accuracy: 98.44%\n",
      "Batch 4, Loss: 0.054073, Accuracy: 98.44%\n",
      "Batch 5, Loss: 0.062615, Accuracy: 98.12%\n",
      "Batch 6, Loss: 0.075544, Accuracy: 97.92%\n",
      "Batch 7, Loss: 0.144727, Accuracy: 97.32%\n",
      "Batch 8, Loss: 0.119408, Accuracy: 97.07%\n",
      "Batch 9, Loss: 0.172447, Accuracy: 96.70%\n",
      "Batch 10, Loss: 0.092091, Accuracy: 96.88%\n",
      "Batch 11, Loss: 0.044189, Accuracy: 97.02%\n",
      "Batch 12, Loss: 0.043838, Accuracy: 97.14%\n",
      "Batch 13, Loss: 0.110702, Accuracy: 97.00%\n",
      "Batch 14, Loss: 0.311885, Accuracy: 96.76%\n",
      "Batch 15, Loss: 0.126797, Accuracy: 96.77%\n",
      "Batch 16, Loss: 0.118224, Accuracy: 96.68%\n",
      "Batch 17, Loss: 0.064720, Accuracy: 96.78%\n",
      "Batch 18, Loss: 0.048771, Accuracy: 96.88%\n",
      "Batch 19, Loss: 0.062875, Accuracy: 96.88%\n",
      "Batch 20, Loss: 0.029906, Accuracy: 97.03%\n",
      "Batch 21, Loss: 0.118467, Accuracy: 97.02%\n",
      "Batch 22, Loss: 0.119649, Accuracy: 97.02%\n",
      "Batch 23, Loss: 0.072134, Accuracy: 96.94%\n",
      "Batch 24, Loss: 0.029699, Accuracy: 97.01%\n",
      "Batch 25, Loss: 0.076871, Accuracy: 96.94%\n",
      "Batch 26, Loss: 0.035000, Accuracy: 97.00%\n",
      "Batch 27, Loss: 0.063809, Accuracy: 97.05%\n",
      "Batch 28, Loss: 0.071052, Accuracy: 97.04%\n",
      "Batch 29, Loss: 0.080265, Accuracy: 97.04%\n",
      "Batch 30, Loss: 0.070154, Accuracy: 97.03%\n",
      "Batch 31, Loss: 0.049843, Accuracy: 97.08%\n",
      "Batch 32, Loss: 0.027251, Accuracy: 97.12%\n",
      "Batch 33, Loss: 0.068360, Accuracy: 97.11%\n",
      "Batch 34, Loss: 0.258297, Accuracy: 97.01%\n",
      "Batch 35, Loss: 0.120506, Accuracy: 96.96%\n",
      "Batch 36, Loss: 0.141149, Accuracy: 96.92%\n",
      "Batch 37, Loss: 0.123971, Accuracy: 96.92%\n",
      "Batch 38, Loss: 0.033492, Accuracy: 96.96%\n",
      "Batch 39, Loss: 0.159096, Accuracy: 96.88%\n",
      "Batch 40, Loss: 0.016675, Accuracy: 96.95%\n",
      "Batch 41, Loss: 0.106305, Accuracy: 96.88%\n",
      "Batch 42, Loss: 0.109050, Accuracy: 96.84%\n",
      "Batch 43, Loss: 0.131557, Accuracy: 96.80%\n",
      "Batch 44, Loss: 0.045801, Accuracy: 96.88%\n",
      "Batch 45, Loss: 0.028007, Accuracy: 96.94%\n",
      "Batch 46, Loss: 0.108640, Accuracy: 96.94%\n",
      "Batch 47, Loss: 0.237058, Accuracy: 96.81%\n",
      "Batch 48, Loss: 0.111985, Accuracy: 96.78%\n",
      "Batch 49, Loss: 0.100573, Accuracy: 96.78%\n",
      "Batch 50, Loss: 0.106281, Accuracy: 96.72%\n",
      "Batch 51, Loss: 0.150938, Accuracy: 96.69%\n",
      "Batch 52, Loss: 0.168151, Accuracy: 96.66%\n",
      "Batch 53, Loss: 0.075567, Accuracy: 96.70%\n",
      "Batch 54, Loss: 0.287145, Accuracy: 96.53%\n",
      "Batch 55, Loss: 0.101382, Accuracy: 96.53%\n",
      "Batch 56, Loss: 0.098369, Accuracy: 96.54%\n",
      "Batch 57, Loss: 0.030091, Accuracy: 96.60%\n",
      "Batch 58, Loss: 0.125895, Accuracy: 96.63%\n",
      "Batch 59, Loss: 0.139968, Accuracy: 96.61%\n",
      "Batch 60, Loss: 0.066424, Accuracy: 96.64%\n",
      "Batch 61, Loss: 0.044927, Accuracy: 96.67%\n",
      "Batch 62, Loss: 0.020202, Accuracy: 96.72%\n",
      "Batch 63, Loss: 0.101948, Accuracy: 96.73%\n",
      "Batch 64, Loss: 0.191456, Accuracy: 96.70%\n",
      "Batch 65, Loss: 0.223920, Accuracy: 96.66%\n",
      "Batch 66, Loss: 0.059384, Accuracy: 96.69%\n",
      "Batch 67, Loss: 0.053453, Accuracy: 96.69%\n",
      "Batch 68, Loss: 0.065820, Accuracy: 96.71%\n",
      "Batch 69, Loss: 0.107353, Accuracy: 96.67%\n",
      "Batch 70, Loss: 0.044769, Accuracy: 96.70%\n",
      "Batch 71, Loss: 0.021464, Accuracy: 96.74%\n",
      "Batch 72, Loss: 0.115318, Accuracy: 96.72%\n",
      "Batch 73, Loss: 0.039871, Accuracy: 96.75%\n",
      "Batch 74, Loss: 0.040564, Accuracy: 96.77%\n",
      "Batch 75, Loss: 0.034783, Accuracy: 96.79%\n",
      "Batch 76, Loss: 0.092250, Accuracy: 96.79%\n",
      "Batch 77, Loss: 0.028218, Accuracy: 96.81%\n",
      "Batch 78, Loss: 0.174481, Accuracy: 96.81%\n",
      "Batch 79, Loss: 0.153710, Accuracy: 96.80%\n",
      "Batch 80, Loss: 0.152018, Accuracy: 96.80%\n",
      "Batch 81, Loss: 0.086400, Accuracy: 96.82%\n",
      "Batch 82, Loss: 0.147750, Accuracy: 96.82%\n",
      "Batch 83, Loss: 0.056428, Accuracy: 96.84%\n",
      "Batch 84, Loss: 0.085187, Accuracy: 96.82%\n",
      "Batch 85, Loss: 0.027429, Accuracy: 96.84%\n",
      "Batch 86, Loss: 0.095956, Accuracy: 96.84%\n",
      "Batch 87, Loss: 0.200338, Accuracy: 96.80%\n",
      "Batch 88, Loss: 0.052191, Accuracy: 96.82%\n",
      "Batch 89, Loss: 0.020605, Accuracy: 96.86%\n",
      "Batch 90, Loss: 0.063253, Accuracy: 96.86%\n",
      "Batch 91, Loss: 0.237817, Accuracy: 96.81%\n",
      "Batch 92, Loss: 0.086046, Accuracy: 96.82%\n",
      "Batch 93, Loss: 0.073091, Accuracy: 96.81%\n",
      "Batch 94, Loss: 0.198167, Accuracy: 96.78%\n",
      "Batch 95, Loss: 0.072237, Accuracy: 96.79%\n",
      "Batch 96, Loss: 0.078901, Accuracy: 96.79%\n",
      "Batch 97, Loss: 0.081589, Accuracy: 96.83%\n",
      "Batch 98, Loss: 0.118775, Accuracy: 96.83%\n",
      "Batch 99, Loss: 0.063293, Accuracy: 96.84%\n",
      "Batch 100, Loss: 0.132062, Accuracy: 96.84%\n",
      "Batch 101, Loss: 0.035903, Accuracy: 96.88%\n",
      "Batch 102, Loss: 0.041006, Accuracy: 96.89%\n",
      "Batch 103, Loss: 0.090216, Accuracy: 96.89%\n",
      "Batch 104, Loss: 0.064667, Accuracy: 96.89%\n",
      "Batch 105, Loss: 0.044312, Accuracy: 96.89%\n",
      "Batch 106, Loss: 0.066582, Accuracy: 96.89%\n",
      "Batch 107, Loss: 0.028535, Accuracy: 96.92%\n",
      "Batch 108, Loss: 0.059301, Accuracy: 96.93%\n",
      "Batch 109, Loss: 0.102569, Accuracy: 96.92%\n",
      "Batch 110, Loss: 0.124934, Accuracy: 96.92%\n",
      "Batch 111, Loss: 0.007456, Accuracy: 96.95%\n",
      "Batch 112, Loss: 0.077402, Accuracy: 96.94%\n",
      "Batch 113, Loss: 0.014137, Accuracy: 96.97%\n",
      "Batch 114, Loss: 0.014207, Accuracy: 97.00%\n",
      "Batch 115, Loss: 0.069985, Accuracy: 97.00%\n",
      "Batch 116, Loss: 0.077166, Accuracy: 96.98%\n",
      "Batch 117, Loss: 0.075976, Accuracy: 97.00%\n",
      "Batch 118, Loss: 0.130005, Accuracy: 96.99%\n",
      "Batch 119, Loss: 0.095549, Accuracy: 96.98%\n",
      "Batch 120, Loss: 0.014664, Accuracy: 97.01%\n",
      "Batch 121, Loss: 0.063325, Accuracy: 97.02%\n",
      "Batch 122, Loss: 0.071483, Accuracy: 97.00%\n",
      "Batch 123, Loss: 0.211548, Accuracy: 96.98%\n",
      "Batch 124, Loss: 0.056822, Accuracy: 96.99%\n",
      "Batch 125, Loss: 0.213182, Accuracy: 96.97%\n",
      "Batch 126, Loss: 0.285303, Accuracy: 96.95%\n",
      "Batch 127, Loss: 0.065443, Accuracy: 96.96%\n",
      "Batch 128, Loss: 0.253646, Accuracy: 96.94%\n",
      "Batch 129, Loss: 0.101621, Accuracy: 96.94%\n",
      "Batch 130, Loss: 0.085656, Accuracy: 96.95%\n",
      "Batch 131, Loss: 0.243770, Accuracy: 96.90%\n",
      "Batch 132, Loss: 0.070390, Accuracy: 96.90%\n",
      "Batch 133, Loss: 0.171451, Accuracy: 96.86%\n",
      "Batch 134, Loss: 0.014760, Accuracy: 96.89%\n",
      "Batch 135, Loss: 0.053479, Accuracy: 96.89%\n",
      "Batch 136, Loss: 0.038019, Accuracy: 96.90%\n",
      "Batch 137, Loss: 0.336860, Accuracy: 96.82%\n",
      "Batch 138, Loss: 0.268073, Accuracy: 96.77%\n",
      "Batch 139, Loss: 0.192243, Accuracy: 96.76%\n",
      "Batch 140, Loss: 0.059015, Accuracy: 96.77%\n",
      "Batch 141, Loss: 0.099892, Accuracy: 96.76%\n",
      "Batch 142, Loss: 0.110778, Accuracy: 96.76%\n",
      "Batch 143, Loss: 0.173997, Accuracy: 96.73%\n",
      "Batch 144, Loss: 0.190702, Accuracy: 96.70%\n",
      "Batch 145, Loss: 0.054361, Accuracy: 96.71%\n",
      "Batch 146, Loss: 0.174329, Accuracy: 96.70%\n",
      "Batch 147, Loss: 0.041281, Accuracy: 96.73%\n",
      "Batch 148, Loss: 0.105057, Accuracy: 96.72%\n",
      "Batch 149, Loss: 0.066152, Accuracy: 96.72%\n",
      "Batch 150, Loss: 0.134231, Accuracy: 96.69%\n",
      "Batch 151, Loss: 0.171295, Accuracy: 96.68%\n",
      "Batch 152, Loss: 0.118360, Accuracy: 96.67%\n",
      "Batch 153, Loss: 0.124299, Accuracy: 96.66%\n",
      "Batch 154, Loss: 0.112686, Accuracy: 96.66%\n",
      "Batch 155, Loss: 0.138697, Accuracy: 96.66%\n",
      "Batch 156, Loss: 0.159155, Accuracy: 96.64%\n",
      "Batch 157, Loss: 0.152749, Accuracy: 96.63%\n",
      "Batch 158, Loss: 0.087745, Accuracy: 96.62%\n",
      "Batch 159, Loss: 0.024874, Accuracy: 96.64%\n",
      "Batch 160, Loss: 0.009187, Accuracy: 96.66%\n",
      "Batch 161, Loss: 0.161888, Accuracy: 96.66%\n",
      "Batch 162, Loss: 0.117565, Accuracy: 96.66%\n",
      "Batch 163, Loss: 0.169332, Accuracy: 96.65%\n",
      "Batch 164, Loss: 0.048001, Accuracy: 96.67%\n",
      "Batch 165, Loss: 0.050621, Accuracy: 96.68%\n",
      "Batch 166, Loss: 0.029408, Accuracy: 96.70%\n",
      "Batch 167, Loss: 0.028323, Accuracy: 96.72%\n",
      "Batch 168, Loss: 0.206483, Accuracy: 96.71%\n",
      "Batch 169, Loss: 0.075049, Accuracy: 96.72%\n",
      "Batch 170, Loss: 0.082047, Accuracy: 96.72%\n",
      "Batch 171, Loss: 0.026638, Accuracy: 96.74%\n",
      "Batch 172, Loss: 0.169527, Accuracy: 96.72%\n",
      "Batch 173, Loss: 0.070263, Accuracy: 96.72%\n",
      "Batch 174, Loss: 0.140242, Accuracy: 96.70%\n",
      "Batch 175, Loss: 0.140426, Accuracy: 96.71%\n",
      "Batch 176, Loss: 0.072263, Accuracy: 96.71%\n",
      "Batch 177, Loss: 0.019521, Accuracy: 96.72%\n",
      "Batch 178, Loss: 0.062123, Accuracy: 96.73%\n",
      "Batch 179, Loss: 0.018976, Accuracy: 96.75%\n",
      "Batch 180, Loss: 0.075643, Accuracy: 96.75%\n",
      "Batch 181, Loss: 0.139981, Accuracy: 96.75%\n",
      "Batch 182, Loss: 0.008959, Accuracy: 96.76%\n",
      "Batch 183, Loss: 0.060677, Accuracy: 96.76%\n",
      "Batch 184, Loss: 0.275533, Accuracy: 96.75%\n",
      "Batch 185, Loss: 0.025837, Accuracy: 96.76%\n",
      "Batch 186, Loss: 0.074780, Accuracy: 96.77%\n",
      "Batch 187, Loss: 0.059455, Accuracy: 96.77%\n",
      "Batch 188, Loss: 0.113726, Accuracy: 96.78%\n",
      "Batch 189, Loss: 0.055755, Accuracy: 96.78%\n",
      "Batch 190, Loss: 0.075158, Accuracy: 96.78%\n",
      "Batch 191, Loss: 0.165251, Accuracy: 96.79%\n",
      "Batch 192, Loss: 0.061841, Accuracy: 96.79%\n",
      "Batch 193, Loss: 0.022036, Accuracy: 96.80%\n",
      "Batch 194, Loss: 0.021883, Accuracy: 96.82%\n",
      "Batch 195, Loss: 0.044706, Accuracy: 96.83%\n",
      "Batch 196, Loss: 0.104303, Accuracy: 96.84%\n",
      "Batch 197, Loss: 0.099665, Accuracy: 96.84%\n",
      "Batch 198, Loss: 0.095212, Accuracy: 96.84%\n",
      "Batch 199, Loss: 0.036977, Accuracy: 96.85%\n",
      "Batch 200, Loss: 0.031037, Accuracy: 96.86%\n",
      "Batch 201, Loss: 0.036009, Accuracy: 96.88%\n",
      "Batch 202, Loss: 0.121159, Accuracy: 96.87%\n",
      "Batch 203, Loss: 0.037338, Accuracy: 96.88%\n",
      "Batch 204, Loss: 0.076375, Accuracy: 96.87%\n",
      "Batch 205, Loss: 0.057653, Accuracy: 96.88%\n",
      "Batch 206, Loss: 0.101501, Accuracy: 96.88%\n",
      "Batch 207, Loss: 0.113096, Accuracy: 96.88%\n",
      "Batch 208, Loss: 0.027062, Accuracy: 96.89%\n",
      "Batch 209, Loss: 0.022678, Accuracy: 96.90%\n",
      "Batch 210, Loss: 0.027551, Accuracy: 96.91%\n",
      "Batch 211, Loss: 0.071878, Accuracy: 96.92%\n",
      "Batch 212, Loss: 0.143423, Accuracy: 96.91%\n",
      "Batch 213, Loss: 0.220166, Accuracy: 96.90%\n",
      "Training - Epoch 6, Loss: 0.095788, Accuracy: 96.90%\n",
      "Validation Batch 1, Loss: 0.031483, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.129704, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.093076, Accuracy: 96.88%\n",
      "Validation Batch 4, Loss: 0.053131, Accuracy: 97.27%\n",
      "Validation Batch 5, Loss: 0.076145, Accuracy: 97.50%\n",
      "Validation Batch 6, Loss: 0.061411, Accuracy: 97.66%\n",
      "Validation Batch 7, Loss: 0.005226, Accuracy: 97.99%\n",
      "Validation Batch 8, Loss: 0.116458, Accuracy: 97.46%\n",
      "Validation Batch 9, Loss: 0.101081, Accuracy: 97.22%\n",
      "Validation Batch 10, Loss: 0.044172, Accuracy: 97.34%\n",
      "Validation Batch 11, Loss: 0.079900, Accuracy: 97.16%\n",
      "Validation Batch 12, Loss: 0.111087, Accuracy: 97.14%\n",
      "Validation Batch 13, Loss: 0.022560, Accuracy: 97.36%\n",
      "Validation Batch 14, Loss: 0.223587, Accuracy: 97.21%\n",
      "Validation Batch 15, Loss: 0.032846, Accuracy: 97.29%\n",
      "Validation Batch 16, Loss: 0.044968, Accuracy: 97.36%\n",
      "Validation Batch 17, Loss: 0.054068, Accuracy: 97.33%\n",
      "Validation Batch 18, Loss: 0.048880, Accuracy: 97.40%\n",
      "Validation Batch 19, Loss: 0.170686, Accuracy: 97.12%\n",
      "Validation Batch 20, Loss: 0.027716, Accuracy: 97.27%\n",
      "Validation Batch 21, Loss: 0.191487, Accuracy: 97.10%\n",
      "Validation Batch 22, Loss: 0.031339, Accuracy: 97.23%\n",
      "Validation Batch 23, Loss: 0.094524, Accuracy: 97.21%\n",
      "Validation Batch 24, Loss: 0.033177, Accuracy: 97.27%\n",
      "Validation Batch 25, Loss: 0.010499, Accuracy: 97.38%\n",
      "Validation Batch 26, Loss: 0.084623, Accuracy: 97.36%\n",
      "Validation Batch 27, Loss: 0.062392, Accuracy: 97.36%\n",
      "Validation - Epoch 6, Loss: 0.075416, Accuracy: 97.36%\n",
      "Patience—0\n",
      "Epoch 7\n",
      "Batch 1, Loss: 0.015168, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.080266, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.057496, Accuracy: 98.44%\n",
      "Batch 4, Loss: 0.072486, Accuracy: 98.44%\n",
      "Batch 5, Loss: 0.081549, Accuracy: 97.81%\n",
      "Batch 6, Loss: 0.074052, Accuracy: 97.66%\n",
      "Batch 7, Loss: 0.033739, Accuracy: 97.77%\n",
      "Batch 8, Loss: 0.020365, Accuracy: 98.05%\n",
      "Batch 9, Loss: 0.126963, Accuracy: 97.57%\n",
      "Batch 10, Loss: 0.027260, Accuracy: 97.81%\n",
      "Batch 11, Loss: 0.028142, Accuracy: 98.01%\n",
      "Batch 12, Loss: 0.054291, Accuracy: 97.92%\n",
      "Batch 13, Loss: 0.063586, Accuracy: 97.96%\n",
      "Batch 14, Loss: 0.128970, Accuracy: 97.77%\n",
      "Batch 15, Loss: 0.085070, Accuracy: 97.60%\n",
      "Batch 16, Loss: 0.034366, Accuracy: 97.66%\n",
      "Batch 17, Loss: 0.056419, Accuracy: 97.70%\n",
      "Batch 18, Loss: 0.016295, Accuracy: 97.83%\n",
      "Batch 19, Loss: 0.065155, Accuracy: 97.86%\n",
      "Batch 20, Loss: 0.051408, Accuracy: 97.89%\n",
      "Batch 21, Loss: 0.020469, Accuracy: 97.99%\n",
      "Batch 22, Loss: 0.161074, Accuracy: 97.94%\n",
      "Batch 23, Loss: 0.026820, Accuracy: 97.96%\n",
      "Batch 24, Loss: 0.024717, Accuracy: 97.98%\n",
      "Batch 25, Loss: 0.074747, Accuracy: 98.00%\n",
      "Batch 26, Loss: 0.005166, Accuracy: 98.08%\n",
      "Batch 27, Loss: 0.011850, Accuracy: 98.15%\n",
      "Batch 28, Loss: 0.004523, Accuracy: 98.21%\n",
      "Batch 29, Loss: 0.078911, Accuracy: 98.17%\n",
      "Batch 30, Loss: 0.018305, Accuracy: 98.23%\n",
      "Batch 31, Loss: 0.031789, Accuracy: 98.24%\n",
      "Batch 32, Loss: 0.055680, Accuracy: 98.19%\n",
      "Batch 33, Loss: 0.014408, Accuracy: 98.20%\n",
      "Batch 34, Loss: 0.141177, Accuracy: 98.12%\n",
      "Batch 35, Loss: 0.036301, Accuracy: 98.08%\n",
      "Batch 36, Loss: 0.040760, Accuracy: 98.09%\n",
      "Batch 37, Loss: 0.171897, Accuracy: 98.02%\n",
      "Batch 38, Loss: 0.077870, Accuracy: 97.99%\n",
      "Batch 39, Loss: 0.079075, Accuracy: 97.96%\n",
      "Batch 40, Loss: 0.173770, Accuracy: 97.89%\n",
      "Batch 41, Loss: 0.088599, Accuracy: 97.87%\n",
      "Batch 42, Loss: 0.002571, Accuracy: 97.92%\n",
      "Batch 43, Loss: 0.028387, Accuracy: 97.93%\n",
      "Batch 44, Loss: 0.028001, Accuracy: 97.98%\n",
      "Batch 45, Loss: 0.095311, Accuracy: 97.95%\n",
      "Batch 46, Loss: 0.124723, Accuracy: 97.93%\n",
      "Batch 47, Loss: 0.017622, Accuracy: 97.97%\n",
      "Batch 48, Loss: 0.032523, Accuracy: 98.01%\n",
      "Batch 49, Loss: 0.101926, Accuracy: 97.96%\n",
      "Batch 50, Loss: 0.022025, Accuracy: 98.00%\n",
      "Batch 51, Loss: 0.124255, Accuracy: 97.95%\n",
      "Batch 52, Loss: 0.035665, Accuracy: 97.96%\n",
      "Batch 53, Loss: 0.033805, Accuracy: 97.97%\n",
      "Batch 54, Loss: 0.164333, Accuracy: 97.92%\n",
      "Batch 55, Loss: 0.018443, Accuracy: 97.95%\n",
      "Batch 56, Loss: 0.029128, Accuracy: 97.96%\n",
      "Batch 57, Loss: 0.022375, Accuracy: 97.97%\n",
      "Batch 58, Loss: 0.011432, Accuracy: 98.01%\n",
      "Batch 59, Loss: 0.003945, Accuracy: 98.04%\n",
      "Batch 60, Loss: 0.011316, Accuracy: 98.07%\n",
      "Batch 61, Loss: 0.049994, Accuracy: 98.08%\n",
      "Batch 62, Loss: 0.136026, Accuracy: 98.03%\n",
      "Batch 63, Loss: 0.028387, Accuracy: 98.04%\n",
      "Batch 64, Loss: 0.014421, Accuracy: 98.07%\n",
      "Batch 65, Loss: 0.066587, Accuracy: 98.08%\n",
      "Batch 66, Loss: 0.209067, Accuracy: 98.01%\n",
      "Batch 67, Loss: 0.064619, Accuracy: 97.99%\n",
      "Batch 68, Loss: 0.020430, Accuracy: 98.00%\n",
      "Batch 69, Loss: 0.102392, Accuracy: 97.98%\n",
      "Batch 70, Loss: 0.089996, Accuracy: 97.97%\n",
      "Batch 71, Loss: 0.036039, Accuracy: 98.00%\n",
      "Batch 72, Loss: 0.043497, Accuracy: 98.00%\n",
      "Batch 73, Loss: 0.024150, Accuracy: 98.03%\n",
      "Batch 74, Loss: 0.147932, Accuracy: 97.99%\n",
      "Batch 75, Loss: 0.064617, Accuracy: 97.98%\n",
      "Batch 76, Loss: 0.092850, Accuracy: 97.96%\n",
      "Batch 77, Loss: 0.039376, Accuracy: 97.97%\n",
      "Batch 78, Loss: 0.027907, Accuracy: 98.00%\n",
      "Batch 79, Loss: 0.113979, Accuracy: 97.96%\n",
      "Batch 80, Loss: 0.018385, Accuracy: 97.99%\n",
      "Batch 81, Loss: 0.188701, Accuracy: 97.92%\n",
      "Batch 82, Loss: 0.082421, Accuracy: 97.90%\n",
      "Batch 83, Loss: 0.113426, Accuracy: 97.89%\n",
      "Batch 84, Loss: 0.045958, Accuracy: 97.90%\n",
      "Batch 85, Loss: 0.311148, Accuracy: 97.85%\n",
      "Batch 86, Loss: 0.047973, Accuracy: 97.86%\n",
      "Batch 87, Loss: 0.008600, Accuracy: 97.88%\n",
      "Batch 88, Loss: 0.139684, Accuracy: 97.87%\n",
      "Batch 89, Loss: 0.040388, Accuracy: 97.88%\n",
      "Batch 90, Loss: 0.055742, Accuracy: 97.88%\n",
      "Batch 91, Loss: 0.067588, Accuracy: 97.87%\n",
      "Batch 92, Loss: 0.068131, Accuracy: 97.86%\n",
      "Batch 93, Loss: 0.072917, Accuracy: 97.87%\n",
      "Batch 94, Loss: 0.066888, Accuracy: 97.87%\n",
      "Batch 95, Loss: 0.072718, Accuracy: 97.88%\n",
      "Batch 96, Loss: 0.013707, Accuracy: 97.90%\n",
      "Batch 97, Loss: 0.035697, Accuracy: 97.91%\n",
      "Batch 98, Loss: 0.114181, Accuracy: 97.91%\n",
      "Batch 99, Loss: 0.068032, Accuracy: 97.90%\n",
      "Batch 100, Loss: 0.054844, Accuracy: 97.89%\n",
      "Batch 101, Loss: 0.012969, Accuracy: 97.91%\n",
      "Batch 102, Loss: 0.062578, Accuracy: 97.90%\n",
      "Batch 103, Loss: 0.127281, Accuracy: 97.88%\n",
      "Batch 104, Loss: 0.051541, Accuracy: 97.88%\n",
      "Batch 105, Loss: 0.010525, Accuracy: 97.90%\n",
      "Batch 106, Loss: 0.020129, Accuracy: 97.92%\n",
      "Batch 107, Loss: 0.041990, Accuracy: 97.93%\n",
      "Batch 108, Loss: 0.128189, Accuracy: 97.90%\n",
      "Batch 109, Loss: 0.081624, Accuracy: 97.89%\n",
      "Batch 110, Loss: 0.002906, Accuracy: 97.91%\n",
      "Batch 111, Loss: 0.070841, Accuracy: 97.90%\n",
      "Batch 112, Loss: 0.083049, Accuracy: 97.89%\n",
      "Batch 113, Loss: 0.262714, Accuracy: 97.82%\n",
      "Batch 114, Loss: 0.025347, Accuracy: 97.82%\n",
      "Batch 115, Loss: 0.009105, Accuracy: 97.84%\n",
      "Batch 116, Loss: 0.064961, Accuracy: 97.83%\n",
      "Batch 117, Loss: 0.116062, Accuracy: 97.81%\n",
      "Batch 118, Loss: 0.215512, Accuracy: 97.78%\n",
      "Batch 119, Loss: 0.121053, Accuracy: 97.74%\n",
      "Batch 120, Loss: 0.159193, Accuracy: 97.71%\n",
      "Batch 121, Loss: 0.035800, Accuracy: 97.71%\n",
      "Batch 122, Loss: 0.259685, Accuracy: 97.68%\n",
      "Batch 123, Loss: 0.288157, Accuracy: 97.61%\n",
      "Batch 124, Loss: 0.094847, Accuracy: 97.59%\n",
      "Batch 125, Loss: 0.125995, Accuracy: 97.58%\n",
      "Batch 126, Loss: 0.044368, Accuracy: 97.58%\n",
      "Batch 127, Loss: 0.083667, Accuracy: 97.59%\n",
      "Batch 128, Loss: 0.073032, Accuracy: 97.60%\n",
      "Batch 129, Loss: 0.289259, Accuracy: 97.53%\n",
      "Batch 130, Loss: 0.100322, Accuracy: 97.52%\n",
      "Batch 131, Loss: 0.093488, Accuracy: 97.53%\n",
      "Batch 132, Loss: 0.179581, Accuracy: 97.48%\n",
      "Batch 133, Loss: 0.131724, Accuracy: 97.45%\n",
      "Batch 134, Loss: 0.130064, Accuracy: 97.42%\n",
      "Batch 135, Loss: 0.037235, Accuracy: 97.43%\n",
      "Batch 136, Loss: 0.082462, Accuracy: 97.43%\n",
      "Batch 137, Loss: 0.155516, Accuracy: 97.41%\n",
      "Batch 138, Loss: 0.055354, Accuracy: 97.42%\n",
      "Batch 139, Loss: 0.095651, Accuracy: 97.40%\n",
      "Batch 140, Loss: 0.065743, Accuracy: 97.40%\n",
      "Batch 141, Loss: 0.043513, Accuracy: 97.41%\n",
      "Batch 142, Loss: 0.091841, Accuracy: 97.39%\n",
      "Batch 143, Loss: 0.070674, Accuracy: 97.40%\n",
      "Batch 144, Loss: 0.071139, Accuracy: 97.41%\n",
      "Batch 145, Loss: 0.027989, Accuracy: 97.41%\n",
      "Batch 146, Loss: 0.134768, Accuracy: 97.41%\n",
      "Batch 147, Loss: 0.208250, Accuracy: 97.39%\n",
      "Batch 148, Loss: 0.110499, Accuracy: 97.36%\n",
      "Batch 149, Loss: 0.266957, Accuracy: 97.35%\n",
      "Batch 150, Loss: 0.189157, Accuracy: 97.32%\n",
      "Batch 151, Loss: 0.082710, Accuracy: 97.31%\n",
      "Batch 152, Loss: 0.010318, Accuracy: 97.33%\n",
      "Batch 153, Loss: 0.140827, Accuracy: 97.32%\n",
      "Batch 154, Loss: 0.034715, Accuracy: 97.33%\n",
      "Batch 155, Loss: 0.054530, Accuracy: 97.34%\n",
      "Batch 156, Loss: 0.031592, Accuracy: 97.36%\n",
      "Batch 157, Loss: 0.098215, Accuracy: 97.34%\n",
      "Batch 158, Loss: 0.049335, Accuracy: 97.35%\n",
      "Batch 159, Loss: 0.075247, Accuracy: 97.35%\n",
      "Batch 160, Loss: 0.093392, Accuracy: 97.34%\n",
      "Batch 161, Loss: 0.033291, Accuracy: 97.35%\n",
      "Batch 162, Loss: 0.022452, Accuracy: 97.37%\n",
      "Batch 163, Loss: 0.049227, Accuracy: 97.37%\n",
      "Batch 164, Loss: 0.013036, Accuracy: 97.39%\n",
      "Batch 165, Loss: 0.041655, Accuracy: 97.40%\n",
      "Batch 166, Loss: 0.038990, Accuracy: 97.40%\n",
      "Batch 167, Loss: 0.009589, Accuracy: 97.42%\n",
      "Batch 168, Loss: 0.042079, Accuracy: 97.42%\n",
      "Batch 169, Loss: 0.023592, Accuracy: 97.44%\n",
      "Batch 170, Loss: 0.013986, Accuracy: 97.45%\n",
      "Batch 171, Loss: 0.015422, Accuracy: 97.47%\n",
      "Batch 172, Loss: 0.037898, Accuracy: 97.47%\n",
      "Batch 173, Loss: 0.079976, Accuracy: 97.46%\n",
      "Batch 174, Loss: 0.011992, Accuracy: 97.48%\n",
      "Batch 175, Loss: 0.071357, Accuracy: 97.47%\n",
      "Batch 176, Loss: 0.177749, Accuracy: 97.47%\n",
      "Batch 177, Loss: 0.120452, Accuracy: 97.46%\n",
      "Batch 178, Loss: 0.038125, Accuracy: 97.46%\n",
      "Batch 179, Loss: 0.150065, Accuracy: 97.46%\n",
      "Batch 180, Loss: 0.028501, Accuracy: 97.47%\n",
      "Batch 181, Loss: 0.021424, Accuracy: 97.48%\n",
      "Batch 182, Loss: 0.021250, Accuracy: 97.49%\n",
      "Batch 183, Loss: 0.025297, Accuracy: 97.51%\n",
      "Batch 184, Loss: 0.022940, Accuracy: 97.52%\n",
      "Batch 185, Loss: 0.040175, Accuracy: 97.53%\n",
      "Batch 186, Loss: 0.046736, Accuracy: 97.53%\n",
      "Batch 187, Loss: 0.062880, Accuracy: 97.53%\n",
      "Batch 188, Loss: 0.018248, Accuracy: 97.54%\n",
      "Batch 189, Loss: 0.007631, Accuracy: 97.55%\n",
      "Batch 190, Loss: 0.055869, Accuracy: 97.55%\n",
      "Batch 191, Loss: 0.132905, Accuracy: 97.54%\n",
      "Batch 192, Loss: 0.088309, Accuracy: 97.54%\n",
      "Batch 193, Loss: 0.019280, Accuracy: 97.56%\n",
      "Batch 194, Loss: 0.005812, Accuracy: 97.57%\n",
      "Batch 195, Loss: 0.040259, Accuracy: 97.57%\n",
      "Batch 196, Loss: 0.011203, Accuracy: 97.58%\n",
      "Batch 197, Loss: 0.005623, Accuracy: 97.60%\n",
      "Batch 198, Loss: 0.008882, Accuracy: 97.61%\n",
      "Batch 199, Loss: 0.050700, Accuracy: 97.61%\n",
      "Batch 200, Loss: 0.016556, Accuracy: 97.62%\n",
      "Batch 201, Loss: 0.020631, Accuracy: 97.63%\n",
      "Batch 202, Loss: 0.044353, Accuracy: 97.63%\n",
      "Batch 203, Loss: 0.141472, Accuracy: 97.63%\n",
      "Batch 204, Loss: 0.009754, Accuracy: 97.64%\n",
      "Batch 205, Loss: 0.054483, Accuracy: 97.64%\n",
      "Batch 206, Loss: 0.002523, Accuracy: 97.65%\n",
      "Batch 207, Loss: 0.007197, Accuracy: 97.66%\n",
      "Batch 208, Loss: 0.065641, Accuracy: 97.65%\n",
      "Batch 209, Loss: 0.069897, Accuracy: 97.65%\n",
      "Batch 210, Loss: 0.079221, Accuracy: 97.64%\n",
      "Batch 211, Loss: 0.034645, Accuracy: 97.64%\n",
      "Batch 212, Loss: 0.003633, Accuracy: 97.65%\n",
      "Batch 213, Loss: 0.003644, Accuracy: 97.66%\n",
      "Training - Epoch 7, Loss: 0.069070, Accuracy: 97.66%\n",
      "Validation Batch 1, Loss: 0.054836, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.151872, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.069192, Accuracy: 97.40%\n",
      "Validation Batch 4, Loss: 0.010742, Accuracy: 98.05%\n",
      "Validation Batch 5, Loss: 0.034536, Accuracy: 98.12%\n",
      "Validation Batch 6, Loss: 0.001412, Accuracy: 98.44%\n",
      "Validation Batch 7, Loss: 0.037867, Accuracy: 98.44%\n",
      "Validation Batch 8, Loss: 0.006548, Accuracy: 98.63%\n",
      "Validation Batch 9, Loss: 0.092612, Accuracy: 98.26%\n",
      "Validation Batch 10, Loss: 0.026538, Accuracy: 98.44%\n",
      "Validation Batch 11, Loss: 0.027413, Accuracy: 98.44%\n",
      "Validation Batch 12, Loss: 0.103505, Accuracy: 98.18%\n",
      "Validation Batch 13, Loss: 0.084069, Accuracy: 98.08%\n",
      "Validation Batch 14, Loss: 0.005861, Accuracy: 98.21%\n",
      "Validation Batch 15, Loss: 0.094060, Accuracy: 98.02%\n",
      "Validation Batch 16, Loss: 0.038940, Accuracy: 98.05%\n",
      "Validation Batch 17, Loss: 0.029995, Accuracy: 98.07%\n",
      "Validation Batch 18, Loss: 0.017388, Accuracy: 98.18%\n",
      "Validation Batch 19, Loss: 0.077356, Accuracy: 98.11%\n",
      "Validation Batch 20, Loss: 0.036372, Accuracy: 98.05%\n",
      "Validation Batch 21, Loss: 0.105290, Accuracy: 98.07%\n",
      "Validation Batch 22, Loss: 0.067075, Accuracy: 98.08%\n",
      "Validation Batch 23, Loss: 0.073003, Accuracy: 98.10%\n",
      "Validation Batch 24, Loss: 0.034248, Accuracy: 98.11%\n",
      "Validation Batch 25, Loss: 0.045710, Accuracy: 98.12%\n",
      "Validation Batch 26, Loss: 0.111430, Accuracy: 98.08%\n",
      "Validation Batch 27, Loss: 0.051551, Accuracy: 98.12%\n",
      "Validation - Epoch 7, Loss: 0.055164, Accuracy: 98.12%\n",
      "Patience—0\n",
      "Epoch 8\n",
      "Batch 1, Loss: 0.004068, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.040222, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.005531, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.018647, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.168691, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.046596, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.004411, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.039848, Accuracy: 98.83%\n",
      "Batch 9, Loss: 0.004509, Accuracy: 98.96%\n",
      "Batch 10, Loss: 0.080370, Accuracy: 98.91%\n",
      "Batch 11, Loss: 0.059230, Accuracy: 98.86%\n",
      "Batch 12, Loss: 0.010142, Accuracy: 98.96%\n",
      "Batch 13, Loss: 0.073119, Accuracy: 98.92%\n",
      "Batch 14, Loss: 0.008633, Accuracy: 99.00%\n",
      "Batch 15, Loss: 0.045623, Accuracy: 98.85%\n",
      "Batch 16, Loss: 0.016929, Accuracy: 98.93%\n",
      "Batch 17, Loss: 0.047365, Accuracy: 98.90%\n",
      "Batch 18, Loss: 0.022538, Accuracy: 98.96%\n",
      "Batch 19, Loss: 0.022862, Accuracy: 99.01%\n",
      "Batch 20, Loss: 0.006785, Accuracy: 99.06%\n",
      "Batch 21, Loss: 0.027337, Accuracy: 99.03%\n",
      "Batch 22, Loss: 0.024954, Accuracy: 99.01%\n",
      "Batch 23, Loss: 0.048597, Accuracy: 98.91%\n",
      "Batch 24, Loss: 0.034848, Accuracy: 98.89%\n",
      "Batch 25, Loss: 0.011061, Accuracy: 98.94%\n",
      "Batch 26, Loss: 0.051770, Accuracy: 98.86%\n",
      "Batch 27, Loss: 0.027210, Accuracy: 98.84%\n",
      "Batch 28, Loss: 0.038220, Accuracy: 98.83%\n",
      "Batch 29, Loss: 0.064254, Accuracy: 98.81%\n",
      "Batch 30, Loss: 0.007565, Accuracy: 98.85%\n",
      "Batch 31, Loss: 0.038876, Accuracy: 98.84%\n",
      "Batch 32, Loss: 0.031793, Accuracy: 98.83%\n",
      "Batch 33, Loss: 0.059747, Accuracy: 98.77%\n",
      "Batch 34, Loss: 0.071877, Accuracy: 98.71%\n",
      "Batch 35, Loss: 0.006725, Accuracy: 98.75%\n",
      "Batch 36, Loss: 0.030946, Accuracy: 98.74%\n",
      "Batch 37, Loss: 0.082722, Accuracy: 98.69%\n",
      "Batch 38, Loss: 0.012290, Accuracy: 98.73%\n",
      "Batch 39, Loss: 0.096033, Accuracy: 98.68%\n",
      "Batch 40, Loss: 0.003417, Accuracy: 98.71%\n",
      "Batch 41, Loss: 0.016632, Accuracy: 98.74%\n",
      "Batch 42, Loss: 0.040063, Accuracy: 98.74%\n",
      "Batch 43, Loss: 0.029323, Accuracy: 98.73%\n",
      "Batch 44, Loss: 0.092922, Accuracy: 98.72%\n",
      "Batch 45, Loss: 0.046774, Accuracy: 98.72%\n",
      "Batch 46, Loss: 0.013394, Accuracy: 98.74%\n",
      "Batch 47, Loss: 0.065444, Accuracy: 98.74%\n",
      "Batch 48, Loss: 0.121203, Accuracy: 98.70%\n",
      "Batch 49, Loss: 0.020468, Accuracy: 98.72%\n",
      "Batch 50, Loss: 0.081487, Accuracy: 98.66%\n",
      "Batch 51, Loss: 0.028030, Accuracy: 98.65%\n",
      "Batch 52, Loss: 0.010705, Accuracy: 98.68%\n",
      "Batch 53, Loss: 0.089986, Accuracy: 98.67%\n",
      "Batch 54, Loss: 0.095997, Accuracy: 98.64%\n",
      "Batch 55, Loss: 0.071946, Accuracy: 98.64%\n",
      "Batch 56, Loss: 0.050971, Accuracy: 98.60%\n",
      "Batch 57, Loss: 0.118804, Accuracy: 98.55%\n",
      "Batch 58, Loss: 0.076090, Accuracy: 98.55%\n",
      "Batch 59, Loss: 0.178379, Accuracy: 98.49%\n",
      "Batch 60, Loss: 0.063360, Accuracy: 98.49%\n",
      "Batch 61, Loss: 0.026370, Accuracy: 98.49%\n",
      "Batch 62, Loss: 0.042609, Accuracy: 98.46%\n",
      "Batch 63, Loss: 0.004562, Accuracy: 98.49%\n",
      "Batch 64, Loss: 0.027374, Accuracy: 98.49%\n",
      "Batch 65, Loss: 0.066158, Accuracy: 98.46%\n",
      "Batch 66, Loss: 0.017685, Accuracy: 98.48%\n",
      "Batch 67, Loss: 0.119971, Accuracy: 98.41%\n",
      "Batch 68, Loss: 0.023836, Accuracy: 98.41%\n",
      "Batch 69, Loss: 0.013938, Accuracy: 98.44%\n",
      "Batch 70, Loss: 0.031452, Accuracy: 98.46%\n",
      "Batch 71, Loss: 0.029705, Accuracy: 98.46%\n",
      "Batch 72, Loss: 0.010713, Accuracy: 98.48%\n",
      "Batch 73, Loss: 0.015622, Accuracy: 98.48%\n",
      "Batch 74, Loss: 0.014789, Accuracy: 98.50%\n",
      "Batch 75, Loss: 0.042960, Accuracy: 98.50%\n",
      "Batch 76, Loss: 0.024464, Accuracy: 98.50%\n",
      "Batch 77, Loss: 0.003043, Accuracy: 98.52%\n",
      "Batch 78, Loss: 0.036191, Accuracy: 98.52%\n",
      "Batch 79, Loss: 0.001790, Accuracy: 98.54%\n",
      "Batch 80, Loss: 0.207179, Accuracy: 98.52%\n",
      "Batch 81, Loss: 0.026835, Accuracy: 98.51%\n",
      "Batch 82, Loss: 0.004042, Accuracy: 98.53%\n",
      "Batch 83, Loss: 0.045292, Accuracy: 98.53%\n",
      "Batch 84, Loss: 0.002454, Accuracy: 98.55%\n",
      "Batch 85, Loss: 0.066558, Accuracy: 98.53%\n",
      "Batch 86, Loss: 0.004769, Accuracy: 98.55%\n",
      "Batch 87, Loss: 0.026321, Accuracy: 98.55%\n",
      "Batch 88, Loss: 0.002605, Accuracy: 98.56%\n",
      "Batch 89, Loss: 0.043423, Accuracy: 98.56%\n",
      "Batch 90, Loss: 0.025853, Accuracy: 98.58%\n",
      "Batch 91, Loss: 0.076367, Accuracy: 98.56%\n",
      "Batch 92, Loss: 0.038917, Accuracy: 98.56%\n",
      "Batch 93, Loss: 0.040443, Accuracy: 98.54%\n",
      "Batch 94, Loss: 0.201352, Accuracy: 98.50%\n",
      "Batch 95, Loss: 0.007035, Accuracy: 98.52%\n",
      "Batch 96, Loss: 0.022035, Accuracy: 98.54%\n",
      "Batch 97, Loss: 0.046267, Accuracy: 98.53%\n",
      "Batch 98, Loss: 0.015750, Accuracy: 98.53%\n",
      "Batch 99, Loss: 0.111297, Accuracy: 98.48%\n",
      "Batch 100, Loss: 0.226124, Accuracy: 98.45%\n",
      "Batch 101, Loss: 0.055097, Accuracy: 98.45%\n",
      "Batch 102, Loss: 0.049809, Accuracy: 98.44%\n",
      "Batch 103, Loss: 0.077331, Accuracy: 98.42%\n",
      "Batch 104, Loss: 0.028543, Accuracy: 98.42%\n",
      "Batch 105, Loss: 0.050125, Accuracy: 98.42%\n",
      "Batch 106, Loss: 0.170679, Accuracy: 98.39%\n",
      "Batch 107, Loss: 0.007205, Accuracy: 98.41%\n",
      "Batch 108, Loss: 0.011026, Accuracy: 98.42%\n",
      "Batch 109, Loss: 0.053483, Accuracy: 98.42%\n",
      "Batch 110, Loss: 0.173634, Accuracy: 98.39%\n",
      "Batch 111, Loss: 0.011475, Accuracy: 98.41%\n",
      "Batch 112, Loss: 0.005679, Accuracy: 98.42%\n",
      "Batch 113, Loss: 0.031811, Accuracy: 98.42%\n",
      "Batch 114, Loss: 0.050986, Accuracy: 98.42%\n",
      "Batch 115, Loss: 0.021830, Accuracy: 98.44%\n",
      "Batch 116, Loss: 0.177174, Accuracy: 98.42%\n",
      "Batch 117, Loss: 0.048228, Accuracy: 98.42%\n",
      "Batch 118, Loss: 0.065584, Accuracy: 98.42%\n",
      "Batch 119, Loss: 0.030532, Accuracy: 98.42%\n",
      "Batch 120, Loss: 0.026403, Accuracy: 98.42%\n",
      "Batch 121, Loss: 0.050298, Accuracy: 98.41%\n",
      "Batch 122, Loss: 0.023386, Accuracy: 98.41%\n",
      "Batch 123, Loss: 0.063217, Accuracy: 98.39%\n",
      "Batch 124, Loss: 0.046726, Accuracy: 98.39%\n",
      "Batch 125, Loss: 0.009337, Accuracy: 98.40%\n",
      "Batch 126, Loss: 0.151312, Accuracy: 98.36%\n",
      "Batch 127, Loss: 0.009834, Accuracy: 98.38%\n",
      "Batch 128, Loss: 0.082301, Accuracy: 98.36%\n",
      "Batch 129, Loss: 0.024700, Accuracy: 98.36%\n",
      "Batch 130, Loss: 0.032000, Accuracy: 98.37%\n",
      "Batch 131, Loss: 0.112171, Accuracy: 98.35%\n",
      "Batch 132, Loss: 0.043929, Accuracy: 98.34%\n",
      "Batch 133, Loss: 0.088503, Accuracy: 98.34%\n",
      "Batch 134, Loss: 0.014403, Accuracy: 98.36%\n",
      "Batch 135, Loss: 0.091979, Accuracy: 98.33%\n",
      "Batch 136, Loss: 0.100074, Accuracy: 98.31%\n",
      "Batch 137, Loss: 0.031244, Accuracy: 98.31%\n",
      "Batch 138, Loss: 0.030931, Accuracy: 98.31%\n",
      "Batch 139, Loss: 0.033779, Accuracy: 98.31%\n",
      "Batch 140, Loss: 0.009572, Accuracy: 98.33%\n",
      "Batch 141, Loss: 0.027161, Accuracy: 98.33%\n",
      "Batch 142, Loss: 0.118904, Accuracy: 98.32%\n",
      "Batch 143, Loss: 0.187306, Accuracy: 98.28%\n",
      "Batch 144, Loss: 0.014480, Accuracy: 98.30%\n",
      "Batch 145, Loss: 0.039262, Accuracy: 98.30%\n",
      "Batch 146, Loss: 0.004187, Accuracy: 98.31%\n",
      "Batch 147, Loss: 0.005517, Accuracy: 98.32%\n",
      "Batch 148, Loss: 0.045177, Accuracy: 98.32%\n",
      "Batch 149, Loss: 0.060466, Accuracy: 98.31%\n",
      "Batch 150, Loss: 0.116905, Accuracy: 98.29%\n",
      "Batch 151, Loss: 0.037662, Accuracy: 98.29%\n",
      "Batch 152, Loss: 0.030154, Accuracy: 98.29%\n",
      "Batch 153, Loss: 0.074948, Accuracy: 98.28%\n",
      "Batch 154, Loss: 0.033579, Accuracy: 98.29%\n",
      "Batch 155, Loss: 0.003289, Accuracy: 98.30%\n",
      "Batch 156, Loss: 0.006598, Accuracy: 98.31%\n",
      "Batch 157, Loss: 0.047171, Accuracy: 98.30%\n",
      "Batch 158, Loss: 0.073714, Accuracy: 98.29%\n",
      "Batch 159, Loss: 0.024410, Accuracy: 98.29%\n",
      "Batch 160, Loss: 0.029838, Accuracy: 98.29%\n",
      "Batch 161, Loss: 0.073438, Accuracy: 98.28%\n",
      "Batch 162, Loss: 0.059838, Accuracy: 98.28%\n",
      "Batch 163, Loss: 0.098054, Accuracy: 98.27%\n",
      "Batch 164, Loss: 0.003323, Accuracy: 98.29%\n",
      "Batch 165, Loss: 0.181655, Accuracy: 98.26%\n",
      "Batch 166, Loss: 0.021160, Accuracy: 98.27%\n",
      "Batch 167, Loss: 0.036301, Accuracy: 98.27%\n",
      "Batch 168, Loss: 0.039160, Accuracy: 98.27%\n",
      "Batch 169, Loss: 0.024173, Accuracy: 98.28%\n",
      "Batch 170, Loss: 0.025624, Accuracy: 98.28%\n",
      "Batch 171, Loss: 0.168968, Accuracy: 98.27%\n",
      "Batch 172, Loss: 0.028263, Accuracy: 98.27%\n",
      "Batch 173, Loss: 0.005078, Accuracy: 98.28%\n",
      "Batch 174, Loss: 0.024547, Accuracy: 98.28%\n",
      "Batch 175, Loss: 0.143806, Accuracy: 98.28%\n",
      "Batch 176, Loss: 0.005381, Accuracy: 98.29%\n",
      "Batch 177, Loss: 0.008071, Accuracy: 98.30%\n",
      "Batch 178, Loss: 0.040918, Accuracy: 98.29%\n",
      "Batch 179, Loss: 0.164283, Accuracy: 98.26%\n",
      "Batch 180, Loss: 0.032086, Accuracy: 98.26%\n",
      "Batch 181, Loss: 0.067732, Accuracy: 98.26%\n",
      "Batch 182, Loss: 0.026933, Accuracy: 98.26%\n",
      "Batch 183, Loss: 0.029246, Accuracy: 98.26%\n",
      "Batch 184, Loss: 0.028877, Accuracy: 98.26%\n",
      "Batch 185, Loss: 0.023485, Accuracy: 98.26%\n",
      "Batch 186, Loss: 0.003725, Accuracy: 98.27%\n",
      "Batch 187, Loss: 0.096842, Accuracy: 98.25%\n",
      "Batch 188, Loss: 0.090289, Accuracy: 98.25%\n",
      "Batch 189, Loss: 0.075656, Accuracy: 98.25%\n",
      "Batch 190, Loss: 0.150411, Accuracy: 98.23%\n",
      "Batch 191, Loss: 0.074556, Accuracy: 98.22%\n",
      "Batch 192, Loss: 0.046152, Accuracy: 98.23%\n",
      "Batch 193, Loss: 0.060102, Accuracy: 98.22%\n",
      "Batch 194, Loss: 0.107323, Accuracy: 98.20%\n",
      "Batch 195, Loss: 0.020143, Accuracy: 98.21%\n",
      "Batch 196, Loss: 0.029699, Accuracy: 98.21%\n",
      "Batch 197, Loss: 0.014816, Accuracy: 98.22%\n",
      "Batch 198, Loss: 0.033349, Accuracy: 98.22%\n",
      "Batch 199, Loss: 0.010386, Accuracy: 98.23%\n",
      "Batch 200, Loss: 0.044735, Accuracy: 98.24%\n",
      "Batch 201, Loss: 0.144530, Accuracy: 98.23%\n",
      "Batch 202, Loss: 0.022422, Accuracy: 98.23%\n",
      "Batch 203, Loss: 0.016932, Accuracy: 98.24%\n",
      "Batch 204, Loss: 0.034309, Accuracy: 98.24%\n",
      "Batch 205, Loss: 0.090358, Accuracy: 98.22%\n",
      "Batch 206, Loss: 0.013514, Accuracy: 98.23%\n",
      "Batch 207, Loss: 0.004947, Accuracy: 98.24%\n",
      "Batch 208, Loss: 0.074699, Accuracy: 98.23%\n",
      "Batch 209, Loss: 0.070406, Accuracy: 98.24%\n",
      "Batch 210, Loss: 0.074001, Accuracy: 98.24%\n",
      "Batch 211, Loss: 0.036165, Accuracy: 98.24%\n",
      "Batch 212, Loss: 0.124265, Accuracy: 98.22%\n",
      "Batch 213, Loss: 0.055409, Accuracy: 98.22%\n",
      "Training - Epoch 8, Loss: 0.050517, Accuracy: 98.22%\n",
      "Validation Batch 1, Loss: 0.045923, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.228332, Accuracy: 94.53%\n",
      "Validation Batch 3, Loss: 0.195402, Accuracy: 94.27%\n",
      "Validation Batch 4, Loss: 0.102673, Accuracy: 94.53%\n",
      "Validation Batch 5, Loss: 0.026027, Accuracy: 95.31%\n",
      "Validation Batch 6, Loss: 0.052921, Accuracy: 95.57%\n",
      "Validation Batch 7, Loss: 0.012385, Accuracy: 96.21%\n",
      "Validation Batch 8, Loss: 0.013733, Accuracy: 96.68%\n",
      "Validation Batch 9, Loss: 0.041465, Accuracy: 97.05%\n",
      "Validation Batch 10, Loss: 0.010284, Accuracy: 97.34%\n",
      "Validation Batch 11, Loss: 0.282686, Accuracy: 97.02%\n",
      "Validation Batch 12, Loss: 0.051974, Accuracy: 97.14%\n",
      "Validation Batch 13, Loss: 0.148147, Accuracy: 97.00%\n",
      "Validation Batch 14, Loss: 0.145517, Accuracy: 96.99%\n",
      "Validation Batch 15, Loss: 0.228128, Accuracy: 96.67%\n",
      "Validation Batch 16, Loss: 0.187235, Accuracy: 96.58%\n",
      "Validation Batch 17, Loss: 0.130553, Accuracy: 96.60%\n",
      "Validation Batch 18, Loss: 0.097287, Accuracy: 96.53%\n",
      "Validation Batch 19, Loss: 0.258912, Accuracy: 96.22%\n",
      "Validation Batch 20, Loss: 0.021621, Accuracy: 96.41%\n",
      "Validation Batch 21, Loss: 0.260894, Accuracy: 96.28%\n",
      "Validation Batch 22, Loss: 0.095810, Accuracy: 96.24%\n",
      "Validation Batch 23, Loss: 0.029969, Accuracy: 96.40%\n",
      "Validation Batch 24, Loss: 0.141864, Accuracy: 96.42%\n",
      "Validation Batch 25, Loss: 0.046846, Accuracy: 96.50%\n",
      "Validation Batch 26, Loss: 0.127698, Accuracy: 96.45%\n",
      "Validation Batch 27, Loss: 0.009272, Accuracy: 96.54%\n",
      "Validation - Epoch 8, Loss: 0.110873, Accuracy: 96.54%\n",
      "Patience—1\n",
      "Epoch 9\n",
      "Batch 1, Loss: 0.141831, Accuracy: 95.31%\n",
      "Batch 2, Loss: 0.245435, Accuracy: 93.75%\n",
      "Batch 3, Loss: 0.018616, Accuracy: 95.31%\n",
      "Batch 4, Loss: 0.004189, Accuracy: 96.48%\n",
      "Batch 5, Loss: 0.027337, Accuracy: 97.19%\n",
      "Batch 6, Loss: 0.105741, Accuracy: 97.40%\n",
      "Batch 7, Loss: 0.101289, Accuracy: 97.10%\n",
      "Batch 8, Loss: 0.139739, Accuracy: 96.68%\n",
      "Batch 9, Loss: 0.103905, Accuracy: 96.53%\n",
      "Batch 10, Loss: 0.023013, Accuracy: 96.72%\n",
      "Batch 11, Loss: 0.040025, Accuracy: 97.02%\n",
      "Batch 12, Loss: 0.092612, Accuracy: 97.01%\n",
      "Batch 13, Loss: 0.121779, Accuracy: 96.75%\n",
      "Batch 14, Loss: 0.048632, Accuracy: 96.76%\n",
      "Batch 15, Loss: 0.031184, Accuracy: 96.88%\n",
      "Batch 16, Loss: 0.052389, Accuracy: 96.88%\n",
      "Batch 17, Loss: 0.045703, Accuracy: 96.97%\n",
      "Batch 18, Loss: 0.017832, Accuracy: 97.05%\n",
      "Batch 19, Loss: 0.130356, Accuracy: 96.96%\n",
      "Batch 20, Loss: 0.104772, Accuracy: 96.95%\n",
      "Batch 21, Loss: 0.053437, Accuracy: 97.02%\n",
      "Batch 22, Loss: 0.044712, Accuracy: 97.09%\n",
      "Batch 23, Loss: 0.013762, Accuracy: 97.21%\n",
      "Batch 24, Loss: 0.060156, Accuracy: 97.27%\n",
      "Batch 25, Loss: 0.160994, Accuracy: 97.19%\n",
      "Batch 26, Loss: 0.076692, Accuracy: 97.12%\n",
      "Batch 27, Loss: 0.005442, Accuracy: 97.22%\n",
      "Batch 28, Loss: 0.014528, Accuracy: 97.32%\n",
      "Batch 29, Loss: 0.068751, Accuracy: 97.31%\n",
      "Batch 30, Loss: 0.033439, Accuracy: 97.34%\n",
      "Batch 31, Loss: 0.058107, Accuracy: 97.38%\n",
      "Batch 32, Loss: 0.017986, Accuracy: 97.46%\n",
      "Batch 33, Loss: 0.050820, Accuracy: 97.49%\n",
      "Batch 34, Loss: 0.019112, Accuracy: 97.52%\n",
      "Batch 35, Loss: 0.044711, Accuracy: 97.54%\n",
      "Batch 36, Loss: 0.139999, Accuracy: 97.44%\n",
      "Batch 37, Loss: 0.006206, Accuracy: 97.51%\n",
      "Batch 38, Loss: 0.067177, Accuracy: 97.49%\n",
      "Batch 39, Loss: 0.008346, Accuracy: 97.56%\n",
      "Batch 40, Loss: 0.006011, Accuracy: 97.62%\n",
      "Batch 41, Loss: 0.021206, Accuracy: 97.64%\n",
      "Batch 42, Loss: 0.028858, Accuracy: 97.66%\n",
      "Batch 43, Loss: 0.021951, Accuracy: 97.71%\n",
      "Batch 44, Loss: 0.093944, Accuracy: 97.66%\n",
      "Batch 45, Loss: 0.005364, Accuracy: 97.71%\n",
      "Batch 46, Loss: 0.022435, Accuracy: 97.72%\n",
      "Batch 47, Loss: 0.036698, Accuracy: 97.71%\n",
      "Batch 48, Loss: 0.164323, Accuracy: 97.62%\n",
      "Batch 49, Loss: 0.083693, Accuracy: 97.64%\n",
      "Batch 50, Loss: 0.046556, Accuracy: 97.62%\n",
      "Batch 51, Loss: 0.012193, Accuracy: 97.67%\n",
      "Batch 52, Loss: 0.004661, Accuracy: 97.72%\n",
      "Batch 53, Loss: 0.042927, Accuracy: 97.70%\n",
      "Batch 54, Loss: 0.111256, Accuracy: 97.66%\n",
      "Batch 55, Loss: 0.009770, Accuracy: 97.70%\n",
      "Batch 56, Loss: 0.016306, Accuracy: 97.74%\n",
      "Batch 57, Loss: 0.008548, Accuracy: 97.78%\n",
      "Batch 58, Loss: 0.008459, Accuracy: 97.82%\n",
      "Batch 59, Loss: 0.039290, Accuracy: 97.80%\n",
      "Batch 60, Loss: 0.026661, Accuracy: 97.81%\n",
      "Batch 61, Loss: 0.032330, Accuracy: 97.82%\n",
      "Batch 62, Loss: 0.037229, Accuracy: 97.83%\n",
      "Batch 63, Loss: 0.009034, Accuracy: 97.87%\n",
      "Batch 64, Loss: 0.005571, Accuracy: 97.90%\n",
      "Batch 65, Loss: 0.020572, Accuracy: 97.91%\n",
      "Batch 66, Loss: 0.004121, Accuracy: 97.94%\n",
      "Batch 67, Loss: 0.014215, Accuracy: 97.97%\n",
      "Batch 68, Loss: 0.018874, Accuracy: 97.98%\n",
      "Batch 69, Loss: 0.052652, Accuracy: 97.94%\n",
      "Batch 70, Loss: 0.017799, Accuracy: 97.95%\n",
      "Batch 71, Loss: 0.038836, Accuracy: 97.95%\n",
      "Batch 72, Loss: 0.041276, Accuracy: 97.94%\n",
      "Batch 73, Loss: 0.003516, Accuracy: 97.97%\n",
      "Batch 74, Loss: 0.002560, Accuracy: 97.99%\n",
      "Batch 75, Loss: 0.105119, Accuracy: 98.00%\n",
      "Batch 76, Loss: 0.161292, Accuracy: 97.96%\n",
      "Batch 77, Loss: 0.018997, Accuracy: 97.99%\n",
      "Batch 78, Loss: 0.025058, Accuracy: 98.00%\n",
      "Batch 79, Loss: 0.060547, Accuracy: 98.00%\n",
      "Batch 80, Loss: 0.036718, Accuracy: 98.01%\n",
      "Batch 81, Loss: 0.031097, Accuracy: 97.99%\n",
      "Batch 82, Loss: 0.036869, Accuracy: 98.00%\n",
      "Batch 83, Loss: 0.037957, Accuracy: 98.00%\n",
      "Batch 84, Loss: 0.015081, Accuracy: 98.01%\n",
      "Batch 85, Loss: 0.006507, Accuracy: 98.03%\n",
      "Batch 86, Loss: 0.162607, Accuracy: 98.04%\n",
      "Batch 87, Loss: 0.080563, Accuracy: 98.04%\n",
      "Batch 88, Loss: 0.019116, Accuracy: 98.05%\n",
      "Batch 89, Loss: 0.012015, Accuracy: 98.07%\n",
      "Batch 90, Loss: 0.007824, Accuracy: 98.09%\n",
      "Batch 91, Loss: 0.132436, Accuracy: 98.09%\n",
      "Batch 92, Loss: 0.252199, Accuracy: 98.06%\n",
      "Batch 93, Loss: 0.215883, Accuracy: 98.03%\n",
      "Batch 94, Loss: 0.004841, Accuracy: 98.06%\n",
      "Batch 95, Loss: 0.012137, Accuracy: 98.08%\n",
      "Batch 96, Loss: 0.024875, Accuracy: 98.08%\n",
      "Batch 97, Loss: 0.024379, Accuracy: 98.08%\n",
      "Batch 98, Loss: 0.039472, Accuracy: 98.09%\n",
      "Batch 99, Loss: 0.126248, Accuracy: 98.06%\n",
      "Batch 100, Loss: 0.139590, Accuracy: 98.03%\n",
      "Batch 101, Loss: 0.285436, Accuracy: 98.00%\n",
      "Batch 102, Loss: 0.045158, Accuracy: 97.99%\n",
      "Batch 103, Loss: 0.019003, Accuracy: 98.01%\n",
      "Batch 104, Loss: 0.050066, Accuracy: 98.02%\n",
      "Batch 105, Loss: 0.115122, Accuracy: 97.99%\n",
      "Batch 106, Loss: 0.086167, Accuracy: 97.98%\n",
      "Batch 107, Loss: 0.110734, Accuracy: 97.96%\n",
      "Batch 108, Loss: 0.206361, Accuracy: 97.90%\n",
      "Batch 109, Loss: 0.032651, Accuracy: 97.91%\n",
      "Batch 110, Loss: 0.018620, Accuracy: 97.93%\n",
      "Batch 111, Loss: 0.083684, Accuracy: 97.92%\n",
      "Batch 112, Loss: 0.068228, Accuracy: 97.91%\n",
      "Batch 113, Loss: 0.083775, Accuracy: 97.90%\n",
      "Batch 114, Loss: 0.028286, Accuracy: 97.92%\n",
      "Batch 115, Loss: 0.096554, Accuracy: 97.89%\n",
      "Batch 116, Loss: 0.123127, Accuracy: 97.86%\n",
      "Batch 117, Loss: 0.066271, Accuracy: 97.86%\n",
      "Batch 118, Loss: 0.017916, Accuracy: 97.88%\n",
      "Batch 119, Loss: 0.164700, Accuracy: 97.87%\n",
      "Batch 120, Loss: 0.192592, Accuracy: 97.84%\n",
      "Batch 121, Loss: 0.022381, Accuracy: 97.86%\n",
      "Batch 122, Loss: 0.125332, Accuracy: 97.85%\n",
      "Batch 123, Loss: 0.059444, Accuracy: 97.85%\n",
      "Batch 124, Loss: 0.018401, Accuracy: 97.87%\n",
      "Batch 125, Loss: 0.012665, Accuracy: 97.89%\n",
      "Batch 126, Loss: 0.071516, Accuracy: 97.88%\n",
      "Batch 127, Loss: 0.025818, Accuracy: 97.90%\n",
      "Batch 128, Loss: 0.068396, Accuracy: 97.90%\n",
      "Batch 129, Loss: 0.026614, Accuracy: 97.92%\n",
      "Batch 130, Loss: 0.038417, Accuracy: 97.92%\n",
      "Batch 131, Loss: 0.139271, Accuracy: 97.91%\n",
      "Batch 132, Loss: 0.051763, Accuracy: 97.92%\n",
      "Batch 133, Loss: 0.012193, Accuracy: 97.93%\n",
      "Batch 134, Loss: 0.015278, Accuracy: 97.95%\n",
      "Batch 135, Loss: 0.030319, Accuracy: 97.96%\n",
      "Batch 136, Loss: 0.014751, Accuracy: 97.98%\n",
      "Batch 137, Loss: 0.016560, Accuracy: 97.99%\n",
      "Batch 138, Loss: 0.017514, Accuracy: 98.01%\n",
      "Batch 139, Loss: 0.005749, Accuracy: 98.02%\n",
      "Batch 140, Loss: 0.009041, Accuracy: 98.04%\n",
      "Batch 141, Loss: 0.015458, Accuracy: 98.05%\n",
      "Batch 142, Loss: 0.008075, Accuracy: 98.06%\n",
      "Batch 143, Loss: 0.006882, Accuracy: 98.08%\n",
      "Batch 144, Loss: 0.012462, Accuracy: 98.09%\n",
      "Batch 145, Loss: 0.024406, Accuracy: 98.10%\n",
      "Batch 146, Loss: 0.039515, Accuracy: 98.11%\n",
      "Batch 147, Loss: 0.014435, Accuracy: 98.12%\n",
      "Batch 148, Loss: 0.011584, Accuracy: 98.13%\n",
      "Batch 149, Loss: 0.076921, Accuracy: 98.13%\n",
      "Batch 150, Loss: 0.003913, Accuracy: 98.15%\n",
      "Batch 151, Loss: 0.003802, Accuracy: 98.16%\n",
      "Batch 152, Loss: 0.033991, Accuracy: 98.16%\n",
      "Batch 153, Loss: 0.002571, Accuracy: 98.17%\n",
      "Batch 154, Loss: 0.092717, Accuracy: 98.16%\n",
      "Batch 155, Loss: 0.007352, Accuracy: 98.18%\n",
      "Batch 156, Loss: 0.015593, Accuracy: 98.18%\n",
      "Batch 157, Loss: 0.024916, Accuracy: 98.18%\n",
      "Batch 158, Loss: 0.067403, Accuracy: 98.18%\n",
      "Batch 159, Loss: 0.025307, Accuracy: 98.19%\n",
      "Batch 160, Loss: 0.257405, Accuracy: 98.17%\n",
      "Batch 161, Loss: 0.018600, Accuracy: 98.18%\n",
      "Batch 162, Loss: 0.002232, Accuracy: 98.19%\n",
      "Batch 163, Loss: 0.058746, Accuracy: 98.19%\n",
      "Batch 164, Loss: 0.103975, Accuracy: 98.16%\n",
      "Batch 165, Loss: 0.018083, Accuracy: 98.16%\n",
      "Batch 166, Loss: 0.044966, Accuracy: 98.16%\n",
      "Batch 167, Loss: 0.075106, Accuracy: 98.16%\n",
      "Batch 168, Loss: 0.130379, Accuracy: 98.16%\n",
      "Batch 169, Loss: 0.034944, Accuracy: 98.16%\n",
      "Batch 170, Loss: 0.018539, Accuracy: 98.17%\n",
      "Batch 171, Loss: 0.025693, Accuracy: 98.17%\n",
      "Batch 172, Loss: 0.175976, Accuracy: 98.16%\n",
      "Batch 173, Loss: 0.134282, Accuracy: 98.14%\n",
      "Batch 174, Loss: 0.117848, Accuracy: 98.13%\n",
      "Batch 175, Loss: 0.004849, Accuracy: 98.14%\n",
      "Batch 176, Loss: 0.011083, Accuracy: 98.15%\n",
      "Batch 177, Loss: 0.062456, Accuracy: 98.15%\n",
      "Batch 178, Loss: 0.063384, Accuracy: 98.15%\n",
      "Batch 179, Loss: 0.012838, Accuracy: 98.16%\n",
      "Batch 180, Loss: 0.059375, Accuracy: 98.15%\n",
      "Batch 181, Loss: 0.057495, Accuracy: 98.15%\n",
      "Batch 182, Loss: 0.045843, Accuracy: 98.15%\n",
      "Batch 183, Loss: 0.017516, Accuracy: 98.16%\n",
      "Batch 184, Loss: 0.046801, Accuracy: 98.17%\n",
      "Batch 185, Loss: 0.012604, Accuracy: 98.18%\n",
      "Batch 186, Loss: 0.035933, Accuracy: 98.18%\n",
      "Batch 187, Loss: 0.075161, Accuracy: 98.18%\n",
      "Batch 188, Loss: 0.010354, Accuracy: 98.19%\n",
      "Batch 189, Loss: 0.019737, Accuracy: 98.19%\n",
      "Batch 190, Loss: 0.085034, Accuracy: 98.19%\n",
      "Batch 191, Loss: 0.009566, Accuracy: 98.20%\n",
      "Batch 192, Loss: 0.041428, Accuracy: 98.20%\n",
      "Batch 193, Loss: 0.035730, Accuracy: 98.20%\n",
      "Batch 194, Loss: 0.099350, Accuracy: 98.20%\n",
      "Batch 195, Loss: 0.006697, Accuracy: 98.21%\n",
      "Batch 196, Loss: 0.002914, Accuracy: 98.21%\n",
      "Batch 197, Loss: 0.028781, Accuracy: 98.22%\n",
      "Batch 198, Loss: 0.014778, Accuracy: 98.23%\n",
      "Batch 199, Loss: 0.010097, Accuracy: 98.24%\n",
      "Batch 200, Loss: 0.101608, Accuracy: 98.23%\n",
      "Batch 201, Loss: 0.031942, Accuracy: 98.23%\n",
      "Batch 202, Loss: 0.009278, Accuracy: 98.24%\n",
      "Batch 203, Loss: 0.015857, Accuracy: 98.25%\n",
      "Batch 204, Loss: 0.086995, Accuracy: 98.24%\n",
      "Batch 205, Loss: 0.014590, Accuracy: 98.24%\n",
      "Batch 206, Loss: 0.026973, Accuracy: 98.24%\n",
      "Batch 207, Loss: 0.014159, Accuracy: 98.25%\n",
      "Batch 208, Loss: 0.111461, Accuracy: 98.23%\n",
      "Batch 209, Loss: 0.002289, Accuracy: 98.24%\n",
      "Batch 210, Loss: 0.016560, Accuracy: 98.25%\n",
      "Batch 211, Loss: 0.112081, Accuracy: 98.25%\n",
      "Batch 212, Loss: 0.135491, Accuracy: 98.24%\n",
      "Batch 213, Loss: 0.010993, Accuracy: 98.25%\n",
      "Training - Epoch 9, Loss: 0.053427, Accuracy: 98.25%\n",
      "Validation Batch 1, Loss: 0.092073, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.099882, Accuracy: 96.88%\n",
      "Validation Batch 3, Loss: 0.073951, Accuracy: 96.88%\n",
      "Validation Batch 4, Loss: 0.038434, Accuracy: 97.27%\n",
      "Validation Batch 5, Loss: 0.092053, Accuracy: 96.88%\n",
      "Validation Batch 6, Loss: 0.044274, Accuracy: 97.14%\n",
      "Validation Batch 7, Loss: 0.004158, Accuracy: 97.54%\n",
      "Validation Batch 8, Loss: 0.090280, Accuracy: 97.27%\n",
      "Validation Batch 9, Loss: 0.011247, Accuracy: 97.57%\n",
      "Validation Batch 10, Loss: 0.025286, Accuracy: 97.66%\n",
      "Validation Batch 11, Loss: 0.007486, Accuracy: 97.87%\n",
      "Validation Batch 12, Loss: 0.030960, Accuracy: 97.92%\n",
      "Validation Batch 13, Loss: 0.040381, Accuracy: 97.96%\n",
      "Validation Batch 14, Loss: 0.038278, Accuracy: 97.99%\n",
      "Validation Batch 15, Loss: 0.120882, Accuracy: 97.92%\n",
      "Validation Batch 16, Loss: 0.037417, Accuracy: 97.85%\n",
      "Validation Batch 17, Loss: 0.094247, Accuracy: 97.79%\n",
      "Validation Batch 18, Loss: 0.057482, Accuracy: 97.83%\n",
      "Validation Batch 19, Loss: 0.007643, Accuracy: 97.94%\n",
      "Validation Batch 20, Loss: 0.024722, Accuracy: 97.97%\n",
      "Validation Batch 21, Loss: 0.057695, Accuracy: 97.92%\n",
      "Validation Batch 22, Loss: 0.070581, Accuracy: 97.87%\n",
      "Validation Batch 23, Loss: 0.035967, Accuracy: 97.89%\n",
      "Validation Batch 24, Loss: 0.048250, Accuracy: 97.92%\n",
      "Validation Batch 25, Loss: 0.063632, Accuracy: 97.88%\n",
      "Validation Batch 26, Loss: 0.056514, Accuracy: 97.84%\n",
      "Validation Batch 27, Loss: 0.014933, Accuracy: 97.89%\n",
      "Validation - Epoch 9, Loss: 0.051063, Accuracy: 97.89%\n",
      "Patience—0\n",
      "Epoch 10\n",
      "Batch 1, Loss: 0.017538, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.009899, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.077228, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.004542, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.007409, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.040992, Accuracy: 99.22%\n",
      "Batch 7, Loss: 0.040364, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.064726, Accuracy: 98.63%\n",
      "Batch 9, Loss: 0.107410, Accuracy: 98.61%\n",
      "Batch 10, Loss: 0.100852, Accuracy: 98.44%\n",
      "Batch 11, Loss: 0.049524, Accuracy: 98.44%\n",
      "Batch 12, Loss: 0.028738, Accuracy: 98.44%\n",
      "Batch 13, Loss: 0.020611, Accuracy: 98.56%\n",
      "Batch 14, Loss: 0.014869, Accuracy: 98.66%\n",
      "Batch 15, Loss: 0.084167, Accuracy: 98.54%\n",
      "Batch 16, Loss: 0.003821, Accuracy: 98.63%\n",
      "Batch 17, Loss: 0.011365, Accuracy: 98.71%\n",
      "Batch 18, Loss: 0.032216, Accuracy: 98.70%\n",
      "Batch 19, Loss: 0.028999, Accuracy: 98.77%\n",
      "Batch 20, Loss: 0.009434, Accuracy: 98.83%\n",
      "Batch 21, Loss: 0.063315, Accuracy: 98.81%\n",
      "Batch 22, Loss: 0.075185, Accuracy: 98.72%\n",
      "Batch 23, Loss: 0.143963, Accuracy: 98.64%\n",
      "Batch 24, Loss: 0.029877, Accuracy: 98.63%\n",
      "Batch 25, Loss: 0.037910, Accuracy: 98.62%\n",
      "Batch 26, Loss: 0.013663, Accuracy: 98.68%\n",
      "Batch 27, Loss: 0.027724, Accuracy: 98.67%\n",
      "Batch 28, Loss: 0.099942, Accuracy: 98.55%\n",
      "Batch 29, Loss: 0.083077, Accuracy: 98.49%\n",
      "Batch 30, Loss: 0.014384, Accuracy: 98.54%\n",
      "Batch 31, Loss: 0.010560, Accuracy: 98.59%\n",
      "Batch 32, Loss: 0.011620, Accuracy: 98.63%\n",
      "Batch 33, Loss: 0.010436, Accuracy: 98.67%\n",
      "Batch 34, Loss: 0.002956, Accuracy: 98.71%\n",
      "Batch 35, Loss: 0.057604, Accuracy: 98.71%\n",
      "Batch 36, Loss: 0.072787, Accuracy: 98.65%\n",
      "Batch 37, Loss: 0.031860, Accuracy: 98.65%\n",
      "Batch 38, Loss: 0.004464, Accuracy: 98.68%\n",
      "Batch 39, Loss: 0.047610, Accuracy: 98.68%\n",
      "Batch 40, Loss: 0.031375, Accuracy: 98.67%\n",
      "Batch 41, Loss: 0.128902, Accuracy: 98.63%\n",
      "Batch 42, Loss: 0.007749, Accuracy: 98.66%\n",
      "Batch 43, Loss: 0.002565, Accuracy: 98.69%\n",
      "Batch 44, Loss: 0.002279, Accuracy: 98.72%\n",
      "Batch 45, Loss: 0.003956, Accuracy: 98.75%\n",
      "Batch 46, Loss: 0.192234, Accuracy: 98.68%\n",
      "Batch 47, Loss: 0.104642, Accuracy: 98.67%\n",
      "Batch 48, Loss: 0.125015, Accuracy: 98.67%\n",
      "Batch 49, Loss: 0.017377, Accuracy: 98.69%\n",
      "Batch 50, Loss: 0.091796, Accuracy: 98.69%\n",
      "Batch 51, Loss: 0.109408, Accuracy: 98.68%\n",
      "Batch 52, Loss: 0.081567, Accuracy: 98.65%\n",
      "Batch 53, Loss: 0.017999, Accuracy: 98.67%\n",
      "Batch 54, Loss: 0.065351, Accuracy: 98.67%\n",
      "Batch 55, Loss: 0.009237, Accuracy: 98.69%\n",
      "Batch 56, Loss: 0.025593, Accuracy: 98.72%\n",
      "Batch 57, Loss: 0.038506, Accuracy: 98.71%\n",
      "Batch 58, Loss: 0.016806, Accuracy: 98.71%\n",
      "Batch 59, Loss: 0.014772, Accuracy: 98.73%\n",
      "Batch 60, Loss: 0.010925, Accuracy: 98.75%\n",
      "Batch 61, Loss: 0.023635, Accuracy: 98.74%\n",
      "Batch 62, Loss: 0.016649, Accuracy: 98.74%\n",
      "Batch 63, Loss: 0.027320, Accuracy: 98.76%\n",
      "Batch 64, Loss: 0.074653, Accuracy: 98.73%\n",
      "Batch 65, Loss: 0.028583, Accuracy: 98.73%\n",
      "Batch 66, Loss: 0.055218, Accuracy: 98.72%\n",
      "Batch 67, Loss: 0.055010, Accuracy: 98.69%\n",
      "Batch 68, Loss: 0.004244, Accuracy: 98.71%\n",
      "Batch 69, Loss: 0.006444, Accuracy: 98.73%\n",
      "Batch 70, Loss: 0.010822, Accuracy: 98.75%\n",
      "Batch 71, Loss: 0.087035, Accuracy: 98.75%\n",
      "Batch 72, Loss: 0.059481, Accuracy: 98.72%\n",
      "Batch 73, Loss: 0.012871, Accuracy: 98.74%\n",
      "Batch 74, Loss: 0.011968, Accuracy: 98.75%\n",
      "Batch 75, Loss: 0.005821, Accuracy: 98.77%\n",
      "Batch 76, Loss: 0.009847, Accuracy: 98.79%\n",
      "Batch 77, Loss: 0.010626, Accuracy: 98.80%\n",
      "Batch 78, Loss: 0.035552, Accuracy: 98.80%\n",
      "Batch 79, Loss: 0.009119, Accuracy: 98.81%\n",
      "Batch 80, Loss: 0.005557, Accuracy: 98.83%\n",
      "Batch 81, Loss: 0.008592, Accuracy: 98.84%\n",
      "Batch 82, Loss: 0.002005, Accuracy: 98.86%\n",
      "Batch 83, Loss: 0.003618, Accuracy: 98.87%\n",
      "Batch 84, Loss: 0.051547, Accuracy: 98.85%\n",
      "Batch 85, Loss: 0.060513, Accuracy: 98.82%\n",
      "Batch 86, Loss: 0.009601, Accuracy: 98.84%\n",
      "Batch 87, Loss: 0.042943, Accuracy: 98.83%\n",
      "Batch 88, Loss: 0.063407, Accuracy: 98.83%\n",
      "Batch 89, Loss: 0.006006, Accuracy: 98.84%\n",
      "Batch 90, Loss: 0.018538, Accuracy: 98.85%\n",
      "Batch 91, Loss: 0.004887, Accuracy: 98.87%\n",
      "Batch 92, Loss: 0.010948, Accuracy: 98.88%\n",
      "Batch 93, Loss: 0.026136, Accuracy: 98.89%\n",
      "Batch 94, Loss: 0.019939, Accuracy: 98.89%\n",
      "Batch 95, Loss: 0.013749, Accuracy: 98.90%\n",
      "Batch 96, Loss: 0.017779, Accuracy: 98.91%\n",
      "Batch 97, Loss: 0.040522, Accuracy: 98.89%\n",
      "Batch 98, Loss: 0.011739, Accuracy: 98.90%\n",
      "Batch 99, Loss: 0.017913, Accuracy: 98.91%\n",
      "Batch 100, Loss: 0.003807, Accuracy: 98.92%\n",
      "Batch 101, Loss: 0.031655, Accuracy: 98.92%\n",
      "Batch 102, Loss: 0.002406, Accuracy: 98.93%\n",
      "Batch 103, Loss: 0.045017, Accuracy: 98.91%\n",
      "Batch 104, Loss: 0.006819, Accuracy: 98.92%\n",
      "Batch 105, Loss: 0.088546, Accuracy: 98.91%\n",
      "Batch 106, Loss: 0.008581, Accuracy: 98.92%\n",
      "Batch 107, Loss: 0.104611, Accuracy: 98.90%\n",
      "Batch 108, Loss: 0.005736, Accuracy: 98.91%\n",
      "Batch 109, Loss: 0.040392, Accuracy: 98.91%\n",
      "Batch 110, Loss: 0.002801, Accuracy: 98.92%\n",
      "Batch 111, Loss: 0.039506, Accuracy: 98.90%\n",
      "Batch 112, Loss: 0.010038, Accuracy: 98.91%\n",
      "Batch 113, Loss: 0.079394, Accuracy: 98.88%\n",
      "Batch 114, Loss: 0.071003, Accuracy: 98.86%\n",
      "Batch 115, Loss: 0.020633, Accuracy: 98.87%\n",
      "Batch 116, Loss: 0.074355, Accuracy: 98.84%\n",
      "Batch 117, Loss: 0.072982, Accuracy: 98.82%\n",
      "Batch 118, Loss: 0.077869, Accuracy: 98.81%\n",
      "Batch 119, Loss: 0.004328, Accuracy: 98.82%\n",
      "Batch 120, Loss: 0.165402, Accuracy: 98.79%\n",
      "Batch 121, Loss: 0.120957, Accuracy: 98.76%\n",
      "Batch 122, Loss: 0.130815, Accuracy: 98.73%\n",
      "Batch 123, Loss: 0.006577, Accuracy: 98.74%\n",
      "Batch 124, Loss: 0.002209, Accuracy: 98.75%\n",
      "Batch 125, Loss: 0.067384, Accuracy: 98.74%\n",
      "Batch 126, Loss: 0.032723, Accuracy: 98.74%\n",
      "Batch 127, Loss: 0.075370, Accuracy: 98.73%\n",
      "Batch 128, Loss: 0.092849, Accuracy: 98.72%\n",
      "Batch 129, Loss: 0.023465, Accuracy: 98.72%\n",
      "Batch 130, Loss: 0.008613, Accuracy: 98.73%\n",
      "Batch 131, Loss: 0.105951, Accuracy: 98.72%\n",
      "Batch 132, Loss: 0.051483, Accuracy: 98.72%\n",
      "Batch 133, Loss: 0.003318, Accuracy: 98.73%\n",
      "Batch 134, Loss: 0.033616, Accuracy: 98.73%\n",
      "Batch 135, Loss: 0.018794, Accuracy: 98.74%\n",
      "Batch 136, Loss: 0.016233, Accuracy: 98.74%\n",
      "Batch 137, Loss: 0.032548, Accuracy: 98.73%\n",
      "Batch 138, Loss: 0.135542, Accuracy: 98.72%\n",
      "Batch 139, Loss: 0.005904, Accuracy: 98.73%\n",
      "Batch 140, Loss: 0.017117, Accuracy: 98.74%\n",
      "Batch 141, Loss: 0.024870, Accuracy: 98.74%\n",
      "Batch 142, Loss: 0.009749, Accuracy: 98.75%\n",
      "Batch 143, Loss: 0.015064, Accuracy: 98.75%\n",
      "Batch 144, Loss: 0.028471, Accuracy: 98.75%\n",
      "Batch 145, Loss: 0.028650, Accuracy: 98.75%\n",
      "Batch 146, Loss: 0.106032, Accuracy: 98.74%\n",
      "Batch 147, Loss: 0.003574, Accuracy: 98.75%\n",
      "Batch 148, Loss: 0.105206, Accuracy: 98.74%\n",
      "Batch 149, Loss: 0.081615, Accuracy: 98.73%\n",
      "Batch 150, Loss: 0.083468, Accuracy: 98.73%\n",
      "Batch 151, Loss: 0.047849, Accuracy: 98.73%\n",
      "Batch 152, Loss: 0.015670, Accuracy: 98.74%\n",
      "Batch 153, Loss: 0.005882, Accuracy: 98.74%\n",
      "Batch 154, Loss: 0.052347, Accuracy: 98.74%\n",
      "Batch 155, Loss: 0.045625, Accuracy: 98.74%\n",
      "Batch 156, Loss: 0.016525, Accuracy: 98.74%\n",
      "Batch 157, Loss: 0.011475, Accuracy: 98.75%\n",
      "Batch 158, Loss: 0.109643, Accuracy: 98.72%\n",
      "Batch 159, Loss: 0.011707, Accuracy: 98.73%\n",
      "Batch 160, Loss: 0.025381, Accuracy: 98.73%\n",
      "Batch 161, Loss: 0.032821, Accuracy: 98.73%\n",
      "Batch 162, Loss: 0.010225, Accuracy: 98.74%\n",
      "Batch 163, Loss: 0.012176, Accuracy: 98.74%\n",
      "Batch 164, Loss: 0.108465, Accuracy: 98.72%\n",
      "Batch 165, Loss: 0.055651, Accuracy: 98.71%\n",
      "Batch 166, Loss: 0.039188, Accuracy: 98.71%\n",
      "Batch 167, Loss: 0.001338, Accuracy: 98.72%\n",
      "Batch 168, Loss: 0.005595, Accuracy: 98.73%\n",
      "Batch 169, Loss: 0.004594, Accuracy: 98.73%\n",
      "Batch 170, Loss: 0.120090, Accuracy: 98.72%\n",
      "Batch 171, Loss: 0.035770, Accuracy: 98.72%\n",
      "Batch 172, Loss: 0.087670, Accuracy: 98.71%\n",
      "Batch 173, Loss: 0.053798, Accuracy: 98.70%\n",
      "Batch 174, Loss: 0.048405, Accuracy: 98.70%\n",
      "Batch 175, Loss: 0.013719, Accuracy: 98.71%\n",
      "Batch 176, Loss: 0.057994, Accuracy: 98.70%\n",
      "Batch 177, Loss: 0.061891, Accuracy: 98.70%\n",
      "Batch 178, Loss: 0.009944, Accuracy: 98.71%\n",
      "Batch 179, Loss: 0.032377, Accuracy: 98.70%\n",
      "Batch 180, Loss: 0.008362, Accuracy: 98.71%\n",
      "Batch 181, Loss: 0.013534, Accuracy: 98.71%\n",
      "Batch 182, Loss: 0.014604, Accuracy: 98.72%\n",
      "Batch 183, Loss: 0.014064, Accuracy: 98.73%\n",
      "Batch 184, Loss: 0.021933, Accuracy: 98.73%\n",
      "Batch 185, Loss: 0.002325, Accuracy: 98.74%\n",
      "Batch 186, Loss: 0.007937, Accuracy: 98.75%\n",
      "Batch 187, Loss: 0.056957, Accuracy: 98.75%\n",
      "Batch 188, Loss: 0.019980, Accuracy: 98.75%\n",
      "Batch 189, Loss: 0.019358, Accuracy: 98.76%\n",
      "Batch 190, Loss: 0.004198, Accuracy: 98.77%\n",
      "Batch 191, Loss: 0.003157, Accuracy: 98.77%\n",
      "Batch 192, Loss: 0.013599, Accuracy: 98.78%\n",
      "Batch 193, Loss: 0.023855, Accuracy: 98.78%\n",
      "Batch 194, Loss: 0.025505, Accuracy: 98.78%\n",
      "Batch 195, Loss: 0.005652, Accuracy: 98.78%\n",
      "Batch 196, Loss: 0.003257, Accuracy: 98.79%\n",
      "Batch 197, Loss: 0.004923, Accuracy: 98.79%\n",
      "Batch 198, Loss: 0.019030, Accuracy: 98.80%\n",
      "Batch 199, Loss: 0.001290, Accuracy: 98.81%\n",
      "Batch 200, Loss: 0.000787, Accuracy: 98.81%\n",
      "Batch 201, Loss: 0.001057, Accuracy: 98.82%\n",
      "Batch 202, Loss: 0.028947, Accuracy: 98.82%\n",
      "Batch 203, Loss: 0.000809, Accuracy: 98.82%\n",
      "Batch 204, Loss: 0.012802, Accuracy: 98.82%\n",
      "Batch 205, Loss: 0.032008, Accuracy: 98.82%\n",
      "Batch 206, Loss: 0.013622, Accuracy: 98.82%\n",
      "Batch 207, Loss: 0.002296, Accuracy: 98.82%\n",
      "Batch 208, Loss: 0.000864, Accuracy: 98.83%\n",
      "Batch 209, Loss: 0.000952, Accuracy: 98.83%\n",
      "Batch 210, Loss: 0.016847, Accuracy: 98.83%\n",
      "Batch 211, Loss: 0.009628, Accuracy: 98.84%\n",
      "Batch 212, Loss: 0.009623, Accuracy: 98.84%\n",
      "Batch 213, Loss: 0.004671, Accuracy: 98.85%\n",
      "Training - Epoch 10, Loss: 0.035910, Accuracy: 98.85%\n",
      "Validation Batch 1, Loss: 0.056859, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.006495, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.050962, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.008147, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.003567, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.101684, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.000390, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.002919, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.010365, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.039659, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.070782, Accuracy: 99.29%\n",
      "Validation Batch 12, Loss: 0.042779, Accuracy: 99.09%\n",
      "Validation Batch 13, Loss: 0.006911, Accuracy: 99.16%\n",
      "Validation Batch 14, Loss: 0.005312, Accuracy: 99.22%\n",
      "Validation Batch 15, Loss: 0.010857, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.089947, Accuracy: 99.22%\n",
      "Validation Batch 17, Loss: 0.123327, Accuracy: 99.08%\n",
      "Validation Batch 18, Loss: 0.013428, Accuracy: 99.05%\n",
      "Validation Batch 19, Loss: 0.025188, Accuracy: 99.01%\n",
      "Validation Batch 20, Loss: 0.075889, Accuracy: 98.83%\n",
      "Validation Batch 21, Loss: 0.095440, Accuracy: 98.81%\n",
      "Validation Batch 22, Loss: 0.093313, Accuracy: 98.72%\n",
      "Validation Batch 23, Loss: 0.055766, Accuracy: 98.71%\n",
      "Validation Batch 24, Loss: 0.000978, Accuracy: 98.76%\n",
      "Validation Batch 25, Loss: 0.036558, Accuracy: 98.75%\n",
      "Validation Batch 26, Loss: 0.069510, Accuracy: 98.74%\n",
      "Validation Batch 27, Loss: 0.095146, Accuracy: 98.65%\n",
      "Validation - Epoch 10, Loss: 0.044155, Accuracy: 98.65%\n",
      "Patience—0\n",
      "Epoch 11\n",
      "Batch 1, Loss: 0.001018, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000838, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.003376, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.004884, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.053597, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.007182, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.108147, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.001373, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.007272, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.000651, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.002844, Accuracy: 99.72%\n",
      "Batch 12, Loss: 0.039155, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.010662, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.134136, Accuracy: 99.33%\n",
      "Batch 15, Loss: 0.001866, Accuracy: 99.38%\n",
      "Batch 16, Loss: 0.053660, Accuracy: 99.22%\n",
      "Batch 17, Loss: 0.011459, Accuracy: 99.26%\n",
      "Batch 18, Loss: 0.031611, Accuracy: 99.22%\n",
      "Batch 19, Loss: 0.009309, Accuracy: 99.26%\n",
      "Batch 20, Loss: 0.003137, Accuracy: 99.30%\n",
      "Batch 21, Loss: 0.000568, Accuracy: 99.33%\n",
      "Batch 22, Loss: 0.045975, Accuracy: 99.29%\n",
      "Batch 23, Loss: 0.155240, Accuracy: 99.18%\n",
      "Batch 24, Loss: 0.085481, Accuracy: 99.15%\n",
      "Batch 25, Loss: 0.010449, Accuracy: 99.19%\n",
      "Batch 26, Loss: 0.025204, Accuracy: 99.16%\n",
      "Batch 27, Loss: 0.066549, Accuracy: 99.13%\n",
      "Batch 28, Loss: 0.002914, Accuracy: 99.16%\n",
      "Batch 29, Loss: 0.004376, Accuracy: 99.19%\n",
      "Batch 30, Loss: 0.066503, Accuracy: 99.17%\n",
      "Batch 31, Loss: 0.174471, Accuracy: 99.04%\n",
      "Batch 32, Loss: 0.008105, Accuracy: 99.07%\n",
      "Batch 33, Loss: 0.016921, Accuracy: 99.10%\n",
      "Batch 34, Loss: 0.020746, Accuracy: 99.13%\n",
      "Batch 35, Loss: 0.004948, Accuracy: 99.15%\n",
      "Batch 36, Loss: 0.005287, Accuracy: 99.18%\n",
      "Batch 37, Loss: 0.005075, Accuracy: 99.20%\n",
      "Batch 38, Loss: 0.029894, Accuracy: 99.18%\n",
      "Batch 39, Loss: 0.027457, Accuracy: 99.16%\n",
      "Batch 40, Loss: 0.067356, Accuracy: 99.14%\n",
      "Batch 41, Loss: 0.178450, Accuracy: 99.09%\n",
      "Batch 42, Loss: 0.021029, Accuracy: 99.07%\n",
      "Batch 43, Loss: 0.007649, Accuracy: 99.09%\n",
      "Batch 44, Loss: 0.019445, Accuracy: 99.08%\n",
      "Batch 45, Loss: 0.042095, Accuracy: 99.06%\n",
      "Batch 46, Loss: 0.037933, Accuracy: 99.05%\n",
      "Batch 47, Loss: 0.141332, Accuracy: 99.00%\n",
      "Batch 48, Loss: 0.004143, Accuracy: 99.02%\n",
      "Batch 49, Loss: 0.004273, Accuracy: 99.04%\n",
      "Batch 50, Loss: 0.034938, Accuracy: 99.03%\n",
      "Batch 51, Loss: 0.074417, Accuracy: 99.02%\n",
      "Batch 52, Loss: 0.119767, Accuracy: 99.01%\n",
      "Batch 53, Loss: 0.003421, Accuracy: 99.03%\n",
      "Batch 54, Loss: 0.103533, Accuracy: 99.02%\n",
      "Batch 55, Loss: 0.011918, Accuracy: 99.03%\n",
      "Batch 56, Loss: 0.051385, Accuracy: 99.00%\n",
      "Batch 57, Loss: 0.013225, Accuracy: 99.01%\n",
      "Batch 58, Loss: 0.011024, Accuracy: 99.03%\n",
      "Batch 59, Loss: 0.009384, Accuracy: 99.05%\n",
      "Batch 60, Loss: 0.029424, Accuracy: 99.01%\n",
      "Batch 61, Loss: 0.013134, Accuracy: 99.03%\n",
      "Batch 62, Loss: 0.004678, Accuracy: 99.04%\n",
      "Batch 63, Loss: 0.008139, Accuracy: 99.06%\n",
      "Batch 64, Loss: 0.003642, Accuracy: 99.07%\n",
      "Batch 65, Loss: 0.011147, Accuracy: 99.09%\n",
      "Batch 66, Loss: 0.037953, Accuracy: 99.08%\n",
      "Batch 67, Loss: 0.023560, Accuracy: 99.07%\n",
      "Batch 68, Loss: 0.020657, Accuracy: 99.06%\n",
      "Batch 69, Loss: 0.012982, Accuracy: 99.07%\n",
      "Batch 70, Loss: 0.003684, Accuracy: 99.08%\n",
      "Batch 71, Loss: 0.026895, Accuracy: 99.08%\n",
      "Batch 72, Loss: 0.096118, Accuracy: 99.07%\n",
      "Batch 73, Loss: 0.016719, Accuracy: 99.06%\n",
      "Batch 74, Loss: 0.003836, Accuracy: 99.07%\n",
      "Batch 75, Loss: 0.012374, Accuracy: 99.08%\n",
      "Batch 76, Loss: 0.003116, Accuracy: 99.10%\n",
      "Batch 77, Loss: 0.003354, Accuracy: 99.11%\n",
      "Batch 78, Loss: 0.002921, Accuracy: 99.12%\n",
      "Batch 79, Loss: 0.004796, Accuracy: 99.13%\n",
      "Batch 80, Loss: 0.001825, Accuracy: 99.14%\n",
      "Batch 81, Loss: 0.082177, Accuracy: 99.11%\n",
      "Batch 82, Loss: 0.009564, Accuracy: 99.12%\n",
      "Batch 83, Loss: 0.001212, Accuracy: 99.13%\n",
      "Batch 84, Loss: 0.004952, Accuracy: 99.14%\n",
      "Batch 85, Loss: 0.003989, Accuracy: 99.15%\n",
      "Batch 86, Loss: 0.001278, Accuracy: 99.16%\n",
      "Batch 87, Loss: 0.046890, Accuracy: 99.16%\n",
      "Batch 88, Loss: 0.006103, Accuracy: 99.17%\n",
      "Batch 89, Loss: 0.058866, Accuracy: 99.14%\n",
      "Batch 90, Loss: 0.002665, Accuracy: 99.15%\n",
      "Batch 91, Loss: 0.049756, Accuracy: 99.12%\n",
      "Batch 92, Loss: 0.009616, Accuracy: 99.13%\n",
      "Batch 93, Loss: 0.003078, Accuracy: 99.14%\n",
      "Batch 94, Loss: 0.001393, Accuracy: 99.15%\n",
      "Batch 95, Loss: 0.019475, Accuracy: 99.14%\n",
      "Batch 96, Loss: 0.001391, Accuracy: 99.15%\n",
      "Batch 97, Loss: 0.002481, Accuracy: 99.16%\n",
      "Batch 98, Loss: 0.004418, Accuracy: 99.17%\n",
      "Batch 99, Loss: 0.008239, Accuracy: 99.18%\n",
      "Batch 100, Loss: 0.001994, Accuracy: 99.19%\n",
      "Batch 101, Loss: 0.001333, Accuracy: 99.20%\n",
      "Batch 102, Loss: 0.017620, Accuracy: 99.19%\n",
      "Batch 103, Loss: 0.003755, Accuracy: 99.20%\n",
      "Batch 104, Loss: 0.002820, Accuracy: 99.20%\n",
      "Batch 105, Loss: 0.001517, Accuracy: 99.21%\n",
      "Batch 106, Loss: 0.001091, Accuracy: 99.22%\n",
      "Batch 107, Loss: 0.023939, Accuracy: 99.21%\n",
      "Batch 108, Loss: 0.010599, Accuracy: 99.22%\n",
      "Batch 109, Loss: 0.024247, Accuracy: 99.21%\n",
      "Batch 110, Loss: 0.052147, Accuracy: 99.20%\n",
      "Batch 111, Loss: 0.003351, Accuracy: 99.21%\n",
      "Batch 112, Loss: 0.001487, Accuracy: 99.22%\n",
      "Batch 113, Loss: 0.001192, Accuracy: 99.23%\n",
      "Batch 114, Loss: 0.000693, Accuracy: 99.23%\n",
      "Batch 115, Loss: 0.013832, Accuracy: 99.24%\n",
      "Batch 116, Loss: 0.048325, Accuracy: 99.23%\n",
      "Batch 117, Loss: 0.000992, Accuracy: 99.24%\n",
      "Batch 118, Loss: 0.005313, Accuracy: 99.25%\n",
      "Batch 119, Loss: 0.000280, Accuracy: 99.25%\n",
      "Batch 120, Loss: 0.000849, Accuracy: 99.26%\n",
      "Batch 121, Loss: 0.001203, Accuracy: 99.26%\n",
      "Batch 122, Loss: 0.110894, Accuracy: 99.26%\n",
      "Batch 123, Loss: 0.004151, Accuracy: 99.26%\n",
      "Batch 124, Loss: 0.055701, Accuracy: 99.26%\n",
      "Batch 125, Loss: 0.005015, Accuracy: 99.26%\n",
      "Batch 126, Loss: 0.011303, Accuracy: 99.27%\n",
      "Batch 127, Loss: 0.000598, Accuracy: 99.27%\n",
      "Batch 128, Loss: 0.004813, Accuracy: 99.28%\n",
      "Batch 129, Loss: 0.001143, Accuracy: 99.29%\n",
      "Batch 130, Loss: 0.077587, Accuracy: 99.27%\n",
      "Batch 131, Loss: 0.004694, Accuracy: 99.27%\n",
      "Batch 132, Loss: 0.008416, Accuracy: 99.28%\n",
      "Batch 133, Loss: 0.012443, Accuracy: 99.28%\n",
      "Batch 134, Loss: 0.001758, Accuracy: 99.29%\n",
      "Batch 135, Loss: 0.004791, Accuracy: 99.29%\n",
      "Batch 136, Loss: 0.014713, Accuracy: 99.30%\n",
      "Batch 137, Loss: 0.002305, Accuracy: 99.30%\n",
      "Batch 138, Loss: 0.005747, Accuracy: 99.31%\n",
      "Batch 139, Loss: 0.035107, Accuracy: 99.29%\n",
      "Batch 140, Loss: 0.044006, Accuracy: 99.29%\n",
      "Batch 141, Loss: 0.000533, Accuracy: 99.29%\n",
      "Batch 142, Loss: 0.000856, Accuracy: 99.30%\n",
      "Batch 143, Loss: 0.005566, Accuracy: 99.30%\n",
      "Batch 144, Loss: 0.004675, Accuracy: 99.31%\n",
      "Batch 145, Loss: 0.067613, Accuracy: 99.28%\n",
      "Batch 146, Loss: 0.031737, Accuracy: 99.26%\n",
      "Batch 147, Loss: 0.073964, Accuracy: 99.26%\n",
      "Batch 148, Loss: 0.001130, Accuracy: 99.26%\n",
      "Batch 149, Loss: 0.066074, Accuracy: 99.26%\n",
      "Batch 150, Loss: 0.066603, Accuracy: 99.25%\n",
      "Batch 151, Loss: 0.045859, Accuracy: 99.23%\n",
      "Batch 152, Loss: 0.010833, Accuracy: 99.24%\n",
      "Batch 153, Loss: 0.086190, Accuracy: 99.23%\n",
      "Batch 154, Loss: 0.053446, Accuracy: 99.23%\n",
      "Batch 155, Loss: 0.003101, Accuracy: 99.23%\n",
      "Batch 156, Loss: 0.022918, Accuracy: 99.23%\n",
      "Batch 157, Loss: 0.050577, Accuracy: 99.22%\n",
      "Batch 158, Loss: 0.036376, Accuracy: 99.22%\n",
      "Batch 159, Loss: 0.009132, Accuracy: 99.22%\n",
      "Batch 160, Loss: 0.266327, Accuracy: 99.19%\n",
      "Batch 161, Loss: 0.070940, Accuracy: 99.18%\n",
      "Batch 162, Loss: 0.015540, Accuracy: 99.18%\n",
      "Batch 163, Loss: 0.016957, Accuracy: 99.19%\n",
      "Batch 164, Loss: 0.046547, Accuracy: 99.18%\n",
      "Batch 165, Loss: 0.016595, Accuracy: 99.18%\n",
      "Batch 166, Loss: 0.022578, Accuracy: 99.17%\n",
      "Batch 167, Loss: 0.092154, Accuracy: 99.15%\n",
      "Batch 168, Loss: 0.130023, Accuracy: 99.13%\n",
      "Batch 169, Loss: 0.062607, Accuracy: 99.12%\n",
      "Batch 170, Loss: 0.011103, Accuracy: 99.13%\n",
      "Batch 171, Loss: 0.019412, Accuracy: 99.12%\n",
      "Batch 172, Loss: 0.045800, Accuracy: 99.11%\n",
      "Batch 173, Loss: 0.067492, Accuracy: 99.10%\n",
      "Batch 174, Loss: 0.026675, Accuracy: 99.10%\n",
      "Batch 175, Loss: 0.017362, Accuracy: 99.11%\n",
      "Batch 176, Loss: 0.079732, Accuracy: 99.10%\n",
      "Batch 177, Loss: 0.074204, Accuracy: 99.09%\n",
      "Batch 178, Loss: 0.054677, Accuracy: 99.09%\n",
      "Batch 179, Loss: 0.159873, Accuracy: 99.07%\n",
      "Batch 180, Loss: 0.019603, Accuracy: 99.08%\n",
      "Batch 181, Loss: 0.076834, Accuracy: 99.07%\n",
      "Batch 182, Loss: 0.060256, Accuracy: 99.06%\n",
      "Batch 183, Loss: 0.013075, Accuracy: 99.06%\n",
      "Batch 184, Loss: 0.021838, Accuracy: 99.06%\n",
      "Batch 185, Loss: 0.023059, Accuracy: 99.06%\n",
      "Batch 186, Loss: 0.047311, Accuracy: 99.05%\n",
      "Batch 187, Loss: 0.060335, Accuracy: 99.04%\n",
      "Batch 188, Loss: 0.213964, Accuracy: 99.02%\n",
      "Batch 189, Loss: 0.006835, Accuracy: 99.02%\n",
      "Batch 190, Loss: 0.030630, Accuracy: 99.02%\n",
      "Batch 191, Loss: 0.034335, Accuracy: 99.02%\n",
      "Batch 192, Loss: 0.003417, Accuracy: 99.02%\n",
      "Batch 193, Loss: 0.002875, Accuracy: 99.03%\n",
      "Batch 194, Loss: 0.015292, Accuracy: 99.03%\n",
      "Batch 195, Loss: 0.046717, Accuracy: 99.01%\n",
      "Batch 196, Loss: 0.002685, Accuracy: 99.02%\n",
      "Batch 197, Loss: 0.001172, Accuracy: 99.02%\n",
      "Batch 198, Loss: 0.009697, Accuracy: 99.03%\n",
      "Batch 199, Loss: 0.003343, Accuracy: 99.03%\n",
      "Batch 200, Loss: 0.001651, Accuracy: 99.04%\n",
      "Batch 201, Loss: 0.003428, Accuracy: 99.04%\n",
      "Batch 202, Loss: 0.015352, Accuracy: 99.05%\n",
      "Batch 203, Loss: 0.071665, Accuracy: 99.05%\n",
      "Batch 204, Loss: 0.006025, Accuracy: 99.05%\n",
      "Batch 205, Loss: 0.140754, Accuracy: 99.05%\n",
      "Batch 206, Loss: 0.040107, Accuracy: 99.04%\n",
      "Batch 207, Loss: 0.009109, Accuracy: 99.04%\n",
      "Batch 208, Loss: 0.077503, Accuracy: 99.02%\n",
      "Batch 209, Loss: 0.009441, Accuracy: 99.03%\n",
      "Batch 210, Loss: 0.059479, Accuracy: 99.03%\n",
      "Batch 211, Loss: 0.006113, Accuracy: 99.03%\n",
      "Batch 212, Loss: 0.019656, Accuracy: 99.03%\n",
      "Batch 213, Loss: 0.057320, Accuracy: 99.02%\n",
      "Training - Epoch 11, Loss: 0.031108, Accuracy: 99.02%\n",
      "Validation Batch 1, Loss: 0.059424, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.027217, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.115067, Accuracy: 97.40%\n",
      "Validation Batch 4, Loss: 0.044726, Accuracy: 97.27%\n",
      "Validation Batch 5, Loss: 0.069798, Accuracy: 97.19%\n",
      "Validation Batch 6, Loss: 0.002496, Accuracy: 97.66%\n",
      "Validation Batch 7, Loss: 0.008212, Accuracy: 97.99%\n",
      "Validation Batch 8, Loss: 0.050619, Accuracy: 97.85%\n",
      "Validation Batch 9, Loss: 0.046816, Accuracy: 97.74%\n",
      "Validation Batch 10, Loss: 0.063322, Accuracy: 97.81%\n",
      "Validation Batch 11, Loss: 0.046580, Accuracy: 97.87%\n",
      "Validation Batch 12, Loss: 0.261262, Accuracy: 97.53%\n",
      "Validation Batch 13, Loss: 0.037960, Accuracy: 97.60%\n",
      "Validation Batch 14, Loss: 0.024605, Accuracy: 97.66%\n",
      "Validation Batch 15, Loss: 0.073424, Accuracy: 97.50%\n",
      "Validation Batch 16, Loss: 0.021265, Accuracy: 97.56%\n",
      "Validation Batch 17, Loss: 0.010244, Accuracy: 97.70%\n",
      "Validation Batch 18, Loss: 0.032965, Accuracy: 97.74%\n",
      "Validation Batch 19, Loss: 0.060035, Accuracy: 97.70%\n",
      "Validation Batch 20, Loss: 0.015759, Accuracy: 97.81%\n",
      "Validation Batch 21, Loss: 0.119147, Accuracy: 97.77%\n",
      "Validation Batch 22, Loss: 0.007155, Accuracy: 97.87%\n",
      "Validation Batch 23, Loss: 0.086943, Accuracy: 97.89%\n",
      "Validation Batch 24, Loss: 0.044108, Accuracy: 97.92%\n",
      "Validation Batch 25, Loss: 0.009753, Accuracy: 98.00%\n",
      "Validation Batch 26, Loss: 0.022835, Accuracy: 98.08%\n",
      "Validation Batch 27, Loss: 0.007810, Accuracy: 98.12%\n",
      "Validation - Epoch 11, Loss: 0.050724, Accuracy: 98.12%\n",
      "Patience—1\n",
      "Epoch 12\n",
      "Batch 1, Loss: 0.030799, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.007491, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.010907, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.013523, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.007363, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.003449, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.001454, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.020004, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.007093, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.001671, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.001055, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.001791, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.023561, Accuracy: 99.76%\n",
      "Batch 14, Loss: 0.004421, Accuracy: 99.78%\n",
      "Batch 15, Loss: 0.005466, Accuracy: 99.79%\n",
      "Batch 16, Loss: 0.045640, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.002708, Accuracy: 99.72%\n",
      "Batch 18, Loss: 0.000979, Accuracy: 99.74%\n",
      "Batch 19, Loss: 0.005586, Accuracy: 99.75%\n",
      "Batch 20, Loss: 0.002435, Accuracy: 99.77%\n",
      "Batch 21, Loss: 0.001224, Accuracy: 99.78%\n",
      "Batch 22, Loss: 0.004436, Accuracy: 99.79%\n",
      "Batch 23, Loss: 0.041052, Accuracy: 99.73%\n",
      "Batch 24, Loss: 0.023418, Accuracy: 99.67%\n",
      "Batch 25, Loss: 0.003130, Accuracy: 99.69%\n",
      "Batch 26, Loss: 0.001678, Accuracy: 99.70%\n",
      "Batch 27, Loss: 0.000735, Accuracy: 99.71%\n",
      "Batch 28, Loss: 0.005215, Accuracy: 99.72%\n",
      "Batch 29, Loss: 0.031500, Accuracy: 99.68%\n",
      "Batch 30, Loss: 0.001715, Accuracy: 99.69%\n",
      "Batch 31, Loss: 0.079125, Accuracy: 99.60%\n",
      "Batch 32, Loss: 0.001472, Accuracy: 99.61%\n",
      "Batch 33, Loss: 0.021083, Accuracy: 99.62%\n",
      "Batch 34, Loss: 0.011060, Accuracy: 99.63%\n",
      "Batch 35, Loss: 0.003514, Accuracy: 99.64%\n",
      "Batch 36, Loss: 0.133322, Accuracy: 99.57%\n",
      "Batch 37, Loss: 0.001672, Accuracy: 99.58%\n",
      "Batch 38, Loss: 0.100779, Accuracy: 99.51%\n",
      "Batch 39, Loss: 0.223295, Accuracy: 99.40%\n",
      "Batch 40, Loss: 0.203435, Accuracy: 99.34%\n",
      "Batch 41, Loss: 0.112565, Accuracy: 99.24%\n",
      "Batch 42, Loss: 0.169939, Accuracy: 99.14%\n",
      "Batch 43, Loss: 0.110393, Accuracy: 99.13%\n",
      "Batch 44, Loss: 0.207829, Accuracy: 99.08%\n",
      "Batch 45, Loss: 0.174245, Accuracy: 98.99%\n",
      "Batch 46, Loss: 0.297601, Accuracy: 98.85%\n",
      "Batch 47, Loss: 0.060136, Accuracy: 98.77%\n",
      "Batch 48, Loss: 0.245549, Accuracy: 98.67%\n",
      "Batch 49, Loss: 0.074752, Accuracy: 98.63%\n",
      "Batch 50, Loss: 0.087902, Accuracy: 98.56%\n",
      "Batch 51, Loss: 0.140561, Accuracy: 98.50%\n",
      "Batch 52, Loss: 0.258716, Accuracy: 98.32%\n",
      "Batch 53, Loss: 0.104222, Accuracy: 98.29%\n",
      "Batch 54, Loss: 0.160561, Accuracy: 98.26%\n",
      "Batch 55, Loss: 0.314273, Accuracy: 98.15%\n",
      "Batch 56, Loss: 0.329752, Accuracy: 97.96%\n",
      "Batch 57, Loss: 0.372708, Accuracy: 97.83%\n",
      "Batch 58, Loss: 0.098482, Accuracy: 97.79%\n",
      "Batch 59, Loss: 0.131757, Accuracy: 97.72%\n",
      "Batch 60, Loss: 0.257230, Accuracy: 97.60%\n",
      "Batch 61, Loss: 0.216657, Accuracy: 97.52%\n",
      "Batch 62, Loss: 0.148826, Accuracy: 97.48%\n",
      "Batch 63, Loss: 0.240438, Accuracy: 97.40%\n",
      "Batch 64, Loss: 0.125751, Accuracy: 97.36%\n",
      "Batch 65, Loss: 0.104890, Accuracy: 97.38%\n",
      "Batch 66, Loss: 0.085719, Accuracy: 97.40%\n",
      "Batch 67, Loss: 0.088940, Accuracy: 97.39%\n",
      "Batch 68, Loss: 0.190108, Accuracy: 97.33%\n",
      "Batch 69, Loss: 0.154297, Accuracy: 97.28%\n",
      "Batch 70, Loss: 0.097323, Accuracy: 97.25%\n",
      "Batch 71, Loss: 0.028295, Accuracy: 97.29%\n",
      "Batch 72, Loss: 0.066143, Accuracy: 97.31%\n",
      "Batch 73, Loss: 0.037048, Accuracy: 97.32%\n",
      "Batch 74, Loss: 0.029432, Accuracy: 97.36%\n",
      "Batch 75, Loss: 0.133653, Accuracy: 97.33%\n",
      "Batch 76, Loss: 0.094046, Accuracy: 97.31%\n",
      "Batch 77, Loss: 0.048271, Accuracy: 97.30%\n",
      "Batch 78, Loss: 0.070440, Accuracy: 97.32%\n",
      "Batch 79, Loss: 0.035891, Accuracy: 97.35%\n",
      "Batch 80, Loss: 0.022812, Accuracy: 97.38%\n",
      "Batch 81, Loss: 0.121741, Accuracy: 97.38%\n",
      "Batch 82, Loss: 0.114373, Accuracy: 97.33%\n",
      "Batch 83, Loss: 0.032446, Accuracy: 97.36%\n",
      "Batch 84, Loss: 0.047238, Accuracy: 97.38%\n",
      "Batch 85, Loss: 0.026723, Accuracy: 97.41%\n",
      "Batch 86, Loss: 0.020348, Accuracy: 97.44%\n",
      "Batch 87, Loss: 0.137456, Accuracy: 97.43%\n",
      "Batch 88, Loss: 0.011019, Accuracy: 97.46%\n",
      "Batch 89, Loss: 0.051110, Accuracy: 97.47%\n",
      "Batch 90, Loss: 0.040826, Accuracy: 97.48%\n",
      "Batch 91, Loss: 0.045537, Accuracy: 97.49%\n",
      "Batch 92, Loss: 0.098440, Accuracy: 97.49%\n",
      "Batch 93, Loss: 0.061146, Accuracy: 97.50%\n",
      "Batch 94, Loss: 0.027439, Accuracy: 97.51%\n",
      "Batch 95, Loss: 0.058701, Accuracy: 97.50%\n",
      "Batch 96, Loss: 0.028593, Accuracy: 97.51%\n",
      "Batch 97, Loss: 0.069766, Accuracy: 97.50%\n",
      "Batch 98, Loss: 0.011999, Accuracy: 97.53%\n",
      "Batch 99, Loss: 0.047260, Accuracy: 97.54%\n",
      "Batch 100, Loss: 0.008911, Accuracy: 97.56%\n",
      "Batch 101, Loss: 0.014705, Accuracy: 97.59%\n",
      "Batch 102, Loss: 0.003931, Accuracy: 97.61%\n",
      "Batch 103, Loss: 0.175914, Accuracy: 97.59%\n",
      "Batch 104, Loss: 0.029689, Accuracy: 97.61%\n",
      "Batch 105, Loss: 0.129548, Accuracy: 97.60%\n",
      "Batch 106, Loss: 0.005195, Accuracy: 97.63%\n",
      "Batch 107, Loss: 0.019663, Accuracy: 97.65%\n",
      "Batch 108, Loss: 0.089154, Accuracy: 97.64%\n",
      "Batch 109, Loss: 0.011949, Accuracy: 97.66%\n",
      "Batch 110, Loss: 0.128214, Accuracy: 97.66%\n",
      "Batch 111, Loss: 0.023186, Accuracy: 97.68%\n",
      "Batch 112, Loss: 0.067596, Accuracy: 97.67%\n",
      "Batch 113, Loss: 0.044323, Accuracy: 97.68%\n",
      "Batch 114, Loss: 0.008813, Accuracy: 97.70%\n",
      "Batch 115, Loss: 0.003405, Accuracy: 97.72%\n",
      "Batch 116, Loss: 0.058640, Accuracy: 97.72%\n",
      "Batch 117, Loss: 0.015114, Accuracy: 97.73%\n",
      "Batch 118, Loss: 0.007775, Accuracy: 97.75%\n",
      "Batch 119, Loss: 0.082441, Accuracy: 97.74%\n",
      "Batch 120, Loss: 0.064594, Accuracy: 97.75%\n",
      "Batch 121, Loss: 0.016686, Accuracy: 97.77%\n",
      "Batch 122, Loss: 0.110733, Accuracy: 97.75%\n",
      "Batch 123, Loss: 0.058418, Accuracy: 97.74%\n",
      "Batch 124, Loss: 0.051898, Accuracy: 97.74%\n",
      "Batch 125, Loss: 0.052625, Accuracy: 97.75%\n",
      "Batch 126, Loss: 0.017653, Accuracy: 97.77%\n",
      "Batch 127, Loss: 0.115429, Accuracy: 97.76%\n",
      "Batch 128, Loss: 0.018739, Accuracy: 97.78%\n",
      "Batch 129, Loss: 0.021436, Accuracy: 97.80%\n",
      "Batch 130, Loss: 0.006443, Accuracy: 97.81%\n",
      "Batch 131, Loss: 0.069460, Accuracy: 97.81%\n",
      "Batch 132, Loss: 0.014158, Accuracy: 97.82%\n",
      "Batch 133, Loss: 0.033778, Accuracy: 97.83%\n",
      "Batch 134, Loss: 0.040216, Accuracy: 97.82%\n",
      "Batch 135, Loss: 0.040725, Accuracy: 97.82%\n",
      "Batch 136, Loss: 0.020683, Accuracy: 97.84%\n",
      "Batch 137, Loss: 0.007336, Accuracy: 97.86%\n",
      "Batch 138, Loss: 0.004403, Accuracy: 97.87%\n",
      "Batch 139, Loss: 0.027797, Accuracy: 97.88%\n",
      "Batch 140, Loss: 0.004311, Accuracy: 97.89%\n",
      "Batch 141, Loss: 0.103663, Accuracy: 97.89%\n",
      "Batch 142, Loss: 0.023046, Accuracy: 97.90%\n",
      "Batch 143, Loss: 0.127399, Accuracy: 97.88%\n",
      "Batch 144, Loss: 0.003439, Accuracy: 97.89%\n",
      "Batch 145, Loss: 0.008873, Accuracy: 97.91%\n",
      "Batch 146, Loss: 0.007042, Accuracy: 97.92%\n",
      "Batch 147, Loss: 0.025376, Accuracy: 97.94%\n",
      "Batch 148, Loss: 0.011041, Accuracy: 97.95%\n",
      "Batch 149, Loss: 0.049795, Accuracy: 97.94%\n",
      "Batch 150, Loss: 0.009737, Accuracy: 97.96%\n",
      "Batch 151, Loss: 0.006350, Accuracy: 97.97%\n",
      "Batch 152, Loss: 0.006000, Accuracy: 97.99%\n",
      "Batch 153, Loss: 0.003793, Accuracy: 98.00%\n",
      "Batch 154, Loss: 0.002666, Accuracy: 98.01%\n",
      "Batch 155, Loss: 0.006388, Accuracy: 98.02%\n",
      "Batch 156, Loss: 0.009989, Accuracy: 98.04%\n",
      "Batch 157, Loss: 0.013045, Accuracy: 98.05%\n",
      "Batch 158, Loss: 0.001019, Accuracy: 98.06%\n",
      "Batch 159, Loss: 0.022149, Accuracy: 98.06%\n",
      "Batch 160, Loss: 0.003059, Accuracy: 98.08%\n",
      "Batch 161, Loss: 0.002038, Accuracy: 98.09%\n",
      "Batch 162, Loss: 0.005296, Accuracy: 98.10%\n",
      "Batch 163, Loss: 0.008822, Accuracy: 98.11%\n",
      "Batch 164, Loss: 0.008748, Accuracy: 98.12%\n",
      "Batch 165, Loss: 0.012022, Accuracy: 98.13%\n",
      "Batch 166, Loss: 0.001612, Accuracy: 98.15%\n",
      "Batch 167, Loss: 0.000936, Accuracy: 98.16%\n",
      "Batch 168, Loss: 0.004746, Accuracy: 98.17%\n",
      "Batch 169, Loss: 0.094918, Accuracy: 98.17%\n",
      "Batch 170, Loss: 0.047827, Accuracy: 98.17%\n",
      "Batch 171, Loss: 0.002008, Accuracy: 98.18%\n",
      "Batch 172, Loss: 0.030445, Accuracy: 98.17%\n",
      "Batch 173, Loss: 0.000944, Accuracy: 98.18%\n",
      "Batch 174, Loss: 0.000632, Accuracy: 98.20%\n",
      "Batch 175, Loss: 0.001813, Accuracy: 98.21%\n",
      "Batch 176, Loss: 0.001455, Accuracy: 98.22%\n",
      "Batch 177, Loss: 0.043085, Accuracy: 98.22%\n",
      "Batch 178, Loss: 0.011185, Accuracy: 98.23%\n",
      "Batch 179, Loss: 0.002965, Accuracy: 98.24%\n",
      "Batch 180, Loss: 0.082738, Accuracy: 98.24%\n",
      "Batch 181, Loss: 0.003906, Accuracy: 98.25%\n",
      "Batch 182, Loss: 0.098632, Accuracy: 98.25%\n",
      "Batch 183, Loss: 0.000769, Accuracy: 98.26%\n",
      "Batch 184, Loss: 0.013087, Accuracy: 98.27%\n",
      "Batch 185, Loss: 0.125617, Accuracy: 98.26%\n",
      "Batch 186, Loss: 0.001333, Accuracy: 98.27%\n",
      "Batch 187, Loss: 0.015889, Accuracy: 98.28%\n",
      "Batch 188, Loss: 0.008018, Accuracy: 98.29%\n",
      "Batch 189, Loss: 0.005464, Accuracy: 98.30%\n",
      "Batch 190, Loss: 0.018163, Accuracy: 98.30%\n",
      "Batch 191, Loss: 0.065682, Accuracy: 98.29%\n",
      "Batch 192, Loss: 0.004834, Accuracy: 98.30%\n",
      "Batch 193, Loss: 0.001854, Accuracy: 98.31%\n",
      "Batch 194, Loss: 0.006548, Accuracy: 98.32%\n",
      "Batch 195, Loss: 0.062719, Accuracy: 98.32%\n",
      "Batch 196, Loss: 0.062275, Accuracy: 98.32%\n",
      "Batch 197, Loss: 0.011401, Accuracy: 98.33%\n",
      "Batch 198, Loss: 0.070821, Accuracy: 98.32%\n",
      "Batch 199, Loss: 0.007911, Accuracy: 98.33%\n",
      "Batch 200, Loss: 0.018276, Accuracy: 98.33%\n",
      "Batch 201, Loss: 0.001196, Accuracy: 98.34%\n",
      "Batch 202, Loss: 0.005142, Accuracy: 98.34%\n",
      "Batch 203, Loss: 0.001680, Accuracy: 98.35%\n",
      "Batch 204, Loss: 0.062012, Accuracy: 98.35%\n",
      "Batch 205, Loss: 0.003828, Accuracy: 98.36%\n",
      "Batch 206, Loss: 0.042052, Accuracy: 98.36%\n",
      "Batch 207, Loss: 0.016044, Accuracy: 98.37%\n",
      "Batch 208, Loss: 0.002402, Accuracy: 98.38%\n",
      "Batch 209, Loss: 0.019452, Accuracy: 98.39%\n",
      "Batch 210, Loss: 0.019279, Accuracy: 98.39%\n",
      "Batch 211, Loss: 0.043393, Accuracy: 98.39%\n",
      "Batch 212, Loss: 0.044184, Accuracy: 98.39%\n",
      "Batch 213, Loss: 0.004503, Accuracy: 98.39%\n",
      "Training - Epoch 12, Loss: 0.052924, Accuracy: 98.39%\n",
      "Validation Batch 1, Loss: 0.022932, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.010772, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.054627, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.005437, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.067306, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.002834, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.004142, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.005859, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.008860, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.021199, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.046511, Accuracy: 99.29%\n",
      "Validation Batch 12, Loss: 0.025751, Accuracy: 99.22%\n",
      "Validation Batch 13, Loss: 0.020434, Accuracy: 99.16%\n",
      "Validation Batch 14, Loss: 0.002698, Accuracy: 99.22%\n",
      "Validation Batch 15, Loss: 0.028872, Accuracy: 99.17%\n",
      "Validation Batch 16, Loss: 0.074187, Accuracy: 99.12%\n",
      "Validation Batch 17, Loss: 0.083552, Accuracy: 98.99%\n",
      "Validation Batch 18, Loss: 0.026966, Accuracy: 98.96%\n",
      "Validation Batch 19, Loss: 0.052925, Accuracy: 98.85%\n",
      "Validation Batch 20, Loss: 0.005725, Accuracy: 98.91%\n",
      "Validation Batch 21, Loss: 0.008469, Accuracy: 98.96%\n",
      "Validation Batch 22, Loss: 0.025342, Accuracy: 98.93%\n",
      "Validation Batch 23, Loss: 0.052333, Accuracy: 98.85%\n",
      "Validation Batch 24, Loss: 0.024077, Accuracy: 98.83%\n",
      "Validation Batch 25, Loss: 0.070983, Accuracy: 98.81%\n",
      "Validation Batch 26, Loss: 0.007981, Accuracy: 98.86%\n",
      "Validation Batch 27, Loss: 0.116391, Accuracy: 98.83%\n",
      "Validation - Epoch 12, Loss: 0.032488, Accuracy: 98.83%\n",
      "Patience—0\n",
      "Epoch 13\n",
      "Batch 1, Loss: 0.087642, Accuracy: 95.31%\n",
      "Batch 2, Loss: 0.003327, Accuracy: 97.66%\n",
      "Batch 3, Loss: 0.009746, Accuracy: 98.44%\n",
      "Batch 4, Loss: 0.002635, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.095547, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.084866, Accuracy: 98.44%\n",
      "Batch 7, Loss: 0.016088, Accuracy: 98.44%\n",
      "Batch 8, Loss: 0.003873, Accuracy: 98.63%\n",
      "Batch 9, Loss: 0.001426, Accuracy: 98.78%\n",
      "Batch 10, Loss: 0.004105, Accuracy: 98.91%\n",
      "Batch 11, Loss: 0.003734, Accuracy: 99.01%\n",
      "Batch 12, Loss: 0.004290, Accuracy: 99.09%\n",
      "Batch 13, Loss: 0.062370, Accuracy: 98.92%\n",
      "Batch 14, Loss: 0.033766, Accuracy: 98.77%\n",
      "Batch 15, Loss: 0.032565, Accuracy: 98.75%\n",
      "Batch 16, Loss: 0.002876, Accuracy: 98.83%\n",
      "Batch 17, Loss: 0.013512, Accuracy: 98.90%\n",
      "Batch 18, Loss: 0.002838, Accuracy: 98.96%\n",
      "Batch 19, Loss: 0.035178, Accuracy: 98.85%\n",
      "Batch 20, Loss: 0.049230, Accuracy: 98.83%\n",
      "Batch 21, Loss: 0.002995, Accuracy: 98.88%\n",
      "Batch 22, Loss: 0.002522, Accuracy: 98.93%\n",
      "Batch 23, Loss: 0.238030, Accuracy: 98.85%\n",
      "Batch 24, Loss: 0.036079, Accuracy: 98.83%\n",
      "Batch 25, Loss: 0.001043, Accuracy: 98.88%\n",
      "Batch 26, Loss: 0.006470, Accuracy: 98.92%\n",
      "Batch 27, Loss: 0.000785, Accuracy: 98.96%\n",
      "Batch 28, Loss: 0.005300, Accuracy: 99.00%\n",
      "Batch 29, Loss: 0.125805, Accuracy: 98.98%\n",
      "Batch 30, Loss: 0.003072, Accuracy: 99.01%\n",
      "Batch 31, Loss: 0.086735, Accuracy: 98.99%\n",
      "Batch 32, Loss: 0.005382, Accuracy: 99.02%\n",
      "Batch 33, Loss: 0.003963, Accuracy: 99.05%\n",
      "Batch 34, Loss: 0.004247, Accuracy: 99.08%\n",
      "Batch 35, Loss: 0.037870, Accuracy: 99.06%\n",
      "Batch 36, Loss: 0.003344, Accuracy: 99.09%\n",
      "Batch 37, Loss: 0.004793, Accuracy: 99.11%\n",
      "Batch 38, Loss: 0.017138, Accuracy: 99.14%\n",
      "Batch 39, Loss: 0.002892, Accuracy: 99.16%\n",
      "Batch 40, Loss: 0.002509, Accuracy: 99.18%\n",
      "Batch 41, Loss: 0.002801, Accuracy: 99.20%\n",
      "Batch 42, Loss: 0.023287, Accuracy: 99.18%\n",
      "Batch 43, Loss: 0.001899, Accuracy: 99.20%\n",
      "Batch 44, Loss: 0.002518, Accuracy: 99.22%\n",
      "Batch 45, Loss: 0.001224, Accuracy: 99.24%\n",
      "Batch 46, Loss: 0.011862, Accuracy: 99.25%\n",
      "Batch 47, Loss: 0.002342, Accuracy: 99.27%\n",
      "Batch 48, Loss: 0.018309, Accuracy: 99.28%\n",
      "Batch 49, Loss: 0.038433, Accuracy: 99.27%\n",
      "Batch 50, Loss: 0.010516, Accuracy: 99.28%\n",
      "Batch 51, Loss: 0.035671, Accuracy: 99.26%\n",
      "Batch 52, Loss: 0.001340, Accuracy: 99.28%\n",
      "Batch 53, Loss: 0.004386, Accuracy: 99.29%\n",
      "Batch 54, Loss: 0.095830, Accuracy: 99.25%\n",
      "Batch 55, Loss: 0.031295, Accuracy: 99.23%\n",
      "Batch 56, Loss: 0.057318, Accuracy: 99.19%\n",
      "Batch 57, Loss: 0.007792, Accuracy: 99.21%\n",
      "Batch 58, Loss: 0.063394, Accuracy: 99.16%\n",
      "Batch 59, Loss: 0.001242, Accuracy: 99.18%\n",
      "Batch 60, Loss: 0.039865, Accuracy: 99.14%\n",
      "Batch 61, Loss: 0.003697, Accuracy: 99.15%\n",
      "Batch 62, Loss: 0.005842, Accuracy: 99.17%\n",
      "Batch 63, Loss: 0.052292, Accuracy: 99.16%\n",
      "Batch 64, Loss: 0.018319, Accuracy: 99.17%\n",
      "Batch 65, Loss: 0.072259, Accuracy: 99.16%\n",
      "Batch 66, Loss: 0.069751, Accuracy: 99.15%\n",
      "Batch 67, Loss: 0.003086, Accuracy: 99.16%\n",
      "Batch 68, Loss: 0.019013, Accuracy: 99.15%\n",
      "Batch 69, Loss: 0.003898, Accuracy: 99.16%\n",
      "Batch 70, Loss: 0.002489, Accuracy: 99.17%\n",
      "Batch 71, Loss: 0.051343, Accuracy: 99.16%\n",
      "Batch 72, Loss: 0.006527, Accuracy: 99.18%\n",
      "Batch 73, Loss: 0.009129, Accuracy: 99.19%\n",
      "Batch 74, Loss: 0.022278, Accuracy: 99.18%\n",
      "Batch 75, Loss: 0.003750, Accuracy: 99.19%\n",
      "Batch 76, Loss: 0.012210, Accuracy: 99.20%\n",
      "Batch 77, Loss: 0.008932, Accuracy: 99.21%\n",
      "Batch 78, Loss: 0.007822, Accuracy: 99.22%\n",
      "Batch 79, Loss: 0.006695, Accuracy: 99.23%\n",
      "Batch 80, Loss: 0.104584, Accuracy: 99.20%\n",
      "Batch 81, Loss: 0.005503, Accuracy: 99.21%\n",
      "Batch 82, Loss: 0.009811, Accuracy: 99.22%\n",
      "Batch 83, Loss: 0.005963, Accuracy: 99.23%\n",
      "Batch 84, Loss: 0.010717, Accuracy: 99.24%\n",
      "Batch 85, Loss: 0.005420, Accuracy: 99.25%\n",
      "Batch 86, Loss: 0.009141, Accuracy: 99.26%\n",
      "Batch 87, Loss: 0.039798, Accuracy: 99.23%\n",
      "Batch 88, Loss: 0.015260, Accuracy: 99.22%\n",
      "Batch 89, Loss: 0.001538, Accuracy: 99.23%\n",
      "Batch 90, Loss: 0.002636, Accuracy: 99.24%\n",
      "Batch 91, Loss: 0.011348, Accuracy: 99.24%\n",
      "Batch 92, Loss: 0.001273, Accuracy: 99.25%\n",
      "Batch 93, Loss: 0.000927, Accuracy: 99.26%\n",
      "Batch 94, Loss: 0.002584, Accuracy: 99.27%\n",
      "Batch 95, Loss: 0.001862, Accuracy: 99.28%\n",
      "Batch 96, Loss: 0.020400, Accuracy: 99.27%\n",
      "Batch 97, Loss: 0.000772, Accuracy: 99.28%\n",
      "Batch 98, Loss: 0.028692, Accuracy: 99.27%\n",
      "Batch 99, Loss: 0.072505, Accuracy: 99.26%\n",
      "Batch 100, Loss: 0.001499, Accuracy: 99.27%\n",
      "Batch 101, Loss: 0.005950, Accuracy: 99.27%\n",
      "Batch 102, Loss: 0.003435, Accuracy: 99.28%\n",
      "Batch 103, Loss: 0.033596, Accuracy: 99.27%\n",
      "Batch 104, Loss: 0.003860, Accuracy: 99.28%\n",
      "Batch 105, Loss: 0.032013, Accuracy: 99.27%\n",
      "Batch 106, Loss: 0.007488, Accuracy: 99.28%\n",
      "Batch 107, Loss: 0.006972, Accuracy: 99.28%\n",
      "Batch 108, Loss: 0.002230, Accuracy: 99.29%\n",
      "Batch 109, Loss: 0.004378, Accuracy: 99.30%\n",
      "Batch 110, Loss: 0.052709, Accuracy: 99.29%\n",
      "Batch 111, Loss: 0.086611, Accuracy: 99.28%\n",
      "Batch 112, Loss: 0.007770, Accuracy: 99.29%\n",
      "Batch 113, Loss: 0.030107, Accuracy: 99.28%\n",
      "Batch 114, Loss: 0.002824, Accuracy: 99.29%\n",
      "Batch 115, Loss: 0.016315, Accuracy: 99.28%\n",
      "Batch 116, Loss: 0.004592, Accuracy: 99.29%\n",
      "Batch 117, Loss: 0.004410, Accuracy: 99.29%\n",
      "Batch 118, Loss: 0.011898, Accuracy: 99.30%\n",
      "Batch 119, Loss: 0.010021, Accuracy: 99.30%\n",
      "Batch 120, Loss: 0.026793, Accuracy: 99.30%\n",
      "Batch 121, Loss: 0.101982, Accuracy: 99.29%\n",
      "Batch 122, Loss: 0.144866, Accuracy: 99.26%\n",
      "Batch 123, Loss: 0.043998, Accuracy: 99.25%\n",
      "Batch 124, Loss: 0.046019, Accuracy: 99.23%\n",
      "Batch 125, Loss: 0.034246, Accuracy: 99.22%\n",
      "Batch 126, Loss: 0.030377, Accuracy: 99.22%\n",
      "Batch 127, Loss: 0.042766, Accuracy: 99.20%\n",
      "Batch 128, Loss: 0.057126, Accuracy: 99.19%\n",
      "Batch 129, Loss: 0.103845, Accuracy: 99.16%\n",
      "Batch 130, Loss: 0.035533, Accuracy: 99.17%\n",
      "Batch 131, Loss: 0.097040, Accuracy: 99.14%\n",
      "Batch 132, Loss: 0.019063, Accuracy: 99.15%\n",
      "Batch 133, Loss: 0.004020, Accuracy: 99.15%\n",
      "Batch 134, Loss: 0.060504, Accuracy: 99.14%\n",
      "Batch 135, Loss: 0.030709, Accuracy: 99.13%\n",
      "Batch 136, Loss: 0.257283, Accuracy: 99.08%\n",
      "Batch 137, Loss: 0.031992, Accuracy: 99.08%\n",
      "Batch 138, Loss: 0.010750, Accuracy: 99.08%\n",
      "Batch 139, Loss: 0.030778, Accuracy: 99.08%\n",
      "Batch 140, Loss: 0.014539, Accuracy: 99.08%\n",
      "Batch 141, Loss: 0.005866, Accuracy: 99.09%\n",
      "Batch 142, Loss: 0.002920, Accuracy: 99.10%\n",
      "Batch 143, Loss: 0.011152, Accuracy: 99.10%\n",
      "Batch 144, Loss: 0.002199, Accuracy: 99.11%\n",
      "Batch 145, Loss: 0.039062, Accuracy: 99.09%\n",
      "Batch 146, Loss: 0.022566, Accuracy: 99.10%\n",
      "Batch 147, Loss: 0.022172, Accuracy: 99.10%\n",
      "Batch 148, Loss: 0.004567, Accuracy: 99.10%\n",
      "Batch 149, Loss: 0.008601, Accuracy: 99.11%\n",
      "Batch 150, Loss: 0.004271, Accuracy: 99.11%\n",
      "Batch 151, Loss: 0.007695, Accuracy: 99.12%\n",
      "Batch 152, Loss: 0.009344, Accuracy: 99.13%\n",
      "Batch 153, Loss: 0.002082, Accuracy: 99.13%\n",
      "Batch 154, Loss: 0.008181, Accuracy: 99.14%\n",
      "Batch 155, Loss: 0.002071, Accuracy: 99.14%\n",
      "Batch 156, Loss: 0.007019, Accuracy: 99.15%\n",
      "Batch 157, Loss: 0.114679, Accuracy: 99.12%\n",
      "Batch 158, Loss: 0.001309, Accuracy: 99.13%\n",
      "Batch 159, Loss: 0.005929, Accuracy: 99.14%\n",
      "Batch 160, Loss: 0.004461, Accuracy: 99.14%\n",
      "Batch 161, Loss: 0.024075, Accuracy: 99.14%\n",
      "Batch 162, Loss: 0.021376, Accuracy: 99.13%\n",
      "Batch 163, Loss: 0.072094, Accuracy: 99.13%\n",
      "Batch 164, Loss: 0.007720, Accuracy: 99.13%\n",
      "Batch 165, Loss: 0.006848, Accuracy: 99.14%\n",
      "Batch 166, Loss: 0.004364, Accuracy: 99.14%\n",
      "Batch 167, Loss: 0.062340, Accuracy: 99.13%\n",
      "Batch 168, Loss: 0.019809, Accuracy: 99.14%\n",
      "Batch 169, Loss: 0.006783, Accuracy: 99.14%\n",
      "Batch 170, Loss: 0.029252, Accuracy: 99.14%\n",
      "Batch 171, Loss: 0.001712, Accuracy: 99.14%\n",
      "Batch 172, Loss: 0.003785, Accuracy: 99.15%\n",
      "Batch 173, Loss: 0.003029, Accuracy: 99.15%\n",
      "Batch 174, Loss: 0.015229, Accuracy: 99.15%\n",
      "Batch 175, Loss: 0.013400, Accuracy: 99.15%\n",
      "Batch 176, Loss: 0.021674, Accuracy: 99.16%\n",
      "Batch 177, Loss: 0.001172, Accuracy: 99.16%\n",
      "Batch 178, Loss: 0.002970, Accuracy: 99.17%\n",
      "Batch 179, Loss: 0.044051, Accuracy: 99.16%\n",
      "Batch 180, Loss: 0.041283, Accuracy: 99.16%\n",
      "Batch 181, Loss: 0.064255, Accuracy: 99.15%\n",
      "Batch 182, Loss: 0.001521, Accuracy: 99.16%\n",
      "Batch 183, Loss: 0.002513, Accuracy: 99.16%\n",
      "Batch 184, Loss: 0.000994, Accuracy: 99.17%\n",
      "Batch 185, Loss: 0.000872, Accuracy: 99.17%\n",
      "Batch 186, Loss: 0.002753, Accuracy: 99.18%\n",
      "Batch 187, Loss: 0.001350, Accuracy: 99.18%\n",
      "Batch 188, Loss: 0.176012, Accuracy: 99.15%\n",
      "Batch 189, Loss: 0.034221, Accuracy: 99.15%\n",
      "Batch 190, Loss: 0.008054, Accuracy: 99.15%\n",
      "Batch 191, Loss: 0.005329, Accuracy: 99.16%\n",
      "Batch 192, Loss: 0.004321, Accuracy: 99.16%\n",
      "Batch 193, Loss: 0.001136, Accuracy: 99.17%\n",
      "Batch 194, Loss: 0.004958, Accuracy: 99.17%\n",
      "Batch 195, Loss: 0.004509, Accuracy: 99.17%\n",
      "Batch 196, Loss: 0.009018, Accuracy: 99.18%\n",
      "Batch 197, Loss: 0.003271, Accuracy: 99.18%\n",
      "Batch 198, Loss: 0.009080, Accuracy: 99.19%\n",
      "Batch 199, Loss: 0.001557, Accuracy: 99.19%\n",
      "Batch 200, Loss: 0.015308, Accuracy: 99.19%\n",
      "Batch 201, Loss: 0.011230, Accuracy: 99.19%\n",
      "Batch 202, Loss: 0.077754, Accuracy: 99.18%\n",
      "Batch 203, Loss: 0.008693, Accuracy: 99.18%\n",
      "Batch 204, Loss: 0.020669, Accuracy: 99.19%\n",
      "Batch 205, Loss: 0.003615, Accuracy: 99.19%\n",
      "Batch 206, Loss: 0.013992, Accuracy: 99.20%\n",
      "Batch 207, Loss: 0.002691, Accuracy: 99.20%\n",
      "Batch 208, Loss: 0.054813, Accuracy: 99.19%\n",
      "Batch 209, Loss: 0.023512, Accuracy: 99.19%\n",
      "Batch 210, Loss: 0.003502, Accuracy: 99.19%\n",
      "Batch 211, Loss: 0.033784, Accuracy: 99.19%\n",
      "Batch 212, Loss: 0.002144, Accuracy: 99.19%\n",
      "Batch 213, Loss: 0.002846, Accuracy: 99.19%\n",
      "Training - Epoch 13, Loss: 0.024292, Accuracy: 99.19%\n",
      "Validation Batch 1, Loss: 0.005077, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.041048, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.010652, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.011702, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.004336, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.031366, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.001138, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.001235, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.015109, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.004855, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.016090, Accuracy: 99.57%\n",
      "Validation Batch 12, Loss: 0.003488, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.017808, Accuracy: 99.52%\n",
      "Validation Batch 14, Loss: 0.009352, Accuracy: 99.55%\n",
      "Validation Batch 15, Loss: 0.005485, Accuracy: 99.58%\n",
      "Validation Batch 16, Loss: 0.053657, Accuracy: 99.51%\n",
      "Validation Batch 17, Loss: 0.002299, Accuracy: 99.54%\n",
      "Validation Batch 18, Loss: 0.002376, Accuracy: 99.57%\n",
      "Validation Batch 19, Loss: 0.008879, Accuracy: 99.59%\n",
      "Validation Batch 20, Loss: 0.003543, Accuracy: 99.61%\n",
      "Validation Batch 21, Loss: 0.008255, Accuracy: 99.63%\n",
      "Validation Batch 22, Loss: 0.048162, Accuracy: 99.57%\n",
      "Validation Batch 23, Loss: 0.004394, Accuracy: 99.59%\n",
      "Validation Batch 24, Loss: 0.069404, Accuracy: 99.54%\n",
      "Validation Batch 25, Loss: 0.002356, Accuracy: 99.56%\n",
      "Validation Batch 26, Loss: 0.004879, Accuracy: 99.58%\n",
      "Validation Batch 27, Loss: 0.008557, Accuracy: 99.59%\n",
      "Validation - Epoch 13, Loss: 0.014648, Accuracy: 99.59%\n",
      "Patience—0\n",
      "Epoch 14\n",
      "Batch 1, Loss: 0.001867, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001075, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.038713, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.006183, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.002628, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.004286, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.003112, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.020211, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.005555, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.000923, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.083157, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.042261, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.001364, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.000516, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.000717, Accuracy: 99.58%\n",
      "Batch 16, Loss: 0.002271, Accuracy: 99.61%\n",
      "Batch 17, Loss: 0.035410, Accuracy: 99.54%\n",
      "Batch 18, Loss: 0.001158, Accuracy: 99.57%\n",
      "Batch 19, Loss: 0.001108, Accuracy: 99.59%\n",
      "Batch 20, Loss: 0.079787, Accuracy: 99.53%\n",
      "Batch 21, Loss: 0.006539, Accuracy: 99.55%\n",
      "Batch 22, Loss: 0.001471, Accuracy: 99.57%\n",
      "Batch 23, Loss: 0.001743, Accuracy: 99.59%\n",
      "Batch 24, Loss: 0.002988, Accuracy: 99.61%\n",
      "Batch 25, Loss: 0.008852, Accuracy: 99.62%\n",
      "Batch 26, Loss: 0.064891, Accuracy: 99.58%\n",
      "Batch 27, Loss: 0.002532, Accuracy: 99.59%\n",
      "Batch 28, Loss: 0.001190, Accuracy: 99.61%\n",
      "Batch 29, Loss: 0.033568, Accuracy: 99.57%\n",
      "Batch 30, Loss: 0.001840, Accuracy: 99.58%\n",
      "Batch 31, Loss: 0.019181, Accuracy: 99.60%\n",
      "Batch 32, Loss: 0.005120, Accuracy: 99.61%\n",
      "Batch 33, Loss: 0.009229, Accuracy: 99.62%\n",
      "Batch 34, Loss: 0.043292, Accuracy: 99.54%\n",
      "Batch 35, Loss: 0.003899, Accuracy: 99.55%\n",
      "Batch 36, Loss: 0.024605, Accuracy: 99.52%\n",
      "Batch 37, Loss: 0.001613, Accuracy: 99.54%\n",
      "Batch 38, Loss: 0.027501, Accuracy: 99.51%\n",
      "Batch 39, Loss: 0.005822, Accuracy: 99.52%\n",
      "Batch 40, Loss: 0.030494, Accuracy: 99.49%\n",
      "Batch 41, Loss: 0.001325, Accuracy: 99.50%\n",
      "Batch 42, Loss: 0.005292, Accuracy: 99.52%\n",
      "Batch 43, Loss: 0.116160, Accuracy: 99.49%\n",
      "Batch 44, Loss: 0.017855, Accuracy: 99.50%\n",
      "Batch 45, Loss: 0.000907, Accuracy: 99.51%\n",
      "Batch 46, Loss: 0.078075, Accuracy: 99.46%\n",
      "Batch 47, Loss: 0.013097, Accuracy: 99.47%\n",
      "Batch 48, Loss: 0.014537, Accuracy: 99.45%\n",
      "Batch 49, Loss: 0.013184, Accuracy: 99.43%\n",
      "Batch 50, Loss: 0.009463, Accuracy: 99.44%\n",
      "Batch 51, Loss: 0.001874, Accuracy: 99.45%\n",
      "Batch 52, Loss: 0.010364, Accuracy: 99.46%\n",
      "Batch 53, Loss: 0.133810, Accuracy: 99.41%\n",
      "Batch 54, Loss: 0.002302, Accuracy: 99.42%\n",
      "Batch 55, Loss: 0.011460, Accuracy: 99.43%\n",
      "Batch 56, Loss: 0.002055, Accuracy: 99.44%\n",
      "Batch 57, Loss: 0.010487, Accuracy: 99.45%\n",
      "Batch 58, Loss: 0.001386, Accuracy: 99.46%\n",
      "Batch 59, Loss: 0.009998, Accuracy: 99.47%\n",
      "Batch 60, Loss: 0.022491, Accuracy: 99.45%\n",
      "Batch 61, Loss: 0.032376, Accuracy: 99.44%\n",
      "Batch 62, Loss: 0.002441, Accuracy: 99.45%\n",
      "Batch 63, Loss: 0.000868, Accuracy: 99.45%\n",
      "Batch 64, Loss: 0.009639, Accuracy: 99.46%\n",
      "Batch 65, Loss: 0.084862, Accuracy: 99.42%\n",
      "Batch 66, Loss: 0.001916, Accuracy: 99.43%\n",
      "Batch 67, Loss: 0.040309, Accuracy: 99.42%\n",
      "Batch 68, Loss: 0.052539, Accuracy: 99.40%\n",
      "Batch 69, Loss: 0.003489, Accuracy: 99.41%\n",
      "Batch 70, Loss: 0.007625, Accuracy: 99.42%\n",
      "Batch 71, Loss: 0.000534, Accuracy: 99.43%\n",
      "Batch 72, Loss: 0.003366, Accuracy: 99.44%\n",
      "Batch 73, Loss: 0.019008, Accuracy: 99.44%\n",
      "Batch 74, Loss: 0.009870, Accuracy: 99.45%\n",
      "Batch 75, Loss: 0.004411, Accuracy: 99.46%\n",
      "Batch 76, Loss: 0.005145, Accuracy: 99.47%\n",
      "Batch 77, Loss: 0.017734, Accuracy: 99.45%\n",
      "Batch 78, Loss: 0.033521, Accuracy: 99.42%\n",
      "Batch 79, Loss: 0.002684, Accuracy: 99.43%\n",
      "Batch 80, Loss: 0.002527, Accuracy: 99.43%\n",
      "Batch 81, Loss: 0.002084, Accuracy: 99.44%\n",
      "Batch 82, Loss: 0.001266, Accuracy: 99.45%\n",
      "Batch 83, Loss: 0.008887, Accuracy: 99.45%\n",
      "Batch 84, Loss: 0.001599, Accuracy: 99.46%\n",
      "Batch 85, Loss: 0.044399, Accuracy: 99.45%\n",
      "Batch 86, Loss: 0.026230, Accuracy: 99.44%\n",
      "Batch 87, Loss: 0.001260, Accuracy: 99.44%\n",
      "Batch 88, Loss: 0.000757, Accuracy: 99.45%\n",
      "Batch 89, Loss: 0.010890, Accuracy: 99.46%\n",
      "Batch 90, Loss: 0.017834, Accuracy: 99.44%\n",
      "Batch 91, Loss: 0.050412, Accuracy: 99.43%\n",
      "Batch 92, Loss: 0.015786, Accuracy: 99.42%\n",
      "Batch 93, Loss: 0.009032, Accuracy: 99.43%\n",
      "Batch 94, Loss: 0.004516, Accuracy: 99.43%\n",
      "Batch 95, Loss: 0.005058, Accuracy: 99.44%\n",
      "Batch 96, Loss: 0.003768, Accuracy: 99.45%\n",
      "Batch 97, Loss: 0.008257, Accuracy: 99.45%\n",
      "Batch 98, Loss: 0.001326, Accuracy: 99.46%\n",
      "Batch 99, Loss: 0.006896, Accuracy: 99.46%\n",
      "Batch 100, Loss: 0.013061, Accuracy: 99.45%\n",
      "Batch 101, Loss: 0.009789, Accuracy: 99.46%\n",
      "Batch 102, Loss: 0.025186, Accuracy: 99.45%\n",
      "Batch 103, Loss: 0.020674, Accuracy: 99.44%\n",
      "Batch 104, Loss: 0.014408, Accuracy: 99.43%\n",
      "Batch 105, Loss: 0.011314, Accuracy: 99.43%\n",
      "Batch 106, Loss: 0.123130, Accuracy: 99.40%\n",
      "Batch 107, Loss: 0.000578, Accuracy: 99.40%\n",
      "Batch 108, Loss: 0.001470, Accuracy: 99.41%\n",
      "Batch 109, Loss: 0.008852, Accuracy: 99.41%\n",
      "Batch 110, Loss: 0.001363, Accuracy: 99.42%\n",
      "Batch 111, Loss: 0.106594, Accuracy: 99.41%\n",
      "Batch 112, Loss: 0.115720, Accuracy: 99.39%\n",
      "Batch 113, Loss: 0.016520, Accuracy: 99.39%\n",
      "Batch 114, Loss: 0.004810, Accuracy: 99.40%\n",
      "Batch 115, Loss: 0.003465, Accuracy: 99.40%\n",
      "Batch 116, Loss: 0.121853, Accuracy: 99.39%\n",
      "Batch 117, Loss: 0.187239, Accuracy: 99.36%\n",
      "Batch 118, Loss: 0.172873, Accuracy: 99.31%\n",
      "Batch 119, Loss: 0.004529, Accuracy: 99.32%\n",
      "Batch 120, Loss: 0.095303, Accuracy: 99.30%\n",
      "Batch 121, Loss: 0.011284, Accuracy: 99.30%\n",
      "Batch 122, Loss: 0.012058, Accuracy: 99.31%\n",
      "Batch 123, Loss: 0.170901, Accuracy: 99.29%\n",
      "Batch 124, Loss: 0.070178, Accuracy: 99.27%\n",
      "Batch 125, Loss: 0.017017, Accuracy: 99.28%\n",
      "Batch 126, Loss: 0.007582, Accuracy: 99.28%\n",
      "Batch 127, Loss: 0.013795, Accuracy: 99.29%\n",
      "Batch 128, Loss: 0.041525, Accuracy: 99.28%\n",
      "Batch 129, Loss: 0.063030, Accuracy: 99.27%\n",
      "Batch 130, Loss: 0.005342, Accuracy: 99.28%\n",
      "Batch 131, Loss: 0.008720, Accuracy: 99.28%\n",
      "Batch 132, Loss: 0.012538, Accuracy: 99.29%\n",
      "Batch 133, Loss: 0.023359, Accuracy: 99.28%\n",
      "Batch 134, Loss: 0.014390, Accuracy: 99.29%\n",
      "Batch 135, Loss: 0.051868, Accuracy: 99.28%\n",
      "Batch 136, Loss: 0.006082, Accuracy: 99.29%\n",
      "Batch 137, Loss: 0.008334, Accuracy: 99.29%\n",
      "Batch 138, Loss: 0.027930, Accuracy: 99.29%\n",
      "Batch 139, Loss: 0.014139, Accuracy: 99.29%\n",
      "Batch 140, Loss: 0.025068, Accuracy: 99.30%\n",
      "Batch 141, Loss: 0.019618, Accuracy: 99.30%\n",
      "Batch 142, Loss: 0.014843, Accuracy: 99.31%\n",
      "Batch 143, Loss: 0.028142, Accuracy: 99.30%\n",
      "Batch 144, Loss: 0.039730, Accuracy: 99.29%\n",
      "Batch 145, Loss: 0.010715, Accuracy: 99.30%\n",
      "Batch 146, Loss: 0.040647, Accuracy: 99.29%\n",
      "Batch 147, Loss: 0.078416, Accuracy: 99.29%\n",
      "Batch 148, Loss: 0.039620, Accuracy: 99.28%\n",
      "Batch 149, Loss: 0.021315, Accuracy: 99.29%\n",
      "Batch 150, Loss: 0.028815, Accuracy: 99.27%\n",
      "Batch 151, Loss: 0.076045, Accuracy: 99.25%\n",
      "Batch 152, Loss: 0.076493, Accuracy: 99.25%\n",
      "Batch 153, Loss: 0.033476, Accuracy: 99.24%\n",
      "Batch 154, Loss: 0.096737, Accuracy: 99.23%\n",
      "Batch 155, Loss: 0.003322, Accuracy: 99.23%\n",
      "Batch 156, Loss: 0.015156, Accuracy: 99.24%\n",
      "Batch 157, Loss: 0.182071, Accuracy: 99.20%\n",
      "Batch 158, Loss: 0.014661, Accuracy: 99.21%\n",
      "Batch 159, Loss: 0.032905, Accuracy: 99.20%\n",
      "Batch 160, Loss: 0.074381, Accuracy: 99.20%\n",
      "Batch 161, Loss: 0.039952, Accuracy: 99.19%\n",
      "Batch 162, Loss: 0.043678, Accuracy: 99.19%\n",
      "Batch 163, Loss: 0.051469, Accuracy: 99.19%\n",
      "Batch 164, Loss: 0.100365, Accuracy: 99.17%\n",
      "Batch 165, Loss: 0.012136, Accuracy: 99.18%\n",
      "Batch 166, Loss: 0.125179, Accuracy: 99.15%\n",
      "Batch 167, Loss: 0.009228, Accuracy: 99.16%\n",
      "Batch 168, Loss: 0.039559, Accuracy: 99.15%\n",
      "Batch 169, Loss: 0.047285, Accuracy: 99.15%\n",
      "Batch 170, Loss: 0.058295, Accuracy: 99.15%\n",
      "Batch 171, Loss: 0.070729, Accuracy: 99.14%\n",
      "Batch 172, Loss: 0.071967, Accuracy: 99.13%\n",
      "Batch 173, Loss: 0.086585, Accuracy: 99.10%\n",
      "Batch 174, Loss: 0.003874, Accuracy: 99.10%\n",
      "Batch 175, Loss: 0.021996, Accuracy: 99.11%\n",
      "Batch 176, Loss: 0.003867, Accuracy: 99.11%\n",
      "Batch 177, Loss: 0.030982, Accuracy: 99.11%\n",
      "Batch 178, Loss: 0.014263, Accuracy: 99.11%\n",
      "Batch 179, Loss: 0.045496, Accuracy: 99.11%\n",
      "Batch 180, Loss: 0.093308, Accuracy: 99.10%\n",
      "Batch 181, Loss: 0.004808, Accuracy: 99.10%\n",
      "Batch 182, Loss: 0.025064, Accuracy: 99.11%\n",
      "Batch 183, Loss: 0.055029, Accuracy: 99.10%\n",
      "Batch 184, Loss: 0.157119, Accuracy: 99.09%\n",
      "Batch 185, Loss: 0.070499, Accuracy: 99.08%\n",
      "Batch 186, Loss: 0.021893, Accuracy: 99.08%\n",
      "Batch 187, Loss: 0.117042, Accuracy: 99.06%\n",
      "Batch 188, Loss: 0.011123, Accuracy: 99.06%\n",
      "Batch 189, Loss: 0.061054, Accuracy: 99.06%\n",
      "Batch 190, Loss: 0.025373, Accuracy: 99.05%\n",
      "Batch 191, Loss: 0.178309, Accuracy: 99.03%\n",
      "Batch 192, Loss: 0.022646, Accuracy: 99.03%\n",
      "Batch 193, Loss: 0.005147, Accuracy: 99.04%\n",
      "Batch 194, Loss: 0.040388, Accuracy: 99.03%\n",
      "Batch 195, Loss: 0.068741, Accuracy: 99.01%\n",
      "Batch 196, Loss: 0.010826, Accuracy: 99.02%\n",
      "Batch 197, Loss: 0.025645, Accuracy: 99.02%\n",
      "Batch 198, Loss: 0.064132, Accuracy: 99.01%\n",
      "Batch 199, Loss: 0.006864, Accuracy: 99.02%\n",
      "Batch 200, Loss: 0.048446, Accuracy: 99.02%\n",
      "Batch 201, Loss: 0.002509, Accuracy: 99.02%\n",
      "Batch 202, Loss: 0.008657, Accuracy: 99.03%\n",
      "Batch 203, Loss: 0.003341, Accuracy: 99.03%\n",
      "Batch 204, Loss: 0.024382, Accuracy: 99.03%\n",
      "Batch 205, Loss: 0.007322, Accuracy: 99.03%\n",
      "Batch 206, Loss: 0.011824, Accuracy: 99.04%\n",
      "Batch 207, Loss: 0.087275, Accuracy: 99.03%\n",
      "Batch 208, Loss: 0.054878, Accuracy: 99.02%\n",
      "Batch 209, Loss: 0.067387, Accuracy: 99.01%\n",
      "Batch 210, Loss: 0.004648, Accuracy: 99.02%\n",
      "Batch 211, Loss: 0.027868, Accuracy: 99.02%\n",
      "Batch 212, Loss: 0.005506, Accuracy: 99.02%\n",
      "Batch 213, Loss: 0.036901, Accuracy: 99.02%\n",
      "Training - Epoch 14, Loss: 0.030910, Accuracy: 99.02%\n",
      "Validation Batch 1, Loss: 0.002849, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.130114, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.028415, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.004441, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.053941, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.107212, Accuracy: 98.70%\n",
      "Validation Batch 7, Loss: 0.069055, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.026807, Accuracy: 98.63%\n",
      "Validation Batch 9, Loss: 0.012191, Accuracy: 98.78%\n",
      "Validation Batch 10, Loss: 0.002282, Accuracy: 98.91%\n",
      "Validation Batch 11, Loss: 0.010343, Accuracy: 99.01%\n",
      "Validation Batch 12, Loss: 0.105195, Accuracy: 98.83%\n",
      "Validation Batch 13, Loss: 0.016587, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.206605, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.012505, Accuracy: 98.75%\n",
      "Validation Batch 16, Loss: 0.011939, Accuracy: 98.83%\n",
      "Validation Batch 17, Loss: 0.020359, Accuracy: 98.81%\n",
      "Validation Batch 18, Loss: 0.022257, Accuracy: 98.87%\n",
      "Validation Batch 19, Loss: 0.030352, Accuracy: 98.93%\n",
      "Validation Batch 20, Loss: 0.013921, Accuracy: 98.98%\n",
      "Validation Batch 21, Loss: 0.165865, Accuracy: 98.66%\n",
      "Validation Batch 22, Loss: 0.014807, Accuracy: 98.72%\n",
      "Validation Batch 23, Loss: 0.010416, Accuracy: 98.78%\n",
      "Validation Batch 24, Loss: 0.047180, Accuracy: 98.76%\n",
      "Validation Batch 25, Loss: 0.001309, Accuracy: 98.81%\n",
      "Validation Batch 26, Loss: 0.010621, Accuracy: 98.86%\n",
      "Validation Batch 27, Loss: 0.134793, Accuracy: 98.77%\n",
      "Validation - Epoch 14, Loss: 0.047124, Accuracy: 98.77%\n",
      "Patience—1\n",
      "Epoch 15\n",
      "Batch 1, Loss: 0.044266, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.001752, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.023666, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.082573, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.007967, Accuracy: 99.06%\n",
      "Batch 6, Loss: 0.023894, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.002805, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.012645, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.013021, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.063780, Accuracy: 99.22%\n",
      "Batch 11, Loss: 0.008273, Accuracy: 99.29%\n",
      "Batch 12, Loss: 0.001556, Accuracy: 99.35%\n",
      "Batch 13, Loss: 0.015434, Accuracy: 99.28%\n",
      "Batch 14, Loss: 0.017291, Accuracy: 99.33%\n",
      "Batch 15, Loss: 0.010885, Accuracy: 99.38%\n",
      "Batch 16, Loss: 0.016761, Accuracy: 99.32%\n",
      "Batch 17, Loss: 0.085722, Accuracy: 99.17%\n",
      "Batch 18, Loss: 0.049147, Accuracy: 99.13%\n",
      "Batch 19, Loss: 0.006261, Accuracy: 99.18%\n",
      "Batch 20, Loss: 0.002427, Accuracy: 99.22%\n",
      "Batch 21, Loss: 0.001602, Accuracy: 99.26%\n",
      "Batch 22, Loss: 0.026664, Accuracy: 99.22%\n",
      "Batch 23, Loss: 0.023948, Accuracy: 99.18%\n",
      "Batch 24, Loss: 0.002297, Accuracy: 99.22%\n",
      "Batch 25, Loss: 0.003302, Accuracy: 99.25%\n",
      "Batch 26, Loss: 0.002753, Accuracy: 99.28%\n",
      "Batch 27, Loss: 0.034524, Accuracy: 99.19%\n",
      "Batch 28, Loss: 0.036862, Accuracy: 99.16%\n",
      "Batch 29, Loss: 0.008036, Accuracy: 99.19%\n",
      "Batch 30, Loss: 0.012268, Accuracy: 99.22%\n",
      "Batch 31, Loss: 0.007962, Accuracy: 99.24%\n",
      "Batch 32, Loss: 0.017909, Accuracy: 99.27%\n",
      "Batch 33, Loss: 0.042862, Accuracy: 99.20%\n",
      "Batch 34, Loss: 0.027977, Accuracy: 99.17%\n",
      "Batch 35, Loss: 0.057416, Accuracy: 99.11%\n",
      "Batch 36, Loss: 0.006772, Accuracy: 99.13%\n",
      "Batch 37, Loss: 0.051913, Accuracy: 99.11%\n",
      "Batch 38, Loss: 0.020499, Accuracy: 99.10%\n",
      "Batch 39, Loss: 0.001057, Accuracy: 99.12%\n",
      "Batch 40, Loss: 0.014155, Accuracy: 99.14%\n",
      "Batch 41, Loss: 0.050382, Accuracy: 99.09%\n",
      "Batch 42, Loss: 0.004143, Accuracy: 99.11%\n",
      "Batch 43, Loss: 0.014472, Accuracy: 99.09%\n",
      "Batch 44, Loss: 0.033740, Accuracy: 99.08%\n",
      "Batch 45, Loss: 0.085989, Accuracy: 99.03%\n",
      "Batch 46, Loss: 0.004524, Accuracy: 99.05%\n",
      "Batch 47, Loss: 0.004844, Accuracy: 99.07%\n",
      "Batch 48, Loss: 0.036558, Accuracy: 99.06%\n",
      "Batch 49, Loss: 0.005502, Accuracy: 99.08%\n",
      "Batch 50, Loss: 0.189996, Accuracy: 99.00%\n",
      "Batch 51, Loss: 0.017460, Accuracy: 99.02%\n",
      "Batch 52, Loss: 0.015224, Accuracy: 99.04%\n",
      "Batch 53, Loss: 0.035054, Accuracy: 99.03%\n",
      "Batch 54, Loss: 0.027481, Accuracy: 99.02%\n",
      "Batch 55, Loss: 0.008166, Accuracy: 99.03%\n",
      "Batch 56, Loss: 0.019532, Accuracy: 99.02%\n",
      "Batch 57, Loss: 0.089990, Accuracy: 98.99%\n",
      "Batch 58, Loss: 0.010641, Accuracy: 99.00%\n",
      "Batch 59, Loss: 0.015447, Accuracy: 99.02%\n",
      "Batch 60, Loss: 0.002125, Accuracy: 99.04%\n",
      "Batch 61, Loss: 0.002475, Accuracy: 99.05%\n",
      "Batch 62, Loss: 0.007014, Accuracy: 99.07%\n",
      "Batch 63, Loss: 0.027528, Accuracy: 99.06%\n",
      "Batch 64, Loss: 0.007479, Accuracy: 99.07%\n",
      "Batch 65, Loss: 0.028008, Accuracy: 99.06%\n",
      "Batch 66, Loss: 0.042174, Accuracy: 99.03%\n",
      "Batch 67, Loss: 0.019932, Accuracy: 99.04%\n",
      "Batch 68, Loss: 0.008161, Accuracy: 99.06%\n",
      "Batch 69, Loss: 0.073588, Accuracy: 99.03%\n",
      "Batch 70, Loss: 0.002742, Accuracy: 99.04%\n",
      "Batch 71, Loss: 0.115177, Accuracy: 99.03%\n",
      "Batch 72, Loss: 0.001842, Accuracy: 99.05%\n",
      "Batch 73, Loss: 0.086748, Accuracy: 98.99%\n",
      "Batch 74, Loss: 0.041982, Accuracy: 98.97%\n",
      "Batch 75, Loss: 0.034869, Accuracy: 98.96%\n",
      "Batch 76, Loss: 0.009097, Accuracy: 98.97%\n",
      "Batch 77, Loss: 0.003395, Accuracy: 98.99%\n",
      "Batch 78, Loss: 0.005894, Accuracy: 99.00%\n",
      "Batch 79, Loss: 0.002183, Accuracy: 99.01%\n",
      "Batch 80, Loss: 0.000759, Accuracy: 99.02%\n",
      "Batch 81, Loss: 0.001550, Accuracy: 99.04%\n",
      "Batch 82, Loss: 0.032530, Accuracy: 99.03%\n",
      "Batch 83, Loss: 0.116122, Accuracy: 99.00%\n",
      "Batch 84, Loss: 0.026580, Accuracy: 99.00%\n",
      "Batch 85, Loss: 0.003907, Accuracy: 99.01%\n",
      "Batch 86, Loss: 0.183523, Accuracy: 98.98%\n",
      "Batch 87, Loss: 0.001336, Accuracy: 98.99%\n",
      "Batch 88, Loss: 0.003962, Accuracy: 99.01%\n",
      "Batch 89, Loss: 0.117488, Accuracy: 98.98%\n",
      "Batch 90, Loss: 0.007436, Accuracy: 98.99%\n",
      "Batch 91, Loss: 0.091409, Accuracy: 98.99%\n",
      "Batch 92, Loss: 0.006645, Accuracy: 99.00%\n",
      "Batch 93, Loss: 0.004544, Accuracy: 99.01%\n",
      "Batch 94, Loss: 0.009774, Accuracy: 99.02%\n",
      "Batch 95, Loss: 0.053533, Accuracy: 99.00%\n",
      "Batch 96, Loss: 0.001677, Accuracy: 99.01%\n",
      "Batch 97, Loss: 0.001773, Accuracy: 99.02%\n",
      "Batch 98, Loss: 0.041530, Accuracy: 99.01%\n",
      "Batch 99, Loss: 0.007438, Accuracy: 99.02%\n",
      "Batch 100, Loss: 0.004050, Accuracy: 99.03%\n",
      "Batch 101, Loss: 0.019544, Accuracy: 99.03%\n",
      "Batch 102, Loss: 0.031131, Accuracy: 99.02%\n",
      "Batch 103, Loss: 0.006954, Accuracy: 99.03%\n",
      "Batch 104, Loss: 0.001442, Accuracy: 99.04%\n",
      "Batch 105, Loss: 0.006752, Accuracy: 99.05%\n",
      "Batch 106, Loss: 0.002188, Accuracy: 99.06%\n",
      "Batch 107, Loss: 0.006422, Accuracy: 99.07%\n",
      "Batch 108, Loss: 0.002328, Accuracy: 99.07%\n",
      "Batch 109, Loss: 0.082620, Accuracy: 99.07%\n",
      "Batch 110, Loss: 0.012658, Accuracy: 99.06%\n",
      "Batch 111, Loss: 0.001981, Accuracy: 99.07%\n",
      "Batch 112, Loss: 0.005672, Accuracy: 99.08%\n",
      "Batch 113, Loss: 0.006110, Accuracy: 99.09%\n",
      "Batch 114, Loss: 0.006452, Accuracy: 99.10%\n",
      "Batch 115, Loss: 0.006780, Accuracy: 99.10%\n",
      "Batch 116, Loss: 0.005489, Accuracy: 99.11%\n",
      "Batch 117, Loss: 0.001717, Accuracy: 99.12%\n",
      "Batch 118, Loss: 0.103077, Accuracy: 99.11%\n",
      "Batch 119, Loss: 0.013517, Accuracy: 99.12%\n",
      "Batch 120, Loss: 0.009318, Accuracy: 99.13%\n",
      "Batch 121, Loss: 0.016471, Accuracy: 99.12%\n",
      "Batch 122, Loss: 0.001450, Accuracy: 99.13%\n",
      "Batch 123, Loss: 0.000901, Accuracy: 99.14%\n",
      "Batch 124, Loss: 0.000697, Accuracy: 99.14%\n",
      "Batch 125, Loss: 0.001654, Accuracy: 99.15%\n",
      "Batch 126, Loss: 0.165672, Accuracy: 99.14%\n",
      "Batch 127, Loss: 0.001306, Accuracy: 99.15%\n",
      "Batch 128, Loss: 0.001181, Accuracy: 99.16%\n",
      "Batch 129, Loss: 0.138155, Accuracy: 99.13%\n",
      "Batch 130, Loss: 0.008372, Accuracy: 99.13%\n",
      "Batch 131, Loss: 0.024591, Accuracy: 99.13%\n",
      "Batch 132, Loss: 0.003530, Accuracy: 99.14%\n",
      "Batch 133, Loss: 0.001218, Accuracy: 99.14%\n",
      "Batch 134, Loss: 0.010669, Accuracy: 99.15%\n",
      "Batch 135, Loss: 0.004038, Accuracy: 99.16%\n",
      "Batch 136, Loss: 0.018931, Accuracy: 99.16%\n",
      "Batch 137, Loss: 0.016449, Accuracy: 99.16%\n",
      "Batch 138, Loss: 0.004647, Accuracy: 99.16%\n",
      "Batch 139, Loss: 0.015115, Accuracy: 99.17%\n",
      "Batch 140, Loss: 0.016427, Accuracy: 99.17%\n",
      "Batch 141, Loss: 0.110539, Accuracy: 99.17%\n",
      "Batch 142, Loss: 0.017032, Accuracy: 99.17%\n",
      "Batch 143, Loss: 0.003571, Accuracy: 99.18%\n",
      "Batch 144, Loss: 0.119433, Accuracy: 99.18%\n",
      "Batch 145, Loss: 0.018653, Accuracy: 99.18%\n",
      "Batch 146, Loss: 0.018992, Accuracy: 99.18%\n",
      "Batch 147, Loss: 0.005080, Accuracy: 99.18%\n",
      "Batch 148, Loss: 0.029755, Accuracy: 99.18%\n",
      "Batch 149, Loss: 0.012855, Accuracy: 99.18%\n",
      "Batch 150, Loss: 0.027169, Accuracy: 99.18%\n",
      "Batch 151, Loss: 0.105154, Accuracy: 99.15%\n",
      "Batch 152, Loss: 0.002163, Accuracy: 99.16%\n",
      "Batch 153, Loss: 0.025662, Accuracy: 99.15%\n",
      "Batch 154, Loss: 0.020714, Accuracy: 99.15%\n",
      "Batch 155, Loss: 0.024397, Accuracy: 99.14%\n",
      "Batch 156, Loss: 0.071879, Accuracy: 99.13%\n",
      "Batch 157, Loss: 0.008905, Accuracy: 99.13%\n",
      "Batch 158, Loss: 0.008890, Accuracy: 99.14%\n",
      "Batch 159, Loss: 0.022757, Accuracy: 99.14%\n",
      "Batch 160, Loss: 0.002152, Accuracy: 99.14%\n",
      "Batch 161, Loss: 0.022129, Accuracy: 99.14%\n",
      "Batch 162, Loss: 0.009576, Accuracy: 99.14%\n",
      "Batch 163, Loss: 0.009645, Accuracy: 99.15%\n",
      "Batch 164, Loss: 0.002933, Accuracy: 99.15%\n",
      "Batch 165, Loss: 0.005751, Accuracy: 99.16%\n",
      "Batch 166, Loss: 0.157500, Accuracy: 99.12%\n",
      "Batch 167, Loss: 0.001912, Accuracy: 99.13%\n",
      "Batch 168, Loss: 0.002134, Accuracy: 99.14%\n",
      "Batch 169, Loss: 0.001216, Accuracy: 99.14%\n",
      "Batch 170, Loss: 0.044548, Accuracy: 99.13%\n",
      "Batch 171, Loss: 0.002743, Accuracy: 99.13%\n",
      "Batch 172, Loss: 0.004965, Accuracy: 99.14%\n",
      "Batch 173, Loss: 0.042355, Accuracy: 99.13%\n",
      "Batch 174, Loss: 0.002364, Accuracy: 99.14%\n",
      "Batch 175, Loss: 0.014918, Accuracy: 99.13%\n",
      "Batch 176, Loss: 0.011856, Accuracy: 99.14%\n",
      "Batch 177, Loss: 0.004883, Accuracy: 99.14%\n",
      "Batch 178, Loss: 0.014117, Accuracy: 99.15%\n",
      "Batch 179, Loss: 0.035477, Accuracy: 99.14%\n",
      "Batch 180, Loss: 0.004478, Accuracy: 99.15%\n",
      "Batch 181, Loss: 0.002575, Accuracy: 99.15%\n",
      "Batch 182, Loss: 0.001159, Accuracy: 99.16%\n",
      "Batch 183, Loss: 0.029460, Accuracy: 99.15%\n",
      "Batch 184, Loss: 0.011826, Accuracy: 99.16%\n",
      "Batch 185, Loss: 0.016941, Accuracy: 99.16%\n",
      "Batch 186, Loss: 0.019359, Accuracy: 99.15%\n",
      "Batch 187, Loss: 0.000464, Accuracy: 99.16%\n",
      "Batch 188, Loss: 0.008417, Accuracy: 99.16%\n",
      "Batch 189, Loss: 0.003420, Accuracy: 99.17%\n",
      "Batch 190, Loss: 0.004617, Accuracy: 99.17%\n",
      "Batch 191, Loss: 0.040456, Accuracy: 99.17%\n",
      "Batch 192, Loss: 0.036089, Accuracy: 99.16%\n",
      "Batch 193, Loss: 0.001912, Accuracy: 99.17%\n",
      "Batch 194, Loss: 0.002005, Accuracy: 99.17%\n",
      "Batch 195, Loss: 0.002940, Accuracy: 99.17%\n",
      "Batch 196, Loss: 0.008575, Accuracy: 99.18%\n",
      "Batch 197, Loss: 0.014952, Accuracy: 99.18%\n",
      "Batch 198, Loss: 0.106983, Accuracy: 99.16%\n",
      "Batch 199, Loss: 0.001972, Accuracy: 99.17%\n",
      "Batch 200, Loss: 0.172588, Accuracy: 99.15%\n",
      "Batch 201, Loss: 0.000695, Accuracy: 99.15%\n",
      "Batch 202, Loss: 0.003596, Accuracy: 99.16%\n",
      "Batch 203, Loss: 0.202377, Accuracy: 99.14%\n",
      "Batch 204, Loss: 0.053965, Accuracy: 99.13%\n",
      "Batch 205, Loss: 0.020982, Accuracy: 99.13%\n",
      "Batch 206, Loss: 0.076895, Accuracy: 99.13%\n",
      "Batch 207, Loss: 0.038882, Accuracy: 99.12%\n",
      "Batch 208, Loss: 0.003896, Accuracy: 99.13%\n",
      "Batch 209, Loss: 0.013964, Accuracy: 99.13%\n",
      "Batch 210, Loss: 0.004006, Accuracy: 99.14%\n",
      "Batch 211, Loss: 0.207440, Accuracy: 99.11%\n",
      "Batch 212, Loss: 0.002126, Accuracy: 99.12%\n",
      "Batch 213, Loss: 0.104477, Accuracy: 99.10%\n",
      "Training - Epoch 15, Loss: 0.027488, Accuracy: 99.10%\n",
      "Validation Batch 1, Loss: 0.035829, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.072372, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.019628, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.035666, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.007228, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.015388, Accuracy: 98.70%\n",
      "Validation Batch 7, Loss: 0.027559, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.035250, Accuracy: 98.63%\n",
      "Validation Batch 9, Loss: 0.059620, Accuracy: 98.61%\n",
      "Validation Batch 10, Loss: 0.007759, Accuracy: 98.75%\n",
      "Validation Batch 11, Loss: 0.010902, Accuracy: 98.86%\n",
      "Validation Batch 12, Loss: 0.031269, Accuracy: 98.83%\n",
      "Validation Batch 13, Loss: 0.089249, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.020179, Accuracy: 98.77%\n",
      "Validation Batch 15, Loss: 0.074961, Accuracy: 98.75%\n",
      "Validation Batch 16, Loss: 0.002972, Accuracy: 98.83%\n",
      "Validation Batch 17, Loss: 0.049454, Accuracy: 98.71%\n",
      "Validation Batch 18, Loss: 0.017232, Accuracy: 98.78%\n",
      "Validation Batch 19, Loss: 0.011301, Accuracy: 98.85%\n",
      "Validation Batch 20, Loss: 0.117694, Accuracy: 98.75%\n",
      "Validation Batch 21, Loss: 0.037883, Accuracy: 98.74%\n",
      "Validation Batch 22, Loss: 0.093248, Accuracy: 98.65%\n",
      "Validation Batch 23, Loss: 0.193905, Accuracy: 98.44%\n",
      "Validation Batch 24, Loss: 0.020367, Accuracy: 98.44%\n",
      "Validation Batch 25, Loss: 0.072347, Accuracy: 98.38%\n",
      "Validation Batch 26, Loss: 0.059864, Accuracy: 98.38%\n",
      "Validation Batch 27, Loss: 0.019908, Accuracy: 98.41%\n",
      "Validation - Epoch 15, Loss: 0.045890, Accuracy: 98.41%\n",
      "Patience—2\n",
      "Epoch 16\n",
      "Batch 1, Loss: 0.108814, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.004998, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.008474, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.016597, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.013398, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.014373, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.017321, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.015405, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.061239, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.099727, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.014689, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.107098, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.001777, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.012296, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.027184, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.004536, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.026767, Accuracy: 99.45%\n",
      "Batch 18, Loss: 0.003614, Accuracy: 99.48%\n",
      "Batch 19, Loss: 0.006193, Accuracy: 99.51%\n",
      "Batch 20, Loss: 0.001625, Accuracy: 99.53%\n",
      "Batch 21, Loss: 0.048187, Accuracy: 99.40%\n",
      "Batch 22, Loss: 0.053557, Accuracy: 99.29%\n",
      "Batch 23, Loss: 0.001098, Accuracy: 99.32%\n",
      "Batch 24, Loss: 0.001178, Accuracy: 99.35%\n",
      "Batch 25, Loss: 0.014764, Accuracy: 99.38%\n",
      "Batch 26, Loss: 0.004361, Accuracy: 99.40%\n",
      "Batch 27, Loss: 0.004736, Accuracy: 99.42%\n",
      "Batch 28, Loss: 0.001885, Accuracy: 99.44%\n",
      "Batch 29, Loss: 0.005770, Accuracy: 99.46%\n",
      "Batch 30, Loss: 0.005825, Accuracy: 99.48%\n",
      "Batch 31, Loss: 0.077504, Accuracy: 99.45%\n",
      "Batch 32, Loss: 0.001838, Accuracy: 99.46%\n",
      "Batch 33, Loss: 0.008669, Accuracy: 99.48%\n",
      "Batch 34, Loss: 0.001780, Accuracy: 99.49%\n",
      "Batch 35, Loss: 0.020964, Accuracy: 99.46%\n",
      "Batch 36, Loss: 0.042260, Accuracy: 99.44%\n",
      "Batch 37, Loss: 0.001267, Accuracy: 99.45%\n",
      "Batch 38, Loss: 0.007250, Accuracy: 99.47%\n",
      "Batch 39, Loss: 0.002230, Accuracy: 99.48%\n",
      "Batch 40, Loss: 0.007366, Accuracy: 99.49%\n",
      "Batch 41, Loss: 0.020749, Accuracy: 99.47%\n",
      "Batch 42, Loss: 0.022425, Accuracy: 99.48%\n",
      "Batch 43, Loss: 0.014452, Accuracy: 99.49%\n",
      "Batch 44, Loss: 0.001871, Accuracy: 99.50%\n",
      "Batch 45, Loss: 0.009889, Accuracy: 99.51%\n",
      "Batch 46, Loss: 0.002501, Accuracy: 99.52%\n",
      "Batch 47, Loss: 0.007670, Accuracy: 99.53%\n",
      "Batch 48, Loss: 0.002085, Accuracy: 99.54%\n",
      "Batch 49, Loss: 0.001251, Accuracy: 99.55%\n",
      "Batch 50, Loss: 0.108946, Accuracy: 99.50%\n",
      "Batch 51, Loss: 0.008049, Accuracy: 99.51%\n",
      "Batch 52, Loss: 0.003089, Accuracy: 99.52%\n",
      "Batch 53, Loss: 0.248052, Accuracy: 99.44%\n",
      "Batch 54, Loss: 0.002270, Accuracy: 99.45%\n",
      "Batch 55, Loss: 0.003556, Accuracy: 99.46%\n",
      "Batch 56, Loss: 0.053964, Accuracy: 99.44%\n",
      "Batch 57, Loss: 0.006627, Accuracy: 99.45%\n",
      "Batch 58, Loss: 0.003872, Accuracy: 99.46%\n",
      "Batch 59, Loss: 0.030441, Accuracy: 99.44%\n",
      "Batch 60, Loss: 0.070957, Accuracy: 99.40%\n",
      "Batch 61, Loss: 0.123434, Accuracy: 99.36%\n",
      "Batch 62, Loss: 0.003985, Accuracy: 99.37%\n",
      "Batch 63, Loss: 0.006719, Accuracy: 99.38%\n",
      "Batch 64, Loss: 0.022917, Accuracy: 99.37%\n",
      "Batch 65, Loss: 0.009558, Accuracy: 99.38%\n",
      "Batch 66, Loss: 0.003700, Accuracy: 99.38%\n",
      "Batch 67, Loss: 0.020188, Accuracy: 99.37%\n",
      "Batch 68, Loss: 0.049834, Accuracy: 99.33%\n",
      "Batch 69, Loss: 0.004503, Accuracy: 99.34%\n",
      "Batch 70, Loss: 0.003474, Accuracy: 99.35%\n",
      "Batch 71, Loss: 0.001769, Accuracy: 99.36%\n",
      "Batch 72, Loss: 0.058053, Accuracy: 99.35%\n",
      "Batch 73, Loss: 0.063886, Accuracy: 99.34%\n",
      "Batch 74, Loss: 0.000992, Accuracy: 99.35%\n",
      "Batch 75, Loss: 0.001890, Accuracy: 99.35%\n",
      "Batch 76, Loss: 0.028971, Accuracy: 99.34%\n",
      "Batch 77, Loss: 0.030468, Accuracy: 99.33%\n",
      "Batch 78, Loss: 0.003521, Accuracy: 99.34%\n",
      "Batch 79, Loss: 0.004378, Accuracy: 99.35%\n",
      "Batch 80, Loss: 0.002017, Accuracy: 99.36%\n",
      "Batch 81, Loss: 0.015806, Accuracy: 99.34%\n",
      "Batch 82, Loss: 0.288336, Accuracy: 99.29%\n",
      "Batch 83, Loss: 0.001255, Accuracy: 99.30%\n",
      "Batch 84, Loss: 0.000965, Accuracy: 99.31%\n",
      "Batch 85, Loss: 0.027721, Accuracy: 99.30%\n",
      "Batch 86, Loss: 0.004472, Accuracy: 99.31%\n",
      "Batch 87, Loss: 0.002830, Accuracy: 99.32%\n",
      "Batch 88, Loss: 0.003024, Accuracy: 99.33%\n",
      "Batch 89, Loss: 0.001981, Accuracy: 99.33%\n",
      "Batch 90, Loss: 0.007380, Accuracy: 99.34%\n",
      "Batch 91, Loss: 0.003443, Accuracy: 99.35%\n",
      "Batch 92, Loss: 0.006011, Accuracy: 99.35%\n",
      "Batch 93, Loss: 0.008355, Accuracy: 99.36%\n",
      "Batch 94, Loss: 0.011566, Accuracy: 99.37%\n",
      "Batch 95, Loss: 0.002039, Accuracy: 99.38%\n",
      "Batch 96, Loss: 0.035956, Accuracy: 99.35%\n",
      "Batch 97, Loss: 0.025379, Accuracy: 99.34%\n",
      "Batch 98, Loss: 0.003781, Accuracy: 99.35%\n",
      "Batch 99, Loss: 0.013375, Accuracy: 99.34%\n",
      "Batch 100, Loss: 0.017542, Accuracy: 99.34%\n",
      "Batch 101, Loss: 0.001411, Accuracy: 99.35%\n",
      "Batch 102, Loss: 0.014100, Accuracy: 99.34%\n",
      "Batch 103, Loss: 0.028574, Accuracy: 99.33%\n",
      "Batch 104, Loss: 0.001574, Accuracy: 99.34%\n",
      "Batch 105, Loss: 0.057169, Accuracy: 99.33%\n",
      "Batch 106, Loss: 0.002188, Accuracy: 99.34%\n",
      "Batch 107, Loss: 0.002069, Accuracy: 99.34%\n",
      "Batch 108, Loss: 0.002990, Accuracy: 99.35%\n",
      "Batch 109, Loss: 0.001925, Accuracy: 99.35%\n",
      "Batch 110, Loss: 0.004363, Accuracy: 99.36%\n",
      "Batch 111, Loss: 0.003091, Accuracy: 99.37%\n",
      "Batch 112, Loss: 0.004374, Accuracy: 99.37%\n",
      "Batch 113, Loss: 0.001877, Accuracy: 99.38%\n",
      "Batch 114, Loss: 0.027730, Accuracy: 99.37%\n",
      "Batch 115, Loss: 0.015077, Accuracy: 99.38%\n",
      "Batch 116, Loss: 0.062427, Accuracy: 99.37%\n",
      "Batch 117, Loss: 0.004345, Accuracy: 99.37%\n",
      "Batch 118, Loss: 0.002742, Accuracy: 99.38%\n",
      "Batch 119, Loss: 0.000849, Accuracy: 99.38%\n",
      "Batch 120, Loss: 0.002255, Accuracy: 99.39%\n",
      "Batch 121, Loss: 0.006802, Accuracy: 99.39%\n",
      "Batch 122, Loss: 0.018127, Accuracy: 99.39%\n",
      "Batch 123, Loss: 0.000929, Accuracy: 99.39%\n",
      "Batch 124, Loss: 0.000668, Accuracy: 99.40%\n",
      "Batch 125, Loss: 0.002096, Accuracy: 99.40%\n",
      "Batch 126, Loss: 0.043740, Accuracy: 99.39%\n",
      "Batch 127, Loss: 0.001995, Accuracy: 99.40%\n",
      "Batch 128, Loss: 0.014153, Accuracy: 99.39%\n",
      "Batch 129, Loss: 0.002660, Accuracy: 99.39%\n",
      "Batch 130, Loss: 0.000549, Accuracy: 99.40%\n",
      "Batch 131, Loss: 0.003143, Accuracy: 99.40%\n",
      "Batch 132, Loss: 0.020072, Accuracy: 99.40%\n",
      "Batch 133, Loss: 0.000565, Accuracy: 99.40%\n",
      "Batch 134, Loss: 0.001520, Accuracy: 99.41%\n",
      "Batch 135, Loss: 0.026921, Accuracy: 99.40%\n",
      "Batch 136, Loss: 0.001599, Accuracy: 99.40%\n",
      "Batch 137, Loss: 0.006636, Accuracy: 99.41%\n",
      "Batch 138, Loss: 0.001643, Accuracy: 99.41%\n",
      "Batch 139, Loss: 0.002574, Accuracy: 99.42%\n",
      "Batch 140, Loss: 0.002962, Accuracy: 99.42%\n",
      "Batch 141, Loss: 0.001959, Accuracy: 99.42%\n",
      "Batch 142, Loss: 0.003286, Accuracy: 99.43%\n",
      "Batch 143, Loss: 0.071423, Accuracy: 99.42%\n",
      "Batch 144, Loss: 0.033701, Accuracy: 99.41%\n",
      "Batch 145, Loss: 0.002466, Accuracy: 99.42%\n",
      "Batch 146, Loss: 0.000950, Accuracy: 99.42%\n",
      "Batch 147, Loss: 0.000606, Accuracy: 99.43%\n",
      "Batch 148, Loss: 0.016302, Accuracy: 99.42%\n",
      "Batch 149, Loss: 0.023682, Accuracy: 99.41%\n",
      "Batch 150, Loss: 0.001476, Accuracy: 99.42%\n",
      "Batch 151, Loss: 0.000845, Accuracy: 99.42%\n",
      "Batch 152, Loss: 0.000594, Accuracy: 99.42%\n",
      "Batch 153, Loss: 0.001303, Accuracy: 99.43%\n",
      "Batch 154, Loss: 0.003348, Accuracy: 99.43%\n",
      "Batch 155, Loss: 0.003464, Accuracy: 99.44%\n",
      "Batch 156, Loss: 0.074922, Accuracy: 99.43%\n",
      "Batch 157, Loss: 0.005176, Accuracy: 99.43%\n",
      "Batch 158, Loss: 0.001836, Accuracy: 99.44%\n",
      "Batch 159, Loss: 0.003567, Accuracy: 99.44%\n",
      "Batch 160, Loss: 0.002118, Accuracy: 99.44%\n",
      "Batch 161, Loss: 0.004342, Accuracy: 99.45%\n",
      "Batch 162, Loss: 0.003295, Accuracy: 99.45%\n",
      "Batch 163, Loss: 0.025933, Accuracy: 99.44%\n",
      "Batch 164, Loss: 0.014597, Accuracy: 99.45%\n",
      "Batch 165, Loss: 0.004169, Accuracy: 99.45%\n",
      "Batch 166, Loss: 0.007140, Accuracy: 99.45%\n",
      "Batch 167, Loss: 0.001085, Accuracy: 99.46%\n",
      "Batch 168, Loss: 0.065326, Accuracy: 99.45%\n",
      "Batch 169, Loss: 0.011635, Accuracy: 99.45%\n",
      "Batch 170, Loss: 0.021649, Accuracy: 99.45%\n",
      "Batch 171, Loss: 0.006396, Accuracy: 99.45%\n",
      "Batch 172, Loss: 0.096313, Accuracy: 99.45%\n",
      "Batch 173, Loss: 0.001709, Accuracy: 99.45%\n",
      "Batch 174, Loss: 0.000725, Accuracy: 99.45%\n",
      "Batch 175, Loss: 0.002269, Accuracy: 99.46%\n",
      "Batch 176, Loss: 0.000838, Accuracy: 99.46%\n",
      "Batch 177, Loss: 0.020655, Accuracy: 99.45%\n",
      "Batch 178, Loss: 0.001883, Accuracy: 99.46%\n",
      "Batch 179, Loss: 0.003472, Accuracy: 99.46%\n",
      "Batch 180, Loss: 0.001793, Accuracy: 99.46%\n",
      "Batch 181, Loss: 0.029494, Accuracy: 99.46%\n",
      "Batch 182, Loss: 0.001594, Accuracy: 99.46%\n",
      "Batch 183, Loss: 0.061079, Accuracy: 99.45%\n",
      "Batch 184, Loss: 0.003202, Accuracy: 99.45%\n",
      "Batch 185, Loss: 0.076652, Accuracy: 99.44%\n",
      "Batch 186, Loss: 0.002803, Accuracy: 99.45%\n",
      "Batch 187, Loss: 0.012125, Accuracy: 99.45%\n",
      "Batch 188, Loss: 0.007023, Accuracy: 99.45%\n",
      "Batch 189, Loss: 0.002972, Accuracy: 99.45%\n",
      "Batch 190, Loss: 0.006996, Accuracy: 99.46%\n",
      "Batch 191, Loss: 0.023406, Accuracy: 99.45%\n",
      "Batch 192, Loss: 0.004193, Accuracy: 99.45%\n",
      "Batch 193, Loss: 0.017949, Accuracy: 99.45%\n",
      "Batch 194, Loss: 0.063486, Accuracy: 99.44%\n",
      "Batch 195, Loss: 0.013857, Accuracy: 99.44%\n",
      "Batch 196, Loss: 0.018430, Accuracy: 99.44%\n",
      "Batch 197, Loss: 0.000450, Accuracy: 99.44%\n",
      "Batch 198, Loss: 0.003368, Accuracy: 99.45%\n",
      "Batch 199, Loss: 0.041797, Accuracy: 99.44%\n",
      "Batch 200, Loss: 0.005573, Accuracy: 99.45%\n",
      "Batch 201, Loss: 0.002292, Accuracy: 99.45%\n",
      "Batch 202, Loss: 0.076332, Accuracy: 99.44%\n",
      "Batch 203, Loss: 0.001308, Accuracy: 99.44%\n",
      "Batch 204, Loss: 0.007359, Accuracy: 99.44%\n",
      "Batch 205, Loss: 0.000386, Accuracy: 99.44%\n",
      "Batch 206, Loss: 0.040470, Accuracy: 99.44%\n",
      "Batch 207, Loss: 0.064533, Accuracy: 99.43%\n",
      "Batch 208, Loss: 0.016196, Accuracy: 99.43%\n",
      "Batch 209, Loss: 0.071615, Accuracy: 99.42%\n",
      "Batch 210, Loss: 0.010415, Accuracy: 99.43%\n",
      "Batch 211, Loss: 0.024776, Accuracy: 99.42%\n",
      "Batch 212, Loss: 0.025939, Accuracy: 99.42%\n",
      "Batch 213, Loss: 0.021438, Accuracy: 99.41%\n",
      "Training - Epoch 16, Loss: 0.019413, Accuracy: 99.41%\n",
      "Validation Batch 1, Loss: 0.000431, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.009419, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000951, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.016429, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.001117, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.026631, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.013472, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.171240, Accuracy: 99.02%\n",
      "Validation Batch 9, Loss: 0.019007, Accuracy: 98.96%\n",
      "Validation Batch 10, Loss: 0.088773, Accuracy: 98.75%\n",
      "Validation Batch 11, Loss: 0.023220, Accuracy: 98.72%\n",
      "Validation Batch 12, Loss: 0.087089, Accuracy: 98.70%\n",
      "Validation Batch 13, Loss: 0.052344, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.056970, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.004406, Accuracy: 98.75%\n",
      "Validation Batch 16, Loss: 0.000823, Accuracy: 98.83%\n",
      "Validation Batch 17, Loss: 0.146711, Accuracy: 98.71%\n",
      "Validation Batch 18, Loss: 0.078862, Accuracy: 98.70%\n",
      "Validation Batch 19, Loss: 0.006812, Accuracy: 98.77%\n",
      "Validation Batch 20, Loss: 0.111136, Accuracy: 98.75%\n",
      "Validation Batch 21, Loss: 0.015328, Accuracy: 98.81%\n",
      "Validation Batch 22, Loss: 0.079366, Accuracy: 98.72%\n",
      "Validation Batch 23, Loss: 0.008206, Accuracy: 98.78%\n",
      "Validation Batch 24, Loss: 0.001700, Accuracy: 98.83%\n",
      "Validation Batch 25, Loss: 0.008186, Accuracy: 98.88%\n",
      "Validation Batch 26, Loss: 0.034984, Accuracy: 98.86%\n",
      "Validation Batch 27, Loss: 0.002851, Accuracy: 98.88%\n",
      "Validation - Epoch 16, Loss: 0.039499, Accuracy: 98.88%\n",
      "Patience—3\n",
      "Epoch 17\n",
      "Batch 1, Loss: 0.050275, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.012203, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.003788, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.001618, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.161320, Accuracy: 99.06%\n",
      "Batch 6, Loss: 0.001244, Accuracy: 99.22%\n",
      "Batch 7, Loss: 0.031655, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.001074, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.048353, Accuracy: 99.13%\n",
      "Batch 10, Loss: 0.155014, Accuracy: 99.06%\n",
      "Batch 11, Loss: 0.257113, Accuracy: 98.58%\n",
      "Batch 12, Loss: 0.046429, Accuracy: 98.57%\n",
      "Batch 13, Loss: 0.002056, Accuracy: 98.68%\n",
      "Batch 14, Loss: 0.002017, Accuracy: 98.77%\n",
      "Batch 15, Loss: 0.018478, Accuracy: 98.85%\n",
      "Batch 16, Loss: 0.001726, Accuracy: 98.93%\n",
      "Batch 17, Loss: 0.001165, Accuracy: 98.99%\n",
      "Batch 18, Loss: 0.002620, Accuracy: 99.05%\n",
      "Batch 19, Loss: 0.002692, Accuracy: 99.10%\n",
      "Batch 20, Loss: 0.067514, Accuracy: 98.98%\n",
      "Batch 21, Loss: 0.004619, Accuracy: 99.03%\n",
      "Batch 22, Loss: 0.018833, Accuracy: 99.08%\n",
      "Batch 23, Loss: 0.036341, Accuracy: 99.05%\n",
      "Batch 24, Loss: 0.090493, Accuracy: 98.96%\n",
      "Batch 25, Loss: 0.005965, Accuracy: 99.00%\n",
      "Batch 26, Loss: 0.004603, Accuracy: 99.04%\n",
      "Batch 27, Loss: 0.008654, Accuracy: 99.07%\n",
      "Batch 28, Loss: 0.007091, Accuracy: 99.11%\n",
      "Batch 29, Loss: 0.072598, Accuracy: 99.08%\n",
      "Batch 30, Loss: 0.005681, Accuracy: 99.11%\n",
      "Batch 31, Loss: 0.033878, Accuracy: 99.09%\n",
      "Batch 32, Loss: 0.008950, Accuracy: 99.12%\n",
      "Batch 33, Loss: 0.060150, Accuracy: 99.01%\n",
      "Batch 34, Loss: 0.018940, Accuracy: 98.99%\n",
      "Batch 35, Loss: 0.006427, Accuracy: 99.02%\n",
      "Batch 36, Loss: 0.002872, Accuracy: 99.05%\n",
      "Batch 37, Loss: 0.002074, Accuracy: 99.07%\n",
      "Batch 38, Loss: 0.005515, Accuracy: 99.10%\n",
      "Batch 39, Loss: 0.043485, Accuracy: 99.08%\n",
      "Batch 40, Loss: 0.004856, Accuracy: 99.10%\n",
      "Batch 41, Loss: 0.003157, Accuracy: 99.12%\n",
      "Batch 42, Loss: 0.001966, Accuracy: 99.14%\n",
      "Batch 43, Loss: 0.055408, Accuracy: 99.13%\n",
      "Batch 44, Loss: 0.002638, Accuracy: 99.15%\n",
      "Batch 45, Loss: 0.002241, Accuracy: 99.17%\n",
      "Batch 46, Loss: 0.186850, Accuracy: 99.12%\n",
      "Batch 47, Loss: 0.007424, Accuracy: 99.14%\n",
      "Batch 48, Loss: 0.001587, Accuracy: 99.15%\n",
      "Batch 49, Loss: 0.004752, Accuracy: 99.17%\n",
      "Batch 50, Loss: 0.005591, Accuracy: 99.19%\n",
      "Batch 51, Loss: 0.019971, Accuracy: 99.17%\n",
      "Batch 52, Loss: 0.045437, Accuracy: 99.13%\n",
      "Batch 53, Loss: 0.026607, Accuracy: 99.12%\n",
      "Batch 54, Loss: 0.008175, Accuracy: 99.13%\n",
      "Batch 55, Loss: 0.001712, Accuracy: 99.15%\n",
      "Batch 56, Loss: 0.009536, Accuracy: 99.16%\n",
      "Batch 57, Loss: 0.007209, Accuracy: 99.18%\n",
      "Batch 58, Loss: 0.026221, Accuracy: 99.16%\n",
      "Batch 59, Loss: 0.018977, Accuracy: 99.15%\n",
      "Batch 60, Loss: 0.009963, Accuracy: 99.17%\n",
      "Batch 61, Loss: 0.002405, Accuracy: 99.18%\n",
      "Batch 62, Loss: 0.003057, Accuracy: 99.19%\n",
      "Batch 63, Loss: 0.006873, Accuracy: 99.21%\n",
      "Batch 64, Loss: 0.027412, Accuracy: 99.19%\n",
      "Batch 65, Loss: 0.007991, Accuracy: 99.21%\n",
      "Batch 66, Loss: 0.002574, Accuracy: 99.22%\n",
      "Batch 67, Loss: 0.046090, Accuracy: 99.21%\n",
      "Batch 68, Loss: 0.046833, Accuracy: 99.20%\n",
      "Batch 69, Loss: 0.002065, Accuracy: 99.21%\n",
      "Batch 70, Loss: 0.013237, Accuracy: 99.22%\n",
      "Batch 71, Loss: 0.040959, Accuracy: 99.21%\n",
      "Batch 72, Loss: 0.000508, Accuracy: 99.22%\n",
      "Batch 73, Loss: 0.000789, Accuracy: 99.23%\n",
      "Batch 74, Loss: 0.018633, Accuracy: 99.22%\n",
      "Batch 75, Loss: 0.012372, Accuracy: 99.23%\n",
      "Batch 76, Loss: 0.002266, Accuracy: 99.24%\n",
      "Batch 77, Loss: 0.013540, Accuracy: 99.23%\n",
      "Batch 78, Loss: 0.015137, Accuracy: 99.22%\n",
      "Batch 79, Loss: 0.062519, Accuracy: 99.19%\n",
      "Batch 80, Loss: 0.000652, Accuracy: 99.20%\n",
      "Batch 81, Loss: 0.011613, Accuracy: 99.21%\n",
      "Batch 82, Loss: 0.001040, Accuracy: 99.22%\n",
      "Batch 83, Loss: 0.002203, Accuracy: 99.23%\n",
      "Batch 84, Loss: 0.002763, Accuracy: 99.24%\n",
      "Batch 85, Loss: 0.001509, Accuracy: 99.25%\n",
      "Batch 86, Loss: 0.002607, Accuracy: 99.26%\n",
      "Batch 87, Loss: 0.002375, Accuracy: 99.26%\n",
      "Batch 88, Loss: 0.110862, Accuracy: 99.24%\n",
      "Batch 89, Loss: 0.076248, Accuracy: 99.23%\n",
      "Batch 90, Loss: 0.036411, Accuracy: 99.22%\n",
      "Batch 91, Loss: 0.056282, Accuracy: 99.19%\n",
      "Batch 92, Loss: 0.010100, Accuracy: 99.20%\n",
      "Batch 93, Loss: 0.003748, Accuracy: 99.21%\n",
      "Batch 94, Loss: 0.023624, Accuracy: 99.20%\n",
      "Batch 95, Loss: 0.002251, Accuracy: 99.21%\n",
      "Batch 96, Loss: 0.001369, Accuracy: 99.22%\n",
      "Batch 97, Loss: 0.279346, Accuracy: 99.19%\n",
      "Batch 98, Loss: 0.020042, Accuracy: 99.19%\n",
      "Batch 99, Loss: 0.007309, Accuracy: 99.20%\n",
      "Batch 100, Loss: 0.000679, Accuracy: 99.20%\n",
      "Batch 101, Loss: 0.012977, Accuracy: 99.21%\n",
      "Batch 102, Loss: 0.003045, Accuracy: 99.22%\n",
      "Batch 103, Loss: 0.006566, Accuracy: 99.23%\n",
      "Batch 104, Loss: 0.078337, Accuracy: 99.22%\n",
      "Batch 105, Loss: 0.002041, Accuracy: 99.23%\n",
      "Batch 106, Loss: 0.096336, Accuracy: 99.22%\n",
      "Batch 107, Loss: 0.047459, Accuracy: 99.21%\n",
      "Batch 108, Loss: 0.065900, Accuracy: 99.20%\n",
      "Batch 109, Loss: 0.002287, Accuracy: 99.21%\n",
      "Batch 110, Loss: 0.111041, Accuracy: 99.18%\n",
      "Batch 111, Loss: 0.000820, Accuracy: 99.18%\n",
      "Batch 112, Loss: 0.005463, Accuracy: 99.19%\n",
      "Batch 113, Loss: 0.073149, Accuracy: 99.17%\n",
      "Batch 114, Loss: 0.039698, Accuracy: 99.16%\n",
      "Batch 115, Loss: 0.047925, Accuracy: 99.16%\n",
      "Batch 116, Loss: 0.062628, Accuracy: 99.14%\n",
      "Batch 117, Loss: 0.004756, Accuracy: 99.15%\n",
      "Batch 118, Loss: 0.001946, Accuracy: 99.15%\n",
      "Batch 119, Loss: 0.060036, Accuracy: 99.15%\n",
      "Batch 120, Loss: 0.016912, Accuracy: 99.15%\n",
      "Batch 121, Loss: 0.023118, Accuracy: 99.15%\n",
      "Batch 122, Loss: 0.092622, Accuracy: 99.13%\n",
      "Batch 123, Loss: 0.033829, Accuracy: 99.12%\n",
      "Batch 124, Loss: 0.020652, Accuracy: 99.13%\n",
      "Batch 125, Loss: 0.018319, Accuracy: 99.14%\n",
      "Batch 126, Loss: 0.003038, Accuracy: 99.14%\n",
      "Batch 127, Loss: 0.016599, Accuracy: 99.15%\n",
      "Batch 128, Loss: 0.037348, Accuracy: 99.13%\n",
      "Batch 129, Loss: 0.004187, Accuracy: 99.14%\n",
      "Batch 130, Loss: 0.024874, Accuracy: 99.15%\n",
      "Batch 131, Loss: 0.002326, Accuracy: 99.15%\n",
      "Batch 132, Loss: 0.071641, Accuracy: 99.15%\n",
      "Batch 133, Loss: 0.018435, Accuracy: 99.14%\n",
      "Batch 134, Loss: 0.002778, Accuracy: 99.15%\n",
      "Batch 135, Loss: 0.120046, Accuracy: 99.14%\n",
      "Batch 136, Loss: 0.007737, Accuracy: 99.15%\n",
      "Batch 137, Loss: 0.047327, Accuracy: 99.13%\n",
      "Batch 138, Loss: 0.006184, Accuracy: 99.14%\n",
      "Batch 139, Loss: 0.015202, Accuracy: 99.13%\n",
      "Batch 140, Loss: 0.001922, Accuracy: 99.14%\n",
      "Batch 141, Loss: 0.001698, Accuracy: 99.15%\n",
      "Batch 142, Loss: 0.008284, Accuracy: 99.15%\n",
      "Batch 143, Loss: 0.001345, Accuracy: 99.16%\n",
      "Batch 144, Loss: 0.011767, Accuracy: 99.16%\n",
      "Batch 145, Loss: 0.002332, Accuracy: 99.17%\n",
      "Batch 146, Loss: 0.139722, Accuracy: 99.17%\n",
      "Batch 147, Loss: 0.002726, Accuracy: 99.17%\n",
      "Batch 148, Loss: 0.001890, Accuracy: 99.18%\n",
      "Batch 149, Loss: 0.001400, Accuracy: 99.18%\n",
      "Batch 150, Loss: 0.002992, Accuracy: 99.19%\n",
      "Batch 151, Loss: 0.027458, Accuracy: 99.18%\n",
      "Batch 152, Loss: 0.019721, Accuracy: 99.19%\n",
      "Batch 153, Loss: 0.001525, Accuracy: 99.19%\n",
      "Batch 154, Loss: 0.017973, Accuracy: 99.20%\n",
      "Batch 155, Loss: 0.004969, Accuracy: 99.20%\n",
      "Batch 156, Loss: 0.024883, Accuracy: 99.20%\n",
      "Batch 157, Loss: 0.043049, Accuracy: 99.19%\n",
      "Batch 158, Loss: 0.050420, Accuracy: 99.19%\n",
      "Batch 159, Loss: 0.008737, Accuracy: 99.19%\n",
      "Batch 160, Loss: 0.027486, Accuracy: 99.19%\n",
      "Batch 161, Loss: 0.002358, Accuracy: 99.19%\n",
      "Batch 162, Loss: 0.002490, Accuracy: 99.20%\n",
      "Batch 163, Loss: 0.001420, Accuracy: 99.20%\n",
      "Batch 164, Loss: 0.001683, Accuracy: 99.21%\n",
      "Batch 165, Loss: 0.002395, Accuracy: 99.21%\n",
      "Batch 166, Loss: 0.020630, Accuracy: 99.21%\n",
      "Batch 167, Loss: 0.003419, Accuracy: 99.21%\n",
      "Batch 168, Loss: 0.003397, Accuracy: 99.22%\n",
      "Batch 169, Loss: 0.018933, Accuracy: 99.22%\n",
      "Batch 170, Loss: 0.003167, Accuracy: 99.23%\n",
      "Batch 171, Loss: 0.020624, Accuracy: 99.22%\n",
      "Batch 172, Loss: 0.002265, Accuracy: 99.23%\n",
      "Batch 173, Loss: 0.002913, Accuracy: 99.23%\n",
      "Batch 174, Loss: 0.001017, Accuracy: 99.24%\n",
      "Batch 175, Loss: 0.004811, Accuracy: 99.24%\n",
      "Batch 176, Loss: 0.012916, Accuracy: 99.24%\n",
      "Batch 177, Loss: 0.000820, Accuracy: 99.24%\n",
      "Batch 178, Loss: 0.003416, Accuracy: 99.25%\n",
      "Batch 179, Loss: 0.029131, Accuracy: 99.24%\n",
      "Batch 180, Loss: 0.000708, Accuracy: 99.24%\n",
      "Batch 181, Loss: 0.008725, Accuracy: 99.25%\n",
      "Batch 182, Loss: 0.000583, Accuracy: 99.25%\n",
      "Batch 183, Loss: 0.000806, Accuracy: 99.26%\n",
      "Batch 184, Loss: 0.001664, Accuracy: 99.26%\n",
      "Batch 185, Loss: 0.001189, Accuracy: 99.27%\n",
      "Batch 186, Loss: 0.006813, Accuracy: 99.27%\n",
      "Batch 187, Loss: 0.006249, Accuracy: 99.27%\n",
      "Batch 188, Loss: 0.116130, Accuracy: 99.26%\n",
      "Batch 189, Loss: 0.000828, Accuracy: 99.26%\n",
      "Batch 190, Loss: 0.022086, Accuracy: 99.26%\n",
      "Batch 191, Loss: 0.001058, Accuracy: 99.26%\n",
      "Batch 192, Loss: 0.002009, Accuracy: 99.27%\n",
      "Batch 193, Loss: 0.039008, Accuracy: 99.26%\n",
      "Batch 194, Loss: 0.007988, Accuracy: 99.27%\n",
      "Batch 195, Loss: 0.001590, Accuracy: 99.27%\n",
      "Batch 196, Loss: 0.007243, Accuracy: 99.27%\n",
      "Batch 197, Loss: 0.015594, Accuracy: 99.27%\n",
      "Batch 198, Loss: 0.003740, Accuracy: 99.27%\n",
      "Batch 199, Loss: 0.000665, Accuracy: 99.28%\n",
      "Batch 200, Loss: 0.010436, Accuracy: 99.28%\n",
      "Batch 201, Loss: 0.094597, Accuracy: 99.27%\n",
      "Batch 202, Loss: 0.012558, Accuracy: 99.27%\n",
      "Batch 203, Loss: 0.001569, Accuracy: 99.27%\n",
      "Batch 204, Loss: 0.000918, Accuracy: 99.27%\n",
      "Batch 205, Loss: 0.001030, Accuracy: 99.28%\n",
      "Batch 206, Loss: 0.033908, Accuracy: 99.27%\n",
      "Batch 207, Loss: 0.112229, Accuracy: 99.27%\n",
      "Batch 208, Loss: 0.001542, Accuracy: 99.27%\n",
      "Batch 209, Loss: 0.129558, Accuracy: 99.27%\n",
      "Batch 210, Loss: 0.003839, Accuracy: 99.27%\n",
      "Batch 211, Loss: 0.002308, Accuracy: 99.27%\n",
      "Batch 212, Loss: 0.065789, Accuracy: 99.27%\n",
      "Batch 213, Loss: 0.002701, Accuracy: 99.27%\n",
      "Training - Epoch 17, Loss: 0.024871, Accuracy: 99.27%\n",
      "Validation Batch 1, Loss: 0.000850, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.005727, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.001463, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000482, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000743, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000771, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000879, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.003082, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.102731, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.001455, Accuracy: 99.84%\n",
      "Validation Batch 11, Loss: 0.001796, Accuracy: 99.86%\n",
      "Validation Batch 12, Loss: 0.064927, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.000692, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.001594, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.009271, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.001396, Accuracy: 99.71%\n",
      "Validation Batch 17, Loss: 0.002379, Accuracy: 99.72%\n",
      "Validation Batch 18, Loss: 0.001419, Accuracy: 99.74%\n",
      "Validation Batch 19, Loss: 0.035944, Accuracy: 99.67%\n",
      "Validation Batch 20, Loss: 0.002514, Accuracy: 99.69%\n",
      "Validation Batch 21, Loss: 0.075103, Accuracy: 99.63%\n",
      "Validation Batch 22, Loss: 0.005455, Accuracy: 99.64%\n",
      "Validation Batch 23, Loss: 0.003893, Accuracy: 99.66%\n",
      "Validation Batch 24, Loss: 0.011304, Accuracy: 99.67%\n",
      "Validation Batch 25, Loss: 0.005677, Accuracy: 99.69%\n",
      "Validation Batch 26, Loss: 0.006633, Accuracy: 99.70%\n",
      "Validation Batch 27, Loss: 0.049031, Accuracy: 99.65%\n",
      "Validation - Epoch 17, Loss: 0.014712, Accuracy: 99.65%\n",
      "Patience—4\n",
      "Epoch 18\n",
      "Batch 1, Loss: 0.007873, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000940, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000608, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.001239, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001563, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.002818, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.001414, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.002117, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.011136, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.011188, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.002107, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.003386, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.020776, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.017963, Accuracy: 99.78%\n",
      "Batch 15, Loss: 0.024775, Accuracy: 99.69%\n",
      "Batch 16, Loss: 0.002837, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.008203, Accuracy: 99.72%\n",
      "Batch 18, Loss: 0.003168, Accuracy: 99.74%\n",
      "Batch 19, Loss: 0.001629, Accuracy: 99.75%\n",
      "Batch 20, Loss: 0.003385, Accuracy: 99.77%\n",
      "Batch 21, Loss: 0.014260, Accuracy: 99.78%\n",
      "Batch 22, Loss: 0.000768, Accuracy: 99.79%\n",
      "Batch 23, Loss: 0.000822, Accuracy: 99.80%\n",
      "Batch 24, Loss: 0.047060, Accuracy: 99.67%\n",
      "Batch 25, Loss: 0.004158, Accuracy: 99.69%\n",
      "Batch 26, Loss: 0.001061, Accuracy: 99.70%\n",
      "Batch 27, Loss: 0.000742, Accuracy: 99.71%\n",
      "Batch 28, Loss: 0.006202, Accuracy: 99.72%\n",
      "Batch 29, Loss: 0.002158, Accuracy: 99.73%\n",
      "Batch 30, Loss: 0.001123, Accuracy: 99.74%\n",
      "Batch 31, Loss: 0.009929, Accuracy: 99.75%\n",
      "Batch 32, Loss: 0.007378, Accuracy: 99.76%\n",
      "Batch 33, Loss: 0.009892, Accuracy: 99.76%\n",
      "Batch 34, Loss: 0.006185, Accuracy: 99.77%\n",
      "Batch 35, Loss: 0.000960, Accuracy: 99.78%\n",
      "Batch 36, Loss: 0.000336, Accuracy: 99.78%\n",
      "Batch 37, Loss: 0.058765, Accuracy: 99.75%\n",
      "Batch 38, Loss: 0.000996, Accuracy: 99.75%\n",
      "Batch 39, Loss: 0.004226, Accuracy: 99.76%\n",
      "Batch 40, Loss: 0.000441, Accuracy: 99.77%\n",
      "Batch 41, Loss: 0.001810, Accuracy: 99.77%\n",
      "Batch 42, Loss: 0.000451, Accuracy: 99.78%\n",
      "Batch 43, Loss: 0.027601, Accuracy: 99.75%\n",
      "Batch 44, Loss: 0.000543, Accuracy: 99.75%\n",
      "Batch 45, Loss: 0.000315, Accuracy: 99.76%\n",
      "Batch 46, Loss: 0.001446, Accuracy: 99.76%\n",
      "Batch 47, Loss: 0.047239, Accuracy: 99.73%\n",
      "Batch 48, Loss: 0.013104, Accuracy: 99.74%\n",
      "Batch 49, Loss: 0.002298, Accuracy: 99.74%\n",
      "Batch 50, Loss: 0.001100, Accuracy: 99.75%\n",
      "Batch 51, Loss: 0.000649, Accuracy: 99.75%\n",
      "Batch 52, Loss: 0.005408, Accuracy: 99.76%\n",
      "Batch 53, Loss: 0.000566, Accuracy: 99.76%\n",
      "Batch 54, Loss: 0.001013, Accuracy: 99.77%\n",
      "Batch 55, Loss: 0.000685, Accuracy: 99.77%\n",
      "Batch 56, Loss: 0.000308, Accuracy: 99.78%\n",
      "Batch 57, Loss: 0.002489, Accuracy: 99.78%\n",
      "Batch 58, Loss: 0.000916, Accuracy: 99.78%\n",
      "Batch 59, Loss: 0.070025, Accuracy: 99.74%\n",
      "Batch 60, Loss: 0.004134, Accuracy: 99.74%\n",
      "Batch 61, Loss: 0.004377, Accuracy: 99.74%\n",
      "Batch 62, Loss: 0.005931, Accuracy: 99.75%\n",
      "Batch 63, Loss: 0.020722, Accuracy: 99.73%\n",
      "Batch 64, Loss: 0.050178, Accuracy: 99.71%\n",
      "Batch 65, Loss: 0.002773, Accuracy: 99.71%\n",
      "Batch 66, Loss: 0.029006, Accuracy: 99.69%\n",
      "Batch 67, Loss: 0.088597, Accuracy: 99.65%\n",
      "Batch 68, Loss: 0.003223, Accuracy: 99.66%\n",
      "Batch 69, Loss: 0.003231, Accuracy: 99.66%\n",
      "Batch 70, Loss: 0.020288, Accuracy: 99.64%\n",
      "Batch 71, Loss: 0.001198, Accuracy: 99.65%\n",
      "Batch 72, Loss: 0.026280, Accuracy: 99.63%\n",
      "Batch 73, Loss: 0.002874, Accuracy: 99.64%\n",
      "Batch 74, Loss: 0.001256, Accuracy: 99.64%\n",
      "Batch 75, Loss: 0.081901, Accuracy: 99.62%\n",
      "Batch 76, Loss: 0.055219, Accuracy: 99.61%\n",
      "Batch 77, Loss: 0.016868, Accuracy: 99.61%\n",
      "Batch 78, Loss: 0.034346, Accuracy: 99.60%\n",
      "Batch 79, Loss: 0.161246, Accuracy: 99.56%\n",
      "Batch 80, Loss: 0.038070, Accuracy: 99.55%\n",
      "Batch 81, Loss: 0.005392, Accuracy: 99.56%\n",
      "Batch 82, Loss: 0.006052, Accuracy: 99.56%\n",
      "Batch 83, Loss: 0.054173, Accuracy: 99.53%\n",
      "Batch 84, Loss: 0.038851, Accuracy: 99.52%\n",
      "Batch 85, Loss: 0.051024, Accuracy: 99.49%\n",
      "Batch 86, Loss: 0.033672, Accuracy: 99.47%\n",
      "Batch 87, Loss: 0.134271, Accuracy: 99.46%\n",
      "Batch 88, Loss: 0.007792, Accuracy: 99.47%\n",
      "Batch 89, Loss: 0.019337, Accuracy: 99.47%\n",
      "Batch 90, Loss: 0.054907, Accuracy: 99.46%\n",
      "Batch 91, Loss: 0.012716, Accuracy: 99.47%\n",
      "Batch 92, Loss: 0.015048, Accuracy: 99.47%\n",
      "Batch 93, Loss: 0.060131, Accuracy: 99.46%\n",
      "Batch 94, Loss: 0.049067, Accuracy: 99.45%\n",
      "Batch 95, Loss: 0.006792, Accuracy: 99.46%\n",
      "Batch 96, Loss: 0.019868, Accuracy: 99.45%\n",
      "Batch 97, Loss: 0.017704, Accuracy: 99.44%\n",
      "Batch 98, Loss: 0.004219, Accuracy: 99.44%\n",
      "Batch 99, Loss: 0.020786, Accuracy: 99.43%\n",
      "Batch 100, Loss: 0.023684, Accuracy: 99.42%\n",
      "Batch 101, Loss: 0.018512, Accuracy: 99.41%\n",
      "Batch 102, Loss: 0.050194, Accuracy: 99.39%\n",
      "Batch 103, Loss: 0.002951, Accuracy: 99.39%\n",
      "Batch 104, Loss: 0.082505, Accuracy: 99.37%\n",
      "Batch 105, Loss: 0.001582, Accuracy: 99.38%\n",
      "Batch 106, Loss: 0.002521, Accuracy: 99.38%\n",
      "Batch 107, Loss: 0.003770, Accuracy: 99.39%\n",
      "Batch 108, Loss: 0.003296, Accuracy: 99.39%\n",
      "Batch 109, Loss: 0.014723, Accuracy: 99.38%\n",
      "Batch 110, Loss: 0.056052, Accuracy: 99.38%\n",
      "Batch 111, Loss: 0.028221, Accuracy: 99.38%\n",
      "Batch 112, Loss: 0.007843, Accuracy: 99.39%\n",
      "Batch 113, Loss: 0.000812, Accuracy: 99.39%\n",
      "Batch 114, Loss: 0.006868, Accuracy: 99.40%\n",
      "Batch 115, Loss: 0.001506, Accuracy: 99.40%\n",
      "Batch 116, Loss: 0.029941, Accuracy: 99.38%\n",
      "Batch 117, Loss: 0.000602, Accuracy: 99.39%\n",
      "Batch 118, Loss: 0.001130, Accuracy: 99.39%\n",
      "Batch 119, Loss: 0.011947, Accuracy: 99.40%\n",
      "Batch 120, Loss: 0.006416, Accuracy: 99.40%\n",
      "Batch 121, Loss: 0.015869, Accuracy: 99.39%\n",
      "Batch 122, Loss: 0.015757, Accuracy: 99.39%\n",
      "Batch 123, Loss: 0.001677, Accuracy: 99.39%\n",
      "Batch 124, Loss: 0.001030, Accuracy: 99.40%\n",
      "Batch 125, Loss: 0.001163, Accuracy: 99.40%\n",
      "Batch 126, Loss: 0.000634, Accuracy: 99.40%\n",
      "Batch 127, Loss: 0.000683, Accuracy: 99.41%\n",
      "Batch 128, Loss: 0.025421, Accuracy: 99.40%\n",
      "Batch 129, Loss: 0.001546, Accuracy: 99.41%\n",
      "Batch 130, Loss: 0.004331, Accuracy: 99.41%\n",
      "Batch 131, Loss: 0.000594, Accuracy: 99.42%\n",
      "Batch 132, Loss: 0.002602, Accuracy: 99.42%\n",
      "Batch 133, Loss: 0.001984, Accuracy: 99.42%\n",
      "Batch 134, Loss: 0.022643, Accuracy: 99.42%\n",
      "Batch 135, Loss: 0.042100, Accuracy: 99.41%\n",
      "Batch 136, Loss: 0.000755, Accuracy: 99.41%\n",
      "Batch 137, Loss: 0.006990, Accuracy: 99.42%\n",
      "Batch 138, Loss: 0.001789, Accuracy: 99.42%\n",
      "Batch 139, Loss: 0.001869, Accuracy: 99.43%\n",
      "Batch 140, Loss: 0.006483, Accuracy: 99.43%\n",
      "Batch 141, Loss: 0.011934, Accuracy: 99.42%\n",
      "Batch 142, Loss: 0.001576, Accuracy: 99.43%\n",
      "Batch 143, Loss: 0.029638, Accuracy: 99.42%\n",
      "Batch 144, Loss: 0.000853, Accuracy: 99.42%\n",
      "Batch 145, Loss: 0.146904, Accuracy: 99.42%\n",
      "Batch 146, Loss: 0.001383, Accuracy: 99.42%\n",
      "Batch 147, Loss: 0.004444, Accuracy: 99.43%\n",
      "Batch 148, Loss: 0.022679, Accuracy: 99.42%\n",
      "Batch 149, Loss: 0.018352, Accuracy: 99.41%\n",
      "Batch 150, Loss: 0.000842, Accuracy: 99.42%\n",
      "Batch 151, Loss: 0.000497, Accuracy: 99.42%\n",
      "Batch 152, Loss: 0.001331, Accuracy: 99.42%\n",
      "Batch 153, Loss: 0.002874, Accuracy: 99.43%\n",
      "Batch 154, Loss: 0.024133, Accuracy: 99.42%\n",
      "Batch 155, Loss: 0.002121, Accuracy: 99.43%\n",
      "Batch 156, Loss: 0.010086, Accuracy: 99.43%\n",
      "Batch 157, Loss: 0.001037, Accuracy: 99.43%\n",
      "Batch 158, Loss: 0.001661, Accuracy: 99.44%\n",
      "Batch 159, Loss: 0.000381, Accuracy: 99.44%\n",
      "Batch 160, Loss: 0.000279, Accuracy: 99.44%\n",
      "Batch 161, Loss: 0.001190, Accuracy: 99.45%\n",
      "Batch 162, Loss: 0.006681, Accuracy: 99.45%\n",
      "Batch 163, Loss: 0.000791, Accuracy: 99.45%\n",
      "Batch 164, Loss: 0.000770, Accuracy: 99.46%\n",
      "Batch 165, Loss: 0.172973, Accuracy: 99.44%\n",
      "Batch 166, Loss: 0.036092, Accuracy: 99.44%\n",
      "Batch 167, Loss: 0.003907, Accuracy: 99.44%\n",
      "Batch 168, Loss: 0.009976, Accuracy: 99.44%\n",
      "Batch 169, Loss: 0.000672, Accuracy: 99.45%\n",
      "Batch 170, Loss: 0.000471, Accuracy: 99.45%\n",
      "Batch 171, Loss: 0.000529, Accuracy: 99.45%\n",
      "Batch 172, Loss: 0.002164, Accuracy: 99.45%\n",
      "Batch 173, Loss: 0.000765, Accuracy: 99.46%\n",
      "Batch 174, Loss: 0.009086, Accuracy: 99.46%\n",
      "Batch 175, Loss: 0.003760, Accuracy: 99.46%\n",
      "Batch 176, Loss: 0.002188, Accuracy: 99.47%\n",
      "Batch 177, Loss: 0.086443, Accuracy: 99.45%\n",
      "Batch 178, Loss: 0.003412, Accuracy: 99.46%\n",
      "Batch 179, Loss: 0.010474, Accuracy: 99.46%\n",
      "Batch 180, Loss: 0.000362, Accuracy: 99.46%\n",
      "Batch 181, Loss: 0.001703, Accuracy: 99.46%\n",
      "Batch 182, Loss: 0.001410, Accuracy: 99.47%\n",
      "Batch 183, Loss: 0.001602, Accuracy: 99.47%\n",
      "Batch 184, Loss: 0.064800, Accuracy: 99.47%\n",
      "Batch 185, Loss: 0.000285, Accuracy: 99.47%\n",
      "Batch 186, Loss: 0.001229, Accuracy: 99.47%\n",
      "Batch 187, Loss: 0.001790, Accuracy: 99.47%\n",
      "Batch 188, Loss: 0.012936, Accuracy: 99.48%\n",
      "Batch 189, Loss: 0.000331, Accuracy: 99.48%\n",
      "Batch 190, Loss: 0.001660, Accuracy: 99.48%\n",
      "Batch 191, Loss: 0.051114, Accuracy: 99.47%\n",
      "Batch 192, Loss: 0.009131, Accuracy: 99.47%\n",
      "Batch 193, Loss: 0.007286, Accuracy: 99.47%\n",
      "Batch 194, Loss: 0.023249, Accuracy: 99.47%\n",
      "Batch 195, Loss: 0.078589, Accuracy: 99.46%\n",
      "Batch 196, Loss: 0.012121, Accuracy: 99.47%\n",
      "Batch 197, Loss: 0.002162, Accuracy: 99.47%\n",
      "Batch 198, Loss: 0.013247, Accuracy: 99.46%\n",
      "Batch 199, Loss: 0.040215, Accuracy: 99.46%\n",
      "Batch 200, Loss: 0.059741, Accuracy: 99.45%\n",
      "Batch 201, Loss: 0.001478, Accuracy: 99.46%\n",
      "Batch 202, Loss: 0.008039, Accuracy: 99.46%\n",
      "Batch 203, Loss: 0.008164, Accuracy: 99.46%\n",
      "Batch 204, Loss: 0.005518, Accuracy: 99.46%\n",
      "Batch 205, Loss: 0.002690, Accuracy: 99.47%\n",
      "Batch 206, Loss: 0.109749, Accuracy: 99.45%\n",
      "Batch 207, Loss: 0.003449, Accuracy: 99.46%\n",
      "Batch 208, Loss: 0.243034, Accuracy: 99.43%\n",
      "Batch 209, Loss: 0.045967, Accuracy: 99.42%\n",
      "Batch 210, Loss: 0.001835, Accuracy: 99.43%\n",
      "Batch 211, Loss: 0.004089, Accuracy: 99.43%\n",
      "Batch 212, Loss: 0.033013, Accuracy: 99.43%\n",
      "Batch 213, Loss: 0.046632, Accuracy: 99.42%\n",
      "Training - Epoch 18, Loss: 0.017808, Accuracy: 99.42%\n",
      "Validation Batch 1, Loss: 0.011739, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.059706, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.013193, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.025737, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.004565, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.004558, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.139202, Accuracy: 98.88%\n",
      "Validation Batch 8, Loss: 0.091481, Accuracy: 98.83%\n",
      "Validation Batch 9, Loss: 0.085945, Accuracy: 98.44%\n",
      "Validation Batch 10, Loss: 0.007773, Accuracy: 98.59%\n",
      "Validation Batch 11, Loss: 0.008015, Accuracy: 98.72%\n",
      "Validation Batch 12, Loss: 0.081898, Accuracy: 98.57%\n",
      "Validation Batch 13, Loss: 0.007819, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.022119, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.043869, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.010846, Accuracy: 98.73%\n",
      "Validation Batch 17, Loss: 0.075067, Accuracy: 98.62%\n",
      "Validation Batch 18, Loss: 0.062382, Accuracy: 98.61%\n",
      "Validation Batch 19, Loss: 0.057801, Accuracy: 98.60%\n",
      "Validation Batch 20, Loss: 0.042835, Accuracy: 98.59%\n",
      "Validation Batch 21, Loss: 0.024452, Accuracy: 98.59%\n",
      "Validation Batch 22, Loss: 0.034706, Accuracy: 98.58%\n",
      "Validation Batch 23, Loss: 0.046861, Accuracy: 98.51%\n",
      "Validation Batch 24, Loss: 0.129184, Accuracy: 98.37%\n",
      "Validation Batch 25, Loss: 0.019781, Accuracy: 98.38%\n",
      "Validation Batch 26, Loss: 0.071098, Accuracy: 98.32%\n",
      "Validation Batch 27, Loss: 0.046068, Accuracy: 98.30%\n",
      "Validation - Epoch 18, Loss: 0.045507, Accuracy: 98.30%\n",
      "Patience—5\n",
      "Epoch 19\n",
      "Batch 1, Loss: 0.013287, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.056813, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.011628, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.023524, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.028610, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.031270, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.102151, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.019473, Accuracy: 99.02%\n",
      "Batch 9, Loss: 0.012480, Accuracy: 99.13%\n",
      "Batch 10, Loss: 0.038222, Accuracy: 99.06%\n",
      "Batch 11, Loss: 0.023546, Accuracy: 99.01%\n",
      "Batch 12, Loss: 0.004649, Accuracy: 99.09%\n",
      "Batch 13, Loss: 0.019695, Accuracy: 99.16%\n",
      "Batch 14, Loss: 0.014973, Accuracy: 99.22%\n",
      "Batch 15, Loss: 0.002521, Accuracy: 99.27%\n",
      "Batch 16, Loss: 0.017081, Accuracy: 99.22%\n",
      "Batch 17, Loss: 0.001795, Accuracy: 99.26%\n",
      "Batch 18, Loss: 0.006449, Accuracy: 99.31%\n",
      "Batch 19, Loss: 0.011234, Accuracy: 99.34%\n",
      "Batch 20, Loss: 0.013130, Accuracy: 99.38%\n",
      "Batch 21, Loss: 0.000741, Accuracy: 99.40%\n",
      "Batch 22, Loss: 0.001866, Accuracy: 99.43%\n",
      "Batch 23, Loss: 0.000846, Accuracy: 99.46%\n",
      "Batch 24, Loss: 0.012934, Accuracy: 99.48%\n",
      "Batch 25, Loss: 0.030469, Accuracy: 99.50%\n",
      "Batch 26, Loss: 0.000955, Accuracy: 99.52%\n",
      "Batch 27, Loss: 0.004748, Accuracy: 99.54%\n",
      "Batch 28, Loss: 0.026101, Accuracy: 99.50%\n",
      "Batch 29, Loss: 0.000692, Accuracy: 99.52%\n",
      "Batch 30, Loss: 0.020541, Accuracy: 99.48%\n",
      "Batch 31, Loss: 0.001084, Accuracy: 99.50%\n",
      "Batch 32, Loss: 0.000799, Accuracy: 99.51%\n",
      "Batch 33, Loss: 0.000803, Accuracy: 99.53%\n",
      "Batch 34, Loss: 0.001246, Accuracy: 99.54%\n",
      "Batch 35, Loss: 0.034106, Accuracy: 99.51%\n",
      "Batch 36, Loss: 0.010423, Accuracy: 99.52%\n",
      "Batch 37, Loss: 0.003958, Accuracy: 99.54%\n",
      "Batch 38, Loss: 0.000562, Accuracy: 99.55%\n",
      "Batch 39, Loss: 0.026323, Accuracy: 99.52%\n",
      "Batch 40, Loss: 0.056366, Accuracy: 99.49%\n",
      "Batch 41, Loss: 0.004039, Accuracy: 99.50%\n",
      "Batch 42, Loss: 0.015955, Accuracy: 99.48%\n",
      "Batch 43, Loss: 0.001067, Accuracy: 99.49%\n",
      "Batch 44, Loss: 0.005153, Accuracy: 99.50%\n",
      "Batch 45, Loss: 0.001145, Accuracy: 99.51%\n",
      "Batch 46, Loss: 0.056509, Accuracy: 99.49%\n",
      "Batch 47, Loss: 0.010120, Accuracy: 99.50%\n",
      "Batch 48, Loss: 0.000298, Accuracy: 99.51%\n",
      "Batch 49, Loss: 0.002366, Accuracy: 99.52%\n",
      "Batch 50, Loss: 0.000891, Accuracy: 99.53%\n",
      "Batch 51, Loss: 0.035718, Accuracy: 99.51%\n",
      "Batch 52, Loss: 0.001993, Accuracy: 99.52%\n",
      "Batch 53, Loss: 0.000212, Accuracy: 99.53%\n",
      "Batch 54, Loss: 0.000283, Accuracy: 99.54%\n",
      "Batch 55, Loss: 0.004206, Accuracy: 99.55%\n",
      "Batch 56, Loss: 0.001489, Accuracy: 99.55%\n",
      "Batch 57, Loss: 0.000199, Accuracy: 99.56%\n",
      "Batch 58, Loss: 0.016123, Accuracy: 99.54%\n",
      "Batch 59, Loss: 0.000432, Accuracy: 99.55%\n",
      "Batch 60, Loss: 0.076148, Accuracy: 99.51%\n",
      "Batch 61, Loss: 0.015243, Accuracy: 99.49%\n",
      "Batch 62, Loss: 0.002010, Accuracy: 99.50%\n",
      "Batch 63, Loss: 0.081588, Accuracy: 99.48%\n",
      "Batch 64, Loss: 0.102786, Accuracy: 99.46%\n",
      "Batch 65, Loss: 0.001488, Accuracy: 99.47%\n",
      "Batch 66, Loss: 0.010567, Accuracy: 99.48%\n",
      "Batch 67, Loss: 0.000492, Accuracy: 99.49%\n",
      "Batch 68, Loss: 0.051361, Accuracy: 99.47%\n",
      "Batch 69, Loss: 0.006992, Accuracy: 99.48%\n",
      "Batch 70, Loss: 0.131218, Accuracy: 99.44%\n",
      "Batch 71, Loss: 0.109190, Accuracy: 99.41%\n",
      "Batch 72, Loss: 0.037914, Accuracy: 99.37%\n",
      "Batch 73, Loss: 0.002903, Accuracy: 99.38%\n",
      "Batch 74, Loss: 0.032805, Accuracy: 99.39%\n",
      "Batch 75, Loss: 0.034516, Accuracy: 99.38%\n",
      "Batch 76, Loss: 0.002767, Accuracy: 99.38%\n",
      "Batch 77, Loss: 0.007170, Accuracy: 99.39%\n",
      "Batch 78, Loss: 0.081395, Accuracy: 99.38%\n",
      "Batch 79, Loss: 0.067781, Accuracy: 99.35%\n",
      "Batch 80, Loss: 0.059115, Accuracy: 99.34%\n",
      "Batch 81, Loss: 0.123882, Accuracy: 99.31%\n",
      "Batch 82, Loss: 0.041171, Accuracy: 99.28%\n",
      "Batch 83, Loss: 0.005312, Accuracy: 99.28%\n",
      "Batch 84, Loss: 0.109104, Accuracy: 99.26%\n",
      "Batch 85, Loss: 0.056664, Accuracy: 99.23%\n",
      "Batch 86, Loss: 0.019463, Accuracy: 99.24%\n",
      "Batch 87, Loss: 0.037068, Accuracy: 99.23%\n",
      "Batch 88, Loss: 0.003627, Accuracy: 99.24%\n",
      "Batch 89, Loss: 0.006985, Accuracy: 99.25%\n",
      "Batch 90, Loss: 0.002420, Accuracy: 99.25%\n",
      "Batch 91, Loss: 0.005081, Accuracy: 99.26%\n",
      "Batch 92, Loss: 0.012839, Accuracy: 99.27%\n",
      "Batch 93, Loss: 0.069784, Accuracy: 99.26%\n",
      "Batch 94, Loss: 0.032773, Accuracy: 99.25%\n",
      "Batch 95, Loss: 0.011790, Accuracy: 99.26%\n",
      "Batch 96, Loss: 0.065521, Accuracy: 99.25%\n",
      "Batch 97, Loss: 0.047519, Accuracy: 99.24%\n",
      "Batch 98, Loss: 0.076486, Accuracy: 99.22%\n",
      "Batch 99, Loss: 0.021082, Accuracy: 99.21%\n",
      "Batch 100, Loss: 0.013985, Accuracy: 99.22%\n",
      "Batch 101, Loss: 0.005782, Accuracy: 99.23%\n",
      "Batch 102, Loss: 0.002898, Accuracy: 99.23%\n",
      "Batch 103, Loss: 0.012780, Accuracy: 99.24%\n",
      "Batch 104, Loss: 0.010013, Accuracy: 99.25%\n",
      "Batch 105, Loss: 0.053347, Accuracy: 99.24%\n",
      "Batch 106, Loss: 0.008112, Accuracy: 99.25%\n",
      "Batch 107, Loss: 0.008400, Accuracy: 99.26%\n",
      "Batch 108, Loss: 0.022744, Accuracy: 99.25%\n",
      "Batch 109, Loss: 0.021196, Accuracy: 99.25%\n",
      "Batch 110, Loss: 0.006906, Accuracy: 99.26%\n",
      "Batch 111, Loss: 0.078604, Accuracy: 99.23%\n",
      "Batch 112, Loss: 0.003201, Accuracy: 99.23%\n",
      "Batch 113, Loss: 0.038670, Accuracy: 99.21%\n",
      "Batch 114, Loss: 0.008805, Accuracy: 99.22%\n",
      "Batch 115, Loss: 0.131265, Accuracy: 99.21%\n",
      "Batch 116, Loss: 0.015197, Accuracy: 99.22%\n",
      "Batch 117, Loss: 0.061829, Accuracy: 99.21%\n",
      "Batch 118, Loss: 0.016215, Accuracy: 99.22%\n",
      "Batch 119, Loss: 0.006063, Accuracy: 99.23%\n",
      "Batch 120, Loss: 0.025406, Accuracy: 99.22%\n",
      "Batch 121, Loss: 0.001453, Accuracy: 99.23%\n",
      "Batch 122, Loss: 0.141508, Accuracy: 99.19%\n",
      "Batch 123, Loss: 0.012875, Accuracy: 99.20%\n",
      "Batch 124, Loss: 0.063291, Accuracy: 99.18%\n",
      "Batch 125, Loss: 0.060745, Accuracy: 99.17%\n",
      "Batch 126, Loss: 0.208532, Accuracy: 99.14%\n",
      "Batch 127, Loss: 0.045200, Accuracy: 99.13%\n",
      "Batch 128, Loss: 0.014211, Accuracy: 99.12%\n",
      "Batch 129, Loss: 0.003527, Accuracy: 99.13%\n",
      "Batch 130, Loss: 0.033123, Accuracy: 99.11%\n",
      "Batch 131, Loss: 0.016020, Accuracy: 99.12%\n",
      "Batch 132, Loss: 0.007552, Accuracy: 99.12%\n",
      "Batch 133, Loss: 0.014308, Accuracy: 99.13%\n",
      "Batch 134, Loss: 0.026704, Accuracy: 99.13%\n",
      "Batch 135, Loss: 0.048873, Accuracy: 99.10%\n",
      "Batch 136, Loss: 0.006685, Accuracy: 99.10%\n",
      "Batch 137, Loss: 0.013059, Accuracy: 99.11%\n",
      "Batch 138, Loss: 0.015554, Accuracy: 99.12%\n",
      "Batch 139, Loss: 0.007136, Accuracy: 99.12%\n",
      "Batch 140, Loss: 0.006096, Accuracy: 99.13%\n",
      "Batch 141, Loss: 0.095783, Accuracy: 99.12%\n",
      "Batch 142, Loss: 0.005108, Accuracy: 99.13%\n",
      "Batch 143, Loss: 0.011039, Accuracy: 99.14%\n",
      "Batch 144, Loss: 0.027441, Accuracy: 99.13%\n",
      "Batch 145, Loss: 0.002076, Accuracy: 99.14%\n",
      "Batch 146, Loss: 0.008695, Accuracy: 99.14%\n",
      "Batch 147, Loss: 0.002589, Accuracy: 99.15%\n",
      "Batch 148, Loss: 0.002855, Accuracy: 99.16%\n",
      "Batch 149, Loss: 0.117632, Accuracy: 99.14%\n",
      "Batch 150, Loss: 0.000934, Accuracy: 99.15%\n",
      "Batch 151, Loss: 0.037186, Accuracy: 99.14%\n",
      "Batch 152, Loss: 0.001207, Accuracy: 99.15%\n",
      "Batch 153, Loss: 0.004226, Accuracy: 99.15%\n",
      "Batch 154, Loss: 0.005738, Accuracy: 99.16%\n",
      "Batch 155, Loss: 0.022456, Accuracy: 99.16%\n",
      "Batch 156, Loss: 0.010577, Accuracy: 99.17%\n",
      "Batch 157, Loss: 0.096554, Accuracy: 99.16%\n",
      "Batch 158, Loss: 0.046662, Accuracy: 99.16%\n",
      "Batch 159, Loss: 0.004423, Accuracy: 99.16%\n",
      "Batch 160, Loss: 0.017242, Accuracy: 99.16%\n",
      "Batch 161, Loss: 0.064699, Accuracy: 99.14%\n",
      "Batch 162, Loss: 0.014755, Accuracy: 99.13%\n",
      "Batch 163, Loss: 0.047498, Accuracy: 99.13%\n",
      "Batch 164, Loss: 0.054629, Accuracy: 99.12%\n",
      "Batch 165, Loss: 0.003780, Accuracy: 99.13%\n",
      "Batch 166, Loss: 0.024221, Accuracy: 99.12%\n",
      "Batch 167, Loss: 0.021665, Accuracy: 99.13%\n",
      "Batch 168, Loss: 0.001671, Accuracy: 99.14%\n",
      "Batch 169, Loss: 0.001841, Accuracy: 99.14%\n",
      "Batch 170, Loss: 0.003498, Accuracy: 99.15%\n",
      "Batch 171, Loss: 0.037294, Accuracy: 99.13%\n",
      "Batch 172, Loss: 0.009872, Accuracy: 99.14%\n",
      "Batch 173, Loss: 0.008231, Accuracy: 99.14%\n",
      "Batch 174, Loss: 0.000922, Accuracy: 99.15%\n",
      "Batch 175, Loss: 0.021596, Accuracy: 99.14%\n",
      "Batch 176, Loss: 0.041175, Accuracy: 99.13%\n",
      "Batch 177, Loss: 0.004581, Accuracy: 99.13%\n",
      "Batch 178, Loss: 0.001832, Accuracy: 99.14%\n",
      "Batch 179, Loss: 0.000647, Accuracy: 99.14%\n",
      "Batch 180, Loss: 0.064451, Accuracy: 99.14%\n",
      "Batch 181, Loss: 0.003701, Accuracy: 99.15%\n",
      "Batch 182, Loss: 0.053778, Accuracy: 99.14%\n",
      "Batch 183, Loss: 0.038089, Accuracy: 99.14%\n",
      "Batch 184, Loss: 0.001410, Accuracy: 99.14%\n",
      "Batch 185, Loss: 0.002544, Accuracy: 99.15%\n",
      "Batch 186, Loss: 0.009489, Accuracy: 99.15%\n",
      "Batch 187, Loss: 0.085689, Accuracy: 99.14%\n",
      "Batch 188, Loss: 0.000582, Accuracy: 99.14%\n",
      "Batch 189, Loss: 0.001351, Accuracy: 99.15%\n",
      "Batch 190, Loss: 0.005446, Accuracy: 99.15%\n",
      "Batch 191, Loss: 0.012328, Accuracy: 99.16%\n",
      "Batch 192, Loss: 0.163719, Accuracy: 99.15%\n",
      "Batch 193, Loss: 0.358077, Accuracy: 99.12%\n",
      "Batch 194, Loss: 0.007630, Accuracy: 99.12%\n",
      "Batch 195, Loss: 0.104712, Accuracy: 99.11%\n",
      "Batch 196, Loss: 0.006047, Accuracy: 99.12%\n",
      "Batch 197, Loss: 0.094560, Accuracy: 99.10%\n",
      "Batch 198, Loss: 0.051331, Accuracy: 99.09%\n",
      "Batch 199, Loss: 0.082497, Accuracy: 99.09%\n",
      "Batch 200, Loss: 0.142690, Accuracy: 99.07%\n",
      "Batch 201, Loss: 0.129622, Accuracy: 99.05%\n",
      "Batch 202, Loss: 0.090720, Accuracy: 99.03%\n",
      "Batch 203, Loss: 0.019137, Accuracy: 99.04%\n",
      "Batch 204, Loss: 0.089366, Accuracy: 99.03%\n",
      "Batch 205, Loss: 0.210911, Accuracy: 99.02%\n",
      "Batch 206, Loss: 0.172022, Accuracy: 98.99%\n",
      "Batch 207, Loss: 0.077823, Accuracy: 98.99%\n",
      "Batch 208, Loss: 0.235431, Accuracy: 98.96%\n",
      "Batch 209, Loss: 0.005809, Accuracy: 98.96%\n",
      "Batch 210, Loss: 0.020901, Accuracy: 98.97%\n",
      "Batch 211, Loss: 0.182458, Accuracy: 98.96%\n",
      "Batch 212, Loss: 0.065965, Accuracy: 98.95%\n",
      "Batch 213, Loss: 0.029271, Accuracy: 98.96%\n",
      "Training - Epoch 19, Loss: 0.034331, Accuracy: 98.96%\n",
      "Validation Batch 1, Loss: 0.185324, Accuracy: 92.19%\n",
      "Validation Batch 2, Loss: 0.140180, Accuracy: 93.75%\n",
      "Validation Batch 3, Loss: 0.102234, Accuracy: 94.27%\n",
      "Validation Batch 4, Loss: 0.210199, Accuracy: 94.53%\n",
      "Validation Batch 5, Loss: 0.118744, Accuracy: 94.69%\n",
      "Validation Batch 6, Loss: 0.042397, Accuracy: 95.31%\n",
      "Validation Batch 7, Loss: 0.071942, Accuracy: 95.31%\n",
      "Validation Batch 8, Loss: 0.102631, Accuracy: 95.51%\n",
      "Validation Batch 9, Loss: 0.173907, Accuracy: 95.83%\n",
      "Validation Batch 10, Loss: 0.364380, Accuracy: 95.62%\n",
      "Validation Batch 11, Loss: 0.290319, Accuracy: 95.45%\n",
      "Validation Batch 12, Loss: 0.182361, Accuracy: 95.44%\n",
      "Validation Batch 13, Loss: 0.282798, Accuracy: 95.43%\n",
      "Validation Batch 14, Loss: 0.180792, Accuracy: 95.54%\n",
      "Validation Batch 15, Loss: 0.137096, Accuracy: 95.42%\n",
      "Validation Batch 16, Loss: 0.145119, Accuracy: 95.51%\n",
      "Validation Batch 17, Loss: 0.137769, Accuracy: 95.50%\n",
      "Validation Batch 18, Loss: 0.097697, Accuracy: 95.66%\n",
      "Validation Batch 19, Loss: 0.196068, Accuracy: 95.39%\n",
      "Validation Batch 20, Loss: 0.097903, Accuracy: 95.47%\n",
      "Validation Batch 21, Loss: 0.524466, Accuracy: 95.09%\n",
      "Validation Batch 22, Loss: 0.198898, Accuracy: 94.96%\n",
      "Validation Batch 23, Loss: 0.192737, Accuracy: 94.90%\n",
      "Validation Batch 24, Loss: 0.234504, Accuracy: 94.79%\n",
      "Validation Batch 25, Loss: 0.055159, Accuracy: 94.94%\n",
      "Validation Batch 26, Loss: 0.123165, Accuracy: 95.01%\n",
      "Validation Batch 27, Loss: 0.110877, Accuracy: 95.01%\n",
      "Validation - Epoch 19, Loss: 0.174062, Accuracy: 95.01%\n",
      "Patience—6\n",
      "Epoch 20\n",
      "Batch 1, Loss: 0.179691, Accuracy: 93.75%\n",
      "Batch 2, Loss: 0.073391, Accuracy: 96.09%\n",
      "Batch 3, Loss: 0.035832, Accuracy: 97.40%\n",
      "Batch 4, Loss: 0.007516, Accuracy: 98.05%\n",
      "Batch 5, Loss: 0.014472, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.009108, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.006089, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.011323, Accuracy: 99.02%\n",
      "Batch 9, Loss: 0.074478, Accuracy: 98.78%\n",
      "Batch 10, Loss: 0.013286, Accuracy: 98.91%\n",
      "Batch 11, Loss: 0.061232, Accuracy: 98.58%\n",
      "Batch 12, Loss: 0.059312, Accuracy: 98.57%\n",
      "Batch 13, Loss: 0.063918, Accuracy: 98.44%\n",
      "Batch 14, Loss: 0.015560, Accuracy: 98.55%\n",
      "Batch 15, Loss: 0.057159, Accuracy: 98.54%\n",
      "Batch 16, Loss: 0.002082, Accuracy: 98.63%\n",
      "Batch 17, Loss: 0.006052, Accuracy: 98.71%\n",
      "Batch 18, Loss: 0.064831, Accuracy: 98.61%\n",
      "Batch 19, Loss: 0.023846, Accuracy: 98.60%\n",
      "Batch 20, Loss: 0.003543, Accuracy: 98.67%\n",
      "Batch 21, Loss: 0.250971, Accuracy: 98.51%\n",
      "Batch 22, Loss: 0.017503, Accuracy: 98.58%\n",
      "Batch 23, Loss: 0.002156, Accuracy: 98.64%\n",
      "Batch 24, Loss: 0.005251, Accuracy: 98.70%\n",
      "Batch 25, Loss: 0.076783, Accuracy: 98.69%\n",
      "Batch 26, Loss: 0.002102, Accuracy: 98.74%\n",
      "Batch 27, Loss: 0.015839, Accuracy: 98.73%\n",
      "Batch 28, Loss: 0.158544, Accuracy: 98.72%\n",
      "Batch 29, Loss: 0.056145, Accuracy: 98.71%\n",
      "Batch 30, Loss: 0.060136, Accuracy: 98.65%\n",
      "Batch 31, Loss: 0.068687, Accuracy: 98.64%\n",
      "Batch 32, Loss: 0.022558, Accuracy: 98.63%\n",
      "Batch 33, Loss: 0.009250, Accuracy: 98.67%\n",
      "Batch 34, Loss: 0.012867, Accuracy: 98.71%\n",
      "Batch 35, Loss: 0.034569, Accuracy: 98.71%\n",
      "Batch 36, Loss: 0.019303, Accuracy: 98.70%\n",
      "Batch 37, Loss: 0.016421, Accuracy: 98.73%\n",
      "Batch 38, Loss: 0.115411, Accuracy: 98.73%\n",
      "Batch 39, Loss: 0.005234, Accuracy: 98.76%\n",
      "Batch 40, Loss: 0.014440, Accuracy: 98.79%\n",
      "Batch 41, Loss: 0.073583, Accuracy: 98.74%\n",
      "Batch 42, Loss: 0.027360, Accuracy: 98.74%\n",
      "Batch 43, Loss: 0.008253, Accuracy: 98.76%\n",
      "Batch 44, Loss: 0.003353, Accuracy: 98.79%\n",
      "Batch 45, Loss: 0.003920, Accuracy: 98.82%\n",
      "Batch 46, Loss: 0.010589, Accuracy: 98.85%\n",
      "Batch 47, Loss: 0.084984, Accuracy: 98.80%\n",
      "Batch 48, Loss: 0.003596, Accuracy: 98.83%\n",
      "Batch 49, Loss: 0.003497, Accuracy: 98.85%\n",
      "Batch 50, Loss: 0.002783, Accuracy: 98.88%\n",
      "Batch 51, Loss: 0.003944, Accuracy: 98.90%\n",
      "Batch 52, Loss: 0.020243, Accuracy: 98.89%\n",
      "Batch 53, Loss: 0.066556, Accuracy: 98.88%\n",
      "Batch 54, Loss: 0.009679, Accuracy: 98.90%\n",
      "Batch 55, Loss: 0.010677, Accuracy: 98.92%\n",
      "Batch 56, Loss: 0.057022, Accuracy: 98.88%\n",
      "Batch 57, Loss: 0.035633, Accuracy: 98.88%\n",
      "Batch 58, Loss: 0.026755, Accuracy: 98.87%\n",
      "Batch 59, Loss: 0.002125, Accuracy: 98.89%\n",
      "Batch 60, Loss: 0.003687, Accuracy: 98.91%\n",
      "Batch 61, Loss: 0.007841, Accuracy: 98.92%\n",
      "Batch 62, Loss: 0.054122, Accuracy: 98.92%\n",
      "Batch 63, Loss: 0.006131, Accuracy: 98.93%\n",
      "Batch 64, Loss: 0.015021, Accuracy: 98.93%\n",
      "Batch 65, Loss: 0.113157, Accuracy: 98.92%\n",
      "Batch 66, Loss: 0.037893, Accuracy: 98.89%\n",
      "Batch 67, Loss: 0.078675, Accuracy: 98.86%\n",
      "Batch 68, Loss: 0.021357, Accuracy: 98.85%\n",
      "Batch 69, Loss: 0.011555, Accuracy: 98.87%\n",
      "Batch 70, Loss: 0.020614, Accuracy: 98.86%\n",
      "Batch 71, Loss: 0.019791, Accuracy: 98.86%\n",
      "Batch 72, Loss: 0.002286, Accuracy: 98.87%\n",
      "Batch 73, Loss: 0.002449, Accuracy: 98.89%\n",
      "Batch 74, Loss: 0.009341, Accuracy: 98.90%\n",
      "Batch 75, Loss: 0.066249, Accuracy: 98.90%\n",
      "Batch 76, Loss: 0.008984, Accuracy: 98.91%\n",
      "Batch 77, Loss: 0.032284, Accuracy: 98.92%\n",
      "Batch 78, Loss: 0.086060, Accuracy: 98.92%\n",
      "Batch 79, Loss: 0.007302, Accuracy: 98.93%\n",
      "Batch 80, Loss: 0.088681, Accuracy: 98.93%\n",
      "Batch 81, Loss: 0.004002, Accuracy: 98.94%\n",
      "Batch 82, Loss: 0.094295, Accuracy: 98.93%\n",
      "Batch 83, Loss: 0.068803, Accuracy: 98.93%\n",
      "Batch 84, Loss: 0.001329, Accuracy: 98.94%\n",
      "Batch 85, Loss: 0.020095, Accuracy: 98.93%\n",
      "Batch 86, Loss: 0.002686, Accuracy: 98.95%\n",
      "Batch 87, Loss: 0.155335, Accuracy: 98.92%\n",
      "Batch 88, Loss: 0.080640, Accuracy: 98.92%\n",
      "Batch 89, Loss: 0.003467, Accuracy: 98.93%\n",
      "Batch 90, Loss: 0.003434, Accuracy: 98.94%\n",
      "Batch 91, Loss: 0.002589, Accuracy: 98.95%\n",
      "Batch 92, Loss: 0.007939, Accuracy: 98.96%\n",
      "Batch 93, Loss: 0.009823, Accuracy: 98.98%\n",
      "Batch 94, Loss: 0.004144, Accuracy: 98.99%\n",
      "Batch 95, Loss: 0.003519, Accuracy: 99.00%\n",
      "Batch 96, Loss: 0.005973, Accuracy: 99.01%\n",
      "Batch 97, Loss: 0.003511, Accuracy: 99.02%\n",
      "Batch 98, Loss: 0.017364, Accuracy: 99.03%\n",
      "Batch 99, Loss: 0.005973, Accuracy: 99.04%\n",
      "Batch 100, Loss: 0.006014, Accuracy: 99.05%\n",
      "Batch 101, Loss: 0.001783, Accuracy: 99.06%\n",
      "Batch 102, Loss: 0.003379, Accuracy: 99.07%\n",
      "Batch 103, Loss: 0.012229, Accuracy: 99.07%\n",
      "Batch 104, Loss: 0.003515, Accuracy: 99.08%\n",
      "Batch 105, Loss: 0.004047, Accuracy: 99.09%\n",
      "Batch 106, Loss: 0.105136, Accuracy: 99.09%\n",
      "Batch 107, Loss: 0.045873, Accuracy: 99.07%\n",
      "Batch 108, Loss: 0.002888, Accuracy: 99.07%\n",
      "Batch 109, Loss: 0.000977, Accuracy: 99.08%\n",
      "Batch 110, Loss: 0.002589, Accuracy: 99.09%\n",
      "Batch 111, Loss: 0.002349, Accuracy: 99.10%\n",
      "Batch 112, Loss: 0.000909, Accuracy: 99.11%\n",
      "Batch 113, Loss: 0.031435, Accuracy: 99.10%\n",
      "Batch 114, Loss: 0.001160, Accuracy: 99.11%\n",
      "Batch 115, Loss: 0.003392, Accuracy: 99.12%\n",
      "Batch 116, Loss: 0.010513, Accuracy: 99.12%\n",
      "Batch 117, Loss: 0.005853, Accuracy: 99.13%\n",
      "Batch 118, Loss: 0.034625, Accuracy: 99.13%\n",
      "Batch 119, Loss: 0.013779, Accuracy: 99.12%\n",
      "Batch 120, Loss: 0.001272, Accuracy: 99.13%\n",
      "Batch 121, Loss: 0.000710, Accuracy: 99.13%\n",
      "Batch 122, Loss: 0.001577, Accuracy: 99.14%\n",
      "Batch 123, Loss: 0.013021, Accuracy: 99.15%\n",
      "Batch 124, Loss: 0.002023, Accuracy: 99.16%\n",
      "Batch 125, Loss: 0.000813, Accuracy: 99.16%\n",
      "Batch 126, Loss: 0.003357, Accuracy: 99.17%\n",
      "Batch 127, Loss: 0.005822, Accuracy: 99.18%\n",
      "Batch 128, Loss: 0.074503, Accuracy: 99.17%\n",
      "Batch 129, Loss: 0.000985, Accuracy: 99.18%\n",
      "Batch 130, Loss: 0.000584, Accuracy: 99.18%\n",
      "Batch 131, Loss: 0.003138, Accuracy: 99.19%\n",
      "Batch 132, Loss: 0.001712, Accuracy: 99.20%\n",
      "Batch 133, Loss: 0.062312, Accuracy: 99.19%\n",
      "Batch 134, Loss: 0.018883, Accuracy: 99.18%\n",
      "Batch 135, Loss: 0.005410, Accuracy: 99.19%\n",
      "Batch 136, Loss: 0.001214, Accuracy: 99.20%\n",
      "Batch 137, Loss: 0.000674, Accuracy: 99.20%\n",
      "Batch 138, Loss: 0.001870, Accuracy: 99.21%\n",
      "Batch 139, Loss: 0.007563, Accuracy: 99.21%\n",
      "Batch 140, Loss: 0.028611, Accuracy: 99.21%\n",
      "Batch 141, Loss: 0.000924, Accuracy: 99.21%\n",
      "Batch 142, Loss: 0.001215, Accuracy: 99.22%\n",
      "Batch 143, Loss: 0.015060, Accuracy: 99.21%\n",
      "Batch 144, Loss: 0.001642, Accuracy: 99.22%\n",
      "Batch 145, Loss: 0.000704, Accuracy: 99.22%\n",
      "Batch 146, Loss: 0.001125, Accuracy: 99.23%\n",
      "Batch 147, Loss: 0.018737, Accuracy: 99.22%\n",
      "Batch 148, Loss: 0.000722, Accuracy: 99.23%\n",
      "Batch 149, Loss: 0.000616, Accuracy: 99.23%\n",
      "Batch 150, Loss: 0.013290, Accuracy: 99.24%\n",
      "Batch 151, Loss: 0.005813, Accuracy: 99.24%\n",
      "Batch 152, Loss: 0.000743, Accuracy: 99.25%\n",
      "Batch 153, Loss: 0.001265, Accuracy: 99.25%\n",
      "Batch 154, Loss: 0.000731, Accuracy: 99.26%\n",
      "Batch 155, Loss: 0.003328, Accuracy: 99.26%\n",
      "Batch 156, Loss: 0.002906, Accuracy: 99.27%\n",
      "Batch 157, Loss: 0.001376, Accuracy: 99.27%\n",
      "Batch 158, Loss: 0.009573, Accuracy: 99.28%\n",
      "Batch 159, Loss: 0.022254, Accuracy: 99.27%\n",
      "Batch 160, Loss: 0.002611, Accuracy: 99.28%\n",
      "Batch 161, Loss: 0.001698, Accuracy: 99.28%\n",
      "Batch 162, Loss: 0.008328, Accuracy: 99.29%\n",
      "Batch 163, Loss: 0.001360, Accuracy: 99.29%\n",
      "Batch 164, Loss: 0.000633, Accuracy: 99.29%\n",
      "Batch 165, Loss: 0.000918, Accuracy: 99.30%\n",
      "Batch 166, Loss: 0.000555, Accuracy: 99.30%\n",
      "Batch 167, Loss: 0.083485, Accuracy: 99.29%\n",
      "Batch 168, Loss: 0.000892, Accuracy: 99.29%\n",
      "Batch 169, Loss: 0.014064, Accuracy: 99.29%\n",
      "Batch 170, Loss: 0.000870, Accuracy: 99.29%\n",
      "Batch 171, Loss: 0.000255, Accuracy: 99.30%\n",
      "Batch 172, Loss: 0.019552, Accuracy: 99.29%\n",
      "Batch 173, Loss: 0.000309, Accuracy: 99.30%\n",
      "Batch 174, Loss: 0.062379, Accuracy: 99.29%\n",
      "Batch 175, Loss: 0.039617, Accuracy: 99.29%\n",
      "Batch 176, Loss: 0.002378, Accuracy: 99.29%\n",
      "Batch 177, Loss: 0.021801, Accuracy: 99.28%\n",
      "Batch 178, Loss: 0.019547, Accuracy: 99.28%\n",
      "Batch 179, Loss: 0.007513, Accuracy: 99.28%\n",
      "Batch 180, Loss: 0.050490, Accuracy: 99.27%\n",
      "Batch 181, Loss: 0.066889, Accuracy: 99.27%\n",
      "Batch 182, Loss: 0.077297, Accuracy: 99.26%\n",
      "Batch 183, Loss: 0.064991, Accuracy: 99.26%\n",
      "Batch 184, Loss: 0.025715, Accuracy: 99.25%\n",
      "Batch 185, Loss: 0.004791, Accuracy: 99.26%\n",
      "Batch 186, Loss: 0.002158, Accuracy: 99.26%\n",
      "Batch 187, Loss: 0.172917, Accuracy: 99.23%\n",
      "Batch 188, Loss: 0.095286, Accuracy: 99.21%\n",
      "Batch 189, Loss: 0.013197, Accuracy: 99.21%\n",
      "Batch 190, Loss: 0.009365, Accuracy: 99.22%\n",
      "Batch 191, Loss: 0.030068, Accuracy: 99.21%\n",
      "Batch 192, Loss: 0.061086, Accuracy: 99.20%\n",
      "Batch 193, Loss: 0.002749, Accuracy: 99.21%\n",
      "Batch 194, Loss: 0.164320, Accuracy: 99.20%\n",
      "Batch 195, Loss: 0.044922, Accuracy: 99.20%\n",
      "Batch 196, Loss: 0.087988, Accuracy: 99.19%\n",
      "Batch 197, Loss: 0.021968, Accuracy: 99.19%\n",
      "Batch 198, Loss: 0.098982, Accuracy: 99.19%\n",
      "Batch 199, Loss: 0.004713, Accuracy: 99.19%\n",
      "Batch 200, Loss: 0.018842, Accuracy: 99.20%\n",
      "Batch 201, Loss: 0.040113, Accuracy: 99.18%\n",
      "Batch 202, Loss: 0.017444, Accuracy: 99.18%\n",
      "Batch 203, Loss: 0.072303, Accuracy: 99.17%\n",
      "Batch 204, Loss: 0.005137, Accuracy: 99.17%\n",
      "Batch 205, Loss: 0.012731, Accuracy: 99.18%\n",
      "Batch 206, Loss: 0.037058, Accuracy: 99.17%\n",
      "Batch 207, Loss: 0.023555, Accuracy: 99.18%\n",
      "Batch 208, Loss: 0.007009, Accuracy: 99.18%\n",
      "Batch 209, Loss: 0.011774, Accuracy: 99.19%\n",
      "Batch 210, Loss: 0.047119, Accuracy: 99.18%\n",
      "Batch 211, Loss: 0.005758, Accuracy: 99.19%\n",
      "Batch 212, Loss: 0.009355, Accuracy: 99.19%\n",
      "Batch 213, Loss: 0.050626, Accuracy: 99.19%\n",
      "Training - Epoch 20, Loss: 0.027079, Accuracy: 99.19%\n",
      "Validation Batch 1, Loss: 0.060653, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.019022, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.027478, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.036028, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.134724, Accuracy: 98.12%\n",
      "Validation Batch 6, Loss: 0.009828, Accuracy: 98.44%\n",
      "Validation Batch 7, Loss: 0.059021, Accuracy: 98.21%\n",
      "Validation Batch 8, Loss: 0.031868, Accuracy: 98.24%\n",
      "Validation Batch 9, Loss: 0.005646, Accuracy: 98.44%\n",
      "Validation Batch 10, Loss: 0.091663, Accuracy: 98.28%\n",
      "Validation Batch 11, Loss: 0.090330, Accuracy: 98.15%\n",
      "Validation Batch 12, Loss: 0.081030, Accuracy: 98.05%\n",
      "Validation Batch 13, Loss: 0.015508, Accuracy: 98.20%\n",
      "Validation Batch 14, Loss: 0.005219, Accuracy: 98.33%\n",
      "Validation Batch 15, Loss: 0.046597, Accuracy: 98.23%\n",
      "Validation Batch 16, Loss: 0.109986, Accuracy: 98.24%\n",
      "Validation Batch 17, Loss: 0.027345, Accuracy: 98.25%\n",
      "Validation Batch 18, Loss: 0.050458, Accuracy: 98.18%\n",
      "Validation Batch 19, Loss: 0.023295, Accuracy: 98.27%\n",
      "Validation Batch 20, Loss: 0.130313, Accuracy: 98.20%\n",
      "Validation Batch 21, Loss: 0.053182, Accuracy: 98.14%\n",
      "Validation Batch 22, Loss: 0.042920, Accuracy: 98.08%\n",
      "Validation Batch 23, Loss: 0.075242, Accuracy: 98.10%\n",
      "Validation Batch 24, Loss: 0.130289, Accuracy: 98.05%\n",
      "Validation Batch 25, Loss: 0.135555, Accuracy: 98.00%\n",
      "Validation Batch 26, Loss: 0.020810, Accuracy: 98.02%\n",
      "Validation Batch 27, Loss: 0.011261, Accuracy: 98.06%\n",
      "Validation - Epoch 20, Loss: 0.056492, Accuracy: 98.06%\n",
      "Patience—7\n",
      "Epoch 21\n",
      "Batch 1, Loss: 0.013063, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.054897, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.039693, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.091329, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.080037, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.006475, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.006585, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.004327, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.015647, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.023038, Accuracy: 99.22%\n",
      "Batch 11, Loss: 0.093316, Accuracy: 99.15%\n",
      "Batch 12, Loss: 0.008009, Accuracy: 99.22%\n",
      "Batch 13, Loss: 0.016076, Accuracy: 99.28%\n",
      "Batch 14, Loss: 0.040205, Accuracy: 99.22%\n",
      "Batch 15, Loss: 0.015101, Accuracy: 99.17%\n",
      "Batch 16, Loss: 0.042414, Accuracy: 99.12%\n",
      "Batch 17, Loss: 0.002141, Accuracy: 99.17%\n",
      "Batch 18, Loss: 0.014346, Accuracy: 99.22%\n",
      "Batch 19, Loss: 0.001617, Accuracy: 99.26%\n",
      "Batch 20, Loss: 0.021924, Accuracy: 99.22%\n",
      "Batch 21, Loss: 0.006765, Accuracy: 99.26%\n",
      "Batch 22, Loss: 0.002099, Accuracy: 99.29%\n",
      "Batch 23, Loss: 0.018699, Accuracy: 99.32%\n",
      "Batch 24, Loss: 0.004045, Accuracy: 99.35%\n",
      "Batch 25, Loss: 0.019939, Accuracy: 99.31%\n",
      "Batch 26, Loss: 0.005096, Accuracy: 99.34%\n",
      "Batch 27, Loss: 0.041339, Accuracy: 99.31%\n",
      "Batch 28, Loss: 0.045035, Accuracy: 99.27%\n",
      "Batch 29, Loss: 0.001732, Accuracy: 99.30%\n",
      "Batch 30, Loss: 0.002054, Accuracy: 99.32%\n",
      "Batch 31, Loss: 0.004559, Accuracy: 99.34%\n",
      "Batch 32, Loss: 0.050225, Accuracy: 99.32%\n",
      "Batch 33, Loss: 0.015557, Accuracy: 99.34%\n",
      "Batch 34, Loss: 0.002906, Accuracy: 99.36%\n",
      "Batch 35, Loss: 0.007215, Accuracy: 99.38%\n",
      "Batch 36, Loss: 0.006658, Accuracy: 99.39%\n",
      "Batch 37, Loss: 0.001302, Accuracy: 99.41%\n",
      "Batch 38, Loss: 0.002165, Accuracy: 99.42%\n",
      "Batch 39, Loss: 0.002791, Accuracy: 99.44%\n",
      "Batch 40, Loss: 0.000992, Accuracy: 99.45%\n",
      "Batch 41, Loss: 0.002924, Accuracy: 99.47%\n",
      "Batch 42, Loss: 0.001644, Accuracy: 99.48%\n",
      "Batch 43, Loss: 0.003617, Accuracy: 99.49%\n",
      "Batch 44, Loss: 0.001817, Accuracy: 99.50%\n",
      "Batch 45, Loss: 0.015635, Accuracy: 99.48%\n",
      "Batch 46, Loss: 0.001047, Accuracy: 99.49%\n",
      "Batch 47, Loss: 0.001971, Accuracy: 99.50%\n",
      "Batch 48, Loss: 0.025765, Accuracy: 99.48%\n",
      "Batch 49, Loss: 0.002108, Accuracy: 99.49%\n",
      "Batch 50, Loss: 0.033976, Accuracy: 99.47%\n",
      "Batch 51, Loss: 0.015184, Accuracy: 99.48%\n",
      "Batch 52, Loss: 0.049891, Accuracy: 99.46%\n",
      "Batch 53, Loss: 0.034089, Accuracy: 99.44%\n",
      "Batch 54, Loss: 0.007685, Accuracy: 99.45%\n",
      "Batch 55, Loss: 0.004540, Accuracy: 99.46%\n",
      "Batch 56, Loss: 0.001403, Accuracy: 99.47%\n",
      "Batch 57, Loss: 0.000577, Accuracy: 99.48%\n",
      "Batch 58, Loss: 0.009723, Accuracy: 99.49%\n",
      "Batch 59, Loss: 0.001265, Accuracy: 99.50%\n",
      "Batch 60, Loss: 0.000730, Accuracy: 99.51%\n",
      "Batch 61, Loss: 0.000607, Accuracy: 99.51%\n",
      "Batch 62, Loss: 0.002192, Accuracy: 99.52%\n",
      "Batch 63, Loss: 0.001956, Accuracy: 99.53%\n",
      "Batch 64, Loss: 0.006122, Accuracy: 99.54%\n",
      "Batch 65, Loss: 0.089715, Accuracy: 99.52%\n",
      "Batch 66, Loss: 0.001522, Accuracy: 99.53%\n",
      "Batch 67, Loss: 0.015211, Accuracy: 99.53%\n",
      "Batch 68, Loss: 0.000675, Accuracy: 99.54%\n",
      "Batch 69, Loss: 0.006097, Accuracy: 99.55%\n",
      "Batch 70, Loss: 0.014422, Accuracy: 99.55%\n",
      "Batch 71, Loss: 0.002908, Accuracy: 99.56%\n",
      "Batch 72, Loss: 0.000819, Accuracy: 99.57%\n",
      "Batch 73, Loss: 0.062491, Accuracy: 99.55%\n",
      "Batch 74, Loss: 0.000629, Accuracy: 99.56%\n",
      "Batch 75, Loss: 0.088363, Accuracy: 99.54%\n",
      "Batch 76, Loss: 0.002120, Accuracy: 99.55%\n",
      "Batch 77, Loss: 0.000780, Accuracy: 99.55%\n",
      "Batch 78, Loss: 0.000867, Accuracy: 99.56%\n",
      "Batch 79, Loss: 0.000777, Accuracy: 99.56%\n",
      "Batch 80, Loss: 0.019470, Accuracy: 99.55%\n",
      "Batch 81, Loss: 0.049279, Accuracy: 99.54%\n",
      "Batch 82, Loss: 0.012509, Accuracy: 99.54%\n",
      "Batch 83, Loss: 0.008067, Accuracy: 99.55%\n",
      "Batch 84, Loss: 0.000563, Accuracy: 99.55%\n",
      "Batch 85, Loss: 0.002859, Accuracy: 99.56%\n",
      "Batch 86, Loss: 0.002719, Accuracy: 99.56%\n",
      "Batch 87, Loss: 0.002422, Accuracy: 99.57%\n",
      "Batch 88, Loss: 0.001426, Accuracy: 99.57%\n",
      "Batch 89, Loss: 0.011860, Accuracy: 99.58%\n",
      "Batch 90, Loss: 0.000467, Accuracy: 99.58%\n",
      "Batch 91, Loss: 0.062137, Accuracy: 99.57%\n",
      "Batch 92, Loss: 0.001060, Accuracy: 99.58%\n",
      "Batch 93, Loss: 0.000334, Accuracy: 99.58%\n",
      "Batch 94, Loss: 0.004249, Accuracy: 99.58%\n",
      "Batch 95, Loss: 0.001561, Accuracy: 99.59%\n",
      "Batch 96, Loss: 0.003760, Accuracy: 99.59%\n",
      "Batch 97, Loss: 0.000659, Accuracy: 99.60%\n",
      "Batch 98, Loss: 0.003867, Accuracy: 99.60%\n",
      "Batch 99, Loss: 0.001076, Accuracy: 99.61%\n",
      "Batch 100, Loss: 0.021405, Accuracy: 99.59%\n",
      "Batch 101, Loss: 0.058305, Accuracy: 99.58%\n",
      "Batch 102, Loss: 0.001517, Accuracy: 99.59%\n",
      "Batch 103, Loss: 0.000565, Accuracy: 99.59%\n",
      "Batch 104, Loss: 0.000643, Accuracy: 99.59%\n",
      "Batch 105, Loss: 0.001836, Accuracy: 99.60%\n",
      "Batch 106, Loss: 0.001081, Accuracy: 99.60%\n",
      "Batch 107, Loss: 0.070257, Accuracy: 99.59%\n",
      "Batch 108, Loss: 0.097571, Accuracy: 99.57%\n",
      "Batch 109, Loss: 0.068127, Accuracy: 99.54%\n",
      "Batch 110, Loss: 0.111140, Accuracy: 99.52%\n",
      "Batch 111, Loss: 0.152645, Accuracy: 99.51%\n",
      "Batch 112, Loss: 0.232647, Accuracy: 99.48%\n",
      "Batch 113, Loss: 0.038679, Accuracy: 99.47%\n",
      "Batch 114, Loss: 0.014725, Accuracy: 99.48%\n",
      "Batch 115, Loss: 0.025649, Accuracy: 99.47%\n",
      "Batch 116, Loss: 0.004877, Accuracy: 99.47%\n",
      "Batch 117, Loss: 0.009833, Accuracy: 99.48%\n",
      "Batch 118, Loss: 0.087754, Accuracy: 99.47%\n",
      "Batch 119, Loss: 0.020019, Accuracy: 99.47%\n",
      "Batch 120, Loss: 0.083615, Accuracy: 99.47%\n",
      "Batch 121, Loss: 0.012173, Accuracy: 99.47%\n",
      "Batch 122, Loss: 0.009100, Accuracy: 99.47%\n",
      "Batch 123, Loss: 0.003738, Accuracy: 99.48%\n",
      "Batch 124, Loss: 0.069499, Accuracy: 99.47%\n",
      "Batch 125, Loss: 0.010572, Accuracy: 99.47%\n",
      "Batch 126, Loss: 0.003229, Accuracy: 99.48%\n",
      "Batch 127, Loss: 0.006022, Accuracy: 99.48%\n",
      "Batch 128, Loss: 0.009273, Accuracy: 99.49%\n",
      "Batch 129, Loss: 0.007412, Accuracy: 99.49%\n",
      "Batch 130, Loss: 0.003742, Accuracy: 99.50%\n",
      "Batch 131, Loss: 0.068770, Accuracy: 99.48%\n",
      "Batch 132, Loss: 0.020654, Accuracy: 99.47%\n",
      "Batch 133, Loss: 0.004953, Accuracy: 99.47%\n",
      "Batch 134, Loss: 0.007682, Accuracy: 99.48%\n",
      "Batch 135, Loss: 0.001692, Accuracy: 99.48%\n",
      "Batch 136, Loss: 0.005353, Accuracy: 99.48%\n",
      "Batch 137, Loss: 0.015989, Accuracy: 99.48%\n",
      "Batch 138, Loss: 0.002092, Accuracy: 99.48%\n",
      "Batch 139, Loss: 0.018573, Accuracy: 99.48%\n",
      "Batch 140, Loss: 0.002660, Accuracy: 99.49%\n",
      "Batch 141, Loss: 0.014522, Accuracy: 99.49%\n",
      "Batch 142, Loss: 0.030646, Accuracy: 99.48%\n",
      "Batch 143, Loss: 0.001371, Accuracy: 99.49%\n",
      "Batch 144, Loss: 0.031756, Accuracy: 99.48%\n",
      "Batch 145, Loss: 0.003128, Accuracy: 99.48%\n",
      "Batch 146, Loss: 0.001780, Accuracy: 99.49%\n",
      "Batch 147, Loss: 0.035117, Accuracy: 99.47%\n",
      "Batch 148, Loss: 0.004588, Accuracy: 99.47%\n",
      "Batch 149, Loss: 0.001134, Accuracy: 99.48%\n",
      "Batch 150, Loss: 0.000792, Accuracy: 99.48%\n",
      "Batch 151, Loss: 0.000847, Accuracy: 99.48%\n",
      "Batch 152, Loss: 0.056247, Accuracy: 99.48%\n",
      "Batch 153, Loss: 0.028810, Accuracy: 99.47%\n",
      "Batch 154, Loss: 0.003800, Accuracy: 99.47%\n",
      "Batch 155, Loss: 0.000758, Accuracy: 99.48%\n",
      "Batch 156, Loss: 0.016388, Accuracy: 99.47%\n",
      "Batch 157, Loss: 0.128048, Accuracy: 99.45%\n",
      "Batch 158, Loss: 0.086362, Accuracy: 99.44%\n",
      "Batch 159, Loss: 0.001124, Accuracy: 99.44%\n",
      "Batch 160, Loss: 0.005431, Accuracy: 99.44%\n",
      "Batch 161, Loss: 0.120629, Accuracy: 99.43%\n",
      "Batch 162, Loss: 0.002526, Accuracy: 99.43%\n",
      "Batch 163, Loss: 0.004361, Accuracy: 99.43%\n",
      "Batch 164, Loss: 0.003080, Accuracy: 99.44%\n",
      "Batch 165, Loss: 0.003957, Accuracy: 99.44%\n",
      "Batch 166, Loss: 0.091445, Accuracy: 99.44%\n",
      "Batch 167, Loss: 0.119560, Accuracy: 99.43%\n",
      "Batch 168, Loss: 0.065242, Accuracy: 99.42%\n",
      "Batch 169, Loss: 0.072025, Accuracy: 99.42%\n",
      "Batch 170, Loss: 0.011971, Accuracy: 99.42%\n",
      "Batch 171, Loss: 0.005371, Accuracy: 99.42%\n",
      "Batch 172, Loss: 0.003457, Accuracy: 99.43%\n",
      "Batch 173, Loss: 0.013269, Accuracy: 99.43%\n",
      "Batch 174, Loss: 0.006742, Accuracy: 99.43%\n",
      "Batch 175, Loss: 0.050121, Accuracy: 99.43%\n",
      "Batch 176, Loss: 0.020038, Accuracy: 99.42%\n",
      "Batch 177, Loss: 0.021014, Accuracy: 99.42%\n",
      "Batch 178, Loss: 0.074711, Accuracy: 99.41%\n",
      "Batch 179, Loss: 0.018549, Accuracy: 99.41%\n",
      "Batch 180, Loss: 0.003406, Accuracy: 99.41%\n",
      "Batch 181, Loss: 0.033613, Accuracy: 99.40%\n",
      "Batch 182, Loss: 0.266078, Accuracy: 99.37%\n",
      "Batch 183, Loss: 0.002394, Accuracy: 99.38%\n",
      "Batch 184, Loss: 0.048656, Accuracy: 99.37%\n",
      "Batch 185, Loss: 0.023008, Accuracy: 99.37%\n",
      "Batch 186, Loss: 0.025729, Accuracy: 99.37%\n",
      "Batch 187, Loss: 0.044062, Accuracy: 99.36%\n",
      "Batch 188, Loss: 0.029567, Accuracy: 99.36%\n",
      "Batch 189, Loss: 0.025953, Accuracy: 99.36%\n",
      "Batch 190, Loss: 0.105581, Accuracy: 99.35%\n",
      "Batch 191, Loss: 0.010710, Accuracy: 99.35%\n",
      "Batch 192, Loss: 0.014894, Accuracy: 99.36%\n",
      "Batch 193, Loss: 0.061400, Accuracy: 99.35%\n",
      "Batch 194, Loss: 0.005053, Accuracy: 99.36%\n",
      "Batch 195, Loss: 0.008237, Accuracy: 99.36%\n",
      "Batch 196, Loss: 0.006386, Accuracy: 99.36%\n",
      "Batch 197, Loss: 0.020719, Accuracy: 99.36%\n",
      "Batch 198, Loss: 0.007278, Accuracy: 99.36%\n",
      "Batch 199, Loss: 0.009158, Accuracy: 99.36%\n",
      "Batch 200, Loss: 0.018989, Accuracy: 99.37%\n",
      "Batch 201, Loss: 0.028212, Accuracy: 99.36%\n",
      "Batch 202, Loss: 0.004158, Accuracy: 99.37%\n",
      "Batch 203, Loss: 0.027447, Accuracy: 99.36%\n",
      "Batch 204, Loss: 0.005438, Accuracy: 99.36%\n",
      "Batch 205, Loss: 0.032328, Accuracy: 99.35%\n",
      "Batch 206, Loss: 0.004783, Accuracy: 99.36%\n",
      "Batch 207, Loss: 0.041165, Accuracy: 99.35%\n",
      "Batch 208, Loss: 0.004201, Accuracy: 99.35%\n",
      "Batch 209, Loss: 0.032338, Accuracy: 99.35%\n",
      "Batch 210, Loss: 0.006645, Accuracy: 99.35%\n",
      "Batch 211, Loss: 0.021312, Accuracy: 99.35%\n",
      "Batch 212, Loss: 0.043376, Accuracy: 99.34%\n",
      "Batch 213, Loss: 0.001745, Accuracy: 99.35%\n",
      "Training - Epoch 21, Loss: 0.023974, Accuracy: 99.35%\n",
      "Validation Batch 1, Loss: 0.004530, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.004104, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.027034, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.002108, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.009780, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.001594, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.001612, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.107719, Accuracy: 99.22%\n",
      "Validation Batch 9, Loss: 0.001737, Accuracy: 99.31%\n",
      "Validation Batch 10, Loss: 0.001561, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.021006, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.001412, Accuracy: 99.48%\n",
      "Validation Batch 13, Loss: 0.043897, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.027252, Accuracy: 99.22%\n",
      "Validation Batch 15, Loss: 0.005609, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.011577, Accuracy: 99.32%\n",
      "Validation Batch 17, Loss: 0.023910, Accuracy: 99.26%\n",
      "Validation Batch 18, Loss: 0.019577, Accuracy: 99.22%\n",
      "Validation Batch 19, Loss: 0.008953, Accuracy: 99.26%\n",
      "Validation Batch 20, Loss: 0.001085, Accuracy: 99.30%\n",
      "Validation Batch 21, Loss: 0.025121, Accuracy: 99.26%\n",
      "Validation Batch 22, Loss: 0.088023, Accuracy: 99.22%\n",
      "Validation Batch 23, Loss: 0.016653, Accuracy: 99.18%\n",
      "Validation Batch 24, Loss: 0.004684, Accuracy: 99.22%\n",
      "Validation Batch 25, Loss: 0.066056, Accuracy: 99.19%\n",
      "Validation Batch 26, Loss: 0.011781, Accuracy: 99.22%\n",
      "Validation Batch 27, Loss: 0.001701, Accuracy: 99.24%\n",
      "Validation - Epoch 21, Loss: 0.020003, Accuracy: 99.24%\n",
      "Patience—8\n",
      "Epoch 22\n",
      "Batch 1, Loss: 0.025639, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.022601, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.005076, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.003688, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.004080, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.002125, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.008265, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.004876, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.002724, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.014168, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.006920, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.011124, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.001482, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.007054, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.002141, Accuracy: 99.69%\n",
      "Batch 16, Loss: 0.000849, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.000374, Accuracy: 99.72%\n",
      "Batch 18, Loss: 0.007878, Accuracy: 99.74%\n",
      "Batch 19, Loss: 0.095228, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.000594, Accuracy: 99.69%\n",
      "Batch 21, Loss: 0.000498, Accuracy: 99.70%\n",
      "Batch 22, Loss: 0.000595, Accuracy: 99.72%\n",
      "Batch 23, Loss: 0.044252, Accuracy: 99.66%\n",
      "Batch 24, Loss: 0.014389, Accuracy: 99.67%\n",
      "Batch 25, Loss: 0.016192, Accuracy: 99.62%\n",
      "Batch 26, Loss: 0.000621, Accuracy: 99.64%\n",
      "Batch 27, Loss: 0.000753, Accuracy: 99.65%\n",
      "Batch 28, Loss: 0.002648, Accuracy: 99.67%\n",
      "Batch 29, Loss: 0.003628, Accuracy: 99.68%\n",
      "Batch 30, Loss: 0.001641, Accuracy: 99.69%\n",
      "Batch 31, Loss: 0.001595, Accuracy: 99.70%\n",
      "Batch 32, Loss: 0.171856, Accuracy: 99.61%\n",
      "Batch 33, Loss: 0.003282, Accuracy: 99.62%\n",
      "Batch 34, Loss: 0.076350, Accuracy: 99.59%\n",
      "Batch 35, Loss: 0.001113, Accuracy: 99.60%\n",
      "Batch 36, Loss: 0.001476, Accuracy: 99.61%\n",
      "Batch 37, Loss: 0.001808, Accuracy: 99.62%\n",
      "Batch 38, Loss: 0.004754, Accuracy: 99.63%\n",
      "Batch 39, Loss: 0.001923, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.008256, Accuracy: 99.65%\n",
      "Batch 41, Loss: 0.001178, Accuracy: 99.66%\n",
      "Batch 42, Loss: 0.008872, Accuracy: 99.67%\n",
      "Batch 43, Loss: 0.002369, Accuracy: 99.67%\n",
      "Batch 44, Loss: 0.002365, Accuracy: 99.68%\n",
      "Batch 45, Loss: 0.003573, Accuracy: 99.69%\n",
      "Batch 46, Loss: 0.015172, Accuracy: 99.69%\n",
      "Batch 47, Loss: 0.002900, Accuracy: 99.70%\n",
      "Batch 48, Loss: 0.013093, Accuracy: 99.67%\n",
      "Batch 49, Loss: 0.000469, Accuracy: 99.68%\n",
      "Batch 50, Loss: 0.002492, Accuracy: 99.69%\n",
      "Batch 51, Loss: 0.002473, Accuracy: 99.69%\n",
      "Batch 52, Loss: 0.000815, Accuracy: 99.70%\n",
      "Batch 53, Loss: 0.002562, Accuracy: 99.71%\n",
      "Batch 54, Loss: 0.003518, Accuracy: 99.71%\n",
      "Batch 55, Loss: 0.001600, Accuracy: 99.72%\n",
      "Batch 56, Loss: 0.000961, Accuracy: 99.72%\n",
      "Batch 57, Loss: 0.000591, Accuracy: 99.73%\n",
      "Batch 58, Loss: 0.017172, Accuracy: 99.70%\n",
      "Batch 59, Loss: 0.001498, Accuracy: 99.71%\n",
      "Batch 60, Loss: 0.002651, Accuracy: 99.71%\n",
      "Batch 61, Loss: 0.104712, Accuracy: 99.69%\n",
      "Batch 62, Loss: 0.000339, Accuracy: 99.70%\n",
      "Batch 63, Loss: 0.001549, Accuracy: 99.70%\n",
      "Batch 64, Loss: 0.000497, Accuracy: 99.71%\n",
      "Batch 65, Loss: 0.009060, Accuracy: 99.71%\n",
      "Batch 66, Loss: 0.000521, Accuracy: 99.72%\n",
      "Batch 67, Loss: 0.001771, Accuracy: 99.72%\n",
      "Batch 68, Loss: 0.001082, Accuracy: 99.72%\n",
      "Batch 69, Loss: 0.000847, Accuracy: 99.73%\n",
      "Batch 70, Loss: 0.001210, Accuracy: 99.73%\n",
      "Batch 71, Loss: 0.000966, Accuracy: 99.74%\n",
      "Batch 72, Loss: 0.001098, Accuracy: 99.74%\n",
      "Batch 73, Loss: 0.000761, Accuracy: 99.74%\n",
      "Batch 74, Loss: 0.001645, Accuracy: 99.75%\n",
      "Batch 75, Loss: 0.020880, Accuracy: 99.73%\n",
      "Batch 76, Loss: 0.000667, Accuracy: 99.73%\n",
      "Batch 77, Loss: 0.000475, Accuracy: 99.74%\n",
      "Batch 78, Loss: 0.001512, Accuracy: 99.74%\n",
      "Batch 79, Loss: 0.001436, Accuracy: 99.74%\n",
      "Batch 80, Loss: 0.013795, Accuracy: 99.73%\n",
      "Batch 81, Loss: 0.000468, Accuracy: 99.73%\n",
      "Batch 82, Loss: 0.002790, Accuracy: 99.73%\n",
      "Batch 83, Loss: 0.000534, Accuracy: 99.74%\n",
      "Batch 84, Loss: 0.001253, Accuracy: 99.74%\n",
      "Batch 85, Loss: 0.001242, Accuracy: 99.74%\n",
      "Batch 86, Loss: 0.002787, Accuracy: 99.75%\n",
      "Batch 87, Loss: 0.002075, Accuracy: 99.75%\n",
      "Batch 88, Loss: 0.012369, Accuracy: 99.73%\n",
      "Batch 89, Loss: 0.005292, Accuracy: 99.74%\n",
      "Batch 90, Loss: 0.001641, Accuracy: 99.74%\n",
      "Batch 91, Loss: 0.000796, Accuracy: 99.74%\n",
      "Batch 92, Loss: 0.005197, Accuracy: 99.75%\n",
      "Batch 93, Loss: 0.000513, Accuracy: 99.75%\n",
      "Batch 94, Loss: 0.000380, Accuracy: 99.75%\n",
      "Batch 95, Loss: 0.001007, Accuracy: 99.75%\n",
      "Batch 96, Loss: 0.000912, Accuracy: 99.76%\n",
      "Batch 97, Loss: 0.000640, Accuracy: 99.76%\n",
      "Batch 98, Loss: 0.001323, Accuracy: 99.76%\n",
      "Batch 99, Loss: 0.001110, Accuracy: 99.76%\n",
      "Batch 100, Loss: 0.000136, Accuracy: 99.77%\n",
      "Batch 101, Loss: 0.001260, Accuracy: 99.77%\n",
      "Batch 102, Loss: 0.000729, Accuracy: 99.77%\n",
      "Batch 103, Loss: 0.005238, Accuracy: 99.77%\n",
      "Batch 104, Loss: 0.000393, Accuracy: 99.77%\n",
      "Batch 105, Loss: 0.000233, Accuracy: 99.78%\n",
      "Batch 106, Loss: 0.000632, Accuracy: 99.78%\n",
      "Batch 107, Loss: 0.000194, Accuracy: 99.78%\n",
      "Batch 108, Loss: 0.000215, Accuracy: 99.78%\n",
      "Batch 109, Loss: 0.000273, Accuracy: 99.78%\n",
      "Batch 110, Loss: 0.000121, Accuracy: 99.79%\n",
      "Batch 111, Loss: 0.000207, Accuracy: 99.79%\n",
      "Batch 112, Loss: 0.000227, Accuracy: 99.79%\n",
      "Batch 113, Loss: 0.000414, Accuracy: 99.79%\n",
      "Batch 114, Loss: 0.000145, Accuracy: 99.79%\n",
      "Batch 115, Loss: 0.006500, Accuracy: 99.80%\n",
      "Batch 116, Loss: 0.000070, Accuracy: 99.80%\n",
      "Batch 117, Loss: 0.000320, Accuracy: 99.80%\n",
      "Batch 118, Loss: 0.000372, Accuracy: 99.80%\n",
      "Batch 119, Loss: 0.000196, Accuracy: 99.80%\n",
      "Batch 120, Loss: 0.000105, Accuracy: 99.80%\n",
      "Batch 121, Loss: 0.000353, Accuracy: 99.81%\n",
      "Batch 122, Loss: 0.000143, Accuracy: 99.81%\n",
      "Batch 123, Loss: 0.000064, Accuracy: 99.81%\n",
      "Batch 124, Loss: 0.000176, Accuracy: 99.81%\n",
      "Batch 125, Loss: 0.000137, Accuracy: 99.81%\n",
      "Batch 126, Loss: 0.000242, Accuracy: 99.81%\n",
      "Batch 127, Loss: 0.000224, Accuracy: 99.82%\n",
      "Batch 128, Loss: 0.000236, Accuracy: 99.82%\n",
      "Batch 129, Loss: 0.000604, Accuracy: 99.82%\n",
      "Batch 130, Loss: 0.000107, Accuracy: 99.82%\n",
      "Batch 131, Loss: 0.000113, Accuracy: 99.82%\n",
      "Batch 132, Loss: 0.000166, Accuracy: 99.82%\n",
      "Batch 133, Loss: 0.000042, Accuracy: 99.82%\n",
      "Batch 134, Loss: 0.000130, Accuracy: 99.83%\n",
      "Batch 135, Loss: 0.000097, Accuracy: 99.83%\n",
      "Batch 136, Loss: 0.000049, Accuracy: 99.83%\n",
      "Batch 137, Loss: 0.000097, Accuracy: 99.83%\n",
      "Batch 138, Loss: 0.000090, Accuracy: 99.83%\n",
      "Batch 139, Loss: 0.000169, Accuracy: 99.83%\n",
      "Batch 140, Loss: 0.000061, Accuracy: 99.83%\n",
      "Batch 141, Loss: 0.000105, Accuracy: 99.83%\n",
      "Batch 142, Loss: 0.000135, Accuracy: 99.83%\n",
      "Batch 143, Loss: 0.000052, Accuracy: 99.84%\n",
      "Batch 144, Loss: 0.000070, Accuracy: 99.84%\n",
      "Batch 145, Loss: 0.000051, Accuracy: 99.84%\n",
      "Batch 146, Loss: 0.000081, Accuracy: 99.84%\n",
      "Batch 147, Loss: 0.000100, Accuracy: 99.84%\n",
      "Batch 148, Loss: 0.000248, Accuracy: 99.84%\n",
      "Batch 149, Loss: 0.000556, Accuracy: 99.84%\n",
      "Batch 150, Loss: 0.000069, Accuracy: 99.84%\n",
      "Batch 151, Loss: 0.000209, Accuracy: 99.84%\n",
      "Batch 152, Loss: 0.000068, Accuracy: 99.85%\n",
      "Batch 153, Loss: 0.000107, Accuracy: 99.85%\n",
      "Batch 154, Loss: 0.000046, Accuracy: 99.85%\n",
      "Batch 155, Loss: 0.000078, Accuracy: 99.85%\n",
      "Batch 156, Loss: 0.000292, Accuracy: 99.85%\n",
      "Batch 157, Loss: 0.001510, Accuracy: 99.85%\n",
      "Batch 158, Loss: 0.000149, Accuracy: 99.85%\n",
      "Batch 159, Loss: 0.000314, Accuracy: 99.85%\n",
      "Batch 160, Loss: 0.000343, Accuracy: 99.85%\n",
      "Batch 161, Loss: 0.000035, Accuracy: 99.85%\n",
      "Batch 162, Loss: 0.000062, Accuracy: 99.86%\n",
      "Batch 163, Loss: 0.000038, Accuracy: 99.86%\n",
      "Batch 164, Loss: 0.000081, Accuracy: 99.86%\n",
      "Batch 165, Loss: 0.000284, Accuracy: 99.86%\n",
      "Batch 166, Loss: 0.000087, Accuracy: 99.86%\n",
      "Batch 167, Loss: 0.000438, Accuracy: 99.86%\n",
      "Batch 168, Loss: 0.000057, Accuracy: 99.86%\n",
      "Batch 169, Loss: 0.000251, Accuracy: 99.86%\n",
      "Batch 170, Loss: 0.000066, Accuracy: 99.86%\n",
      "Batch 171, Loss: 0.000048, Accuracy: 99.86%\n",
      "Batch 172, Loss: 0.000238, Accuracy: 99.86%\n",
      "Batch 173, Loss: 0.000092, Accuracy: 99.86%\n",
      "Batch 174, Loss: 0.000488, Accuracy: 99.87%\n",
      "Batch 175, Loss: 0.000204, Accuracy: 99.87%\n",
      "Batch 176, Loss: 0.000040, Accuracy: 99.87%\n",
      "Batch 177, Loss: 0.000252, Accuracy: 99.87%\n",
      "Batch 178, Loss: 0.000103, Accuracy: 99.87%\n",
      "Batch 179, Loss: 0.000027, Accuracy: 99.87%\n",
      "Batch 180, Loss: 0.000036, Accuracy: 99.87%\n",
      "Batch 181, Loss: 0.000027, Accuracy: 99.87%\n",
      "Batch 182, Loss: 0.000497, Accuracy: 99.87%\n",
      "Batch 183, Loss: 0.001241, Accuracy: 99.87%\n",
      "Batch 184, Loss: 0.009617, Accuracy: 99.87%\n",
      "Batch 185, Loss: 0.000056, Accuracy: 99.87%\n",
      "Batch 186, Loss: 0.000054, Accuracy: 99.87%\n",
      "Batch 187, Loss: 0.000050, Accuracy: 99.87%\n",
      "Batch 188, Loss: 0.000050, Accuracy: 99.88%\n",
      "Batch 189, Loss: 0.000048, Accuracy: 99.88%\n",
      "Batch 190, Loss: 0.000037, Accuracy: 99.88%\n",
      "Batch 191, Loss: 0.000038, Accuracy: 99.88%\n",
      "Batch 192, Loss: 0.000087, Accuracy: 99.88%\n",
      "Batch 193, Loss: 0.000037, Accuracy: 99.88%\n",
      "Batch 194, Loss: 0.000635, Accuracy: 99.88%\n",
      "Batch 195, Loss: 0.000261, Accuracy: 99.88%\n",
      "Batch 196, Loss: 0.000133, Accuracy: 99.88%\n",
      "Batch 197, Loss: 0.000059, Accuracy: 99.88%\n",
      "Batch 198, Loss: 0.000062, Accuracy: 99.88%\n",
      "Batch 199, Loss: 0.000044, Accuracy: 99.88%\n",
      "Batch 200, Loss: 0.000035, Accuracy: 99.88%\n",
      "Batch 201, Loss: 0.000782, Accuracy: 99.88%\n",
      "Batch 202, Loss: 0.000064, Accuracy: 99.88%\n",
      "Batch 203, Loss: 0.000044, Accuracy: 99.88%\n",
      "Batch 204, Loss: 0.001534, Accuracy: 99.89%\n",
      "Batch 205, Loss: 0.050713, Accuracy: 99.88%\n",
      "Batch 206, Loss: 0.000059, Accuracy: 99.88%\n",
      "Batch 207, Loss: 0.000074, Accuracy: 99.88%\n",
      "Batch 208, Loss: 0.000135, Accuracy: 99.88%\n",
      "Batch 209, Loss: 0.000171, Accuracy: 99.88%\n",
      "Batch 210, Loss: 0.000071, Accuracy: 99.88%\n",
      "Batch 211, Loss: 0.002225, Accuracy: 99.88%\n",
      "Batch 212, Loss: 0.000309, Accuracy: 99.88%\n",
      "Batch 213, Loss: 0.000087, Accuracy: 99.88%\n",
      "Training - Epoch 22, Loss: 0.004583, Accuracy: 99.88%\n",
      "Validation Batch 1, Loss: 0.009665, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001274, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000053, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000121, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000949, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000098, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000084, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.001481, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000189, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000103, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000353, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000073, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000067, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000804, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.017992, Accuracy: 99.90%\n",
      "Validation Batch 16, Loss: 0.000087, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.002405, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000433, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000274, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000096, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000449, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000083, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000264, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.010430, Accuracy: 99.93%\n",
      "Validation Batch 25, Loss: 0.085367, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000820, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000254, Accuracy: 99.88%\n",
      "Validation - Epoch 22, Loss: 0.004973, Accuracy: 99.88%\n",
      "Patience—0\n",
      "Epoch 23\n",
      "Batch 1, Loss: 0.000041, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000869, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000601, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000118, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.004071, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000058, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.003760, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000995, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000377, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000150, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000098, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000069, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000047, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000289, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000077, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000355, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000067, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000082, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000147, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000130, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000092, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000071, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000121, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000475, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000078, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000059, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000091, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.002391, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000077, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000062, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.002274, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000142, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000270, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000091, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000335, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000083, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000081, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000071, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000052, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000099, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000063, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000079, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000056, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000071, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000439, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000562, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000113, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000410, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000124, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000045, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000060, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000105, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000058, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000063, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000656, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000081, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000498, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000069, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000072, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.023312, Accuracy: 99.98%\n",
      "Batch 74, Loss: 0.000173, Accuracy: 99.98%\n",
      "Batch 75, Loss: 0.000872, Accuracy: 99.98%\n",
      "Batch 76, Loss: 0.000212, Accuracy: 99.98%\n",
      "Batch 77, Loss: 0.000096, Accuracy: 99.98%\n",
      "Batch 78, Loss: 0.000538, Accuracy: 99.98%\n",
      "Batch 79, Loss: 0.002628, Accuracy: 99.98%\n",
      "Batch 80, Loss: 0.000324, Accuracy: 99.98%\n",
      "Batch 81, Loss: 0.000568, Accuracy: 99.98%\n",
      "Batch 82, Loss: 0.006756, Accuracy: 99.98%\n",
      "Batch 83, Loss: 0.000171, Accuracy: 99.98%\n",
      "Batch 84, Loss: 0.066316, Accuracy: 99.96%\n",
      "Batch 85, Loss: 0.000125, Accuracy: 99.96%\n",
      "Batch 86, Loss: 0.000391, Accuracy: 99.96%\n",
      "Batch 87, Loss: 0.000095, Accuracy: 99.96%\n",
      "Batch 88, Loss: 0.039325, Accuracy: 99.95%\n",
      "Batch 89, Loss: 0.000289, Accuracy: 99.95%\n",
      "Batch 90, Loss: 0.000180, Accuracy: 99.95%\n",
      "Batch 91, Loss: 0.000124, Accuracy: 99.95%\n",
      "Batch 92, Loss: 0.004858, Accuracy: 99.95%\n",
      "Batch 93, Loss: 0.000455, Accuracy: 99.95%\n",
      "Batch 94, Loss: 0.000267, Accuracy: 99.95%\n",
      "Batch 95, Loss: 0.002256, Accuracy: 99.95%\n",
      "Batch 96, Loss: 0.070636, Accuracy: 99.93%\n",
      "Batch 97, Loss: 0.009638, Accuracy: 99.94%\n",
      "Batch 98, Loss: 0.004946, Accuracy: 99.94%\n",
      "Batch 99, Loss: 0.005774, Accuracy: 99.94%\n",
      "Batch 100, Loss: 0.124878, Accuracy: 99.91%\n",
      "Batch 101, Loss: 0.016348, Accuracy: 99.89%\n",
      "Batch 102, Loss: 0.000693, Accuracy: 99.89%\n",
      "Batch 103, Loss: 0.021435, Accuracy: 99.89%\n",
      "Batch 104, Loss: 0.004897, Accuracy: 99.89%\n",
      "Batch 105, Loss: 0.013477, Accuracy: 99.88%\n",
      "Batch 106, Loss: 0.062628, Accuracy: 99.87%\n",
      "Batch 107, Loss: 0.073981, Accuracy: 99.85%\n",
      "Batch 108, Loss: 0.000511, Accuracy: 99.86%\n",
      "Batch 109, Loss: 0.007377, Accuracy: 99.86%\n",
      "Batch 110, Loss: 0.003901, Accuracy: 99.86%\n",
      "Batch 111, Loss: 0.000985, Accuracy: 99.86%\n",
      "Batch 112, Loss: 0.006029, Accuracy: 99.86%\n",
      "Batch 113, Loss: 0.016024, Accuracy: 99.86%\n",
      "Batch 114, Loss: 0.003578, Accuracy: 99.86%\n",
      "Batch 115, Loss: 0.013158, Accuracy: 99.86%\n",
      "Batch 116, Loss: 0.024372, Accuracy: 99.85%\n",
      "Batch 117, Loss: 0.020066, Accuracy: 99.84%\n",
      "Batch 118, Loss: 0.000894, Accuracy: 99.84%\n",
      "Batch 119, Loss: 0.001565, Accuracy: 99.84%\n",
      "Batch 120, Loss: 0.005439, Accuracy: 99.84%\n",
      "Batch 121, Loss: 0.009927, Accuracy: 99.85%\n",
      "Batch 122, Loss: 0.004199, Accuracy: 99.85%\n",
      "Batch 123, Loss: 0.000702, Accuracy: 99.85%\n",
      "Batch 124, Loss: 0.003623, Accuracy: 99.85%\n",
      "Batch 125, Loss: 0.001780, Accuracy: 99.85%\n",
      "Batch 126, Loss: 0.000307, Accuracy: 99.85%\n",
      "Batch 127, Loss: 0.004338, Accuracy: 99.85%\n",
      "Batch 128, Loss: 0.000597, Accuracy: 99.85%\n",
      "Batch 129, Loss: 0.031356, Accuracy: 99.84%\n",
      "Batch 130, Loss: 0.000443, Accuracy: 99.84%\n",
      "Batch 131, Loss: 0.009980, Accuracy: 99.84%\n",
      "Batch 132, Loss: 0.002004, Accuracy: 99.85%\n",
      "Batch 133, Loss: 0.000599, Accuracy: 99.85%\n",
      "Batch 134, Loss: 0.098410, Accuracy: 99.84%\n",
      "Batch 135, Loss: 0.016163, Accuracy: 99.84%\n",
      "Batch 136, Loss: 0.000406, Accuracy: 99.84%\n",
      "Batch 137, Loss: 0.000704, Accuracy: 99.84%\n",
      "Batch 138, Loss: 0.103720, Accuracy: 99.83%\n",
      "Batch 139, Loss: 0.011779, Accuracy: 99.83%\n",
      "Batch 140, Loss: 0.084714, Accuracy: 99.82%\n",
      "Batch 141, Loss: 0.115272, Accuracy: 99.81%\n",
      "Batch 142, Loss: 0.003947, Accuracy: 99.81%\n",
      "Batch 143, Loss: 0.054127, Accuracy: 99.79%\n",
      "Batch 144, Loss: 0.020085, Accuracy: 99.79%\n",
      "Batch 145, Loss: 0.096178, Accuracy: 99.77%\n",
      "Batch 146, Loss: 0.153751, Accuracy: 99.75%\n",
      "Batch 147, Loss: 0.084131, Accuracy: 99.72%\n",
      "Batch 148, Loss: 0.040297, Accuracy: 99.71%\n",
      "Batch 149, Loss: 0.008661, Accuracy: 99.72%\n",
      "Batch 150, Loss: 0.027552, Accuracy: 99.71%\n",
      "Batch 151, Loss: 0.065582, Accuracy: 99.70%\n",
      "Batch 152, Loss: 0.005086, Accuracy: 99.70%\n",
      "Batch 153, Loss: 0.026488, Accuracy: 99.69%\n",
      "Batch 154, Loss: 0.011456, Accuracy: 99.70%\n",
      "Batch 155, Loss: 0.011295, Accuracy: 99.70%\n",
      "Batch 156, Loss: 0.004733, Accuracy: 99.70%\n",
      "Batch 157, Loss: 0.043667, Accuracy: 99.69%\n",
      "Batch 158, Loss: 0.008036, Accuracy: 99.69%\n",
      "Batch 159, Loss: 0.062725, Accuracy: 99.67%\n",
      "Batch 160, Loss: 0.019464, Accuracy: 99.67%\n",
      "Batch 161, Loss: 0.028060, Accuracy: 99.66%\n",
      "Batch 162, Loss: 0.047633, Accuracy: 99.65%\n",
      "Batch 163, Loss: 0.108379, Accuracy: 99.64%\n",
      "Batch 164, Loss: 0.029338, Accuracy: 99.64%\n",
      "Batch 165, Loss: 0.010889, Accuracy: 99.64%\n",
      "Batch 166, Loss: 0.129732, Accuracy: 99.62%\n",
      "Batch 167, Loss: 0.040516, Accuracy: 99.62%\n",
      "Batch 168, Loss: 0.010819, Accuracy: 99.62%\n",
      "Batch 169, Loss: 0.069756, Accuracy: 99.61%\n",
      "Batch 170, Loss: 0.050159, Accuracy: 99.60%\n",
      "Batch 171, Loss: 0.009295, Accuracy: 99.61%\n",
      "Batch 172, Loss: 0.005935, Accuracy: 99.61%\n",
      "Batch 173, Loss: 0.017493, Accuracy: 99.60%\n",
      "Batch 174, Loss: 0.116758, Accuracy: 99.59%\n",
      "Batch 175, Loss: 0.004250, Accuracy: 99.59%\n",
      "Batch 176, Loss: 0.011300, Accuracy: 99.59%\n",
      "Batch 177, Loss: 0.007420, Accuracy: 99.59%\n",
      "Batch 178, Loss: 0.055073, Accuracy: 99.59%\n",
      "Batch 179, Loss: 0.131100, Accuracy: 99.57%\n",
      "Batch 180, Loss: 0.016837, Accuracy: 99.57%\n",
      "Batch 181, Loss: 0.006286, Accuracy: 99.57%\n",
      "Batch 182, Loss: 0.015628, Accuracy: 99.57%\n",
      "Batch 183, Loss: 0.014082, Accuracy: 99.57%\n",
      "Batch 184, Loss: 0.023392, Accuracy: 99.58%\n",
      "Batch 185, Loss: 0.022232, Accuracy: 99.57%\n",
      "Batch 186, Loss: 0.002680, Accuracy: 99.57%\n",
      "Batch 187, Loss: 0.055879, Accuracy: 99.57%\n",
      "Batch 188, Loss: 0.015448, Accuracy: 99.57%\n",
      "Batch 189, Loss: 0.033166, Accuracy: 99.56%\n",
      "Batch 190, Loss: 0.016309, Accuracy: 99.56%\n",
      "Batch 191, Loss: 0.010768, Accuracy: 99.57%\n",
      "Batch 192, Loss: 0.046474, Accuracy: 99.56%\n",
      "Batch 193, Loss: 0.047251, Accuracy: 99.55%\n",
      "Batch 194, Loss: 0.002334, Accuracy: 99.56%\n",
      "Batch 195, Loss: 0.005565, Accuracy: 99.56%\n",
      "Batch 196, Loss: 0.093400, Accuracy: 99.54%\n",
      "Batch 197, Loss: 0.007030, Accuracy: 99.54%\n",
      "Batch 198, Loss: 0.002203, Accuracy: 99.54%\n",
      "Batch 199, Loss: 0.017060, Accuracy: 99.54%\n",
      "Batch 200, Loss: 0.092346, Accuracy: 99.53%\n",
      "Batch 201, Loss: 0.001512, Accuracy: 99.53%\n",
      "Batch 202, Loss: 0.001779, Accuracy: 99.54%\n",
      "Batch 203, Loss: 0.056098, Accuracy: 99.53%\n",
      "Batch 204, Loss: 0.028841, Accuracy: 99.53%\n",
      "Batch 205, Loss: 0.006625, Accuracy: 99.53%\n",
      "Batch 206, Loss: 0.016745, Accuracy: 99.52%\n",
      "Batch 207, Loss: 0.002498, Accuracy: 99.52%\n",
      "Batch 208, Loss: 0.001118, Accuracy: 99.53%\n",
      "Batch 209, Loss: 0.006974, Accuracy: 99.53%\n",
      "Batch 210, Loss: 0.035540, Accuracy: 99.52%\n",
      "Batch 211, Loss: 0.122078, Accuracy: 99.51%\n",
      "Batch 212, Loss: 0.079283, Accuracy: 99.49%\n",
      "Batch 213, Loss: 0.054289, Accuracy: 99.49%\n",
      "Training - Epoch 23, Loss: 0.017752, Accuracy: 99.49%\n",
      "Validation Batch 1, Loss: 0.002006, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001877, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.017122, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.030306, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.002962, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.000622, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.003036, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.024658, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.026011, Accuracy: 99.31%\n",
      "Validation Batch 10, Loss: 0.001980, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.109374, Accuracy: 99.15%\n",
      "Validation Batch 12, Loss: 0.113122, Accuracy: 99.09%\n",
      "Validation Batch 13, Loss: 0.050076, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.054051, Accuracy: 98.88%\n",
      "Validation Batch 15, Loss: 0.001490, Accuracy: 98.96%\n",
      "Validation Batch 16, Loss: 0.012292, Accuracy: 99.02%\n",
      "Validation Batch 17, Loss: 0.059821, Accuracy: 98.99%\n",
      "Validation Batch 18, Loss: 0.055806, Accuracy: 98.96%\n",
      "Validation Batch 19, Loss: 0.032573, Accuracy: 98.93%\n",
      "Validation Batch 20, Loss: 0.008303, Accuracy: 98.98%\n",
      "Validation Batch 21, Loss: 0.006584, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.005395, Accuracy: 99.08%\n",
      "Validation Batch 23, Loss: 0.026990, Accuracy: 99.12%\n",
      "Validation Batch 24, Loss: 0.001514, Accuracy: 99.15%\n",
      "Validation Batch 25, Loss: 0.001460, Accuracy: 99.19%\n",
      "Validation Batch 26, Loss: 0.019435, Accuracy: 99.16%\n",
      "Validation Batch 27, Loss: 0.053283, Accuracy: 99.12%\n",
      "Validation - Epoch 23, Loss: 0.026746, Accuracy: 99.12%\n",
      "Patience—1\n",
      "Epoch 24\n",
      "Batch 1, Loss: 0.001310, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001338, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.027998, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.078275, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.002631, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.021767, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.065780, Accuracy: 99.33%\n",
      "Batch 8, Loss: 0.075460, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.132097, Accuracy: 99.13%\n",
      "Batch 10, Loss: 0.076428, Accuracy: 98.91%\n",
      "Batch 11, Loss: 0.014418, Accuracy: 99.01%\n",
      "Batch 12, Loss: 0.064027, Accuracy: 98.96%\n",
      "Batch 13, Loss: 0.041510, Accuracy: 98.92%\n",
      "Batch 14, Loss: 0.069028, Accuracy: 98.77%\n",
      "Batch 15, Loss: 0.050510, Accuracy: 98.75%\n",
      "Batch 16, Loss: 0.006523, Accuracy: 98.83%\n",
      "Batch 17, Loss: 0.152272, Accuracy: 98.53%\n",
      "Batch 18, Loss: 0.116708, Accuracy: 98.44%\n",
      "Batch 19, Loss: 0.031190, Accuracy: 98.44%\n",
      "Batch 20, Loss: 0.064684, Accuracy: 98.44%\n",
      "Batch 21, Loss: 0.089973, Accuracy: 98.44%\n",
      "Batch 22, Loss: 0.071175, Accuracy: 98.44%\n",
      "Batch 23, Loss: 0.008399, Accuracy: 98.51%\n",
      "Batch 24, Loss: 0.010871, Accuracy: 98.57%\n",
      "Batch 25, Loss: 0.008222, Accuracy: 98.62%\n",
      "Batch 26, Loss: 0.006418, Accuracy: 98.68%\n",
      "Batch 27, Loss: 0.039838, Accuracy: 98.67%\n",
      "Batch 28, Loss: 0.012840, Accuracy: 98.72%\n",
      "Batch 29, Loss: 0.014492, Accuracy: 98.76%\n",
      "Batch 30, Loss: 0.021114, Accuracy: 98.80%\n",
      "Batch 31, Loss: 0.071312, Accuracy: 98.74%\n",
      "Batch 32, Loss: 0.039699, Accuracy: 98.73%\n",
      "Batch 33, Loss: 0.006137, Accuracy: 98.77%\n",
      "Batch 34, Loss: 0.002400, Accuracy: 98.81%\n",
      "Batch 35, Loss: 0.005727, Accuracy: 98.84%\n",
      "Batch 36, Loss: 0.045870, Accuracy: 98.83%\n",
      "Batch 37, Loss: 0.011990, Accuracy: 98.86%\n",
      "Batch 38, Loss: 0.034396, Accuracy: 98.85%\n",
      "Batch 39, Loss: 0.006122, Accuracy: 98.88%\n",
      "Batch 40, Loss: 0.010845, Accuracy: 98.91%\n",
      "Batch 41, Loss: 0.008678, Accuracy: 98.93%\n",
      "Batch 42, Loss: 0.000922, Accuracy: 98.96%\n",
      "Batch 43, Loss: 0.101444, Accuracy: 98.91%\n",
      "Batch 44, Loss: 0.007784, Accuracy: 98.93%\n",
      "Batch 45, Loss: 0.025937, Accuracy: 98.92%\n",
      "Batch 46, Loss: 0.036466, Accuracy: 98.91%\n",
      "Batch 47, Loss: 0.024103, Accuracy: 98.90%\n",
      "Batch 48, Loss: 0.005177, Accuracy: 98.93%\n",
      "Batch 49, Loss: 0.003558, Accuracy: 98.95%\n",
      "Batch 50, Loss: 0.002998, Accuracy: 98.97%\n",
      "Batch 51, Loss: 0.002693, Accuracy: 98.99%\n",
      "Batch 52, Loss: 0.019721, Accuracy: 98.98%\n",
      "Batch 53, Loss: 0.010403, Accuracy: 99.00%\n",
      "Batch 54, Loss: 0.066857, Accuracy: 98.99%\n",
      "Batch 55, Loss: 0.005075, Accuracy: 99.01%\n",
      "Batch 56, Loss: 0.007090, Accuracy: 99.02%\n",
      "Batch 57, Loss: 0.125929, Accuracy: 99.01%\n",
      "Batch 58, Loss: 0.001747, Accuracy: 99.03%\n",
      "Batch 59, Loss: 0.003219, Accuracy: 99.05%\n",
      "Batch 60, Loss: 0.006107, Accuracy: 99.06%\n",
      "Batch 61, Loss: 0.000943, Accuracy: 99.08%\n",
      "Batch 62, Loss: 0.060055, Accuracy: 99.04%\n",
      "Batch 63, Loss: 0.001774, Accuracy: 99.06%\n",
      "Batch 64, Loss: 0.010627, Accuracy: 99.07%\n",
      "Batch 65, Loss: 0.000970, Accuracy: 99.09%\n",
      "Batch 66, Loss: 0.001853, Accuracy: 99.10%\n",
      "Batch 67, Loss: 0.002844, Accuracy: 99.11%\n",
      "Batch 68, Loss: 0.018970, Accuracy: 99.13%\n",
      "Batch 69, Loss: 0.108670, Accuracy: 99.07%\n",
      "Batch 70, Loss: 0.046739, Accuracy: 99.06%\n",
      "Batch 71, Loss: 0.015812, Accuracy: 99.05%\n",
      "Batch 72, Loss: 0.057547, Accuracy: 99.05%\n",
      "Batch 73, Loss: 0.001649, Accuracy: 99.06%\n",
      "Batch 74, Loss: 0.004222, Accuracy: 99.07%\n",
      "Batch 75, Loss: 0.003824, Accuracy: 99.08%\n",
      "Batch 76, Loss: 0.033052, Accuracy: 99.07%\n",
      "Batch 77, Loss: 0.024525, Accuracy: 99.07%\n",
      "Batch 78, Loss: 0.070510, Accuracy: 99.06%\n",
      "Batch 79, Loss: 0.012860, Accuracy: 99.07%\n",
      "Batch 80, Loss: 0.100638, Accuracy: 99.04%\n",
      "Batch 81, Loss: 0.006098, Accuracy: 99.05%\n",
      "Batch 82, Loss: 0.005891, Accuracy: 99.07%\n",
      "Batch 83, Loss: 0.003186, Accuracy: 99.08%\n",
      "Batch 84, Loss: 0.005251, Accuracy: 99.09%\n",
      "Batch 85, Loss: 0.010501, Accuracy: 99.10%\n",
      "Batch 86, Loss: 0.004451, Accuracy: 99.11%\n",
      "Batch 87, Loss: 0.068147, Accuracy: 99.08%\n",
      "Batch 88, Loss: 0.001805, Accuracy: 99.09%\n",
      "Batch 89, Loss: 0.001151, Accuracy: 99.10%\n",
      "Batch 90, Loss: 0.015308, Accuracy: 99.11%\n",
      "Batch 91, Loss: 0.004343, Accuracy: 99.12%\n",
      "Batch 92, Loss: 0.029961, Accuracy: 99.12%\n",
      "Batch 93, Loss: 0.058603, Accuracy: 99.09%\n",
      "Batch 94, Loss: 0.101255, Accuracy: 99.09%\n",
      "Batch 95, Loss: 0.004092, Accuracy: 99.10%\n",
      "Batch 96, Loss: 0.007300, Accuracy: 99.10%\n",
      "Batch 97, Loss: 0.019088, Accuracy: 99.11%\n",
      "Batch 98, Loss: 0.014989, Accuracy: 99.12%\n",
      "Batch 99, Loss: 0.004140, Accuracy: 99.13%\n",
      "Batch 100, Loss: 0.005214, Accuracy: 99.14%\n",
      "Batch 101, Loss: 0.013717, Accuracy: 99.15%\n",
      "Batch 102, Loss: 0.003636, Accuracy: 99.16%\n",
      "Batch 103, Loss: 0.001526, Accuracy: 99.17%\n",
      "Batch 104, Loss: 0.022746, Accuracy: 99.16%\n",
      "Batch 105, Loss: 0.024697, Accuracy: 99.15%\n",
      "Batch 106, Loss: 0.046095, Accuracy: 99.13%\n",
      "Batch 107, Loss: 0.009446, Accuracy: 99.14%\n",
      "Batch 108, Loss: 0.051340, Accuracy: 99.13%\n",
      "Batch 109, Loss: 0.033706, Accuracy: 99.13%\n",
      "Batch 110, Loss: 0.002215, Accuracy: 99.13%\n",
      "Batch 111, Loss: 0.032633, Accuracy: 99.13%\n",
      "Batch 112, Loss: 0.027450, Accuracy: 99.11%\n",
      "Batch 113, Loss: 0.109514, Accuracy: 99.07%\n",
      "Batch 114, Loss: 0.000753, Accuracy: 99.08%\n",
      "Batch 115, Loss: 0.005837, Accuracy: 99.09%\n",
      "Batch 116, Loss: 0.077428, Accuracy: 99.07%\n",
      "Batch 117, Loss: 0.003468, Accuracy: 99.08%\n",
      "Batch 118, Loss: 0.029726, Accuracy: 99.07%\n",
      "Batch 119, Loss: 0.001854, Accuracy: 99.08%\n",
      "Batch 120, Loss: 0.098899, Accuracy: 99.08%\n",
      "Batch 121, Loss: 0.011588, Accuracy: 99.08%\n",
      "Batch 122, Loss: 0.006172, Accuracy: 99.09%\n",
      "Batch 123, Loss: 0.048441, Accuracy: 99.09%\n",
      "Batch 124, Loss: 0.034795, Accuracy: 99.08%\n",
      "Batch 125, Loss: 0.002993, Accuracy: 99.09%\n",
      "Batch 126, Loss: 0.006396, Accuracy: 99.09%\n",
      "Batch 127, Loss: 0.001699, Accuracy: 99.10%\n",
      "Batch 128, Loss: 0.005189, Accuracy: 99.11%\n",
      "Batch 129, Loss: 0.006235, Accuracy: 99.12%\n",
      "Batch 130, Loss: 0.011657, Accuracy: 99.12%\n",
      "Batch 131, Loss: 0.003485, Accuracy: 99.13%\n",
      "Batch 132, Loss: 0.016402, Accuracy: 99.12%\n",
      "Batch 133, Loss: 0.001610, Accuracy: 99.13%\n",
      "Batch 134, Loss: 0.001266, Accuracy: 99.14%\n",
      "Batch 135, Loss: 0.032168, Accuracy: 99.13%\n",
      "Batch 136, Loss: 0.002454, Accuracy: 99.14%\n",
      "Batch 137, Loss: 0.005003, Accuracy: 99.14%\n",
      "Batch 138, Loss: 0.008387, Accuracy: 99.15%\n",
      "Batch 139, Loss: 0.036718, Accuracy: 99.13%\n",
      "Batch 140, Loss: 0.013166, Accuracy: 99.14%\n",
      "Batch 141, Loss: 0.002580, Accuracy: 99.15%\n",
      "Batch 142, Loss: 0.005069, Accuracy: 99.15%\n",
      "Batch 143, Loss: 0.002784, Accuracy: 99.16%\n",
      "Batch 144, Loss: 0.004738, Accuracy: 99.16%\n",
      "Batch 145, Loss: 0.041399, Accuracy: 99.16%\n",
      "Batch 146, Loss: 0.041587, Accuracy: 99.15%\n",
      "Batch 147, Loss: 0.004341, Accuracy: 99.16%\n",
      "Batch 148, Loss: 0.043266, Accuracy: 99.16%\n",
      "Batch 149, Loss: 0.016076, Accuracy: 99.15%\n",
      "Batch 150, Loss: 0.001129, Accuracy: 99.16%\n",
      "Batch 151, Loss: 0.003331, Accuracy: 99.16%\n",
      "Batch 152, Loss: 0.065482, Accuracy: 99.16%\n",
      "Batch 153, Loss: 0.062833, Accuracy: 99.15%\n",
      "Batch 154, Loss: 0.020385, Accuracy: 99.15%\n",
      "Batch 155, Loss: 0.025894, Accuracy: 99.14%\n",
      "Batch 156, Loss: 0.001059, Accuracy: 99.15%\n",
      "Batch 157, Loss: 0.081542, Accuracy: 99.13%\n",
      "Batch 158, Loss: 0.035255, Accuracy: 99.13%\n",
      "Batch 159, Loss: 0.003405, Accuracy: 99.14%\n",
      "Batch 160, Loss: 0.007470, Accuracy: 99.14%\n",
      "Batch 161, Loss: 0.048870, Accuracy: 99.13%\n",
      "Batch 162, Loss: 0.064331, Accuracy: 99.11%\n",
      "Batch 163, Loss: 0.022240, Accuracy: 99.11%\n",
      "Batch 164, Loss: 0.002720, Accuracy: 99.11%\n",
      "Batch 165, Loss: 0.016951, Accuracy: 99.11%\n",
      "Batch 166, Loss: 0.016782, Accuracy: 99.12%\n",
      "Batch 167, Loss: 0.174198, Accuracy: 99.10%\n",
      "Batch 168, Loss: 0.022505, Accuracy: 99.10%\n",
      "Batch 169, Loss: 0.004763, Accuracy: 99.10%\n",
      "Batch 170, Loss: 0.009744, Accuracy: 99.11%\n",
      "Batch 171, Loss: 0.069464, Accuracy: 99.10%\n",
      "Batch 172, Loss: 0.016140, Accuracy: 99.10%\n",
      "Batch 173, Loss: 0.012116, Accuracy: 99.11%\n",
      "Batch 174, Loss: 0.155388, Accuracy: 99.08%\n",
      "Batch 175, Loss: 0.075210, Accuracy: 99.06%\n",
      "Batch 176, Loss: 0.002759, Accuracy: 99.07%\n",
      "Batch 177, Loss: 0.024910, Accuracy: 99.06%\n",
      "Batch 178, Loss: 0.008156, Accuracy: 99.07%\n",
      "Batch 179, Loss: 0.004365, Accuracy: 99.07%\n",
      "Batch 180, Loss: 0.075950, Accuracy: 99.07%\n",
      "Batch 181, Loss: 0.007641, Accuracy: 99.08%\n",
      "Batch 182, Loss: 0.002802, Accuracy: 99.08%\n",
      "Batch 183, Loss: 0.006911, Accuracy: 99.09%\n",
      "Batch 184, Loss: 0.054387, Accuracy: 99.07%\n",
      "Batch 185, Loss: 0.017830, Accuracy: 99.08%\n",
      "Batch 186, Loss: 0.029085, Accuracy: 99.08%\n",
      "Batch 187, Loss: 0.028712, Accuracy: 99.07%\n",
      "Batch 188, Loss: 0.013639, Accuracy: 99.08%\n",
      "Batch 189, Loss: 0.118067, Accuracy: 99.07%\n",
      "Batch 190, Loss: 0.105001, Accuracy: 99.05%\n",
      "Batch 191, Loss: 0.017349, Accuracy: 99.05%\n",
      "Batch 192, Loss: 0.005264, Accuracy: 99.06%\n",
      "Batch 193, Loss: 0.153082, Accuracy: 99.04%\n",
      "Batch 194, Loss: 0.006525, Accuracy: 99.05%\n",
      "Batch 195, Loss: 0.065273, Accuracy: 99.05%\n",
      "Batch 196, Loss: 0.066329, Accuracy: 99.04%\n",
      "Batch 197, Loss: 0.019492, Accuracy: 99.04%\n",
      "Batch 198, Loss: 0.049072, Accuracy: 99.04%\n",
      "Batch 199, Loss: 0.018434, Accuracy: 99.03%\n",
      "Batch 200, Loss: 0.009935, Accuracy: 99.04%\n",
      "Batch 201, Loss: 0.016495, Accuracy: 99.04%\n",
      "Batch 202, Loss: 0.087435, Accuracy: 99.03%\n",
      "Batch 203, Loss: 0.074483, Accuracy: 99.03%\n",
      "Batch 204, Loss: 0.075815, Accuracy: 99.02%\n",
      "Batch 205, Loss: 0.123139, Accuracy: 99.00%\n",
      "Batch 206, Loss: 0.005745, Accuracy: 99.01%\n",
      "Batch 207, Loss: 0.011776, Accuracy: 99.01%\n",
      "Batch 208, Loss: 0.050210, Accuracy: 99.01%\n",
      "Batch 209, Loss: 0.011529, Accuracy: 99.01%\n",
      "Batch 210, Loss: 0.036084, Accuracy: 99.01%\n",
      "Batch 211, Loss: 0.168990, Accuracy: 99.00%\n",
      "Batch 212, Loss: 0.108951, Accuracy: 98.99%\n",
      "Batch 213, Loss: 0.006054, Accuracy: 98.99%\n",
      "Training - Epoch 24, Loss: 0.031680, Accuracy: 98.99%\n",
      "Validation Batch 1, Loss: 0.026426, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.016544, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.017938, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.005157, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.014136, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.029614, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.007287, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.009067, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.022845, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.012333, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.026735, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.017657, Accuracy: 99.48%\n",
      "Validation Batch 13, Loss: 0.085264, Accuracy: 99.28%\n",
      "Validation Batch 14, Loss: 0.040216, Accuracy: 99.22%\n",
      "Validation Batch 15, Loss: 0.005527, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.020951, Accuracy: 99.32%\n",
      "Validation Batch 17, Loss: 0.028607, Accuracy: 99.36%\n",
      "Validation Batch 18, Loss: 0.010878, Accuracy: 99.39%\n",
      "Validation Batch 19, Loss: 0.123576, Accuracy: 99.26%\n",
      "Validation Batch 20, Loss: 0.058286, Accuracy: 99.22%\n",
      "Validation Batch 21, Loss: 0.190751, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.020878, Accuracy: 99.08%\n",
      "Validation Batch 23, Loss: 0.009787, Accuracy: 99.12%\n",
      "Validation Batch 24, Loss: 0.068793, Accuracy: 99.09%\n",
      "Validation Batch 25, Loss: 0.004542, Accuracy: 99.12%\n",
      "Validation Batch 26, Loss: 0.087067, Accuracy: 99.04%\n",
      "Validation Batch 27, Loss: 0.017626, Accuracy: 99.06%\n",
      "Validation - Epoch 24, Loss: 0.036240, Accuracy: 99.06%\n",
      "Patience—2\n",
      "Epoch 25\n",
      "Batch 1, Loss: 0.004033, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.016789, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.067806, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.005695, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.112923, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.016979, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.021305, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.053964, Accuracy: 99.02%\n",
      "Batch 9, Loss: 0.009050, Accuracy: 99.13%\n",
      "Batch 10, Loss: 0.028637, Accuracy: 99.06%\n",
      "Batch 11, Loss: 0.006003, Accuracy: 99.15%\n",
      "Batch 12, Loss: 0.095611, Accuracy: 98.96%\n",
      "Batch 13, Loss: 0.004247, Accuracy: 99.04%\n",
      "Batch 14, Loss: 0.009096, Accuracy: 99.11%\n",
      "Batch 15, Loss: 0.101818, Accuracy: 99.06%\n",
      "Batch 16, Loss: 0.053668, Accuracy: 99.02%\n",
      "Batch 17, Loss: 0.041416, Accuracy: 98.90%\n",
      "Batch 18, Loss: 0.031675, Accuracy: 98.78%\n",
      "Batch 19, Loss: 0.007988, Accuracy: 98.85%\n",
      "Batch 20, Loss: 0.026119, Accuracy: 98.83%\n",
      "Batch 21, Loss: 0.001890, Accuracy: 98.88%\n",
      "Batch 22, Loss: 0.056669, Accuracy: 98.86%\n",
      "Batch 23, Loss: 0.011034, Accuracy: 98.91%\n",
      "Batch 24, Loss: 0.004694, Accuracy: 98.96%\n",
      "Batch 25, Loss: 0.008077, Accuracy: 99.00%\n",
      "Batch 26, Loss: 0.010763, Accuracy: 99.04%\n",
      "Batch 27, Loss: 0.003630, Accuracy: 99.07%\n",
      "Batch 28, Loss: 0.013454, Accuracy: 99.11%\n",
      "Batch 29, Loss: 0.035170, Accuracy: 99.03%\n",
      "Batch 30, Loss: 0.005070, Accuracy: 99.06%\n",
      "Batch 31, Loss: 0.018825, Accuracy: 99.04%\n",
      "Batch 32, Loss: 0.004336, Accuracy: 99.07%\n",
      "Batch 33, Loss: 0.001667, Accuracy: 99.10%\n",
      "Batch 34, Loss: 0.000961, Accuracy: 99.13%\n",
      "Batch 35, Loss: 0.000602, Accuracy: 99.15%\n",
      "Batch 36, Loss: 0.004438, Accuracy: 99.18%\n",
      "Batch 37, Loss: 0.001056, Accuracy: 99.20%\n",
      "Batch 38, Loss: 0.004496, Accuracy: 99.22%\n",
      "Batch 39, Loss: 0.007450, Accuracy: 99.24%\n",
      "Batch 40, Loss: 0.002175, Accuracy: 99.26%\n",
      "Batch 41, Loss: 0.023075, Accuracy: 99.24%\n",
      "Batch 42, Loss: 0.000913, Accuracy: 99.26%\n",
      "Batch 43, Loss: 0.015707, Accuracy: 99.24%\n",
      "Batch 44, Loss: 0.000860, Accuracy: 99.25%\n",
      "Batch 45, Loss: 0.001199, Accuracy: 99.27%\n",
      "Batch 46, Loss: 0.000273, Accuracy: 99.29%\n",
      "Batch 47, Loss: 0.005675, Accuracy: 99.30%\n",
      "Batch 48, Loss: 0.018885, Accuracy: 99.28%\n",
      "Batch 49, Loss: 0.000180, Accuracy: 99.30%\n",
      "Batch 50, Loss: 0.000777, Accuracy: 99.31%\n",
      "Batch 51, Loss: 0.001813, Accuracy: 99.33%\n",
      "Batch 52, Loss: 0.000354, Accuracy: 99.34%\n",
      "Batch 53, Loss: 0.000498, Accuracy: 99.35%\n",
      "Batch 54, Loss: 0.019293, Accuracy: 99.33%\n",
      "Batch 55, Loss: 0.000259, Accuracy: 99.35%\n",
      "Batch 56, Loss: 0.000722, Accuracy: 99.36%\n",
      "Batch 57, Loss: 0.000360, Accuracy: 99.37%\n",
      "Batch 58, Loss: 0.006128, Accuracy: 99.38%\n",
      "Batch 59, Loss: 0.001255, Accuracy: 99.39%\n",
      "Batch 60, Loss: 0.000511, Accuracy: 99.40%\n",
      "Batch 61, Loss: 0.000404, Accuracy: 99.41%\n",
      "Batch 62, Loss: 0.000405, Accuracy: 99.42%\n",
      "Batch 63, Loss: 0.000337, Accuracy: 99.43%\n",
      "Batch 64, Loss: 0.000175, Accuracy: 99.44%\n",
      "Batch 65, Loss: 0.000178, Accuracy: 99.45%\n",
      "Batch 66, Loss: 0.000283, Accuracy: 99.46%\n",
      "Batch 67, Loss: 0.000201, Accuracy: 99.46%\n",
      "Batch 68, Loss: 0.000144, Accuracy: 99.47%\n",
      "Batch 69, Loss: 0.000735, Accuracy: 99.48%\n",
      "Batch 70, Loss: 0.021974, Accuracy: 99.46%\n",
      "Batch 71, Loss: 0.000466, Accuracy: 99.47%\n",
      "Batch 72, Loss: 0.000573, Accuracy: 99.48%\n",
      "Batch 73, Loss: 0.003089, Accuracy: 99.49%\n",
      "Batch 74, Loss: 0.068495, Accuracy: 99.45%\n",
      "Batch 75, Loss: 0.000365, Accuracy: 99.46%\n",
      "Batch 76, Loss: 0.131053, Accuracy: 99.44%\n",
      "Batch 77, Loss: 0.007171, Accuracy: 99.45%\n",
      "Batch 78, Loss: 0.000782, Accuracy: 99.46%\n",
      "Batch 79, Loss: 0.000165, Accuracy: 99.47%\n",
      "Batch 80, Loss: 0.004623, Accuracy: 99.47%\n",
      "Batch 81, Loss: 0.001000, Accuracy: 99.48%\n",
      "Batch 82, Loss: 0.002832, Accuracy: 99.49%\n",
      "Batch 83, Loss: 0.006479, Accuracy: 99.49%\n",
      "Batch 84, Loss: 0.001127, Accuracy: 99.50%\n",
      "Batch 85, Loss: 0.095660, Accuracy: 99.49%\n",
      "Batch 86, Loss: 0.009867, Accuracy: 99.49%\n",
      "Batch 87, Loss: 0.007848, Accuracy: 99.50%\n",
      "Batch 88, Loss: 0.001075, Accuracy: 99.50%\n",
      "Batch 89, Loss: 0.071107, Accuracy: 99.49%\n",
      "Batch 90, Loss: 0.008487, Accuracy: 99.50%\n",
      "Batch 91, Loss: 0.003025, Accuracy: 99.50%\n",
      "Batch 92, Loss: 0.008662, Accuracy: 99.51%\n",
      "Batch 93, Loss: 0.042027, Accuracy: 99.50%\n",
      "Batch 94, Loss: 0.000462, Accuracy: 99.50%\n",
      "Batch 95, Loss: 0.000579, Accuracy: 99.51%\n",
      "Batch 96, Loss: 0.021048, Accuracy: 99.50%\n",
      "Batch 97, Loss: 0.024380, Accuracy: 99.48%\n",
      "Batch 98, Loss: 0.008307, Accuracy: 99.49%\n",
      "Batch 99, Loss: 0.001118, Accuracy: 99.49%\n",
      "Batch 100, Loss: 0.136742, Accuracy: 99.48%\n",
      "Batch 101, Loss: 0.012229, Accuracy: 99.49%\n",
      "Batch 102, Loss: 0.015904, Accuracy: 99.49%\n",
      "Batch 103, Loss: 0.022217, Accuracy: 99.50%\n",
      "Batch 104, Loss: 0.000572, Accuracy: 99.50%\n",
      "Batch 105, Loss: 0.000637, Accuracy: 99.51%\n",
      "Batch 106, Loss: 0.050334, Accuracy: 99.50%\n",
      "Batch 107, Loss: 0.000799, Accuracy: 99.50%\n",
      "Batch 108, Loss: 0.002711, Accuracy: 99.51%\n",
      "Batch 109, Loss: 0.000501, Accuracy: 99.51%\n",
      "Batch 110, Loss: 0.001953, Accuracy: 99.52%\n",
      "Batch 111, Loss: 0.021574, Accuracy: 99.51%\n",
      "Batch 112, Loss: 0.001397, Accuracy: 99.51%\n",
      "Batch 113, Loss: 0.000718, Accuracy: 99.52%\n",
      "Batch 114, Loss: 0.001022, Accuracy: 99.52%\n",
      "Batch 115, Loss: 0.002636, Accuracy: 99.52%\n",
      "Batch 116, Loss: 0.003712, Accuracy: 99.53%\n",
      "Batch 117, Loss: 0.012231, Accuracy: 99.52%\n",
      "Batch 118, Loss: 0.004214, Accuracy: 99.52%\n",
      "Batch 119, Loss: 0.005856, Accuracy: 99.53%\n",
      "Batch 120, Loss: 0.124134, Accuracy: 99.51%\n",
      "Batch 121, Loss: 0.000483, Accuracy: 99.51%\n",
      "Batch 122, Loss: 0.000510, Accuracy: 99.51%\n",
      "Batch 123, Loss: 0.027150, Accuracy: 99.50%\n",
      "Batch 124, Loss: 0.000816, Accuracy: 99.51%\n",
      "Batch 125, Loss: 0.001297, Accuracy: 99.51%\n",
      "Batch 126, Loss: 0.002032, Accuracy: 99.52%\n",
      "Batch 127, Loss: 0.001373, Accuracy: 99.52%\n",
      "Batch 128, Loss: 0.000682, Accuracy: 99.52%\n",
      "Batch 129, Loss: 0.057047, Accuracy: 99.50%\n",
      "Batch 130, Loss: 0.001432, Accuracy: 99.51%\n",
      "Batch 131, Loss: 0.033326, Accuracy: 99.50%\n",
      "Batch 132, Loss: 0.001824, Accuracy: 99.50%\n",
      "Batch 133, Loss: 0.002700, Accuracy: 99.51%\n",
      "Batch 134, Loss: 0.003557, Accuracy: 99.51%\n",
      "Batch 135, Loss: 0.020488, Accuracy: 99.50%\n",
      "Batch 136, Loss: 0.010946, Accuracy: 99.51%\n",
      "Batch 137, Loss: 0.002133, Accuracy: 99.51%\n",
      "Batch 138, Loss: 0.002987, Accuracy: 99.51%\n",
      "Batch 139, Loss: 0.001439, Accuracy: 99.52%\n",
      "Batch 140, Loss: 0.035446, Accuracy: 99.51%\n",
      "Batch 141, Loss: 0.000908, Accuracy: 99.51%\n",
      "Batch 142, Loss: 0.000552, Accuracy: 99.52%\n",
      "Batch 143, Loss: 0.005920, Accuracy: 99.52%\n",
      "Batch 144, Loss: 0.001156, Accuracy: 99.52%\n",
      "Batch 145, Loss: 0.000877, Accuracy: 99.53%\n",
      "Batch 146, Loss: 0.003587, Accuracy: 99.53%\n",
      "Batch 147, Loss: 0.003158, Accuracy: 99.53%\n",
      "Batch 148, Loss: 0.001403, Accuracy: 99.54%\n",
      "Batch 149, Loss: 0.027260, Accuracy: 99.53%\n",
      "Batch 150, Loss: 0.000593, Accuracy: 99.53%\n",
      "Batch 151, Loss: 0.000623, Accuracy: 99.53%\n",
      "Batch 152, Loss: 0.008958, Accuracy: 99.54%\n",
      "Batch 153, Loss: 0.002774, Accuracy: 99.54%\n",
      "Batch 154, Loss: 0.000580, Accuracy: 99.54%\n",
      "Batch 155, Loss: 0.003852, Accuracy: 99.55%\n",
      "Batch 156, Loss: 0.000648, Accuracy: 99.55%\n",
      "Batch 157, Loss: 0.012327, Accuracy: 99.55%\n",
      "Batch 158, Loss: 0.049638, Accuracy: 99.55%\n",
      "Batch 159, Loss: 0.001395, Accuracy: 99.55%\n",
      "Batch 160, Loss: 0.000173, Accuracy: 99.55%\n",
      "Batch 161, Loss: 0.000293, Accuracy: 99.55%\n",
      "Batch 162, Loss: 0.026463, Accuracy: 99.55%\n",
      "Batch 163, Loss: 0.000212, Accuracy: 99.55%\n",
      "Batch 164, Loss: 0.000328, Accuracy: 99.55%\n",
      "Batch 165, Loss: 0.015278, Accuracy: 99.55%\n",
      "Batch 166, Loss: 0.000542, Accuracy: 99.56%\n",
      "Batch 167, Loss: 0.093165, Accuracy: 99.55%\n",
      "Batch 168, Loss: 0.000619, Accuracy: 99.55%\n",
      "Batch 169, Loss: 0.000410, Accuracy: 99.56%\n",
      "Batch 170, Loss: 0.017255, Accuracy: 99.56%\n",
      "Batch 171, Loss: 0.062827, Accuracy: 99.55%\n",
      "Batch 172, Loss: 0.028549, Accuracy: 99.55%\n",
      "Batch 173, Loss: 0.001796, Accuracy: 99.55%\n",
      "Batch 174, Loss: 0.200210, Accuracy: 99.53%\n",
      "Batch 175, Loss: 0.000429, Accuracy: 99.54%\n",
      "Batch 176, Loss: 0.000691, Accuracy: 99.54%\n",
      "Batch 177, Loss: 0.004307, Accuracy: 99.54%\n",
      "Batch 178, Loss: 0.002433, Accuracy: 99.54%\n",
      "Batch 179, Loss: 0.064134, Accuracy: 99.54%\n",
      "Batch 180, Loss: 0.099473, Accuracy: 99.53%\n",
      "Batch 181, Loss: 0.005131, Accuracy: 99.53%\n",
      "Batch 182, Loss: 0.024617, Accuracy: 99.53%\n",
      "Batch 183, Loss: 0.009462, Accuracy: 99.53%\n",
      "Batch 184, Loss: 0.002428, Accuracy: 99.53%\n",
      "Batch 185, Loss: 0.055252, Accuracy: 99.52%\n",
      "Batch 186, Loss: 0.072881, Accuracy: 99.51%\n",
      "Batch 187, Loss: 0.021162, Accuracy: 99.51%\n",
      "Batch 188, Loss: 0.004704, Accuracy: 99.51%\n",
      "Batch 189, Loss: 0.012959, Accuracy: 99.51%\n",
      "Batch 190, Loss: 0.006383, Accuracy: 99.51%\n",
      "Batch 191, Loss: 0.004085, Accuracy: 99.52%\n",
      "Batch 192, Loss: 0.015837, Accuracy: 99.51%\n",
      "Batch 193, Loss: 0.003625, Accuracy: 99.51%\n",
      "Batch 194, Loss: 0.023380, Accuracy: 99.51%\n",
      "Batch 195, Loss: 0.008189, Accuracy: 99.51%\n",
      "Batch 196, Loss: 0.063100, Accuracy: 99.50%\n",
      "Batch 197, Loss: 0.003070, Accuracy: 99.50%\n",
      "Batch 198, Loss: 0.001832, Accuracy: 99.50%\n",
      "Batch 199, Loss: 0.004422, Accuracy: 99.51%\n",
      "Batch 200, Loss: 0.003984, Accuracy: 99.51%\n",
      "Batch 201, Loss: 0.009456, Accuracy: 99.51%\n",
      "Batch 202, Loss: 0.021062, Accuracy: 99.51%\n",
      "Batch 203, Loss: 0.004748, Accuracy: 99.52%\n",
      "Batch 204, Loss: 0.007349, Accuracy: 99.52%\n",
      "Batch 205, Loss: 0.004925, Accuracy: 99.52%\n",
      "Batch 206, Loss: 0.016960, Accuracy: 99.51%\n",
      "Batch 207, Loss: 0.000720, Accuracy: 99.52%\n",
      "Batch 208, Loss: 0.000809, Accuracy: 99.52%\n",
      "Batch 209, Loss: 0.000628, Accuracy: 99.52%\n",
      "Batch 210, Loss: 0.001309, Accuracy: 99.52%\n",
      "Batch 211, Loss: 0.000375, Accuracy: 99.53%\n",
      "Batch 212, Loss: 0.000976, Accuracy: 99.53%\n",
      "Batch 213, Loss: 0.044744, Accuracy: 99.52%\n",
      "Training - Epoch 25, Loss: 0.015976, Accuracy: 99.52%\n",
      "Validation Batch 1, Loss: 0.000678, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.008907, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.023315, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.072105, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.002850, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.018515, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.000381, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.005700, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.002293, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.033162, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.019086, Accuracy: 99.29%\n",
      "Validation Batch 12, Loss: 0.062612, Accuracy: 99.09%\n",
      "Validation Batch 13, Loss: 0.016160, Accuracy: 99.04%\n",
      "Validation Batch 14, Loss: 0.019684, Accuracy: 99.00%\n",
      "Validation Batch 15, Loss: 0.021689, Accuracy: 98.96%\n",
      "Validation Batch 16, Loss: 0.001527, Accuracy: 99.02%\n",
      "Validation Batch 17, Loss: 0.094119, Accuracy: 98.90%\n",
      "Validation Batch 18, Loss: 0.009487, Accuracy: 98.96%\n",
      "Validation Batch 19, Loss: 0.016103, Accuracy: 99.01%\n",
      "Validation Batch 20, Loss: 0.000520, Accuracy: 99.06%\n",
      "Validation Batch 21, Loss: 0.138790, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.073040, Accuracy: 99.01%\n",
      "Validation Batch 23, Loss: 0.013559, Accuracy: 99.05%\n",
      "Validation Batch 24, Loss: 0.017864, Accuracy: 99.02%\n",
      "Validation Batch 25, Loss: 0.001840, Accuracy: 99.06%\n",
      "Validation Batch 26, Loss: 0.069215, Accuracy: 99.04%\n",
      "Validation Batch 27, Loss: 0.090355, Accuracy: 99.00%\n",
      "Validation - Epoch 25, Loss: 0.030872, Accuracy: 99.00%\n",
      "Patience—3\n",
      "Epoch 26\n",
      "Batch 1, Loss: 0.009688, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.008012, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.006800, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001916, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.002637, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000312, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.002361, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000517, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000735, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.012536, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.002827, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.001657, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.044729, Accuracy: 99.80%\n",
      "Batch 17, Loss: 0.001559, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.000433, Accuracy: 99.83%\n",
      "Batch 19, Loss: 0.000198, Accuracy: 99.84%\n",
      "Batch 20, Loss: 0.022850, Accuracy: 99.77%\n",
      "Batch 21, Loss: 0.000539, Accuracy: 99.78%\n",
      "Batch 22, Loss: 0.000210, Accuracy: 99.79%\n",
      "Batch 23, Loss: 0.019172, Accuracy: 99.73%\n",
      "Batch 24, Loss: 0.000746, Accuracy: 99.74%\n",
      "Batch 25, Loss: 0.000187, Accuracy: 99.75%\n",
      "Batch 26, Loss: 0.000376, Accuracy: 99.76%\n",
      "Batch 27, Loss: 0.078220, Accuracy: 99.71%\n",
      "Batch 28, Loss: 0.000587, Accuracy: 99.72%\n",
      "Batch 29, Loss: 0.000257, Accuracy: 99.73%\n",
      "Batch 30, Loss: 0.003270, Accuracy: 99.74%\n",
      "Batch 31, Loss: 0.014165, Accuracy: 99.70%\n",
      "Batch 32, Loss: 0.071087, Accuracy: 99.66%\n",
      "Batch 33, Loss: 0.007560, Accuracy: 99.67%\n",
      "Batch 34, Loss: 0.002479, Accuracy: 99.68%\n",
      "Batch 35, Loss: 0.005290, Accuracy: 99.69%\n",
      "Batch 36, Loss: 0.000387, Accuracy: 99.70%\n",
      "Batch 37, Loss: 0.035004, Accuracy: 99.66%\n",
      "Batch 38, Loss: 0.073302, Accuracy: 99.63%\n",
      "Batch 39, Loss: 0.004897, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.008632, Accuracy: 99.65%\n",
      "Batch 41, Loss: 0.000476, Accuracy: 99.66%\n",
      "Batch 42, Loss: 0.003221, Accuracy: 99.67%\n",
      "Batch 43, Loss: 0.011251, Accuracy: 99.67%\n",
      "Batch 44, Loss: 0.001092, Accuracy: 99.68%\n",
      "Batch 45, Loss: 0.009306, Accuracy: 99.69%\n",
      "Batch 46, Loss: 0.012576, Accuracy: 99.69%\n",
      "Batch 47, Loss: 0.005014, Accuracy: 99.70%\n",
      "Batch 48, Loss: 0.001159, Accuracy: 99.71%\n",
      "Batch 49, Loss: 0.003504, Accuracy: 99.71%\n",
      "Batch 50, Loss: 0.002292, Accuracy: 99.72%\n",
      "Batch 51, Loss: 0.001585, Accuracy: 99.72%\n",
      "Batch 52, Loss: 0.020452, Accuracy: 99.70%\n",
      "Batch 53, Loss: 0.005466, Accuracy: 99.71%\n",
      "Batch 54, Loss: 0.000794, Accuracy: 99.71%\n",
      "Batch 55, Loss: 0.023939, Accuracy: 99.69%\n",
      "Batch 56, Loss: 0.008503, Accuracy: 99.69%\n",
      "Batch 57, Loss: 0.006311, Accuracy: 99.70%\n",
      "Batch 58, Loss: 0.012048, Accuracy: 99.70%\n",
      "Batch 59, Loss: 0.046885, Accuracy: 99.68%\n",
      "Batch 60, Loss: 0.000813, Accuracy: 99.69%\n",
      "Batch 61, Loss: 0.014144, Accuracy: 99.67%\n",
      "Batch 62, Loss: 0.000983, Accuracy: 99.67%\n",
      "Batch 63, Loss: 0.001353, Accuracy: 99.68%\n",
      "Batch 64, Loss: 0.070354, Accuracy: 99.63%\n",
      "Batch 65, Loss: 0.015608, Accuracy: 99.64%\n",
      "Batch 66, Loss: 0.002106, Accuracy: 99.64%\n",
      "Batch 67, Loss: 0.032643, Accuracy: 99.63%\n",
      "Batch 68, Loss: 0.068330, Accuracy: 99.61%\n",
      "Batch 69, Loss: 0.033265, Accuracy: 99.59%\n",
      "Batch 70, Loss: 0.154242, Accuracy: 99.55%\n",
      "Batch 71, Loss: 0.002802, Accuracy: 99.56%\n",
      "Batch 72, Loss: 0.038115, Accuracy: 99.54%\n",
      "Batch 73, Loss: 0.039152, Accuracy: 99.51%\n",
      "Batch 74, Loss: 0.034860, Accuracy: 99.49%\n",
      "Batch 75, Loss: 0.042544, Accuracy: 99.48%\n",
      "Batch 76, Loss: 0.019539, Accuracy: 99.49%\n",
      "Batch 77, Loss: 0.090176, Accuracy: 99.45%\n",
      "Batch 78, Loss: 0.013338, Accuracy: 99.46%\n",
      "Batch 79, Loss: 0.070343, Accuracy: 99.43%\n",
      "Batch 80, Loss: 0.090761, Accuracy: 99.39%\n",
      "Batch 81, Loss: 0.007528, Accuracy: 99.40%\n",
      "Batch 82, Loss: 0.004213, Accuracy: 99.41%\n",
      "Batch 83, Loss: 0.018746, Accuracy: 99.40%\n",
      "Batch 84, Loss: 0.040199, Accuracy: 99.39%\n",
      "Batch 85, Loss: 0.008347, Accuracy: 99.39%\n",
      "Batch 86, Loss: 0.065232, Accuracy: 99.38%\n",
      "Batch 87, Loss: 0.004165, Accuracy: 99.39%\n",
      "Batch 88, Loss: 0.009665, Accuracy: 99.40%\n",
      "Batch 89, Loss: 0.008132, Accuracy: 99.40%\n",
      "Batch 90, Loss: 0.002737, Accuracy: 99.41%\n",
      "Batch 91, Loss: 0.003768, Accuracy: 99.42%\n",
      "Batch 92, Loss: 0.040482, Accuracy: 99.41%\n",
      "Batch 93, Loss: 0.093104, Accuracy: 99.38%\n",
      "Batch 94, Loss: 0.030319, Accuracy: 99.37%\n",
      "Batch 95, Loss: 0.018800, Accuracy: 99.38%\n",
      "Batch 96, Loss: 0.000933, Accuracy: 99.38%\n",
      "Batch 97, Loss: 0.010783, Accuracy: 99.39%\n",
      "Batch 98, Loss: 0.003973, Accuracy: 99.39%\n",
      "Batch 99, Loss: 0.073430, Accuracy: 99.37%\n",
      "Batch 100, Loss: 0.012115, Accuracy: 99.38%\n",
      "Batch 101, Loss: 0.099230, Accuracy: 99.37%\n",
      "Batch 102, Loss: 0.062971, Accuracy: 99.36%\n",
      "Batch 103, Loss: 0.072616, Accuracy: 99.35%\n",
      "Batch 104, Loss: 0.001809, Accuracy: 99.35%\n",
      "Batch 105, Loss: 0.002668, Accuracy: 99.36%\n",
      "Batch 106, Loss: 0.048097, Accuracy: 99.34%\n",
      "Batch 107, Loss: 0.024113, Accuracy: 99.33%\n",
      "Batch 108, Loss: 0.028290, Accuracy: 99.32%\n",
      "Batch 109, Loss: 0.002368, Accuracy: 99.33%\n",
      "Batch 110, Loss: 0.010080, Accuracy: 99.33%\n",
      "Batch 111, Loss: 0.004838, Accuracy: 99.34%\n",
      "Batch 112, Loss: 0.005611, Accuracy: 99.34%\n",
      "Batch 113, Loss: 0.015112, Accuracy: 99.35%\n",
      "Batch 114, Loss: 0.003097, Accuracy: 99.36%\n",
      "Batch 115, Loss: 0.001131, Accuracy: 99.36%\n",
      "Batch 116, Loss: 0.002778, Accuracy: 99.37%\n",
      "Batch 117, Loss: 0.001190, Accuracy: 99.37%\n",
      "Batch 118, Loss: 0.003362, Accuracy: 99.38%\n",
      "Batch 119, Loss: 0.006028, Accuracy: 99.38%\n",
      "Batch 120, Loss: 0.001011, Accuracy: 99.39%\n",
      "Batch 121, Loss: 0.002306, Accuracy: 99.39%\n",
      "Batch 122, Loss: 0.009193, Accuracy: 99.40%\n",
      "Batch 123, Loss: 0.040822, Accuracy: 99.39%\n",
      "Batch 124, Loss: 0.007157, Accuracy: 99.40%\n",
      "Batch 125, Loss: 0.000563, Accuracy: 99.40%\n",
      "Batch 126, Loss: 0.001714, Accuracy: 99.40%\n",
      "Batch 127, Loss: 0.047741, Accuracy: 99.38%\n",
      "Batch 128, Loss: 0.047877, Accuracy: 99.37%\n",
      "Batch 129, Loss: 0.009257, Accuracy: 99.37%\n",
      "Batch 130, Loss: 0.000431, Accuracy: 99.38%\n",
      "Batch 131, Loss: 0.001286, Accuracy: 99.38%\n",
      "Batch 132, Loss: 0.001992, Accuracy: 99.38%\n",
      "Batch 133, Loss: 0.022503, Accuracy: 99.38%\n",
      "Batch 134, Loss: 0.002587, Accuracy: 99.38%\n",
      "Batch 135, Loss: 0.003847, Accuracy: 99.39%\n",
      "Batch 136, Loss: 0.003452, Accuracy: 99.39%\n",
      "Batch 137, Loss: 0.003553, Accuracy: 99.40%\n",
      "Batch 138, Loss: 0.067842, Accuracy: 99.39%\n",
      "Batch 139, Loss: 0.001315, Accuracy: 99.39%\n",
      "Batch 140, Loss: 0.006314, Accuracy: 99.40%\n",
      "Batch 141, Loss: 0.009153, Accuracy: 99.40%\n",
      "Batch 142, Loss: 0.123108, Accuracy: 99.38%\n",
      "Batch 143, Loss: 0.007066, Accuracy: 99.39%\n",
      "Batch 144, Loss: 0.071595, Accuracy: 99.38%\n",
      "Batch 145, Loss: 0.004891, Accuracy: 99.39%\n",
      "Batch 146, Loss: 0.010979, Accuracy: 99.39%\n",
      "Batch 147, Loss: 0.013267, Accuracy: 99.39%\n",
      "Batch 148, Loss: 0.004182, Accuracy: 99.40%\n",
      "Batch 149, Loss: 0.025033, Accuracy: 99.39%\n",
      "Batch 150, Loss: 0.002271, Accuracy: 99.40%\n",
      "Batch 151, Loss: 0.001529, Accuracy: 99.40%\n",
      "Batch 152, Loss: 0.028225, Accuracy: 99.39%\n",
      "Batch 153, Loss: 0.001166, Accuracy: 99.40%\n",
      "Batch 154, Loss: 0.002417, Accuracy: 99.40%\n",
      "Batch 155, Loss: 0.008691, Accuracy: 99.41%\n",
      "Batch 156, Loss: 0.003498, Accuracy: 99.41%\n",
      "Batch 157, Loss: 0.007220, Accuracy: 99.41%\n",
      "Batch 158, Loss: 0.005157, Accuracy: 99.42%\n",
      "Batch 159, Loss: 0.002153, Accuracy: 99.42%\n",
      "Batch 160, Loss: 0.002222, Accuracy: 99.42%\n",
      "Batch 161, Loss: 0.055221, Accuracy: 99.42%\n",
      "Batch 162, Loss: 0.000494, Accuracy: 99.42%\n",
      "Batch 163, Loss: 0.005002, Accuracy: 99.42%\n",
      "Batch 164, Loss: 0.003029, Accuracy: 99.43%\n",
      "Batch 165, Loss: 0.002780, Accuracy: 99.43%\n",
      "Batch 166, Loss: 0.088872, Accuracy: 99.43%\n",
      "Batch 167, Loss: 0.117663, Accuracy: 99.42%\n",
      "Batch 168, Loss: 0.000544, Accuracy: 99.42%\n",
      "Batch 169, Loss: 0.003946, Accuracy: 99.43%\n",
      "Batch 170, Loss: 0.082702, Accuracy: 99.42%\n",
      "Batch 171, Loss: 0.000403, Accuracy: 99.42%\n",
      "Batch 172, Loss: 0.002450, Accuracy: 99.43%\n",
      "Batch 173, Loss: 0.000792, Accuracy: 99.43%\n",
      "Batch 174, Loss: 0.002275, Accuracy: 99.43%\n",
      "Batch 175, Loss: 0.000604, Accuracy: 99.44%\n",
      "Batch 176, Loss: 0.000955, Accuracy: 99.44%\n",
      "Batch 177, Loss: 0.000670, Accuracy: 99.44%\n",
      "Batch 178, Loss: 0.009802, Accuracy: 99.45%\n",
      "Batch 179, Loss: 0.047150, Accuracy: 99.43%\n",
      "Batch 180, Loss: 0.005543, Accuracy: 99.44%\n",
      "Batch 181, Loss: 0.000878, Accuracy: 99.44%\n",
      "Batch 182, Loss: 0.005944, Accuracy: 99.44%\n",
      "Batch 183, Loss: 0.001146, Accuracy: 99.45%\n",
      "Batch 184, Loss: 0.001106, Accuracy: 99.45%\n",
      "Batch 185, Loss: 0.005140, Accuracy: 99.45%\n",
      "Batch 186, Loss: 0.035392, Accuracy: 99.45%\n",
      "Batch 187, Loss: 0.071107, Accuracy: 99.43%\n",
      "Batch 188, Loss: 0.004066, Accuracy: 99.43%\n",
      "Batch 189, Loss: 0.001162, Accuracy: 99.44%\n",
      "Batch 190, Loss: 0.001163, Accuracy: 99.44%\n",
      "Batch 191, Loss: 0.000657, Accuracy: 99.44%\n",
      "Batch 192, Loss: 0.031430, Accuracy: 99.44%\n",
      "Batch 193, Loss: 0.001402, Accuracy: 99.44%\n",
      "Batch 194, Loss: 0.001761, Accuracy: 99.44%\n",
      "Batch 195, Loss: 0.008793, Accuracy: 99.45%\n",
      "Batch 196, Loss: 0.003093, Accuracy: 99.45%\n",
      "Batch 197, Loss: 0.001525, Accuracy: 99.45%\n",
      "Batch 198, Loss: 0.003574, Accuracy: 99.46%\n",
      "Batch 199, Loss: 0.002061, Accuracy: 99.46%\n",
      "Batch 200, Loss: 0.003107, Accuracy: 99.46%\n",
      "Batch 201, Loss: 0.001036, Accuracy: 99.46%\n",
      "Batch 202, Loss: 0.001240, Accuracy: 99.47%\n",
      "Batch 203, Loss: 0.010132, Accuracy: 99.47%\n",
      "Batch 204, Loss: 0.001737, Accuracy: 99.47%\n",
      "Batch 205, Loss: 0.010257, Accuracy: 99.47%\n",
      "Batch 206, Loss: 0.000766, Accuracy: 99.48%\n",
      "Batch 207, Loss: 0.060168, Accuracy: 99.47%\n",
      "Batch 208, Loss: 0.003951, Accuracy: 99.47%\n",
      "Batch 209, Loss: 0.000452, Accuracy: 99.48%\n",
      "Batch 210, Loss: 0.001086, Accuracy: 99.48%\n",
      "Batch 211, Loss: 0.001187, Accuracy: 99.48%\n",
      "Batch 212, Loss: 0.003173, Accuracy: 99.48%\n",
      "Batch 213, Loss: 0.000351, Accuracy: 99.49%\n",
      "Training - Epoch 26, Loss: 0.017079, Accuracy: 99.49%\n",
      "Validation Batch 1, Loss: 0.078789, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.030629, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.003227, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.004113, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.006059, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.000575, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.002783, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.009909, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.002903, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.010057, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.014586, Accuracy: 99.57%\n",
      "Validation Batch 12, Loss: 0.004415, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.000647, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.001321, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.003528, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.000812, Accuracy: 99.71%\n",
      "Validation Batch 17, Loss: 0.041894, Accuracy: 99.63%\n",
      "Validation Batch 18, Loss: 0.000786, Accuracy: 99.65%\n",
      "Validation Batch 19, Loss: 0.003620, Accuracy: 99.67%\n",
      "Validation Batch 20, Loss: 0.076073, Accuracy: 99.61%\n",
      "Validation Batch 21, Loss: 0.000598, Accuracy: 99.63%\n",
      "Validation Batch 22, Loss: 0.086089, Accuracy: 99.57%\n",
      "Validation Batch 23, Loss: 0.002883, Accuracy: 99.59%\n",
      "Validation Batch 24, Loss: 0.059455, Accuracy: 99.54%\n",
      "Validation Batch 25, Loss: 0.020574, Accuracy: 99.50%\n",
      "Validation Batch 26, Loss: 0.002232, Accuracy: 99.52%\n",
      "Validation Batch 27, Loss: 0.070467, Accuracy: 99.47%\n",
      "Validation - Epoch 26, Loss: 0.019964, Accuracy: 99.47%\n",
      "Patience—4\n",
      "Epoch 27\n",
      "Batch 1, Loss: 0.031687, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.000250, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.018432, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.035417, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.000256, Accuracy: 99.06%\n",
      "Batch 6, Loss: 0.000644, Accuracy: 99.22%\n",
      "Batch 7, Loss: 0.000402, Accuracy: 99.33%\n",
      "Batch 8, Loss: 0.011230, Accuracy: 99.41%\n",
      "Batch 9, Loss: 0.003880, Accuracy: 99.48%\n",
      "Batch 10, Loss: 0.000496, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.002055, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.007319, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.003260, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.000944, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.098877, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.006052, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.000622, Accuracy: 99.54%\n",
      "Batch 18, Loss: 0.024468, Accuracy: 99.48%\n",
      "Batch 19, Loss: 0.008943, Accuracy: 99.51%\n",
      "Batch 20, Loss: 0.001123, Accuracy: 99.53%\n",
      "Batch 21, Loss: 0.000385, Accuracy: 99.55%\n",
      "Batch 22, Loss: 0.000509, Accuracy: 99.57%\n",
      "Batch 23, Loss: 0.001328, Accuracy: 99.59%\n",
      "Batch 24, Loss: 0.001410, Accuracy: 99.61%\n",
      "Batch 25, Loss: 0.003089, Accuracy: 99.62%\n",
      "Batch 26, Loss: 0.003852, Accuracy: 99.64%\n",
      "Batch 27, Loss: 0.000345, Accuracy: 99.65%\n",
      "Batch 28, Loss: 0.001525, Accuracy: 99.67%\n",
      "Batch 29, Loss: 0.000325, Accuracy: 99.68%\n",
      "Batch 30, Loss: 0.000579, Accuracy: 99.69%\n",
      "Batch 31, Loss: 0.001121, Accuracy: 99.70%\n",
      "Batch 32, Loss: 0.003962, Accuracy: 99.71%\n",
      "Batch 33, Loss: 0.000217, Accuracy: 99.72%\n",
      "Batch 34, Loss: 0.000482, Accuracy: 99.72%\n",
      "Batch 35, Loss: 0.001573, Accuracy: 99.73%\n",
      "Batch 36, Loss: 0.000402, Accuracy: 99.74%\n",
      "Batch 37, Loss: 0.002036, Accuracy: 99.75%\n",
      "Batch 38, Loss: 0.000835, Accuracy: 99.75%\n",
      "Batch 39, Loss: 0.000282, Accuracy: 99.76%\n",
      "Batch 40, Loss: 0.000542, Accuracy: 99.77%\n",
      "Batch 41, Loss: 0.004971, Accuracy: 99.77%\n",
      "Batch 42, Loss: 0.002501, Accuracy: 99.78%\n",
      "Batch 43, Loss: 0.000289, Accuracy: 99.78%\n",
      "Batch 44, Loss: 0.000164, Accuracy: 99.79%\n",
      "Batch 45, Loss: 0.001624, Accuracy: 99.79%\n",
      "Batch 46, Loss: 0.000374, Accuracy: 99.80%\n",
      "Batch 47, Loss: 0.000456, Accuracy: 99.80%\n",
      "Batch 48, Loss: 0.008035, Accuracy: 99.80%\n",
      "Batch 49, Loss: 0.000102, Accuracy: 99.81%\n",
      "Batch 50, Loss: 0.001572, Accuracy: 99.81%\n",
      "Batch 51, Loss: 0.000509, Accuracy: 99.82%\n",
      "Batch 52, Loss: 0.000310, Accuracy: 99.82%\n",
      "Batch 53, Loss: 0.000291, Accuracy: 99.82%\n",
      "Batch 54, Loss: 0.054391, Accuracy: 99.80%\n",
      "Batch 55, Loss: 0.000386, Accuracy: 99.80%\n",
      "Batch 56, Loss: 0.000124, Accuracy: 99.80%\n",
      "Batch 57, Loss: 0.000253, Accuracy: 99.81%\n",
      "Batch 58, Loss: 0.000502, Accuracy: 99.81%\n",
      "Batch 59, Loss: 0.000605, Accuracy: 99.81%\n",
      "Batch 60, Loss: 0.001429, Accuracy: 99.82%\n",
      "Batch 61, Loss: 0.000190, Accuracy: 99.82%\n",
      "Batch 62, Loss: 0.000512, Accuracy: 99.82%\n",
      "Batch 63, Loss: 0.006161, Accuracy: 99.83%\n",
      "Batch 64, Loss: 0.044492, Accuracy: 99.80%\n",
      "Batch 65, Loss: 0.000317, Accuracy: 99.81%\n",
      "Batch 66, Loss: 0.001236, Accuracy: 99.81%\n",
      "Batch 67, Loss: 0.002269, Accuracy: 99.81%\n",
      "Batch 68, Loss: 0.006808, Accuracy: 99.82%\n",
      "Batch 69, Loss: 0.000793, Accuracy: 99.82%\n",
      "Batch 70, Loss: 0.000132, Accuracy: 99.82%\n",
      "Batch 71, Loss: 0.052815, Accuracy: 99.80%\n",
      "Batch 72, Loss: 0.000205, Accuracy: 99.80%\n",
      "Batch 73, Loss: 0.000302, Accuracy: 99.81%\n",
      "Batch 74, Loss: 0.003150, Accuracy: 99.81%\n",
      "Batch 75, Loss: 0.001108, Accuracy: 99.81%\n",
      "Batch 76, Loss: 0.001704, Accuracy: 99.81%\n",
      "Batch 77, Loss: 0.052164, Accuracy: 99.78%\n",
      "Batch 78, Loss: 0.012093, Accuracy: 99.78%\n",
      "Batch 79, Loss: 0.031554, Accuracy: 99.76%\n",
      "Batch 80, Loss: 0.091868, Accuracy: 99.75%\n",
      "Batch 81, Loss: 0.000550, Accuracy: 99.75%\n",
      "Batch 82, Loss: 0.007276, Accuracy: 99.75%\n",
      "Batch 83, Loss: 0.038498, Accuracy: 99.74%\n",
      "Batch 84, Loss: 0.014531, Accuracy: 99.72%\n",
      "Batch 85, Loss: 0.004344, Accuracy: 99.72%\n",
      "Batch 86, Loss: 0.004497, Accuracy: 99.73%\n",
      "Batch 87, Loss: 0.013875, Accuracy: 99.71%\n",
      "Batch 88, Loss: 0.000596, Accuracy: 99.72%\n",
      "Batch 89, Loss: 0.001025, Accuracy: 99.72%\n",
      "Batch 90, Loss: 0.086264, Accuracy: 99.70%\n",
      "Batch 91, Loss: 0.061819, Accuracy: 99.67%\n",
      "Batch 92, Loss: 0.108987, Accuracy: 99.66%\n",
      "Batch 93, Loss: 0.001615, Accuracy: 99.66%\n",
      "Batch 94, Loss: 0.002484, Accuracy: 99.67%\n",
      "Batch 95, Loss: 0.002970, Accuracy: 99.67%\n",
      "Batch 96, Loss: 0.023572, Accuracy: 99.66%\n",
      "Batch 97, Loss: 0.003747, Accuracy: 99.66%\n",
      "Batch 98, Loss: 0.003303, Accuracy: 99.67%\n",
      "Batch 99, Loss: 0.001007, Accuracy: 99.67%\n",
      "Batch 100, Loss: 0.004179, Accuracy: 99.67%\n",
      "Batch 101, Loss: 0.000844, Accuracy: 99.68%\n",
      "Batch 102, Loss: 0.154180, Accuracy: 99.65%\n",
      "Batch 103, Loss: 0.124266, Accuracy: 99.62%\n",
      "Batch 104, Loss: 0.075966, Accuracy: 99.59%\n",
      "Batch 105, Loss: 0.104446, Accuracy: 99.57%\n",
      "Batch 106, Loss: 0.002412, Accuracy: 99.57%\n",
      "Batch 107, Loss: 0.071388, Accuracy: 99.56%\n",
      "Batch 108, Loss: 0.002108, Accuracy: 99.57%\n",
      "Batch 109, Loss: 0.017793, Accuracy: 99.56%\n",
      "Batch 110, Loss: 0.017982, Accuracy: 99.55%\n",
      "Batch 111, Loss: 0.001935, Accuracy: 99.55%\n",
      "Batch 112, Loss: 0.015113, Accuracy: 99.55%\n",
      "Batch 113, Loss: 0.009403, Accuracy: 99.56%\n",
      "Batch 114, Loss: 0.008146, Accuracy: 99.56%\n",
      "Batch 115, Loss: 0.028476, Accuracy: 99.55%\n",
      "Batch 116, Loss: 0.014410, Accuracy: 99.56%\n",
      "Batch 117, Loss: 0.008462, Accuracy: 99.56%\n",
      "Batch 118, Loss: 0.002043, Accuracy: 99.56%\n",
      "Batch 119, Loss: 0.055346, Accuracy: 99.55%\n",
      "Batch 120, Loss: 0.014647, Accuracy: 99.56%\n",
      "Batch 121, Loss: 0.003802, Accuracy: 99.56%\n",
      "Batch 122, Loss: 0.015818, Accuracy: 99.56%\n",
      "Batch 123, Loss: 0.002212, Accuracy: 99.57%\n",
      "Batch 124, Loss: 0.052794, Accuracy: 99.56%\n",
      "Batch 125, Loss: 0.003495, Accuracy: 99.56%\n",
      "Batch 126, Loss: 0.062688, Accuracy: 99.55%\n",
      "Batch 127, Loss: 0.013088, Accuracy: 99.56%\n",
      "Batch 128, Loss: 0.005480, Accuracy: 99.56%\n",
      "Batch 129, Loss: 0.002834, Accuracy: 99.56%\n",
      "Batch 130, Loss: 0.021545, Accuracy: 99.57%\n",
      "Batch 131, Loss: 0.001805, Accuracy: 99.57%\n",
      "Batch 132, Loss: 0.004709, Accuracy: 99.57%\n",
      "Batch 133, Loss: 0.001544, Accuracy: 99.58%\n",
      "Batch 134, Loss: 0.010610, Accuracy: 99.58%\n",
      "Batch 135, Loss: 0.028923, Accuracy: 99.57%\n",
      "Batch 136, Loss: 0.001788, Accuracy: 99.57%\n",
      "Batch 137, Loss: 0.007604, Accuracy: 99.58%\n",
      "Batch 138, Loss: 0.002656, Accuracy: 99.58%\n",
      "Batch 139, Loss: 0.011671, Accuracy: 99.58%\n",
      "Batch 140, Loss: 0.021545, Accuracy: 99.58%\n",
      "Batch 141, Loss: 0.062605, Accuracy: 99.56%\n",
      "Batch 142, Loss: 0.000622, Accuracy: 99.56%\n",
      "Batch 143, Loss: 0.000724, Accuracy: 99.56%\n",
      "Batch 144, Loss: 0.018707, Accuracy: 99.56%\n",
      "Batch 145, Loss: 0.013338, Accuracy: 99.55%\n",
      "Batch 146, Loss: 0.003137, Accuracy: 99.55%\n",
      "Batch 147, Loss: 0.022504, Accuracy: 99.54%\n",
      "Batch 148, Loss: 0.001977, Accuracy: 99.55%\n",
      "Batch 149, Loss: 0.001114, Accuracy: 99.55%\n",
      "Batch 150, Loss: 0.000388, Accuracy: 99.55%\n",
      "Batch 151, Loss: 0.002390, Accuracy: 99.56%\n",
      "Batch 152, Loss: 0.036015, Accuracy: 99.55%\n",
      "Batch 153, Loss: 0.025237, Accuracy: 99.54%\n",
      "Batch 154, Loss: 0.001469, Accuracy: 99.54%\n",
      "Batch 155, Loss: 0.000492, Accuracy: 99.55%\n",
      "Batch 156, Loss: 0.007908, Accuracy: 99.55%\n",
      "Batch 157, Loss: 0.002205, Accuracy: 99.55%\n",
      "Batch 158, Loss: 0.002570, Accuracy: 99.55%\n",
      "Batch 159, Loss: 0.017594, Accuracy: 99.55%\n",
      "Batch 160, Loss: 0.047533, Accuracy: 99.53%\n",
      "Batch 161, Loss: 0.000830, Accuracy: 99.53%\n",
      "Batch 162, Loss: 0.007948, Accuracy: 99.54%\n",
      "Batch 163, Loss: 0.002583, Accuracy: 99.54%\n",
      "Batch 164, Loss: 0.065626, Accuracy: 99.52%\n",
      "Batch 165, Loss: 0.012513, Accuracy: 99.53%\n",
      "Batch 166, Loss: 0.000256, Accuracy: 99.53%\n",
      "Batch 167, Loss: 0.000276, Accuracy: 99.53%\n",
      "Batch 168, Loss: 0.018154, Accuracy: 99.53%\n",
      "Batch 169, Loss: 0.021987, Accuracy: 99.52%\n",
      "Batch 170, Loss: 0.002698, Accuracy: 99.52%\n",
      "Batch 171, Loss: 0.005319, Accuracy: 99.52%\n",
      "Batch 172, Loss: 0.000974, Accuracy: 99.53%\n",
      "Batch 173, Loss: 0.070410, Accuracy: 99.52%\n",
      "Batch 174, Loss: 0.064473, Accuracy: 99.52%\n",
      "Batch 175, Loss: 0.106570, Accuracy: 99.51%\n",
      "Batch 176, Loss: 0.031169, Accuracy: 99.50%\n",
      "Batch 177, Loss: 0.002526, Accuracy: 99.51%\n",
      "Batch 178, Loss: 0.051507, Accuracy: 99.50%\n",
      "Batch 179, Loss: 0.001041, Accuracy: 99.50%\n",
      "Batch 180, Loss: 0.004278, Accuracy: 99.51%\n",
      "Batch 181, Loss: 0.002658, Accuracy: 99.51%\n",
      "Batch 182, Loss: 0.001257, Accuracy: 99.51%\n",
      "Batch 183, Loss: 0.004649, Accuracy: 99.51%\n",
      "Batch 184, Loss: 0.003582, Accuracy: 99.52%\n",
      "Batch 185, Loss: 0.013326, Accuracy: 99.51%\n",
      "Batch 186, Loss: 0.110643, Accuracy: 99.50%\n",
      "Batch 187, Loss: 0.010406, Accuracy: 99.51%\n",
      "Batch 188, Loss: 0.004369, Accuracy: 99.51%\n",
      "Batch 189, Loss: 0.024222, Accuracy: 99.50%\n",
      "Batch 190, Loss: 0.009089, Accuracy: 99.51%\n",
      "Batch 191, Loss: 0.026417, Accuracy: 99.50%\n",
      "Batch 192, Loss: 0.029106, Accuracy: 99.50%\n",
      "Batch 193, Loss: 0.003996, Accuracy: 99.50%\n",
      "Batch 194, Loss: 0.012364, Accuracy: 99.50%\n",
      "Batch 195, Loss: 0.003364, Accuracy: 99.50%\n",
      "Batch 196, Loss: 0.053566, Accuracy: 99.50%\n",
      "Batch 197, Loss: 0.081340, Accuracy: 99.49%\n",
      "Batch 198, Loss: 0.011571, Accuracy: 99.49%\n",
      "Batch 199, Loss: 0.001184, Accuracy: 99.50%\n",
      "Batch 200, Loss: 0.005406, Accuracy: 99.50%\n",
      "Batch 201, Loss: 0.011656, Accuracy: 99.50%\n",
      "Batch 202, Loss: 0.074917, Accuracy: 99.50%\n",
      "Batch 203, Loss: 0.005870, Accuracy: 99.50%\n",
      "Batch 204, Loss: 0.016729, Accuracy: 99.50%\n",
      "Batch 205, Loss: 0.002590, Accuracy: 99.50%\n",
      "Batch 206, Loss: 0.002622, Accuracy: 99.51%\n",
      "Batch 207, Loss: 0.011127, Accuracy: 99.51%\n",
      "Batch 208, Loss: 0.001038, Accuracy: 99.51%\n",
      "Batch 209, Loss: 0.016048, Accuracy: 99.51%\n",
      "Batch 210, Loss: 0.003997, Accuracy: 99.51%\n",
      "Batch 211, Loss: 0.002405, Accuracy: 99.51%\n",
      "Batch 212, Loss: 0.001623, Accuracy: 99.51%\n",
      "Batch 213, Loss: 0.001488, Accuracy: 99.52%\n",
      "Training - Epoch 27, Loss: 0.015800, Accuracy: 99.52%\n",
      "Validation Batch 1, Loss: 0.001566, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.095947, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.016953, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.136677, Accuracy: 98.05%\n",
      "Validation Batch 5, Loss: 0.129239, Accuracy: 98.12%\n",
      "Validation Batch 6, Loss: 0.025926, Accuracy: 98.18%\n",
      "Validation Batch 7, Loss: 0.001819, Accuracy: 98.44%\n",
      "Validation Batch 8, Loss: 0.000710, Accuracy: 98.63%\n",
      "Validation Batch 9, Loss: 0.014759, Accuracy: 98.61%\n",
      "Validation Batch 10, Loss: 0.003871, Accuracy: 98.75%\n",
      "Validation Batch 11, Loss: 0.022814, Accuracy: 98.72%\n",
      "Validation Batch 12, Loss: 0.190698, Accuracy: 98.57%\n",
      "Validation Batch 13, Loss: 0.011310, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.158379, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.028892, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.207491, Accuracy: 98.44%\n",
      "Validation Batch 17, Loss: 0.022978, Accuracy: 98.44%\n",
      "Validation Batch 18, Loss: 0.089763, Accuracy: 98.44%\n",
      "Validation Batch 19, Loss: 0.280517, Accuracy: 98.27%\n",
      "Validation Batch 20, Loss: 0.022776, Accuracy: 98.28%\n",
      "Validation Batch 21, Loss: 0.203922, Accuracy: 98.29%\n",
      "Validation Batch 22, Loss: 0.003519, Accuracy: 98.37%\n",
      "Validation Batch 23, Loss: 0.017902, Accuracy: 98.37%\n",
      "Validation Batch 24, Loss: 0.080324, Accuracy: 98.37%\n",
      "Validation Batch 25, Loss: 0.001602, Accuracy: 98.44%\n",
      "Validation Batch 26, Loss: 0.133426, Accuracy: 98.38%\n",
      "Validation Batch 27, Loss: 0.000854, Accuracy: 98.41%\n",
      "Validation - Epoch 27, Loss: 0.070542, Accuracy: 98.41%\n",
      "Patience—5\n",
      "Epoch 28\n",
      "Batch 1, Loss: 0.007261, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001668, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.008825, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.003999, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.016537, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.000403, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.073068, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.007404, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.038703, Accuracy: 99.48%\n",
      "Batch 10, Loss: 0.003128, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.000331, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.000380, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.005551, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.001815, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.024594, Accuracy: 99.58%\n",
      "Batch 16, Loss: 0.001050, Accuracy: 99.61%\n",
      "Batch 17, Loss: 0.000724, Accuracy: 99.63%\n",
      "Batch 18, Loss: 0.000921, Accuracy: 99.65%\n",
      "Batch 19, Loss: 0.003564, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.000750, Accuracy: 99.69%\n",
      "Batch 21, Loss: 0.068246, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.000897, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.034166, Accuracy: 99.52%\n",
      "Batch 24, Loss: 0.192735, Accuracy: 99.35%\n",
      "Batch 25, Loss: 0.017805, Accuracy: 99.31%\n",
      "Batch 26, Loss: 0.003365, Accuracy: 99.34%\n",
      "Batch 27, Loss: 0.005587, Accuracy: 99.36%\n",
      "Batch 28, Loss: 0.001174, Accuracy: 99.39%\n",
      "Batch 29, Loss: 0.062541, Accuracy: 99.35%\n",
      "Batch 30, Loss: 0.008034, Accuracy: 99.38%\n",
      "Batch 31, Loss: 0.038561, Accuracy: 99.34%\n",
      "Batch 32, Loss: 0.068511, Accuracy: 99.32%\n",
      "Batch 33, Loss: 0.007014, Accuracy: 99.34%\n",
      "Batch 34, Loss: 0.003899, Accuracy: 99.36%\n",
      "Batch 35, Loss: 0.001401, Accuracy: 99.38%\n",
      "Batch 36, Loss: 0.089819, Accuracy: 99.31%\n",
      "Batch 37, Loss: 0.001760, Accuracy: 99.32%\n",
      "Batch 38, Loss: 0.005766, Accuracy: 99.34%\n",
      "Batch 39, Loss: 0.016763, Accuracy: 99.32%\n",
      "Batch 40, Loss: 0.050658, Accuracy: 99.30%\n",
      "Batch 41, Loss: 0.004393, Accuracy: 99.31%\n",
      "Batch 42, Loss: 0.001643, Accuracy: 99.33%\n",
      "Batch 43, Loss: 0.001834, Accuracy: 99.35%\n",
      "Batch 44, Loss: 0.008605, Accuracy: 99.36%\n",
      "Batch 45, Loss: 0.004526, Accuracy: 99.38%\n",
      "Batch 46, Loss: 0.040288, Accuracy: 99.35%\n",
      "Batch 47, Loss: 0.002820, Accuracy: 99.37%\n",
      "Batch 48, Loss: 0.006033, Accuracy: 99.38%\n",
      "Batch 49, Loss: 0.001852, Accuracy: 99.39%\n",
      "Batch 50, Loss: 0.000931, Accuracy: 99.41%\n",
      "Batch 51, Loss: 0.031173, Accuracy: 99.39%\n",
      "Batch 52, Loss: 0.001740, Accuracy: 99.40%\n",
      "Batch 53, Loss: 0.012483, Accuracy: 99.41%\n",
      "Batch 54, Loss: 0.001209, Accuracy: 99.42%\n",
      "Batch 55, Loss: 0.024543, Accuracy: 99.40%\n",
      "Batch 56, Loss: 0.003675, Accuracy: 99.41%\n",
      "Batch 57, Loss: 0.011558, Accuracy: 99.42%\n",
      "Batch 58, Loss: 0.002881, Accuracy: 99.43%\n",
      "Batch 59, Loss: 0.025190, Accuracy: 99.42%\n",
      "Batch 60, Loss: 0.000805, Accuracy: 99.43%\n",
      "Batch 61, Loss: 0.006563, Accuracy: 99.44%\n",
      "Batch 62, Loss: 0.001158, Accuracy: 99.45%\n",
      "Batch 63, Loss: 0.001172, Accuracy: 99.45%\n",
      "Batch 64, Loss: 0.001635, Accuracy: 99.46%\n",
      "Batch 65, Loss: 0.005068, Accuracy: 99.47%\n",
      "Batch 66, Loss: 0.001631, Accuracy: 99.48%\n",
      "Batch 67, Loss: 0.003986, Accuracy: 99.49%\n",
      "Batch 68, Loss: 0.022621, Accuracy: 99.47%\n",
      "Batch 69, Loss: 0.014314, Accuracy: 99.46%\n",
      "Batch 70, Loss: 0.139676, Accuracy: 99.42%\n",
      "Batch 71, Loss: 0.002794, Accuracy: 99.43%\n",
      "Batch 72, Loss: 0.001161, Accuracy: 99.44%\n",
      "Batch 73, Loss: 0.013735, Accuracy: 99.44%\n",
      "Batch 74, Loss: 0.073887, Accuracy: 99.41%\n",
      "Batch 75, Loss: 0.000543, Accuracy: 99.42%\n",
      "Batch 76, Loss: 0.022572, Accuracy: 99.40%\n",
      "Batch 77, Loss: 0.001653, Accuracy: 99.41%\n",
      "Batch 78, Loss: 0.085633, Accuracy: 99.40%\n",
      "Batch 79, Loss: 0.001042, Accuracy: 99.41%\n",
      "Batch 80, Loss: 0.143053, Accuracy: 99.38%\n",
      "Batch 81, Loss: 0.003487, Accuracy: 99.38%\n",
      "Batch 82, Loss: 0.006299, Accuracy: 99.39%\n",
      "Batch 83, Loss: 0.118195, Accuracy: 99.36%\n",
      "Batch 84, Loss: 0.036125, Accuracy: 99.35%\n",
      "Batch 85, Loss: 0.005529, Accuracy: 99.36%\n",
      "Batch 86, Loss: 0.003360, Accuracy: 99.36%\n",
      "Batch 87, Loss: 0.015044, Accuracy: 99.35%\n",
      "Batch 88, Loss: 0.005075, Accuracy: 99.36%\n",
      "Batch 89, Loss: 0.106160, Accuracy: 99.33%\n",
      "Batch 90, Loss: 0.003314, Accuracy: 99.34%\n",
      "Batch 91, Loss: 0.005285, Accuracy: 99.35%\n",
      "Batch 92, Loss: 0.021548, Accuracy: 99.34%\n",
      "Batch 93, Loss: 0.086729, Accuracy: 99.29%\n",
      "Batch 94, Loss: 0.052986, Accuracy: 99.29%\n",
      "Batch 95, Loss: 0.047744, Accuracy: 99.28%\n",
      "Batch 96, Loss: 0.024428, Accuracy: 99.27%\n",
      "Batch 97, Loss: 0.020763, Accuracy: 99.28%\n",
      "Batch 98, Loss: 0.055727, Accuracy: 99.27%\n",
      "Batch 99, Loss: 0.020534, Accuracy: 99.26%\n",
      "Batch 100, Loss: 0.027498, Accuracy: 99.25%\n",
      "Batch 101, Loss: 0.006474, Accuracy: 99.26%\n",
      "Batch 102, Loss: 0.020722, Accuracy: 99.25%\n",
      "Batch 103, Loss: 0.008847, Accuracy: 99.26%\n",
      "Batch 104, Loss: 0.041961, Accuracy: 99.23%\n",
      "Batch 105, Loss: 0.070330, Accuracy: 99.23%\n",
      "Batch 106, Loss: 0.138048, Accuracy: 99.22%\n",
      "Batch 107, Loss: 0.025580, Accuracy: 99.23%\n",
      "Batch 108, Loss: 0.012636, Accuracy: 99.23%\n",
      "Batch 109, Loss: 0.034395, Accuracy: 99.23%\n",
      "Batch 110, Loss: 0.049506, Accuracy: 99.22%\n",
      "Batch 111, Loss: 0.120539, Accuracy: 99.18%\n",
      "Batch 112, Loss: 0.024247, Accuracy: 99.18%\n",
      "Batch 113, Loss: 0.010065, Accuracy: 99.18%\n",
      "Batch 114, Loss: 0.007211, Accuracy: 99.19%\n",
      "Batch 115, Loss: 0.009909, Accuracy: 99.20%\n",
      "Batch 116, Loss: 0.003604, Accuracy: 99.21%\n",
      "Batch 117, Loss: 0.074075, Accuracy: 99.19%\n",
      "Batch 118, Loss: 0.009177, Accuracy: 99.19%\n",
      "Batch 119, Loss: 0.023489, Accuracy: 99.19%\n",
      "Batch 120, Loss: 0.041867, Accuracy: 99.18%\n",
      "Batch 121, Loss: 0.065331, Accuracy: 99.16%\n",
      "Batch 122, Loss: 0.002009, Accuracy: 99.17%\n",
      "Batch 123, Loss: 0.005405, Accuracy: 99.17%\n",
      "Batch 124, Loss: 0.001715, Accuracy: 99.18%\n",
      "Batch 125, Loss: 0.008758, Accuracy: 99.19%\n",
      "Batch 126, Loss: 0.077685, Accuracy: 99.18%\n",
      "Batch 127, Loss: 0.123208, Accuracy: 99.16%\n",
      "Batch 128, Loss: 0.026541, Accuracy: 99.16%\n",
      "Batch 129, Loss: 0.046325, Accuracy: 99.15%\n",
      "Batch 130, Loss: 0.070667, Accuracy: 99.15%\n",
      "Batch 131, Loss: 0.083373, Accuracy: 99.13%\n",
      "Batch 132, Loss: 0.011346, Accuracy: 99.14%\n",
      "Batch 133, Loss: 0.004621, Accuracy: 99.14%\n",
      "Batch 134, Loss: 0.050938, Accuracy: 99.14%\n",
      "Batch 135, Loss: 0.017808, Accuracy: 99.14%\n",
      "Batch 136, Loss: 0.026431, Accuracy: 99.15%\n",
      "Batch 137, Loss: 0.030056, Accuracy: 99.14%\n",
      "Batch 138, Loss: 0.073789, Accuracy: 99.14%\n",
      "Batch 139, Loss: 0.004313, Accuracy: 99.15%\n",
      "Batch 140, Loss: 0.006129, Accuracy: 99.15%\n",
      "Batch 141, Loss: 0.012579, Accuracy: 99.16%\n",
      "Batch 142, Loss: 0.021248, Accuracy: 99.15%\n",
      "Batch 143, Loss: 0.003804, Accuracy: 99.16%\n",
      "Batch 144, Loss: 0.050034, Accuracy: 99.14%\n",
      "Batch 145, Loss: 0.002375, Accuracy: 99.15%\n",
      "Batch 146, Loss: 0.004703, Accuracy: 99.15%\n",
      "Batch 147, Loss: 0.106211, Accuracy: 99.14%\n",
      "Batch 148, Loss: 0.050717, Accuracy: 99.13%\n",
      "Batch 149, Loss: 0.004301, Accuracy: 99.14%\n",
      "Batch 150, Loss: 0.051635, Accuracy: 99.14%\n",
      "Batch 151, Loss: 0.023764, Accuracy: 99.13%\n",
      "Batch 152, Loss: 0.055106, Accuracy: 99.12%\n",
      "Batch 153, Loss: 0.013264, Accuracy: 99.12%\n",
      "Batch 154, Loss: 0.015584, Accuracy: 99.12%\n",
      "Batch 155, Loss: 0.002483, Accuracy: 99.12%\n",
      "Batch 156, Loss: 0.002061, Accuracy: 99.13%\n",
      "Batch 157, Loss: 0.015019, Accuracy: 99.13%\n",
      "Batch 158, Loss: 0.011461, Accuracy: 99.14%\n",
      "Batch 159, Loss: 0.008762, Accuracy: 99.15%\n",
      "Batch 160, Loss: 0.003157, Accuracy: 99.15%\n",
      "Batch 161, Loss: 0.011237, Accuracy: 99.16%\n",
      "Batch 162, Loss: 0.102016, Accuracy: 99.14%\n",
      "Batch 163, Loss: 0.033603, Accuracy: 99.14%\n",
      "Batch 164, Loss: 0.005098, Accuracy: 99.14%\n",
      "Batch 165, Loss: 0.003563, Accuracy: 99.15%\n",
      "Batch 166, Loss: 0.019902, Accuracy: 99.14%\n",
      "Batch 167, Loss: 0.004267, Accuracy: 99.15%\n",
      "Batch 168, Loss: 0.143022, Accuracy: 99.14%\n",
      "Batch 169, Loss: 0.029905, Accuracy: 99.13%\n",
      "Batch 170, Loss: 0.002490, Accuracy: 99.14%\n",
      "Batch 171, Loss: 0.007741, Accuracy: 99.14%\n",
      "Batch 172, Loss: 0.004801, Accuracy: 99.15%\n",
      "Batch 173, Loss: 0.004603, Accuracy: 99.15%\n",
      "Batch 174, Loss: 0.001079, Accuracy: 99.16%\n",
      "Batch 175, Loss: 0.030320, Accuracy: 99.15%\n",
      "Batch 176, Loss: 0.072018, Accuracy: 99.14%\n",
      "Batch 177, Loss: 0.013102, Accuracy: 99.14%\n",
      "Batch 178, Loss: 0.030823, Accuracy: 99.14%\n",
      "Batch 179, Loss: 0.016378, Accuracy: 99.14%\n",
      "Batch 180, Loss: 0.004798, Accuracy: 99.15%\n",
      "Batch 181, Loss: 0.002290, Accuracy: 99.15%\n",
      "Batch 182, Loss: 0.048991, Accuracy: 99.15%\n",
      "Batch 183, Loss: 0.002185, Accuracy: 99.15%\n",
      "Batch 184, Loss: 0.003860, Accuracy: 99.16%\n",
      "Batch 185, Loss: 0.073270, Accuracy: 99.15%\n",
      "Batch 186, Loss: 0.004225, Accuracy: 99.15%\n",
      "Batch 187, Loss: 0.023629, Accuracy: 99.15%\n",
      "Batch 188, Loss: 0.073147, Accuracy: 99.14%\n",
      "Batch 189, Loss: 0.001564, Accuracy: 99.15%\n",
      "Batch 190, Loss: 0.054065, Accuracy: 99.14%\n",
      "Batch 191, Loss: 0.001341, Accuracy: 99.15%\n",
      "Batch 192, Loss: 0.001715, Accuracy: 99.15%\n",
      "Batch 193, Loss: 0.008643, Accuracy: 99.16%\n",
      "Batch 194, Loss: 0.003643, Accuracy: 99.16%\n",
      "Batch 195, Loss: 0.001715, Accuracy: 99.17%\n",
      "Batch 196, Loss: 0.014691, Accuracy: 99.17%\n",
      "Batch 197, Loss: 0.003033, Accuracy: 99.18%\n",
      "Batch 198, Loss: 0.002841, Accuracy: 99.18%\n",
      "Batch 199, Loss: 0.000993, Accuracy: 99.18%\n",
      "Batch 200, Loss: 0.032462, Accuracy: 99.18%\n",
      "Batch 201, Loss: 0.002773, Accuracy: 99.18%\n",
      "Batch 202, Loss: 0.004538, Accuracy: 99.19%\n",
      "Batch 203, Loss: 0.002178, Accuracy: 99.19%\n",
      "Batch 204, Loss: 0.003603, Accuracy: 99.20%\n",
      "Batch 205, Loss: 0.001742, Accuracy: 99.20%\n",
      "Batch 206, Loss: 0.011073, Accuracy: 99.20%\n",
      "Batch 207, Loss: 0.071335, Accuracy: 99.19%\n",
      "Batch 208, Loss: 0.002212, Accuracy: 99.20%\n",
      "Batch 209, Loss: 0.089636, Accuracy: 99.19%\n",
      "Batch 210, Loss: 0.094460, Accuracy: 99.18%\n",
      "Batch 211, Loss: 0.041691, Accuracy: 99.18%\n",
      "Batch 212, Loss: 0.002744, Accuracy: 99.18%\n",
      "Batch 213, Loss: 0.000659, Accuracy: 99.19%\n",
      "Training - Epoch 28, Loss: 0.025504, Accuracy: 99.19%\n",
      "Validation Batch 1, Loss: 0.012977, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000955, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.002353, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.001474, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000920, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000590, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000353, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.027271, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.016298, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.045150, Accuracy: 99.22%\n",
      "Validation Batch 11, Loss: 0.055875, Accuracy: 99.15%\n",
      "Validation Batch 12, Loss: 0.069255, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.040369, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.071098, Accuracy: 98.88%\n",
      "Validation Batch 15, Loss: 0.060080, Accuracy: 98.75%\n",
      "Validation Batch 16, Loss: 0.005763, Accuracy: 98.83%\n",
      "Validation Batch 17, Loss: 0.081047, Accuracy: 98.81%\n",
      "Validation Batch 18, Loss: 0.001053, Accuracy: 98.87%\n",
      "Validation Batch 19, Loss: 0.062428, Accuracy: 98.85%\n",
      "Validation Batch 20, Loss: 0.002396, Accuracy: 98.91%\n",
      "Validation Batch 21, Loss: 0.010934, Accuracy: 98.96%\n",
      "Validation Batch 22, Loss: 0.010520, Accuracy: 99.01%\n",
      "Validation Batch 23, Loss: 0.000869, Accuracy: 99.05%\n",
      "Validation Batch 24, Loss: 0.103095, Accuracy: 98.96%\n",
      "Validation Batch 25, Loss: 0.000791, Accuracy: 99.00%\n",
      "Validation Batch 26, Loss: 0.024596, Accuracy: 98.98%\n",
      "Validation Batch 27, Loss: 0.001164, Accuracy: 99.00%\n",
      "Validation - Epoch 28, Loss: 0.026284, Accuracy: 99.00%\n",
      "Patience—6\n",
      "Epoch 29\n",
      "Batch 1, Loss: 0.000801, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.009243, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.001195, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000453, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001324, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000606, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.010041, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000743, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000314, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.089614, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.117001, Accuracy: 99.72%\n",
      "Batch 12, Loss: 0.002123, Accuracy: 99.74%\n",
      "Batch 13, Loss: 0.002825, Accuracy: 99.76%\n",
      "Batch 14, Loss: 0.000281, Accuracy: 99.78%\n",
      "Batch 15, Loss: 0.003803, Accuracy: 99.79%\n",
      "Batch 16, Loss: 0.007493, Accuracy: 99.80%\n",
      "Batch 17, Loss: 0.003059, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.026942, Accuracy: 99.74%\n",
      "Batch 19, Loss: 0.017740, Accuracy: 99.75%\n",
      "Batch 20, Loss: 0.024928, Accuracy: 99.69%\n",
      "Batch 21, Loss: 0.002674, Accuracy: 99.70%\n",
      "Batch 22, Loss: 0.013426, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.001461, Accuracy: 99.66%\n",
      "Batch 24, Loss: 0.015640, Accuracy: 99.61%\n",
      "Batch 25, Loss: 0.049641, Accuracy: 99.50%\n",
      "Batch 26, Loss: 0.101428, Accuracy: 99.46%\n",
      "Batch 27, Loss: 0.002220, Accuracy: 99.48%\n",
      "Batch 28, Loss: 0.006809, Accuracy: 99.50%\n",
      "Batch 29, Loss: 0.021418, Accuracy: 99.46%\n",
      "Batch 30, Loss: 0.000658, Accuracy: 99.48%\n",
      "Batch 31, Loss: 0.003857, Accuracy: 99.50%\n",
      "Batch 32, Loss: 0.012879, Accuracy: 99.46%\n",
      "Batch 33, Loss: 0.065400, Accuracy: 99.43%\n",
      "Batch 34, Loss: 0.003830, Accuracy: 99.45%\n",
      "Batch 35, Loss: 0.003910, Accuracy: 99.46%\n",
      "Batch 36, Loss: 0.002507, Accuracy: 99.48%\n",
      "Batch 37, Loss: 0.040718, Accuracy: 99.45%\n",
      "Batch 38, Loss: 0.001628, Accuracy: 99.47%\n",
      "Batch 39, Loss: 0.000503, Accuracy: 99.48%\n",
      "Batch 40, Loss: 0.004297, Accuracy: 99.49%\n",
      "Batch 41, Loss: 0.002135, Accuracy: 99.50%\n",
      "Batch 42, Loss: 0.061023, Accuracy: 99.48%\n",
      "Batch 43, Loss: 0.001758, Accuracy: 99.49%\n",
      "Batch 44, Loss: 0.000559, Accuracy: 99.50%\n",
      "Batch 45, Loss: 0.000445, Accuracy: 99.51%\n",
      "Batch 46, Loss: 0.001015, Accuracy: 99.52%\n",
      "Batch 47, Loss: 0.002673, Accuracy: 99.53%\n",
      "Batch 48, Loss: 0.000790, Accuracy: 99.54%\n",
      "Batch 49, Loss: 0.000627, Accuracy: 99.55%\n",
      "Batch 50, Loss: 0.000780, Accuracy: 99.56%\n",
      "Batch 51, Loss: 0.000951, Accuracy: 99.57%\n",
      "Batch 52, Loss: 0.001291, Accuracy: 99.58%\n",
      "Batch 53, Loss: 0.086890, Accuracy: 99.56%\n",
      "Batch 54, Loss: 0.001180, Accuracy: 99.57%\n",
      "Batch 55, Loss: 0.003612, Accuracy: 99.57%\n",
      "Batch 56, Loss: 0.054444, Accuracy: 99.55%\n",
      "Batch 57, Loss: 0.013038, Accuracy: 99.56%\n",
      "Batch 58, Loss: 0.004126, Accuracy: 99.57%\n",
      "Batch 59, Loss: 0.002786, Accuracy: 99.58%\n",
      "Batch 60, Loss: 0.002347, Accuracy: 99.58%\n",
      "Batch 61, Loss: 0.007903, Accuracy: 99.59%\n",
      "Batch 62, Loss: 0.002722, Accuracy: 99.60%\n",
      "Batch 63, Loss: 0.004593, Accuracy: 99.60%\n",
      "Batch 64, Loss: 0.010610, Accuracy: 99.61%\n",
      "Batch 65, Loss: 0.002588, Accuracy: 99.62%\n",
      "Batch 66, Loss: 0.001030, Accuracy: 99.62%\n",
      "Batch 67, Loss: 0.007339, Accuracy: 99.63%\n",
      "Batch 68, Loss: 0.059497, Accuracy: 99.59%\n",
      "Batch 69, Loss: 0.000431, Accuracy: 99.59%\n",
      "Batch 70, Loss: 0.000338, Accuracy: 99.60%\n",
      "Batch 71, Loss: 0.001034, Accuracy: 99.60%\n",
      "Batch 72, Loss: 0.001638, Accuracy: 99.61%\n",
      "Batch 73, Loss: 0.000799, Accuracy: 99.61%\n",
      "Batch 74, Loss: 0.000469, Accuracy: 99.62%\n",
      "Batch 75, Loss: 0.013120, Accuracy: 99.62%\n",
      "Batch 76, Loss: 0.061703, Accuracy: 99.61%\n",
      "Batch 77, Loss: 0.015786, Accuracy: 99.61%\n",
      "Batch 78, Loss: 0.001153, Accuracy: 99.62%\n",
      "Batch 79, Loss: 0.000914, Accuracy: 99.62%\n",
      "Batch 80, Loss: 0.013404, Accuracy: 99.63%\n",
      "Batch 81, Loss: 0.000557, Accuracy: 99.63%\n",
      "Batch 82, Loss: 0.002704, Accuracy: 99.64%\n",
      "Batch 83, Loss: 0.000320, Accuracy: 99.64%\n",
      "Batch 84, Loss: 0.000988, Accuracy: 99.65%\n",
      "Batch 85, Loss: 0.000725, Accuracy: 99.65%\n",
      "Batch 86, Loss: 0.000458, Accuracy: 99.65%\n",
      "Batch 87, Loss: 0.001901, Accuracy: 99.66%\n",
      "Batch 88, Loss: 0.007197, Accuracy: 99.66%\n",
      "Batch 89, Loss: 0.001403, Accuracy: 99.67%\n",
      "Batch 90, Loss: 0.001897, Accuracy: 99.67%\n",
      "Batch 91, Loss: 0.000714, Accuracy: 99.67%\n",
      "Batch 92, Loss: 0.068891, Accuracy: 99.66%\n",
      "Batch 93, Loss: 0.001298, Accuracy: 99.66%\n",
      "Batch 94, Loss: 0.009174, Accuracy: 99.67%\n",
      "Batch 95, Loss: 0.000776, Accuracy: 99.67%\n",
      "Batch 96, Loss: 0.000831, Accuracy: 99.67%\n",
      "Batch 97, Loss: 0.000274, Accuracy: 99.68%\n",
      "Batch 98, Loss: 0.001902, Accuracy: 99.68%\n",
      "Batch 99, Loss: 0.000646, Accuracy: 99.68%\n",
      "Batch 100, Loss: 0.004839, Accuracy: 99.69%\n",
      "Batch 101, Loss: 0.001265, Accuracy: 99.69%\n",
      "Batch 102, Loss: 0.010989, Accuracy: 99.69%\n",
      "Batch 103, Loss: 0.000446, Accuracy: 99.70%\n",
      "Batch 104, Loss: 0.000820, Accuracy: 99.70%\n",
      "Batch 105, Loss: 0.004439, Accuracy: 99.70%\n",
      "Batch 106, Loss: 0.003067, Accuracy: 99.71%\n",
      "Batch 107, Loss: 0.003212, Accuracy: 99.71%\n",
      "Batch 108, Loss: 0.000218, Accuracy: 99.71%\n",
      "Batch 109, Loss: 0.004107, Accuracy: 99.71%\n",
      "Batch 110, Loss: 0.000840, Accuracy: 99.72%\n",
      "Batch 111, Loss: 0.020777, Accuracy: 99.70%\n",
      "Batch 112, Loss: 0.000659, Accuracy: 99.71%\n",
      "Batch 113, Loss: 0.000481, Accuracy: 99.71%\n",
      "Batch 114, Loss: 0.000904, Accuracy: 99.71%\n",
      "Batch 115, Loss: 0.000529, Accuracy: 99.71%\n",
      "Batch 116, Loss: 0.007537, Accuracy: 99.72%\n",
      "Batch 117, Loss: 0.009578, Accuracy: 99.72%\n",
      "Batch 118, Loss: 0.000297, Accuracy: 99.72%\n",
      "Batch 119, Loss: 0.002741, Accuracy: 99.72%\n",
      "Batch 120, Loss: 0.000376, Accuracy: 99.73%\n",
      "Batch 121, Loss: 0.000380, Accuracy: 99.73%\n",
      "Batch 122, Loss: 0.020128, Accuracy: 99.72%\n",
      "Batch 123, Loss: 0.000150, Accuracy: 99.72%\n",
      "Batch 124, Loss: 0.000561, Accuracy: 99.72%\n",
      "Batch 125, Loss: 0.001130, Accuracy: 99.72%\n",
      "Batch 126, Loss: 0.000202, Accuracy: 99.73%\n",
      "Batch 127, Loss: 0.004110, Accuracy: 99.73%\n",
      "Batch 128, Loss: 0.039403, Accuracy: 99.72%\n",
      "Batch 129, Loss: 0.002504, Accuracy: 99.72%\n",
      "Batch 130, Loss: 0.000199, Accuracy: 99.72%\n",
      "Batch 131, Loss: 0.000273, Accuracy: 99.73%\n",
      "Batch 132, Loss: 0.077655, Accuracy: 99.72%\n",
      "Batch 133, Loss: 0.000173, Accuracy: 99.72%\n",
      "Batch 134, Loss: 0.001652, Accuracy: 99.72%\n",
      "Batch 135, Loss: 0.000141, Accuracy: 99.72%\n",
      "Batch 136, Loss: 0.000447, Accuracy: 99.72%\n",
      "Batch 137, Loss: 0.001120, Accuracy: 99.73%\n",
      "Batch 138, Loss: 0.000681, Accuracy: 99.73%\n",
      "Batch 139, Loss: 0.001750, Accuracy: 99.73%\n",
      "Batch 140, Loss: 0.010697, Accuracy: 99.73%\n",
      "Batch 141, Loss: 0.181385, Accuracy: 99.71%\n",
      "Batch 142, Loss: 0.000228, Accuracy: 99.71%\n",
      "Batch 143, Loss: 0.000530, Accuracy: 99.72%\n",
      "Batch 144, Loss: 0.109114, Accuracy: 99.71%\n",
      "Batch 145, Loss: 0.000502, Accuracy: 99.71%\n",
      "Batch 146, Loss: 0.001578, Accuracy: 99.71%\n",
      "Batch 147, Loss: 0.001480, Accuracy: 99.71%\n",
      "Batch 148, Loss: 0.001295, Accuracy: 99.71%\n",
      "Batch 149, Loss: 0.005882, Accuracy: 99.72%\n",
      "Batch 150, Loss: 0.012193, Accuracy: 99.72%\n",
      "Batch 151, Loss: 0.005025, Accuracy: 99.72%\n",
      "Batch 152, Loss: 0.097087, Accuracy: 99.70%\n",
      "Batch 153, Loss: 0.006168, Accuracy: 99.70%\n",
      "Batch 154, Loss: 0.001874, Accuracy: 99.71%\n",
      "Batch 155, Loss: 0.001440, Accuracy: 99.71%\n",
      "Batch 156, Loss: 0.011062, Accuracy: 99.71%\n",
      "Batch 157, Loss: 0.009232, Accuracy: 99.71%\n",
      "Batch 158, Loss: 0.009986, Accuracy: 99.71%\n",
      "Batch 159, Loss: 0.002632, Accuracy: 99.72%\n",
      "Batch 160, Loss: 0.097041, Accuracy: 99.71%\n",
      "Batch 161, Loss: 0.005742, Accuracy: 99.71%\n",
      "Batch 162, Loss: 0.011323, Accuracy: 99.71%\n",
      "Batch 163, Loss: 0.063556, Accuracy: 99.69%\n",
      "Batch 164, Loss: 0.090163, Accuracy: 99.68%\n",
      "Batch 165, Loss: 0.010763, Accuracy: 99.68%\n",
      "Batch 166, Loss: 0.004829, Accuracy: 99.68%\n",
      "Batch 167, Loss: 0.002334, Accuracy: 99.68%\n",
      "Batch 168, Loss: 0.001976, Accuracy: 99.68%\n",
      "Batch 169, Loss: 0.004750, Accuracy: 99.69%\n",
      "Batch 170, Loss: 0.029961, Accuracy: 99.68%\n",
      "Batch 171, Loss: 0.003323, Accuracy: 99.68%\n",
      "Batch 172, Loss: 0.004428, Accuracy: 99.68%\n",
      "Batch 173, Loss: 0.003931, Accuracy: 99.68%\n",
      "Batch 174, Loss: 0.004211, Accuracy: 99.69%\n",
      "Batch 175, Loss: 0.004036, Accuracy: 99.69%\n",
      "Batch 176, Loss: 0.002586, Accuracy: 99.69%\n",
      "Batch 177, Loss: 0.006436, Accuracy: 99.69%\n",
      "Batch 178, Loss: 0.001888, Accuracy: 99.69%\n",
      "Batch 179, Loss: 0.001407, Accuracy: 99.69%\n",
      "Batch 180, Loss: 0.002958, Accuracy: 99.70%\n",
      "Batch 181, Loss: 0.010769, Accuracy: 99.70%\n",
      "Batch 182, Loss: 0.015402, Accuracy: 99.69%\n",
      "Batch 183, Loss: 0.069769, Accuracy: 99.68%\n",
      "Batch 184, Loss: 0.000825, Accuracy: 99.68%\n",
      "Batch 185, Loss: 0.000685, Accuracy: 99.68%\n",
      "Batch 186, Loss: 0.000534, Accuracy: 99.68%\n",
      "Batch 187, Loss: 0.004293, Accuracy: 99.68%\n",
      "Batch 188, Loss: 0.000229, Accuracy: 99.68%\n",
      "Batch 189, Loss: 0.022495, Accuracy: 99.68%\n",
      "Batch 190, Loss: 0.000447, Accuracy: 99.68%\n",
      "Batch 191, Loss: 0.037060, Accuracy: 99.67%\n",
      "Batch 192, Loss: 0.039880, Accuracy: 99.67%\n",
      "Batch 193, Loss: 0.001889, Accuracy: 99.67%\n",
      "Batch 194, Loss: 0.004698, Accuracy: 99.67%\n",
      "Batch 195, Loss: 0.062099, Accuracy: 99.66%\n",
      "Batch 196, Loss: 0.001670, Accuracy: 99.67%\n",
      "Batch 197, Loss: 0.000668, Accuracy: 99.67%\n",
      "Batch 198, Loss: 0.000909, Accuracy: 99.67%\n",
      "Batch 199, Loss: 0.014868, Accuracy: 99.66%\n",
      "Batch 200, Loss: 0.016962, Accuracy: 99.66%\n",
      "Batch 201, Loss: 0.003527, Accuracy: 99.66%\n",
      "Batch 202, Loss: 0.005204, Accuracy: 99.66%\n",
      "Batch 203, Loss: 0.006508, Accuracy: 99.66%\n",
      "Batch 204, Loss: 0.013665, Accuracy: 99.66%\n",
      "Batch 205, Loss: 0.037620, Accuracy: 99.66%\n",
      "Batch 206, Loss: 0.044327, Accuracy: 99.65%\n",
      "Batch 207, Loss: 0.007757, Accuracy: 99.65%\n",
      "Batch 208, Loss: 0.001920, Accuracy: 99.65%\n",
      "Batch 209, Loss: 0.013661, Accuracy: 99.65%\n",
      "Batch 210, Loss: 0.028654, Accuracy: 99.64%\n",
      "Batch 211, Loss: 0.000359, Accuracy: 99.64%\n",
      "Batch 212, Loss: 0.005498, Accuracy: 99.65%\n",
      "Batch 213, Loss: 0.005149, Accuracy: 99.65%\n",
      "Training - Epoch 29, Loss: 0.012983, Accuracy: 99.65%\n",
      "Validation Batch 1, Loss: 0.002904, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001358, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.082633, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.022906, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.001428, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.000609, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.087936, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.025059, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.025348, Accuracy: 99.31%\n",
      "Validation Batch 10, Loss: 0.111868, Accuracy: 99.06%\n",
      "Validation Batch 11, Loss: 0.029142, Accuracy: 99.01%\n",
      "Validation Batch 12, Loss: 0.067421, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.072080, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.018377, Accuracy: 98.88%\n",
      "Validation Batch 15, Loss: 0.043857, Accuracy: 98.85%\n",
      "Validation Batch 16, Loss: 0.010271, Accuracy: 98.93%\n",
      "Validation Batch 17, Loss: 0.029260, Accuracy: 98.90%\n",
      "Validation Batch 18, Loss: 0.000627, Accuracy: 98.96%\n",
      "Validation Batch 19, Loss: 0.023629, Accuracy: 98.93%\n",
      "Validation Batch 20, Loss: 0.003331, Accuracy: 98.98%\n",
      "Validation Batch 21, Loss: 0.031202, Accuracy: 98.96%\n",
      "Validation Batch 22, Loss: 0.004553, Accuracy: 99.01%\n",
      "Validation Batch 23, Loss: 0.001419, Accuracy: 99.05%\n",
      "Validation Batch 24, Loss: 0.088283, Accuracy: 99.02%\n",
      "Validation Batch 25, Loss: 0.027662, Accuracy: 99.00%\n",
      "Validation Batch 26, Loss: 0.001861, Accuracy: 99.04%\n",
      "Validation Batch 27, Loss: 0.015701, Accuracy: 99.06%\n",
      "Validation - Epoch 29, Loss: 0.030768, Accuracy: 99.06%\n",
      "Patience—7\n",
      "Epoch 30\n",
      "Batch 1, Loss: 0.000506, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.049407, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.006939, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.044306, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.016063, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.000934, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.023578, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.000846, Accuracy: 99.02%\n",
      "Batch 9, Loss: 0.002699, Accuracy: 99.13%\n",
      "Batch 10, Loss: 0.001515, Accuracy: 99.22%\n",
      "Batch 11, Loss: 0.000343, Accuracy: 99.29%\n",
      "Batch 12, Loss: 0.089251, Accuracy: 99.09%\n",
      "Batch 13, Loss: 0.033176, Accuracy: 99.04%\n",
      "Batch 14, Loss: 0.003381, Accuracy: 99.11%\n",
      "Batch 15, Loss: 0.004401, Accuracy: 99.17%\n",
      "Batch 16, Loss: 0.286080, Accuracy: 99.02%\n",
      "Batch 17, Loss: 0.112640, Accuracy: 98.99%\n",
      "Batch 18, Loss: 0.000956, Accuracy: 99.05%\n",
      "Batch 19, Loss: 0.039736, Accuracy: 98.93%\n",
      "Batch 20, Loss: 0.004533, Accuracy: 98.98%\n",
      "Batch 21, Loss: 0.045064, Accuracy: 98.96%\n",
      "Batch 22, Loss: 0.007427, Accuracy: 99.01%\n",
      "Batch 23, Loss: 0.155077, Accuracy: 98.91%\n",
      "Batch 24, Loss: 0.105230, Accuracy: 98.76%\n",
      "Batch 25, Loss: 0.006823, Accuracy: 98.81%\n",
      "Batch 26, Loss: 0.006155, Accuracy: 98.86%\n",
      "Batch 27, Loss: 0.003035, Accuracy: 98.90%\n",
      "Batch 28, Loss: 0.004941, Accuracy: 98.94%\n",
      "Batch 29, Loss: 0.025184, Accuracy: 98.92%\n",
      "Batch 30, Loss: 0.083078, Accuracy: 98.80%\n",
      "Batch 31, Loss: 0.034536, Accuracy: 98.79%\n",
      "Batch 32, Loss: 0.008429, Accuracy: 98.83%\n",
      "Batch 33, Loss: 0.019442, Accuracy: 98.82%\n",
      "Batch 34, Loss: 0.005384, Accuracy: 98.85%\n",
      "Batch 35, Loss: 0.011967, Accuracy: 98.88%\n",
      "Batch 36, Loss: 0.020159, Accuracy: 98.91%\n",
      "Batch 37, Loss: 0.005605, Accuracy: 98.94%\n",
      "Batch 38, Loss: 0.002914, Accuracy: 98.97%\n",
      "Batch 39, Loss: 0.054316, Accuracy: 98.96%\n",
      "Batch 40, Loss: 0.007968, Accuracy: 98.98%\n",
      "Batch 41, Loss: 0.022774, Accuracy: 99.01%\n",
      "Batch 42, Loss: 0.006087, Accuracy: 99.03%\n",
      "Batch 43, Loss: 0.022020, Accuracy: 99.02%\n",
      "Batch 44, Loss: 0.011271, Accuracy: 99.04%\n",
      "Batch 45, Loss: 0.002214, Accuracy: 99.06%\n",
      "Batch 46, Loss: 0.011400, Accuracy: 99.08%\n",
      "Batch 47, Loss: 0.017850, Accuracy: 99.07%\n",
      "Batch 48, Loss: 0.005406, Accuracy: 99.09%\n",
      "Batch 49, Loss: 0.001346, Accuracy: 99.11%\n",
      "Batch 50, Loss: 0.001777, Accuracy: 99.12%\n",
      "Batch 51, Loss: 0.004846, Accuracy: 99.14%\n",
      "Batch 52, Loss: 0.001034, Accuracy: 99.16%\n",
      "Batch 53, Loss: 0.010246, Accuracy: 99.17%\n",
      "Batch 54, Loss: 0.000593, Accuracy: 99.19%\n",
      "Batch 55, Loss: 0.002310, Accuracy: 99.20%\n",
      "Batch 56, Loss: 0.001173, Accuracy: 99.22%\n",
      "Batch 57, Loss: 0.000544, Accuracy: 99.23%\n",
      "Batch 58, Loss: 0.000599, Accuracy: 99.25%\n",
      "Batch 59, Loss: 0.000612, Accuracy: 99.26%\n",
      "Batch 60, Loss: 0.000473, Accuracy: 99.27%\n",
      "Batch 61, Loss: 0.000520, Accuracy: 99.28%\n",
      "Batch 62, Loss: 0.001774, Accuracy: 99.29%\n",
      "Batch 63, Loss: 0.000188, Accuracy: 99.31%\n",
      "Batch 64, Loss: 0.002786, Accuracy: 99.32%\n",
      "Batch 65, Loss: 0.028111, Accuracy: 99.30%\n",
      "Batch 66, Loss: 0.000320, Accuracy: 99.31%\n",
      "Batch 67, Loss: 0.000337, Accuracy: 99.32%\n",
      "Batch 68, Loss: 0.000384, Accuracy: 99.33%\n",
      "Batch 69, Loss: 0.000284, Accuracy: 99.34%\n",
      "Batch 70, Loss: 0.012926, Accuracy: 99.33%\n",
      "Batch 71, Loss: 0.009773, Accuracy: 99.34%\n",
      "Batch 72, Loss: 0.005753, Accuracy: 99.35%\n",
      "Batch 73, Loss: 0.104708, Accuracy: 99.34%\n",
      "Batch 74, Loss: 0.003923, Accuracy: 99.35%\n",
      "Batch 75, Loss: 0.057029, Accuracy: 99.33%\n",
      "Batch 76, Loss: 0.001317, Accuracy: 99.34%\n",
      "Batch 77, Loss: 0.073665, Accuracy: 99.33%\n",
      "Batch 78, Loss: 0.006225, Accuracy: 99.34%\n",
      "Batch 79, Loss: 0.001098, Accuracy: 99.35%\n",
      "Batch 80, Loss: 0.098742, Accuracy: 99.34%\n",
      "Batch 81, Loss: 0.000661, Accuracy: 99.34%\n",
      "Batch 82, Loss: 0.000894, Accuracy: 99.35%\n",
      "Batch 83, Loss: 0.005201, Accuracy: 99.36%\n",
      "Batch 84, Loss: 0.004202, Accuracy: 99.37%\n",
      "Batch 85, Loss: 0.007462, Accuracy: 99.38%\n",
      "Batch 86, Loss: 0.026690, Accuracy: 99.36%\n",
      "Batch 87, Loss: 0.039096, Accuracy: 99.35%\n",
      "Batch 88, Loss: 0.008610, Accuracy: 99.36%\n",
      "Batch 89, Loss: 0.081887, Accuracy: 99.35%\n",
      "Batch 90, Loss: 0.002890, Accuracy: 99.36%\n",
      "Batch 91, Loss: 0.050719, Accuracy: 99.35%\n",
      "Batch 92, Loss: 0.013919, Accuracy: 99.35%\n",
      "Batch 93, Loss: 0.025519, Accuracy: 99.34%\n",
      "Batch 94, Loss: 0.005022, Accuracy: 99.35%\n",
      "Batch 95, Loss: 0.012795, Accuracy: 99.36%\n",
      "Batch 96, Loss: 0.026537, Accuracy: 99.35%\n",
      "Batch 97, Loss: 0.001881, Accuracy: 99.36%\n",
      "Batch 98, Loss: 0.001206, Accuracy: 99.36%\n",
      "Batch 99, Loss: 0.001208, Accuracy: 99.37%\n",
      "Batch 100, Loss: 0.052587, Accuracy: 99.36%\n",
      "Batch 101, Loss: 0.007818, Accuracy: 99.37%\n",
      "Batch 102, Loss: 0.000742, Accuracy: 99.37%\n",
      "Batch 103, Loss: 0.005668, Accuracy: 99.38%\n",
      "Batch 104, Loss: 0.000787, Accuracy: 99.38%\n",
      "Batch 105, Loss: 0.007578, Accuracy: 99.39%\n",
      "Batch 106, Loss: 0.000979, Accuracy: 99.40%\n",
      "Batch 107, Loss: 0.004673, Accuracy: 99.40%\n",
      "Batch 108, Loss: 0.001844, Accuracy: 99.41%\n",
      "Batch 109, Loss: 0.001238, Accuracy: 99.41%\n",
      "Batch 110, Loss: 0.002836, Accuracy: 99.42%\n",
      "Batch 111, Loss: 0.002301, Accuracy: 99.42%\n",
      "Batch 112, Loss: 0.057694, Accuracy: 99.41%\n",
      "Batch 113, Loss: 0.001618, Accuracy: 99.42%\n",
      "Batch 114, Loss: 0.000784, Accuracy: 99.42%\n",
      "Batch 115, Loss: 0.002345, Accuracy: 99.43%\n",
      "Batch 116, Loss: 0.001374, Accuracy: 99.43%\n",
      "Batch 117, Loss: 0.012258, Accuracy: 99.44%\n",
      "Batch 118, Loss: 0.005043, Accuracy: 99.44%\n",
      "Batch 119, Loss: 0.040278, Accuracy: 99.44%\n",
      "Batch 120, Loss: 0.088948, Accuracy: 99.43%\n",
      "Batch 121, Loss: 0.003715, Accuracy: 99.43%\n",
      "Batch 122, Loss: 0.084303, Accuracy: 99.42%\n",
      "Batch 123, Loss: 0.004299, Accuracy: 99.43%\n",
      "Batch 124, Loss: 0.039247, Accuracy: 99.42%\n",
      "Batch 125, Loss: 0.004225, Accuracy: 99.42%\n",
      "Batch 126, Loss: 0.006212, Accuracy: 99.43%\n",
      "Batch 127, Loss: 0.014078, Accuracy: 99.43%\n",
      "Batch 128, Loss: 0.017068, Accuracy: 99.44%\n",
      "Batch 129, Loss: 0.002841, Accuracy: 99.44%\n",
      "Batch 130, Loss: 0.004204, Accuracy: 99.45%\n",
      "Batch 131, Loss: 0.002387, Accuracy: 99.45%\n",
      "Batch 132, Loss: 0.004488, Accuracy: 99.46%\n",
      "Batch 133, Loss: 0.001320, Accuracy: 99.46%\n",
      "Batch 134, Loss: 0.023064, Accuracy: 99.45%\n",
      "Batch 135, Loss: 0.001404, Accuracy: 99.46%\n",
      "Batch 136, Loss: 0.001163, Accuracy: 99.46%\n",
      "Batch 137, Loss: 0.000865, Accuracy: 99.46%\n",
      "Batch 138, Loss: 0.078851, Accuracy: 99.46%\n",
      "Batch 139, Loss: 0.053639, Accuracy: 99.45%\n",
      "Batch 140, Loss: 0.000656, Accuracy: 99.45%\n",
      "Batch 141, Loss: 0.017884, Accuracy: 99.46%\n",
      "Batch 142, Loss: 0.001653, Accuracy: 99.46%\n",
      "Batch 143, Loss: 0.001139, Accuracy: 99.46%\n",
      "Batch 144, Loss: 0.012603, Accuracy: 99.46%\n",
      "Batch 145, Loss: 0.013780, Accuracy: 99.45%\n",
      "Batch 146, Loss: 0.001485, Accuracy: 99.45%\n",
      "Batch 147, Loss: 0.000977, Accuracy: 99.46%\n",
      "Batch 148, Loss: 0.021248, Accuracy: 99.45%\n",
      "Batch 149, Loss: 0.002710, Accuracy: 99.45%\n",
      "Batch 150, Loss: 0.016039, Accuracy: 99.46%\n",
      "Batch 151, Loss: 0.001718, Accuracy: 99.46%\n",
      "Batch 152, Loss: 0.188133, Accuracy: 99.44%\n",
      "Batch 153, Loss: 0.003919, Accuracy: 99.45%\n",
      "Batch 154, Loss: 0.080902, Accuracy: 99.42%\n",
      "Batch 155, Loss: 0.000975, Accuracy: 99.43%\n",
      "Batch 156, Loss: 0.013702, Accuracy: 99.43%\n",
      "Batch 157, Loss: 0.001975, Accuracy: 99.43%\n",
      "Batch 158, Loss: 0.002630, Accuracy: 99.44%\n",
      "Batch 159, Loss: 0.107252, Accuracy: 99.41%\n",
      "Batch 160, Loss: 0.004699, Accuracy: 99.41%\n",
      "Batch 161, Loss: 0.028926, Accuracy: 99.41%\n",
      "Batch 162, Loss: 0.005447, Accuracy: 99.41%\n",
      "Batch 163, Loss: 0.091702, Accuracy: 99.41%\n",
      "Batch 164, Loss: 0.002634, Accuracy: 99.41%\n",
      "Batch 165, Loss: 0.116790, Accuracy: 99.40%\n",
      "Batch 166, Loss: 0.011643, Accuracy: 99.41%\n",
      "Batch 167, Loss: 0.014181, Accuracy: 99.41%\n",
      "Batch 168, Loss: 0.007930, Accuracy: 99.41%\n",
      "Batch 169, Loss: 0.087302, Accuracy: 99.41%\n",
      "Batch 170, Loss: 0.029245, Accuracy: 99.40%\n",
      "Batch 171, Loss: 0.073657, Accuracy: 99.39%\n",
      "Batch 172, Loss: 0.024091, Accuracy: 99.38%\n",
      "Batch 173, Loss: 0.018758, Accuracy: 99.38%\n",
      "Batch 174, Loss: 0.011818, Accuracy: 99.38%\n",
      "Batch 175, Loss: 0.004017, Accuracy: 99.38%\n",
      "Batch 176, Loss: 0.012829, Accuracy: 99.39%\n",
      "Batch 177, Loss: 0.016318, Accuracy: 99.39%\n",
      "Batch 178, Loss: 0.018717, Accuracy: 99.39%\n",
      "Batch 179, Loss: 0.014199, Accuracy: 99.39%\n",
      "Batch 180, Loss: 0.010509, Accuracy: 99.39%\n",
      "Batch 181, Loss: 0.003049, Accuracy: 99.40%\n",
      "Batch 182, Loss: 0.001116, Accuracy: 99.40%\n",
      "Batch 183, Loss: 0.008586, Accuracy: 99.40%\n",
      "Batch 184, Loss: 0.001253, Accuracy: 99.41%\n",
      "Batch 185, Loss: 0.002172, Accuracy: 99.41%\n",
      "Batch 186, Loss: 0.002994, Accuracy: 99.41%\n",
      "Batch 187, Loss: 0.003035, Accuracy: 99.42%\n",
      "Batch 188, Loss: 0.001343, Accuracy: 99.42%\n",
      "Batch 189, Loss: 0.004582, Accuracy: 99.42%\n",
      "Batch 190, Loss: 0.020519, Accuracy: 99.42%\n",
      "Batch 191, Loss: 0.005459, Accuracy: 99.42%\n",
      "Batch 192, Loss: 0.005009, Accuracy: 99.42%\n",
      "Batch 193, Loss: 0.001450, Accuracy: 99.43%\n",
      "Batch 194, Loss: 0.001586, Accuracy: 99.43%\n",
      "Batch 195, Loss: 0.002672, Accuracy: 99.43%\n",
      "Batch 196, Loss: 0.009134, Accuracy: 99.43%\n",
      "Batch 197, Loss: 0.018400, Accuracy: 99.43%\n",
      "Batch 198, Loss: 0.004336, Accuracy: 99.43%\n",
      "Batch 199, Loss: 0.016487, Accuracy: 99.43%\n",
      "Batch 200, Loss: 0.000251, Accuracy: 99.43%\n",
      "Batch 201, Loss: 0.000669, Accuracy: 99.43%\n",
      "Batch 202, Loss: 0.088958, Accuracy: 99.43%\n",
      "Batch 203, Loss: 0.024117, Accuracy: 99.42%\n",
      "Batch 204, Loss: 0.001234, Accuracy: 99.43%\n",
      "Batch 205, Loss: 0.000508, Accuracy: 99.43%\n",
      "Batch 206, Loss: 0.060051, Accuracy: 99.42%\n",
      "Batch 207, Loss: 0.000248, Accuracy: 99.43%\n",
      "Batch 208, Loss: 0.006005, Accuracy: 99.43%\n",
      "Batch 209, Loss: 0.002839, Accuracy: 99.43%\n",
      "Batch 210, Loss: 0.001565, Accuracy: 99.43%\n",
      "Batch 211, Loss: 0.041824, Accuracy: 99.41%\n",
      "Batch 212, Loss: 0.000567, Accuracy: 99.42%\n",
      "Batch 213, Loss: 0.007193, Accuracy: 99.42%\n",
      "Training - Epoch 30, Loss: 0.020083, Accuracy: 99.42%\n",
      "Validation Batch 1, Loss: 0.005192, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.016229, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.002210, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.004315, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.129066, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.040872, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.042226, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.007744, Accuracy: 98.83%\n",
      "Validation Batch 9, Loss: 0.102012, Accuracy: 98.61%\n",
      "Validation Batch 10, Loss: 0.204477, Accuracy: 98.44%\n",
      "Validation Batch 11, Loss: 0.006392, Accuracy: 98.58%\n",
      "Validation Batch 12, Loss: 0.303351, Accuracy: 98.18%\n",
      "Validation Batch 13, Loss: 0.140655, Accuracy: 98.20%\n",
      "Validation Batch 14, Loss: 0.004754, Accuracy: 98.33%\n",
      "Validation Batch 15, Loss: 0.003493, Accuracy: 98.44%\n",
      "Validation Batch 16, Loss: 0.022568, Accuracy: 98.44%\n",
      "Validation Batch 17, Loss: 0.026904, Accuracy: 98.44%\n",
      "Validation Batch 18, Loss: 0.075591, Accuracy: 98.35%\n",
      "Validation Batch 19, Loss: 0.093683, Accuracy: 98.27%\n",
      "Validation Batch 20, Loss: 0.106415, Accuracy: 98.20%\n",
      "Validation Batch 21, Loss: 0.105470, Accuracy: 98.07%\n",
      "Validation Batch 22, Loss: 0.009728, Accuracy: 98.15%\n",
      "Validation Batch 23, Loss: 0.077988, Accuracy: 98.17%\n",
      "Validation Batch 24, Loss: 0.065468, Accuracy: 98.18%\n",
      "Validation Batch 25, Loss: 0.004135, Accuracy: 98.25%\n",
      "Validation Batch 26, Loss: 0.034361, Accuracy: 98.26%\n",
      "Validation Batch 27, Loss: 0.172556, Accuracy: 98.24%\n",
      "Validation - Epoch 30, Loss: 0.066958, Accuracy: 98.24%\n",
      "Patience—8\n",
      "Epoch 31\n",
      "Batch 1, Loss: 0.031035, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.146954, Accuracy: 97.66%\n",
      "Batch 3, Loss: 0.001656, Accuracy: 98.44%\n",
      "Batch 4, Loss: 0.000526, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.000726, Accuracy: 99.06%\n",
      "Batch 6, Loss: 0.001180, Accuracy: 99.22%\n",
      "Batch 7, Loss: 0.034310, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.001218, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.000599, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.015716, Accuracy: 99.22%\n",
      "Batch 11, Loss: 0.006259, Accuracy: 99.29%\n",
      "Batch 12, Loss: 0.012760, Accuracy: 99.35%\n",
      "Batch 13, Loss: 0.046572, Accuracy: 99.28%\n",
      "Batch 14, Loss: 0.013522, Accuracy: 99.22%\n",
      "Batch 15, Loss: 0.001151, Accuracy: 99.27%\n",
      "Batch 16, Loss: 0.002168, Accuracy: 99.32%\n",
      "Batch 17, Loss: 0.012405, Accuracy: 99.36%\n",
      "Batch 18, Loss: 0.051136, Accuracy: 99.31%\n",
      "Batch 19, Loss: 0.053245, Accuracy: 99.18%\n",
      "Batch 20, Loss: 0.028100, Accuracy: 99.14%\n",
      "Batch 21, Loss: 0.000880, Accuracy: 99.18%\n",
      "Batch 22, Loss: 0.002884, Accuracy: 99.22%\n",
      "Batch 23, Loss: 0.001108, Accuracy: 99.25%\n",
      "Batch 24, Loss: 0.001281, Accuracy: 99.28%\n",
      "Batch 25, Loss: 0.000856, Accuracy: 99.31%\n",
      "Batch 26, Loss: 0.004089, Accuracy: 99.34%\n",
      "Batch 27, Loss: 0.000519, Accuracy: 99.36%\n",
      "Batch 28, Loss: 0.083970, Accuracy: 99.33%\n",
      "Batch 29, Loss: 0.000800, Accuracy: 99.35%\n",
      "Batch 30, Loss: 0.000432, Accuracy: 99.38%\n",
      "Batch 31, Loss: 0.001173, Accuracy: 99.40%\n",
      "Batch 32, Loss: 0.028234, Accuracy: 99.37%\n",
      "Batch 33, Loss: 0.070484, Accuracy: 99.34%\n",
      "Batch 34, Loss: 0.043017, Accuracy: 99.31%\n",
      "Batch 35, Loss: 0.008249, Accuracy: 99.33%\n",
      "Batch 36, Loss: 0.009998, Accuracy: 99.35%\n",
      "Batch 37, Loss: 0.055949, Accuracy: 99.28%\n",
      "Batch 38, Loss: 0.043951, Accuracy: 99.26%\n",
      "Batch 39, Loss: 0.014340, Accuracy: 99.28%\n",
      "Batch 40, Loss: 0.089695, Accuracy: 99.26%\n",
      "Batch 41, Loss: 0.004405, Accuracy: 99.28%\n",
      "Batch 42, Loss: 0.003036, Accuracy: 99.29%\n",
      "Batch 43, Loss: 0.001152, Accuracy: 99.31%\n",
      "Batch 44, Loss: 0.062316, Accuracy: 99.25%\n",
      "Batch 45, Loss: 0.005697, Accuracy: 99.27%\n",
      "Batch 46, Loss: 0.171993, Accuracy: 99.18%\n",
      "Batch 47, Loss: 0.004299, Accuracy: 99.20%\n",
      "Batch 48, Loss: 0.001256, Accuracy: 99.22%\n",
      "Batch 49, Loss: 0.020970, Accuracy: 99.20%\n",
      "Batch 50, Loss: 0.002972, Accuracy: 99.22%\n",
      "Batch 51, Loss: 0.036536, Accuracy: 99.20%\n",
      "Batch 52, Loss: 0.002306, Accuracy: 99.22%\n",
      "Batch 53, Loss: 0.001531, Accuracy: 99.23%\n",
      "Batch 54, Loss: 0.001720, Accuracy: 99.25%\n",
      "Batch 55, Loss: 0.014630, Accuracy: 99.23%\n",
      "Batch 56, Loss: 0.004145, Accuracy: 99.25%\n",
      "Batch 57, Loss: 0.004201, Accuracy: 99.26%\n",
      "Batch 58, Loss: 0.003472, Accuracy: 99.27%\n",
      "Batch 59, Loss: 0.003396, Accuracy: 99.28%\n",
      "Batch 60, Loss: 0.025572, Accuracy: 99.27%\n",
      "Batch 61, Loss: 0.020372, Accuracy: 99.26%\n",
      "Batch 62, Loss: 0.003740, Accuracy: 99.27%\n",
      "Batch 63, Loss: 0.086823, Accuracy: 99.23%\n",
      "Batch 64, Loss: 0.106581, Accuracy: 99.19%\n",
      "Batch 65, Loss: 0.016910, Accuracy: 99.21%\n",
      "Batch 66, Loss: 0.004920, Accuracy: 99.22%\n",
      "Batch 67, Loss: 0.033108, Accuracy: 99.21%\n",
      "Batch 68, Loss: 0.007108, Accuracy: 99.22%\n",
      "Batch 69, Loss: 0.003587, Accuracy: 99.23%\n",
      "Batch 70, Loss: 0.046159, Accuracy: 99.22%\n",
      "Batch 71, Loss: 0.061482, Accuracy: 99.21%\n",
      "Batch 72, Loss: 0.034433, Accuracy: 99.20%\n",
      "Batch 73, Loss: 0.098172, Accuracy: 99.17%\n",
      "Batch 74, Loss: 0.039998, Accuracy: 99.13%\n",
      "Batch 75, Loss: 0.005145, Accuracy: 99.15%\n",
      "Batch 76, Loss: 0.008629, Accuracy: 99.16%\n",
      "Batch 77, Loss: 0.004002, Accuracy: 99.17%\n",
      "Batch 78, Loss: 0.024775, Accuracy: 99.16%\n",
      "Batch 79, Loss: 0.004808, Accuracy: 99.17%\n",
      "Batch 80, Loss: 0.020697, Accuracy: 99.18%\n",
      "Batch 81, Loss: 0.011514, Accuracy: 99.19%\n",
      "Batch 82, Loss: 0.074711, Accuracy: 99.16%\n",
      "Batch 83, Loss: 0.003693, Accuracy: 99.17%\n",
      "Batch 84, Loss: 0.001679, Accuracy: 99.18%\n",
      "Batch 85, Loss: 0.000907, Accuracy: 99.19%\n",
      "Batch 86, Loss: 0.000837, Accuracy: 99.20%\n",
      "Batch 87, Loss: 0.009379, Accuracy: 99.21%\n",
      "Batch 88, Loss: 0.000266, Accuracy: 99.22%\n",
      "Batch 89, Loss: 0.004027, Accuracy: 99.23%\n",
      "Batch 90, Loss: 0.046752, Accuracy: 99.22%\n",
      "Batch 91, Loss: 0.001744, Accuracy: 99.23%\n",
      "Batch 92, Loss: 0.008455, Accuracy: 99.24%\n",
      "Batch 93, Loss: 0.000620, Accuracy: 99.24%\n",
      "Batch 94, Loss: 0.011938, Accuracy: 99.24%\n",
      "Batch 95, Loss: 0.009605, Accuracy: 99.24%\n",
      "Batch 96, Loss: 0.001656, Accuracy: 99.25%\n",
      "Batch 97, Loss: 0.000262, Accuracy: 99.26%\n",
      "Batch 98, Loss: 0.005071, Accuracy: 99.27%\n",
      "Batch 99, Loss: 0.001118, Accuracy: 99.27%\n",
      "Batch 100, Loss: 0.121345, Accuracy: 99.27%\n",
      "Batch 101, Loss: 0.171286, Accuracy: 99.24%\n",
      "Batch 102, Loss: 0.051507, Accuracy: 99.23%\n",
      "Batch 103, Loss: 0.063347, Accuracy: 99.23%\n",
      "Batch 104, Loss: 0.000855, Accuracy: 99.23%\n",
      "Batch 105, Loss: 0.002044, Accuracy: 99.24%\n",
      "Batch 106, Loss: 0.003138, Accuracy: 99.25%\n",
      "Batch 107, Loss: 0.016600, Accuracy: 99.24%\n",
      "Batch 108, Loss: 0.001561, Accuracy: 99.25%\n",
      "Batch 109, Loss: 0.077770, Accuracy: 99.24%\n",
      "Batch 110, Loss: 0.000930, Accuracy: 99.25%\n",
      "Batch 111, Loss: 0.018007, Accuracy: 99.24%\n",
      "Batch 112, Loss: 0.001975, Accuracy: 99.25%\n",
      "Batch 113, Loss: 0.001639, Accuracy: 99.25%\n",
      "Batch 114, Loss: 0.016747, Accuracy: 99.25%\n",
      "Batch 115, Loss: 0.044826, Accuracy: 99.24%\n",
      "Batch 116, Loss: 0.006458, Accuracy: 99.25%\n",
      "Batch 117, Loss: 0.008695, Accuracy: 99.25%\n",
      "Batch 118, Loss: 0.004015, Accuracy: 99.26%\n",
      "Batch 119, Loss: 0.004916, Accuracy: 99.26%\n",
      "Batch 120, Loss: 0.009683, Accuracy: 99.27%\n",
      "Batch 121, Loss: 0.004088, Accuracy: 99.28%\n",
      "Batch 122, Loss: 0.012778, Accuracy: 99.28%\n",
      "Batch 123, Loss: 0.057029, Accuracy: 99.26%\n",
      "Batch 124, Loss: 0.004067, Accuracy: 99.27%\n",
      "Batch 125, Loss: 0.004873, Accuracy: 99.28%\n",
      "Batch 126, Loss: 0.007932, Accuracy: 99.28%\n",
      "Batch 127, Loss: 0.001678, Accuracy: 99.29%\n",
      "Batch 128, Loss: 0.000894, Accuracy: 99.29%\n",
      "Batch 129, Loss: 0.001318, Accuracy: 99.30%\n",
      "Batch 130, Loss: 0.001365, Accuracy: 99.30%\n",
      "Batch 131, Loss: 0.004197, Accuracy: 99.31%\n",
      "Batch 132, Loss: 0.003986, Accuracy: 99.31%\n",
      "Batch 133, Loss: 0.001664, Accuracy: 99.32%\n",
      "Batch 134, Loss: 0.004145, Accuracy: 99.32%\n",
      "Batch 135, Loss: 0.000819, Accuracy: 99.33%\n",
      "Batch 136, Loss: 0.003032, Accuracy: 99.33%\n",
      "Batch 137, Loss: 0.000994, Accuracy: 99.34%\n",
      "Batch 138, Loss: 0.000435, Accuracy: 99.34%\n",
      "Batch 139, Loss: 0.001307, Accuracy: 99.35%\n",
      "Batch 140, Loss: 0.001066, Accuracy: 99.35%\n",
      "Batch 141, Loss: 0.001093, Accuracy: 99.36%\n",
      "Batch 142, Loss: 0.000415, Accuracy: 99.36%\n",
      "Batch 143, Loss: 0.001089, Accuracy: 99.37%\n",
      "Batch 144, Loss: 0.000635, Accuracy: 99.37%\n",
      "Batch 145, Loss: 0.000742, Accuracy: 99.38%\n",
      "Batch 146, Loss: 0.031285, Accuracy: 99.37%\n",
      "Batch 147, Loss: 0.000441, Accuracy: 99.37%\n",
      "Batch 148, Loss: 0.000768, Accuracy: 99.38%\n",
      "Batch 149, Loss: 0.009385, Accuracy: 99.38%\n",
      "Batch 150, Loss: 0.000705, Accuracy: 99.39%\n",
      "Batch 151, Loss: 0.000697, Accuracy: 99.39%\n",
      "Batch 152, Loss: 0.090194, Accuracy: 99.37%\n",
      "Batch 153, Loss: 0.000291, Accuracy: 99.38%\n",
      "Batch 154, Loss: 0.000451, Accuracy: 99.38%\n",
      "Batch 155, Loss: 0.000425, Accuracy: 99.39%\n",
      "Batch 156, Loss: 0.001027, Accuracy: 99.39%\n",
      "Batch 157, Loss: 0.000663, Accuracy: 99.39%\n",
      "Batch 158, Loss: 0.016950, Accuracy: 99.39%\n",
      "Batch 159, Loss: 0.001142, Accuracy: 99.39%\n",
      "Batch 160, Loss: 0.001479, Accuracy: 99.39%\n",
      "Batch 161, Loss: 0.000535, Accuracy: 99.40%\n",
      "Batch 162, Loss: 0.001822, Accuracy: 99.40%\n",
      "Batch 163, Loss: 0.001146, Accuracy: 99.41%\n",
      "Batch 164, Loss: 0.000580, Accuracy: 99.41%\n",
      "Batch 165, Loss: 0.000875, Accuracy: 99.41%\n",
      "Batch 166, Loss: 0.010747, Accuracy: 99.42%\n",
      "Batch 167, Loss: 0.000840, Accuracy: 99.42%\n",
      "Batch 168, Loss: 0.006349, Accuracy: 99.42%\n",
      "Batch 169, Loss: 0.005385, Accuracy: 99.43%\n",
      "Batch 170, Loss: 0.000374, Accuracy: 99.43%\n",
      "Batch 171, Loss: 0.000673, Accuracy: 99.43%\n",
      "Batch 172, Loss: 0.000569, Accuracy: 99.44%\n",
      "Batch 173, Loss: 0.003823, Accuracy: 99.44%\n",
      "Batch 174, Loss: 0.000559, Accuracy: 99.44%\n",
      "Batch 175, Loss: 0.021136, Accuracy: 99.44%\n",
      "Batch 176, Loss: 0.034507, Accuracy: 99.43%\n",
      "Batch 177, Loss: 0.002860, Accuracy: 99.44%\n",
      "Batch 178, Loss: 0.005695, Accuracy: 99.44%\n",
      "Batch 179, Loss: 0.003020, Accuracy: 99.44%\n",
      "Batch 180, Loss: 0.000678, Accuracy: 99.44%\n",
      "Batch 181, Loss: 0.001264, Accuracy: 99.45%\n",
      "Batch 182, Loss: 0.000272, Accuracy: 99.45%\n",
      "Batch 183, Loss: 0.000178, Accuracy: 99.45%\n",
      "Batch 184, Loss: 0.000293, Accuracy: 99.46%\n",
      "Batch 185, Loss: 0.000387, Accuracy: 99.46%\n",
      "Batch 186, Loss: 0.077329, Accuracy: 99.45%\n",
      "Batch 187, Loss: 0.000829, Accuracy: 99.46%\n",
      "Batch 188, Loss: 0.000632, Accuracy: 99.46%\n",
      "Batch 189, Loss: 0.003477, Accuracy: 99.46%\n",
      "Batch 190, Loss: 0.001532, Accuracy: 99.47%\n",
      "Batch 191, Loss: 0.001302, Accuracy: 99.47%\n",
      "Batch 192, Loss: 0.003095, Accuracy: 99.47%\n",
      "Batch 193, Loss: 0.001367, Accuracy: 99.47%\n",
      "Batch 194, Loss: 0.048425, Accuracy: 99.47%\n",
      "Batch 195, Loss: 0.000403, Accuracy: 99.47%\n",
      "Batch 196, Loss: 0.005280, Accuracy: 99.47%\n",
      "Batch 197, Loss: 0.002987, Accuracy: 99.48%\n",
      "Batch 198, Loss: 0.000359, Accuracy: 99.48%\n",
      "Batch 199, Loss: 0.001889, Accuracy: 99.48%\n",
      "Batch 200, Loss: 0.002074, Accuracy: 99.48%\n",
      "Batch 201, Loss: 0.000390, Accuracy: 99.49%\n",
      "Batch 202, Loss: 0.000638, Accuracy: 99.49%\n",
      "Batch 203, Loss: 0.001725, Accuracy: 99.49%\n",
      "Batch 204, Loss: 0.000702, Accuracy: 99.49%\n",
      "Batch 205, Loss: 0.000243, Accuracy: 99.50%\n",
      "Batch 206, Loss: 0.000187, Accuracy: 99.50%\n",
      "Batch 207, Loss: 0.000316, Accuracy: 99.50%\n",
      "Batch 208, Loss: 0.000272, Accuracy: 99.50%\n",
      "Batch 209, Loss: 0.003796, Accuracy: 99.51%\n",
      "Batch 210, Loss: 0.004067, Accuracy: 99.51%\n",
      "Batch 211, Loss: 0.000601, Accuracy: 99.51%\n",
      "Batch 212, Loss: 0.007022, Accuracy: 99.51%\n",
      "Batch 213, Loss: 0.000260, Accuracy: 99.52%\n",
      "Training - Epoch 31, Loss: 0.015517, Accuracy: 99.52%\n",
      "Validation Batch 1, Loss: 0.000207, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000420, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000355, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000727, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.004115, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000953, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000214, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.002595, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.019823, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.062312, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.003984, Accuracy: 99.72%\n",
      "Validation Batch 12, Loss: 0.060384, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.001764, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.082234, Accuracy: 99.55%\n",
      "Validation Batch 15, Loss: 0.003580, Accuracy: 99.58%\n",
      "Validation Batch 16, Loss: 0.002559, Accuracy: 99.61%\n",
      "Validation Batch 17, Loss: 0.249488, Accuracy: 99.36%\n",
      "Validation Batch 18, Loss: 0.000279, Accuracy: 99.39%\n",
      "Validation Batch 19, Loss: 0.018495, Accuracy: 99.34%\n",
      "Validation Batch 20, Loss: 0.000974, Accuracy: 99.38%\n",
      "Validation Batch 21, Loss: 0.006943, Accuracy: 99.40%\n",
      "Validation Batch 22, Loss: 0.047009, Accuracy: 99.36%\n",
      "Validation Batch 23, Loss: 0.000403, Accuracy: 99.39%\n",
      "Validation Batch 24, Loss: 0.056725, Accuracy: 99.35%\n",
      "Validation Batch 25, Loss: 0.004225, Accuracy: 99.38%\n",
      "Validation Batch 26, Loss: 0.016046, Accuracy: 99.40%\n",
      "Validation Batch 27, Loss: 0.161544, Accuracy: 99.35%\n",
      "Validation - Epoch 31, Loss: 0.029939, Accuracy: 99.35%\n",
      "Patience—9\n",
      "Epoch 32\n",
      "Batch 1, Loss: 0.049715, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.000408, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.002012, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.000309, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.000717, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.001316, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.002973, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.000185, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.001076, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.001060, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.001887, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.000474, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.007429, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.001273, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.001237, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.000545, Accuracy: 99.90%\n",
      "Batch 17, Loss: 0.000412, Accuracy: 99.91%\n",
      "Batch 18, Loss: 0.000370, Accuracy: 99.91%\n",
      "Batch 19, Loss: 0.000285, Accuracy: 99.92%\n",
      "Batch 20, Loss: 0.000183, Accuracy: 99.92%\n",
      "Batch 21, Loss: 0.046347, Accuracy: 99.85%\n",
      "Batch 22, Loss: 0.000284, Accuracy: 99.86%\n",
      "Batch 23, Loss: 0.000341, Accuracy: 99.86%\n",
      "Batch 24, Loss: 0.009694, Accuracy: 99.87%\n",
      "Batch 25, Loss: 0.006955, Accuracy: 99.88%\n",
      "Batch 26, Loss: 0.000451, Accuracy: 99.88%\n",
      "Batch 27, Loss: 0.000226, Accuracy: 99.88%\n",
      "Batch 28, Loss: 0.029031, Accuracy: 99.83%\n",
      "Batch 29, Loss: 0.000916, Accuracy: 99.84%\n",
      "Batch 30, Loss: 0.000931, Accuracy: 99.84%\n",
      "Batch 31, Loss: 0.010308, Accuracy: 99.85%\n",
      "Batch 32, Loss: 0.002439, Accuracy: 99.85%\n",
      "Batch 33, Loss: 0.107973, Accuracy: 99.76%\n",
      "Batch 34, Loss: 0.008190, Accuracy: 99.77%\n",
      "Batch 35, Loss: 0.005035, Accuracy: 99.78%\n",
      "Batch 36, Loss: 0.006923, Accuracy: 99.78%\n",
      "Batch 37, Loss: 0.009494, Accuracy: 99.79%\n",
      "Batch 38, Loss: 0.014167, Accuracy: 99.79%\n",
      "Batch 39, Loss: 0.001115, Accuracy: 99.80%\n",
      "Batch 40, Loss: 0.001667, Accuracy: 99.80%\n",
      "Batch 41, Loss: 0.002349, Accuracy: 99.81%\n",
      "Batch 42, Loss: 0.130998, Accuracy: 99.74%\n",
      "Batch 43, Loss: 0.001348, Accuracy: 99.75%\n",
      "Batch 44, Loss: 0.006706, Accuracy: 99.75%\n",
      "Batch 45, Loss: 0.000338, Accuracy: 99.76%\n",
      "Batch 46, Loss: 0.003395, Accuracy: 99.76%\n",
      "Batch 47, Loss: 0.000496, Accuracy: 99.77%\n",
      "Batch 48, Loss: 0.001766, Accuracy: 99.77%\n",
      "Batch 49, Loss: 0.062907, Accuracy: 99.74%\n",
      "Batch 50, Loss: 0.008031, Accuracy: 99.75%\n",
      "Batch 51, Loss: 0.002991, Accuracy: 99.75%\n",
      "Batch 52, Loss: 0.038373, Accuracy: 99.73%\n",
      "Batch 53, Loss: 0.000343, Accuracy: 99.73%\n",
      "Batch 54, Loss: 0.000425, Accuracy: 99.74%\n",
      "Batch 55, Loss: 0.000426, Accuracy: 99.74%\n",
      "Batch 56, Loss: 0.004104, Accuracy: 99.75%\n",
      "Batch 57, Loss: 0.002110, Accuracy: 99.75%\n",
      "Batch 58, Loss: 0.010143, Accuracy: 99.76%\n",
      "Batch 59, Loss: 0.077765, Accuracy: 99.71%\n",
      "Batch 60, Loss: 0.036503, Accuracy: 99.66%\n",
      "Batch 61, Loss: 0.000879, Accuracy: 99.67%\n",
      "Batch 62, Loss: 0.000659, Accuracy: 99.67%\n",
      "Batch 63, Loss: 0.000956, Accuracy: 99.68%\n",
      "Batch 64, Loss: 0.000427, Accuracy: 99.68%\n",
      "Batch 65, Loss: 0.001757, Accuracy: 99.69%\n",
      "Batch 66, Loss: 0.007601, Accuracy: 99.69%\n",
      "Batch 67, Loss: 0.010425, Accuracy: 99.70%\n",
      "Batch 68, Loss: 0.021459, Accuracy: 99.68%\n",
      "Batch 69, Loss: 0.000824, Accuracy: 99.68%\n",
      "Batch 70, Loss: 0.001290, Accuracy: 99.69%\n",
      "Batch 71, Loss: 0.001097, Accuracy: 99.69%\n",
      "Batch 72, Loss: 0.002887, Accuracy: 99.70%\n",
      "Batch 73, Loss: 0.001780, Accuracy: 99.70%\n",
      "Batch 74, Loss: 0.002986, Accuracy: 99.70%\n",
      "Batch 75, Loss: 0.002802, Accuracy: 99.71%\n",
      "Batch 76, Loss: 0.001285, Accuracy: 99.71%\n",
      "Batch 77, Loss: 0.003266, Accuracy: 99.72%\n",
      "Batch 78, Loss: 0.070245, Accuracy: 99.68%\n",
      "Batch 79, Loss: 0.014350, Accuracy: 99.66%\n",
      "Batch 80, Loss: 0.009247, Accuracy: 99.67%\n",
      "Batch 81, Loss: 0.021481, Accuracy: 99.65%\n",
      "Batch 82, Loss: 0.008231, Accuracy: 99.66%\n",
      "Batch 83, Loss: 0.002011, Accuracy: 99.66%\n",
      "Batch 84, Loss: 0.000293, Accuracy: 99.67%\n",
      "Batch 85, Loss: 0.000304, Accuracy: 99.67%\n",
      "Batch 86, Loss: 0.000666, Accuracy: 99.67%\n",
      "Batch 87, Loss: 0.000383, Accuracy: 99.68%\n",
      "Batch 88, Loss: 0.001384, Accuracy: 99.68%\n",
      "Batch 89, Loss: 0.031884, Accuracy: 99.67%\n",
      "Batch 90, Loss: 0.033065, Accuracy: 99.65%\n",
      "Batch 91, Loss: 0.073220, Accuracy: 99.64%\n",
      "Batch 92, Loss: 0.059582, Accuracy: 99.63%\n",
      "Batch 93, Loss: 0.005089, Accuracy: 99.63%\n",
      "Batch 94, Loss: 0.001749, Accuracy: 99.63%\n",
      "Batch 95, Loss: 0.002934, Accuracy: 99.64%\n",
      "Batch 96, Loss: 0.004793, Accuracy: 99.64%\n",
      "Batch 97, Loss: 0.000517, Accuracy: 99.65%\n",
      "Batch 98, Loss: 0.000552, Accuracy: 99.65%\n",
      "Batch 99, Loss: 0.019246, Accuracy: 99.64%\n",
      "Batch 100, Loss: 0.022221, Accuracy: 99.62%\n",
      "Batch 101, Loss: 0.007071, Accuracy: 99.63%\n",
      "Batch 102, Loss: 0.001876, Accuracy: 99.63%\n",
      "Batch 103, Loss: 0.001391, Accuracy: 99.64%\n",
      "Batch 104, Loss: 0.003207, Accuracy: 99.64%\n",
      "Batch 105, Loss: 0.031669, Accuracy: 99.63%\n",
      "Batch 106, Loss: 0.001471, Accuracy: 99.63%\n",
      "Batch 107, Loss: 0.042838, Accuracy: 99.62%\n",
      "Batch 108, Loss: 0.011553, Accuracy: 99.62%\n",
      "Batch 109, Loss: 0.050302, Accuracy: 99.61%\n",
      "Batch 110, Loss: 0.000482, Accuracy: 99.62%\n",
      "Batch 111, Loss: 0.001310, Accuracy: 99.62%\n",
      "Batch 112, Loss: 0.004088, Accuracy: 99.62%\n",
      "Batch 113, Loss: 0.010745, Accuracy: 99.63%\n",
      "Batch 114, Loss: 0.001433, Accuracy: 99.63%\n",
      "Batch 115, Loss: 0.002011, Accuracy: 99.63%\n",
      "Batch 116, Loss: 0.007320, Accuracy: 99.64%\n",
      "Batch 117, Loss: 0.008698, Accuracy: 99.64%\n",
      "Batch 118, Loss: 0.166875, Accuracy: 99.62%\n",
      "Batch 119, Loss: 0.001016, Accuracy: 99.62%\n",
      "Batch 120, Loss: 0.002732, Accuracy: 99.62%\n",
      "Batch 121, Loss: 0.025203, Accuracy: 99.61%\n",
      "Batch 122, Loss: 0.001665, Accuracy: 99.62%\n",
      "Batch 123, Loss: 0.089916, Accuracy: 99.59%\n",
      "Batch 124, Loss: 0.002611, Accuracy: 99.60%\n",
      "Batch 125, Loss: 0.001410, Accuracy: 99.60%\n",
      "Batch 126, Loss: 0.001399, Accuracy: 99.60%\n",
      "Batch 127, Loss: 0.001859, Accuracy: 99.61%\n",
      "Batch 128, Loss: 0.058435, Accuracy: 99.60%\n",
      "Batch 129, Loss: 0.000677, Accuracy: 99.60%\n",
      "Batch 130, Loss: 0.020231, Accuracy: 99.59%\n",
      "Batch 131, Loss: 0.012483, Accuracy: 99.59%\n",
      "Batch 132, Loss: 0.001400, Accuracy: 99.60%\n",
      "Batch 133, Loss: 0.104371, Accuracy: 99.58%\n",
      "Batch 134, Loss: 0.000666, Accuracy: 99.58%\n",
      "Batch 135, Loss: 0.008503, Accuracy: 99.58%\n",
      "Batch 136, Loss: 0.037185, Accuracy: 99.57%\n",
      "Batch 137, Loss: 0.023716, Accuracy: 99.57%\n",
      "Batch 138, Loss: 0.035669, Accuracy: 99.56%\n",
      "Batch 139, Loss: 0.107770, Accuracy: 99.54%\n",
      "Batch 140, Loss: 0.018385, Accuracy: 99.54%\n",
      "Batch 141, Loss: 0.002685, Accuracy: 99.55%\n",
      "Batch 142, Loss: 0.002418, Accuracy: 99.55%\n",
      "Batch 143, Loss: 0.025403, Accuracy: 99.54%\n",
      "Batch 144, Loss: 0.002756, Accuracy: 99.54%\n",
      "Batch 145, Loss: 0.003786, Accuracy: 99.55%\n",
      "Batch 146, Loss: 0.002598, Accuracy: 99.55%\n",
      "Batch 147, Loss: 0.008753, Accuracy: 99.55%\n",
      "Batch 148, Loss: 0.053505, Accuracy: 99.55%\n",
      "Batch 149, Loss: 0.000846, Accuracy: 99.55%\n",
      "Batch 150, Loss: 0.094276, Accuracy: 99.53%\n",
      "Batch 151, Loss: 0.001058, Accuracy: 99.53%\n",
      "Batch 152, Loss: 0.011157, Accuracy: 99.54%\n",
      "Batch 153, Loss: 0.003347, Accuracy: 99.54%\n",
      "Batch 154, Loss: 0.003111, Accuracy: 99.54%\n",
      "Batch 155, Loss: 0.010152, Accuracy: 99.55%\n",
      "Batch 156, Loss: 0.001856, Accuracy: 99.55%\n",
      "Batch 157, Loss: 0.004775, Accuracy: 99.55%\n",
      "Batch 158, Loss: 0.039107, Accuracy: 99.55%\n",
      "Batch 159, Loss: 0.039864, Accuracy: 99.54%\n",
      "Batch 160, Loss: 0.006705, Accuracy: 99.54%\n",
      "Batch 161, Loss: 0.018533, Accuracy: 99.53%\n",
      "Batch 162, Loss: 0.002131, Accuracy: 99.54%\n",
      "Batch 163, Loss: 0.025859, Accuracy: 99.53%\n",
      "Batch 164, Loss: 0.038464, Accuracy: 99.52%\n",
      "Batch 165, Loss: 0.008015, Accuracy: 99.53%\n",
      "Batch 166, Loss: 0.011293, Accuracy: 99.53%\n",
      "Batch 167, Loss: 0.020929, Accuracy: 99.53%\n",
      "Batch 168, Loss: 0.004857, Accuracy: 99.53%\n",
      "Batch 169, Loss: 0.016829, Accuracy: 99.53%\n",
      "Batch 170, Loss: 0.003106, Accuracy: 99.53%\n",
      "Batch 171, Loss: 0.021151, Accuracy: 99.52%\n",
      "Batch 172, Loss: 0.018832, Accuracy: 99.52%\n",
      "Batch 173, Loss: 0.005719, Accuracy: 99.52%\n",
      "Batch 174, Loss: 0.017472, Accuracy: 99.52%\n",
      "Batch 175, Loss: 0.002467, Accuracy: 99.53%\n",
      "Batch 176, Loss: 0.001496, Accuracy: 99.53%\n",
      "Batch 177, Loss: 0.008680, Accuracy: 99.53%\n",
      "Batch 178, Loss: 0.001850, Accuracy: 99.53%\n",
      "Batch 179, Loss: 0.001498, Accuracy: 99.54%\n",
      "Batch 180, Loss: 0.047544, Accuracy: 99.53%\n",
      "Batch 181, Loss: 0.032348, Accuracy: 99.53%\n",
      "Batch 182, Loss: 0.002169, Accuracy: 99.53%\n",
      "Batch 183, Loss: 0.007830, Accuracy: 99.53%\n",
      "Batch 184, Loss: 0.001325, Accuracy: 99.53%\n",
      "Batch 185, Loss: 0.010814, Accuracy: 99.54%\n",
      "Batch 186, Loss: 0.002100, Accuracy: 99.54%\n",
      "Batch 187, Loss: 0.080268, Accuracy: 99.53%\n",
      "Batch 188, Loss: 0.096706, Accuracy: 99.53%\n",
      "Batch 189, Loss: 0.001198, Accuracy: 99.53%\n",
      "Batch 190, Loss: 0.006411, Accuracy: 99.53%\n",
      "Batch 191, Loss: 0.011848, Accuracy: 99.53%\n",
      "Batch 192, Loss: 0.003179, Accuracy: 99.54%\n",
      "Batch 193, Loss: 0.006413, Accuracy: 99.54%\n",
      "Batch 194, Loss: 0.050290, Accuracy: 99.53%\n",
      "Batch 195, Loss: 0.002637, Accuracy: 99.54%\n",
      "Batch 196, Loss: 0.048865, Accuracy: 99.53%\n",
      "Batch 197, Loss: 0.001489, Accuracy: 99.53%\n",
      "Batch 198, Loss: 0.017682, Accuracy: 99.53%\n",
      "Batch 199, Loss: 0.019533, Accuracy: 99.52%\n",
      "Batch 200, Loss: 0.006713, Accuracy: 99.52%\n",
      "Batch 201, Loss: 0.000443, Accuracy: 99.53%\n",
      "Batch 202, Loss: 0.016217, Accuracy: 99.52%\n",
      "Batch 203, Loss: 0.048564, Accuracy: 99.51%\n",
      "Batch 204, Loss: 0.002064, Accuracy: 99.51%\n",
      "Batch 205, Loss: 0.062739, Accuracy: 99.50%\n",
      "Batch 206, Loss: 0.021087, Accuracy: 99.50%\n",
      "Batch 207, Loss: 0.023301, Accuracy: 99.49%\n",
      "Batch 208, Loss: 0.018989, Accuracy: 99.49%\n",
      "Batch 209, Loss: 0.001291, Accuracy: 99.49%\n",
      "Batch 210, Loss: 0.021878, Accuracy: 99.49%\n",
      "Batch 211, Loss: 0.001475, Accuracy: 99.49%\n",
      "Batch 212, Loss: 0.002162, Accuracy: 99.49%\n",
      "Batch 213, Loss: 0.006464, Accuracy: 99.49%\n",
      "Training - Epoch 32, Loss: 0.015571, Accuracy: 99.49%\n",
      "Validation Batch 1, Loss: 0.000766, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.171671, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.028668, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.005283, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.006760, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.001914, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.005673, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.029560, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.003179, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.005362, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.020801, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.063419, Accuracy: 99.35%\n",
      "Validation Batch 13, Loss: 0.122729, Accuracy: 99.28%\n",
      "Validation Batch 14, Loss: 0.001057, Accuracy: 99.33%\n",
      "Validation Batch 15, Loss: 0.020682, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.040047, Accuracy: 99.22%\n",
      "Validation Batch 17, Loss: 0.036934, Accuracy: 99.17%\n",
      "Validation Batch 18, Loss: 0.028462, Accuracy: 99.13%\n",
      "Validation Batch 19, Loss: 0.002612, Accuracy: 99.18%\n",
      "Validation Batch 20, Loss: 0.001492, Accuracy: 99.22%\n",
      "Validation Batch 21, Loss: 0.250472, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.038239, Accuracy: 99.01%\n",
      "Validation Batch 23, Loss: 0.103611, Accuracy: 98.91%\n",
      "Validation Batch 24, Loss: 0.082828, Accuracy: 98.83%\n",
      "Validation Batch 25, Loss: 0.038791, Accuracy: 98.81%\n",
      "Validation Batch 26, Loss: 0.006991, Accuracy: 98.86%\n",
      "Validation Batch 27, Loss: 0.142975, Accuracy: 98.77%\n",
      "Validation - Epoch 32, Loss: 0.046703, Accuracy: 98.77%\n",
      "Patience—10\n",
      "Epoch 33\n",
      "Batch 1, Loss: 0.036191, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.011536, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.004934, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.000491, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.161634, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.000835, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.001681, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.002800, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.002160, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.002978, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.008957, Accuracy: 99.72%\n",
      "Batch 12, Loss: 0.047353, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.005913, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.000933, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.000681, Accuracy: 99.69%\n",
      "Batch 16, Loss: 0.012225, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.056813, Accuracy: 99.54%\n",
      "Batch 18, Loss: 0.070349, Accuracy: 99.39%\n",
      "Batch 19, Loss: 0.000574, Accuracy: 99.42%\n",
      "Batch 20, Loss: 0.001553, Accuracy: 99.45%\n",
      "Batch 21, Loss: 0.001956, Accuracy: 99.48%\n",
      "Batch 22, Loss: 0.032659, Accuracy: 99.43%\n",
      "Batch 23, Loss: 0.000651, Accuracy: 99.46%\n",
      "Batch 24, Loss: 0.001711, Accuracy: 99.48%\n",
      "Batch 25, Loss: 0.065722, Accuracy: 99.44%\n",
      "Batch 26, Loss: 0.009189, Accuracy: 99.46%\n",
      "Batch 27, Loss: 0.045225, Accuracy: 99.36%\n",
      "Batch 28, Loss: 0.001234, Accuracy: 99.39%\n",
      "Batch 29, Loss: 0.111317, Accuracy: 99.30%\n",
      "Batch 30, Loss: 0.003555, Accuracy: 99.32%\n",
      "Batch 31, Loss: 0.003425, Accuracy: 99.34%\n",
      "Batch 32, Loss: 0.011559, Accuracy: 99.37%\n",
      "Batch 33, Loss: 0.003449, Accuracy: 99.38%\n",
      "Batch 34, Loss: 0.006211, Accuracy: 99.40%\n",
      "Batch 35, Loss: 0.003601, Accuracy: 99.42%\n",
      "Batch 36, Loss: 0.002025, Accuracy: 99.44%\n",
      "Batch 37, Loss: 0.004179, Accuracy: 99.45%\n",
      "Batch 38, Loss: 0.011266, Accuracy: 99.47%\n",
      "Batch 39, Loss: 0.007263, Accuracy: 99.48%\n",
      "Batch 40, Loss: 0.003015, Accuracy: 99.49%\n",
      "Batch 41, Loss: 0.003961, Accuracy: 99.50%\n",
      "Batch 42, Loss: 0.002455, Accuracy: 99.52%\n",
      "Batch 43, Loss: 0.000898, Accuracy: 99.53%\n",
      "Batch 44, Loss: 0.014782, Accuracy: 99.50%\n",
      "Batch 45, Loss: 0.001469, Accuracy: 99.51%\n",
      "Batch 46, Loss: 0.019577, Accuracy: 99.49%\n",
      "Batch 47, Loss: 0.001221, Accuracy: 99.50%\n",
      "Batch 48, Loss: 0.003180, Accuracy: 99.51%\n",
      "Batch 49, Loss: 0.001266, Accuracy: 99.52%\n",
      "Batch 50, Loss: 0.001815, Accuracy: 99.53%\n",
      "Batch 51, Loss: 0.007841, Accuracy: 99.54%\n",
      "Batch 52, Loss: 0.001517, Accuracy: 99.55%\n",
      "Batch 53, Loss: 0.001099, Accuracy: 99.56%\n",
      "Batch 54, Loss: 0.000714, Accuracy: 99.57%\n",
      "Batch 55, Loss: 0.001374, Accuracy: 99.57%\n",
      "Batch 56, Loss: 0.002873, Accuracy: 99.58%\n",
      "Batch 57, Loss: 0.006105, Accuracy: 99.59%\n",
      "Batch 58, Loss: 0.001567, Accuracy: 99.60%\n",
      "Batch 59, Loss: 0.059524, Accuracy: 99.58%\n",
      "Batch 60, Loss: 0.007523, Accuracy: 99.58%\n",
      "Batch 61, Loss: 0.000570, Accuracy: 99.59%\n",
      "Batch 62, Loss: 0.080441, Accuracy: 99.57%\n",
      "Batch 63, Loss: 0.029781, Accuracy: 99.55%\n",
      "Batch 64, Loss: 0.001045, Accuracy: 99.56%\n",
      "Batch 65, Loss: 0.001425, Accuracy: 99.57%\n",
      "Batch 66, Loss: 0.000779, Accuracy: 99.57%\n",
      "Batch 67, Loss: 0.000621, Accuracy: 99.58%\n",
      "Batch 68, Loss: 0.018592, Accuracy: 99.56%\n",
      "Batch 69, Loss: 0.012733, Accuracy: 99.55%\n",
      "Batch 70, Loss: 0.001664, Accuracy: 99.55%\n",
      "Batch 71, Loss: 0.004690, Accuracy: 99.56%\n",
      "Batch 72, Loss: 0.000297, Accuracy: 99.57%\n",
      "Batch 73, Loss: 0.000794, Accuracy: 99.57%\n",
      "Batch 74, Loss: 0.001095, Accuracy: 99.58%\n",
      "Batch 75, Loss: 0.000432, Accuracy: 99.58%\n",
      "Batch 76, Loss: 0.038706, Accuracy: 99.57%\n",
      "Batch 77, Loss: 0.000743, Accuracy: 99.57%\n",
      "Batch 78, Loss: 0.000307, Accuracy: 99.58%\n",
      "Batch 79, Loss: 0.000872, Accuracy: 99.58%\n",
      "Batch 80, Loss: 0.001620, Accuracy: 99.59%\n",
      "Batch 81, Loss: 0.000703, Accuracy: 99.59%\n",
      "Batch 82, Loss: 0.000532, Accuracy: 99.60%\n",
      "Batch 83, Loss: 0.000911, Accuracy: 99.60%\n",
      "Batch 84, Loss: 0.036741, Accuracy: 99.59%\n",
      "Batch 85, Loss: 0.000223, Accuracy: 99.60%\n",
      "Batch 86, Loss: 0.006194, Accuracy: 99.60%\n",
      "Batch 87, Loss: 0.000923, Accuracy: 99.60%\n",
      "Batch 88, Loss: 0.033153, Accuracy: 99.59%\n",
      "Batch 89, Loss: 0.008505, Accuracy: 99.60%\n",
      "Batch 90, Loss: 0.000724, Accuracy: 99.60%\n",
      "Batch 91, Loss: 0.001176, Accuracy: 99.61%\n",
      "Batch 92, Loss: 0.003044, Accuracy: 99.61%\n",
      "Batch 93, Loss: 0.000922, Accuracy: 99.61%\n",
      "Batch 94, Loss: 0.000175, Accuracy: 99.62%\n",
      "Batch 95, Loss: 0.002298, Accuracy: 99.62%\n",
      "Batch 96, Loss: 0.017413, Accuracy: 99.63%\n",
      "Batch 97, Loss: 0.005140, Accuracy: 99.63%\n",
      "Batch 98, Loss: 0.030076, Accuracy: 99.62%\n",
      "Batch 99, Loss: 0.000213, Accuracy: 99.62%\n",
      "Batch 100, Loss: 0.052676, Accuracy: 99.61%\n",
      "Batch 101, Loss: 0.002286, Accuracy: 99.61%\n",
      "Batch 102, Loss: 0.001845, Accuracy: 99.62%\n",
      "Batch 103, Loss: 0.004385, Accuracy: 99.62%\n",
      "Batch 104, Loss: 0.000527, Accuracy: 99.62%\n",
      "Batch 105, Loss: 0.036803, Accuracy: 99.61%\n",
      "Batch 106, Loss: 0.010539, Accuracy: 99.62%\n",
      "Batch 107, Loss: 0.001713, Accuracy: 99.62%\n",
      "Batch 108, Loss: 0.000594, Accuracy: 99.62%\n",
      "Batch 109, Loss: 0.006430, Accuracy: 99.63%\n",
      "Batch 110, Loss: 0.004309, Accuracy: 99.63%\n",
      "Batch 111, Loss: 0.000542, Accuracy: 99.63%\n",
      "Batch 112, Loss: 0.000558, Accuracy: 99.64%\n",
      "Batch 113, Loss: 0.001841, Accuracy: 99.64%\n",
      "Batch 114, Loss: 0.000267, Accuracy: 99.64%\n",
      "Batch 115, Loss: 0.000661, Accuracy: 99.65%\n",
      "Batch 116, Loss: 0.046943, Accuracy: 99.64%\n",
      "Batch 117, Loss: 0.023284, Accuracy: 99.63%\n",
      "Batch 118, Loss: 0.000279, Accuracy: 99.63%\n",
      "Batch 119, Loss: 0.000706, Accuracy: 99.63%\n",
      "Batch 120, Loss: 0.000122, Accuracy: 99.64%\n",
      "Batch 121, Loss: 0.001182, Accuracy: 99.64%\n",
      "Batch 122, Loss: 0.000715, Accuracy: 99.64%\n",
      "Batch 123, Loss: 0.001839, Accuracy: 99.64%\n",
      "Batch 124, Loss: 0.000649, Accuracy: 99.65%\n",
      "Batch 125, Loss: 0.011775, Accuracy: 99.64%\n",
      "Batch 126, Loss: 0.095852, Accuracy: 99.63%\n",
      "Batch 127, Loss: 0.001613, Accuracy: 99.63%\n",
      "Batch 128, Loss: 0.000629, Accuracy: 99.63%\n",
      "Batch 129, Loss: 0.012531, Accuracy: 99.62%\n",
      "Batch 130, Loss: 0.001259, Accuracy: 99.63%\n",
      "Batch 131, Loss: 0.115517, Accuracy: 99.61%\n",
      "Batch 132, Loss: 0.001651, Accuracy: 99.61%\n",
      "Batch 133, Loss: 0.001860, Accuracy: 99.61%\n",
      "Batch 134, Loss: 0.093415, Accuracy: 99.60%\n",
      "Batch 135, Loss: 0.003873, Accuracy: 99.61%\n",
      "Batch 136, Loss: 0.007444, Accuracy: 99.61%\n",
      "Batch 137, Loss: 0.000668, Accuracy: 99.61%\n",
      "Batch 138, Loss: 0.001125, Accuracy: 99.62%\n",
      "Batch 139, Loss: 0.003445, Accuracy: 99.62%\n",
      "Batch 140, Loss: 0.013863, Accuracy: 99.61%\n",
      "Batch 141, Loss: 0.047630, Accuracy: 99.60%\n",
      "Batch 142, Loss: 0.001166, Accuracy: 99.60%\n",
      "Batch 143, Loss: 0.001776, Accuracy: 99.61%\n",
      "Batch 144, Loss: 0.001771, Accuracy: 99.61%\n",
      "Batch 145, Loss: 0.001618, Accuracy: 99.61%\n",
      "Batch 146, Loss: 0.008509, Accuracy: 99.61%\n",
      "Batch 147, Loss: 0.001060, Accuracy: 99.62%\n",
      "Batch 148, Loss: 0.001124, Accuracy: 99.62%\n",
      "Batch 149, Loss: 0.013620, Accuracy: 99.62%\n",
      "Batch 150, Loss: 0.006583, Accuracy: 99.62%\n",
      "Batch 151, Loss: 0.001394, Accuracy: 99.63%\n",
      "Batch 152, Loss: 0.002146, Accuracy: 99.63%\n",
      "Batch 153, Loss: 0.013092, Accuracy: 99.62%\n",
      "Batch 154, Loss: 0.001770, Accuracy: 99.62%\n",
      "Batch 155, Loss: 0.000952, Accuracy: 99.63%\n",
      "Batch 156, Loss: 0.001401, Accuracy: 99.63%\n",
      "Batch 157, Loss: 0.004417, Accuracy: 99.63%\n",
      "Batch 158, Loss: 0.017850, Accuracy: 99.62%\n",
      "Batch 159, Loss: 0.001426, Accuracy: 99.63%\n",
      "Batch 160, Loss: 0.000834, Accuracy: 99.63%\n",
      "Batch 161, Loss: 0.020345, Accuracy: 99.62%\n",
      "Batch 162, Loss: 0.000625, Accuracy: 99.62%\n",
      "Batch 163, Loss: 0.002837, Accuracy: 99.63%\n",
      "Batch 164, Loss: 0.000445, Accuracy: 99.63%\n",
      "Batch 165, Loss: 0.037072, Accuracy: 99.62%\n",
      "Batch 166, Loss: 0.000728, Accuracy: 99.62%\n",
      "Batch 167, Loss: 0.000260, Accuracy: 99.63%\n",
      "Batch 168, Loss: 0.000526, Accuracy: 99.63%\n",
      "Batch 169, Loss: 0.000440, Accuracy: 99.63%\n",
      "Batch 170, Loss: 0.007627, Accuracy: 99.63%\n",
      "Batch 171, Loss: 0.000594, Accuracy: 99.63%\n",
      "Batch 172, Loss: 0.002810, Accuracy: 99.64%\n",
      "Batch 173, Loss: 0.002988, Accuracy: 99.64%\n",
      "Batch 174, Loss: 0.000194, Accuracy: 99.64%\n",
      "Batch 175, Loss: 0.000197, Accuracy: 99.64%\n",
      "Batch 176, Loss: 0.022666, Accuracy: 99.64%\n",
      "Batch 177, Loss: 0.000492, Accuracy: 99.64%\n",
      "Batch 178, Loss: 0.000298, Accuracy: 99.64%\n",
      "Batch 179, Loss: 0.000521, Accuracy: 99.64%\n",
      "Batch 180, Loss: 0.000134, Accuracy: 99.64%\n",
      "Batch 181, Loss: 0.000207, Accuracy: 99.65%\n",
      "Batch 182, Loss: 0.001373, Accuracy: 99.65%\n",
      "Batch 183, Loss: 0.000263, Accuracy: 99.65%\n",
      "Batch 184, Loss: 0.000453, Accuracy: 99.65%\n",
      "Batch 185, Loss: 0.000316, Accuracy: 99.65%\n",
      "Batch 186, Loss: 0.004136, Accuracy: 99.66%\n",
      "Batch 187, Loss: 0.000157, Accuracy: 99.66%\n",
      "Batch 188, Loss: 0.002433, Accuracy: 99.66%\n",
      "Batch 189, Loss: 0.042512, Accuracy: 99.65%\n",
      "Batch 190, Loss: 0.000289, Accuracy: 99.65%\n",
      "Batch 191, Loss: 0.000264, Accuracy: 99.66%\n",
      "Batch 192, Loss: 0.000344, Accuracy: 99.66%\n",
      "Batch 193, Loss: 0.000483, Accuracy: 99.66%\n",
      "Batch 194, Loss: 0.000117, Accuracy: 99.66%\n",
      "Batch 195, Loss: 0.000225, Accuracy: 99.66%\n",
      "Batch 196, Loss: 0.000608, Accuracy: 99.67%\n",
      "Batch 197, Loss: 0.000440, Accuracy: 99.67%\n",
      "Batch 198, Loss: 0.000504, Accuracy: 99.67%\n",
      "Batch 199, Loss: 0.000125, Accuracy: 99.67%\n",
      "Batch 200, Loss: 0.001139, Accuracy: 99.67%\n",
      "Batch 201, Loss: 0.000537, Accuracy: 99.67%\n",
      "Batch 202, Loss: 0.084175, Accuracy: 99.67%\n",
      "Batch 203, Loss: 0.012683, Accuracy: 99.66%\n",
      "Batch 204, Loss: 0.001843, Accuracy: 99.66%\n",
      "Batch 205, Loss: 0.000137, Accuracy: 99.66%\n",
      "Batch 206, Loss: 0.007133, Accuracy: 99.67%\n",
      "Batch 207, Loss: 0.000570, Accuracy: 99.67%\n",
      "Batch 208, Loss: 0.000213, Accuracy: 99.67%\n",
      "Batch 209, Loss: 0.005380, Accuracy: 99.67%\n",
      "Batch 210, Loss: 0.001869, Accuracy: 99.67%\n",
      "Batch 211, Loss: 0.241714, Accuracy: 99.64%\n",
      "Batch 212, Loss: 0.134604, Accuracy: 99.64%\n",
      "Batch 213, Loss: 0.092129, Accuracy: 99.63%\n",
      "Training - Epoch 33, Loss: 0.012612, Accuracy: 99.63%\n",
      "Validation Batch 1, Loss: 0.025657, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.001110, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.006274, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.001859, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.020116, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.005558, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.000487, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.061931, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.152323, Accuracy: 98.96%\n",
      "Validation Batch 10, Loss: 0.031507, Accuracy: 98.91%\n",
      "Validation Batch 11, Loss: 0.082302, Accuracy: 98.86%\n",
      "Validation Batch 12, Loss: 0.037556, Accuracy: 98.83%\n",
      "Validation Batch 13, Loss: 0.001024, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.011339, Accuracy: 99.00%\n",
      "Validation Batch 15, Loss: 0.002374, Accuracy: 99.06%\n",
      "Validation Batch 16, Loss: 0.001102, Accuracy: 99.12%\n",
      "Validation Batch 17, Loss: 0.003166, Accuracy: 99.17%\n",
      "Validation Batch 18, Loss: 0.001370, Accuracy: 99.22%\n",
      "Validation Batch 19, Loss: 0.096155, Accuracy: 99.18%\n",
      "Validation Batch 20, Loss: 0.000365, Accuracy: 99.22%\n",
      "Validation Batch 21, Loss: 0.113490, Accuracy: 99.11%\n",
      "Validation Batch 22, Loss: 0.036943, Accuracy: 99.08%\n",
      "Validation Batch 23, Loss: 0.020581, Accuracy: 99.05%\n",
      "Validation Batch 24, Loss: 0.196815, Accuracy: 98.96%\n",
      "Validation Batch 25, Loss: 0.000825, Accuracy: 99.00%\n",
      "Validation Batch 26, Loss: 0.105787, Accuracy: 98.92%\n",
      "Validation Batch 27, Loss: 0.000398, Accuracy: 98.94%\n",
      "Validation - Epoch 33, Loss: 0.037719, Accuracy: 98.94%\n",
      "Patience—11\n",
      "Epoch 34\n",
      "Batch 1, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.011497, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.005558, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.006903, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.006145, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.019895, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.036192, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.023598, Accuracy: 99.41%\n",
      "Batch 9, Loss: 0.003703, Accuracy: 99.48%\n",
      "Batch 10, Loss: 0.002415, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.006786, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.001241, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.002262, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.001315, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.005402, Accuracy: 99.69%\n",
      "Batch 16, Loss: 0.013084, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.037486, Accuracy: 99.63%\n",
      "Batch 18, Loss: 0.101979, Accuracy: 99.57%\n",
      "Batch 19, Loss: 0.002859, Accuracy: 99.59%\n",
      "Batch 20, Loss: 0.000401, Accuracy: 99.61%\n",
      "Batch 21, Loss: 0.004089, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.001074, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.000528, Accuracy: 99.66%\n",
      "Batch 24, Loss: 0.003602, Accuracy: 99.67%\n",
      "Batch 25, Loss: 0.001520, Accuracy: 99.69%\n",
      "Batch 26, Loss: 0.001245, Accuracy: 99.70%\n",
      "Batch 27, Loss: 0.001654, Accuracy: 99.71%\n",
      "Batch 28, Loss: 0.007995, Accuracy: 99.72%\n",
      "Batch 29, Loss: 0.002331, Accuracy: 99.73%\n",
      "Batch 30, Loss: 0.001123, Accuracy: 99.74%\n",
      "Batch 31, Loss: 0.019505, Accuracy: 99.70%\n",
      "Batch 32, Loss: 0.000780, Accuracy: 99.71%\n",
      "Batch 33, Loss: 0.004376, Accuracy: 99.72%\n",
      "Batch 34, Loss: 0.004184, Accuracy: 99.72%\n",
      "Batch 35, Loss: 0.000636, Accuracy: 99.73%\n",
      "Batch 36, Loss: 0.000993, Accuracy: 99.74%\n",
      "Batch 37, Loss: 0.004009, Accuracy: 99.75%\n",
      "Batch 38, Loss: 0.011795, Accuracy: 99.75%\n",
      "Batch 39, Loss: 0.001032, Accuracy: 99.76%\n",
      "Batch 40, Loss: 0.001614, Accuracy: 99.77%\n",
      "Batch 41, Loss: 0.003979, Accuracy: 99.77%\n",
      "Batch 42, Loss: 0.000607, Accuracy: 99.78%\n",
      "Batch 43, Loss: 0.001646, Accuracy: 99.78%\n",
      "Batch 44, Loss: 0.001281, Accuracy: 99.79%\n",
      "Batch 45, Loss: 0.000419, Accuracy: 99.79%\n",
      "Batch 46, Loss: 0.000308, Accuracy: 99.80%\n",
      "Batch 47, Loss: 0.000886, Accuracy: 99.80%\n",
      "Batch 48, Loss: 0.001900, Accuracy: 99.80%\n",
      "Batch 49, Loss: 0.000552, Accuracy: 99.81%\n",
      "Batch 50, Loss: 0.001707, Accuracy: 99.81%\n",
      "Batch 51, Loss: 0.002289, Accuracy: 99.82%\n",
      "Batch 52, Loss: 0.000183, Accuracy: 99.82%\n",
      "Batch 53, Loss: 0.000133, Accuracy: 99.82%\n",
      "Batch 54, Loss: 0.002966, Accuracy: 99.83%\n",
      "Batch 55, Loss: 0.000243, Accuracy: 99.83%\n",
      "Batch 56, Loss: 0.000234, Accuracy: 99.83%\n",
      "Batch 57, Loss: 0.035422, Accuracy: 99.81%\n",
      "Batch 58, Loss: 0.000161, Accuracy: 99.81%\n",
      "Batch 59, Loss: 0.000193, Accuracy: 99.81%\n",
      "Batch 60, Loss: 0.000475, Accuracy: 99.82%\n",
      "Batch 61, Loss: 0.004365, Accuracy: 99.82%\n",
      "Batch 62, Loss: 0.000878, Accuracy: 99.82%\n",
      "Batch 63, Loss: 0.026747, Accuracy: 99.80%\n",
      "Batch 64, Loss: 0.000296, Accuracy: 99.80%\n",
      "Batch 65, Loss: 0.000217, Accuracy: 99.81%\n",
      "Batch 66, Loss: 0.000145, Accuracy: 99.81%\n",
      "Batch 67, Loss: 0.000279, Accuracy: 99.81%\n",
      "Batch 68, Loss: 0.059143, Accuracy: 99.79%\n",
      "Batch 69, Loss: 0.000708, Accuracy: 99.80%\n",
      "Batch 70, Loss: 0.005704, Accuracy: 99.80%\n",
      "Batch 71, Loss: 0.000333, Accuracy: 99.80%\n",
      "Batch 72, Loss: 0.000124, Accuracy: 99.80%\n",
      "Batch 73, Loss: 0.000286, Accuracy: 99.81%\n",
      "Batch 74, Loss: 0.001105, Accuracy: 99.81%\n",
      "Batch 75, Loss: 0.000928, Accuracy: 99.81%\n",
      "Batch 76, Loss: 0.000268, Accuracy: 99.81%\n",
      "Batch 77, Loss: 0.000364, Accuracy: 99.82%\n",
      "Batch 78, Loss: 0.009395, Accuracy: 99.82%\n",
      "Batch 79, Loss: 0.000146, Accuracy: 99.82%\n",
      "Batch 80, Loss: 0.027611, Accuracy: 99.80%\n",
      "Batch 81, Loss: 0.000731, Accuracy: 99.81%\n",
      "Batch 82, Loss: 0.001102, Accuracy: 99.81%\n",
      "Batch 83, Loss: 0.000500, Accuracy: 99.81%\n",
      "Batch 84, Loss: 0.000454, Accuracy: 99.81%\n",
      "Batch 85, Loss: 0.001034, Accuracy: 99.82%\n",
      "Batch 86, Loss: 0.000227, Accuracy: 99.82%\n",
      "Batch 87, Loss: 0.005564, Accuracy: 99.82%\n",
      "Batch 88, Loss: 0.000664, Accuracy: 99.82%\n",
      "Batch 89, Loss: 0.006756, Accuracy: 99.82%\n",
      "Batch 90, Loss: 0.001440, Accuracy: 99.83%\n",
      "Batch 91, Loss: 0.000397, Accuracy: 99.83%\n",
      "Batch 92, Loss: 0.016891, Accuracy: 99.83%\n",
      "Batch 93, Loss: 0.004212, Accuracy: 99.83%\n",
      "Batch 94, Loss: 0.000969, Accuracy: 99.83%\n",
      "Batch 95, Loss: 0.143041, Accuracy: 99.80%\n",
      "Batch 96, Loss: 0.000205, Accuracy: 99.80%\n",
      "Batch 97, Loss: 0.000202, Accuracy: 99.81%\n",
      "Batch 98, Loss: 0.002615, Accuracy: 99.81%\n",
      "Batch 99, Loss: 0.001851, Accuracy: 99.81%\n",
      "Batch 100, Loss: 0.080897, Accuracy: 99.80%\n",
      "Batch 101, Loss: 0.253444, Accuracy: 99.75%\n",
      "Batch 102, Loss: 0.116447, Accuracy: 99.72%\n",
      "Batch 103, Loss: 0.026878, Accuracy: 99.71%\n",
      "Batch 104, Loss: 0.001151, Accuracy: 99.71%\n",
      "Batch 105, Loss: 0.001668, Accuracy: 99.72%\n",
      "Batch 106, Loss: 0.001327, Accuracy: 99.72%\n",
      "Batch 107, Loss: 0.023007, Accuracy: 99.71%\n",
      "Batch 108, Loss: 0.001150, Accuracy: 99.71%\n",
      "Batch 109, Loss: 0.047139, Accuracy: 99.70%\n",
      "Batch 110, Loss: 0.008712, Accuracy: 99.70%\n",
      "Batch 111, Loss: 0.160132, Accuracy: 99.66%\n",
      "Batch 112, Loss: 0.010867, Accuracy: 99.67%\n",
      "Batch 113, Loss: 0.137052, Accuracy: 99.60%\n",
      "Batch 114, Loss: 0.030304, Accuracy: 99.59%\n",
      "Batch 115, Loss: 0.016433, Accuracy: 99.59%\n",
      "Batch 116, Loss: 0.014192, Accuracy: 99.60%\n",
      "Batch 117, Loss: 0.003298, Accuracy: 99.60%\n",
      "Batch 118, Loss: 0.012644, Accuracy: 99.60%\n",
      "Batch 119, Loss: 0.003610, Accuracy: 99.61%\n",
      "Batch 120, Loss: 0.005589, Accuracy: 99.61%\n",
      "Batch 121, Loss: 0.005776, Accuracy: 99.61%\n",
      "Batch 122, Loss: 0.021114, Accuracy: 99.62%\n",
      "Batch 123, Loss: 0.007710, Accuracy: 99.62%\n",
      "Batch 124, Loss: 0.007842, Accuracy: 99.62%\n",
      "Batch 125, Loss: 0.016193, Accuracy: 99.62%\n",
      "Batch 126, Loss: 0.003980, Accuracy: 99.63%\n",
      "Batch 127, Loss: 0.074786, Accuracy: 99.61%\n",
      "Batch 128, Loss: 0.054999, Accuracy: 99.60%\n",
      "Batch 129, Loss: 0.003074, Accuracy: 99.60%\n",
      "Batch 130, Loss: 0.021221, Accuracy: 99.59%\n",
      "Batch 131, Loss: 0.007859, Accuracy: 99.59%\n",
      "Batch 132, Loss: 0.065574, Accuracy: 99.59%\n",
      "Batch 133, Loss: 0.032579, Accuracy: 99.58%\n",
      "Batch 134, Loss: 0.010604, Accuracy: 99.58%\n",
      "Batch 135, Loss: 0.000824, Accuracy: 99.58%\n",
      "Batch 136, Loss: 0.054394, Accuracy: 99.57%\n",
      "Batch 137, Loss: 0.048714, Accuracy: 99.57%\n",
      "Batch 138, Loss: 0.020072, Accuracy: 99.56%\n",
      "Batch 139, Loss: 0.028487, Accuracy: 99.55%\n",
      "Batch 140, Loss: 0.000800, Accuracy: 99.55%\n",
      "Batch 141, Loss: 0.000601, Accuracy: 99.56%\n",
      "Batch 142, Loss: 0.000989, Accuracy: 99.56%\n",
      "Batch 143, Loss: 0.001561, Accuracy: 99.56%\n",
      "Batch 144, Loss: 0.009074, Accuracy: 99.57%\n",
      "Batch 145, Loss: 0.007587, Accuracy: 99.57%\n",
      "Batch 146, Loss: 0.001026, Accuracy: 99.57%\n",
      "Batch 147, Loss: 0.027620, Accuracy: 99.56%\n",
      "Batch 148, Loss: 0.001730, Accuracy: 99.57%\n",
      "Batch 149, Loss: 0.017564, Accuracy: 99.56%\n",
      "Batch 150, Loss: 0.002451, Accuracy: 99.56%\n",
      "Batch 151, Loss: 0.002937, Accuracy: 99.57%\n",
      "Batch 152, Loss: 0.102166, Accuracy: 99.56%\n",
      "Batch 153, Loss: 0.015793, Accuracy: 99.56%\n",
      "Batch 154, Loss: 0.004050, Accuracy: 99.56%\n",
      "Batch 155, Loss: 0.012673, Accuracy: 99.56%\n",
      "Batch 156, Loss: 0.000814, Accuracy: 99.56%\n",
      "Batch 157, Loss: 0.007734, Accuracy: 99.56%\n",
      "Batch 158, Loss: 0.053864, Accuracy: 99.55%\n",
      "Batch 159, Loss: 0.012558, Accuracy: 99.56%\n",
      "Batch 160, Loss: 0.025344, Accuracy: 99.55%\n",
      "Batch 161, Loss: 0.021815, Accuracy: 99.54%\n",
      "Batch 162, Loss: 0.021872, Accuracy: 99.54%\n",
      "Batch 163, Loss: 0.000642, Accuracy: 99.54%\n",
      "Batch 164, Loss: 0.008235, Accuracy: 99.54%\n",
      "Batch 165, Loss: 0.001392, Accuracy: 99.55%\n",
      "Batch 166, Loss: 0.033843, Accuracy: 99.54%\n",
      "Batch 167, Loss: 0.069769, Accuracy: 99.53%\n",
      "Batch 168, Loss: 0.003434, Accuracy: 99.53%\n",
      "Batch 169, Loss: 0.005608, Accuracy: 99.54%\n",
      "Batch 170, Loss: 0.012376, Accuracy: 99.54%\n",
      "Batch 171, Loss: 0.077716, Accuracy: 99.53%\n",
      "Batch 172, Loss: 0.011545, Accuracy: 99.54%\n",
      "Batch 173, Loss: 0.009904, Accuracy: 99.54%\n",
      "Batch 174, Loss: 0.006438, Accuracy: 99.54%\n",
      "Batch 175, Loss: 0.000617, Accuracy: 99.54%\n",
      "Batch 176, Loss: 0.027546, Accuracy: 99.54%\n",
      "Batch 177, Loss: 0.006749, Accuracy: 99.54%\n",
      "Batch 178, Loss: 0.002241, Accuracy: 99.54%\n",
      "Batch 179, Loss: 0.001247, Accuracy: 99.55%\n",
      "Batch 180, Loss: 0.019976, Accuracy: 99.54%\n",
      "Batch 181, Loss: 0.003468, Accuracy: 99.54%\n",
      "Batch 182, Loss: 0.005445, Accuracy: 99.54%\n",
      "Batch 183, Loss: 0.082944, Accuracy: 99.52%\n",
      "Batch 184, Loss: 0.003666, Accuracy: 99.52%\n",
      "Batch 185, Loss: 0.000329, Accuracy: 99.53%\n",
      "Batch 186, Loss: 0.039901, Accuracy: 99.52%\n",
      "Batch 187, Loss: 0.000558, Accuracy: 99.52%\n",
      "Batch 188, Loss: 0.000989, Accuracy: 99.53%\n",
      "Batch 189, Loss: 0.005177, Accuracy: 99.53%\n",
      "Batch 190, Loss: 0.000383, Accuracy: 99.53%\n",
      "Batch 191, Loss: 0.009385, Accuracy: 99.53%\n",
      "Batch 192, Loss: 0.001052, Accuracy: 99.54%\n",
      "Batch 193, Loss: 0.001385, Accuracy: 99.54%\n",
      "Batch 194, Loss: 0.000836, Accuracy: 99.54%\n",
      "Batch 195, Loss: 0.031965, Accuracy: 99.54%\n",
      "Batch 196, Loss: 0.002578, Accuracy: 99.54%\n",
      "Batch 197, Loss: 0.000425, Accuracy: 99.54%\n",
      "Batch 198, Loss: 0.022936, Accuracy: 99.53%\n",
      "Batch 199, Loss: 0.000756, Accuracy: 99.54%\n",
      "Batch 200, Loss: 0.000806, Accuracy: 99.54%\n",
      "Batch 201, Loss: 0.000458, Accuracy: 99.54%\n",
      "Batch 202, Loss: 0.003155, Accuracy: 99.54%\n",
      "Batch 203, Loss: 0.000373, Accuracy: 99.55%\n",
      "Batch 204, Loss: 0.001529, Accuracy: 99.55%\n",
      "Batch 205, Loss: 0.001085, Accuracy: 99.55%\n",
      "Batch 206, Loss: 0.007990, Accuracy: 99.55%\n",
      "Batch 207, Loss: 0.002577, Accuracy: 99.55%\n",
      "Batch 208, Loss: 0.087621, Accuracy: 99.54%\n",
      "Batch 209, Loss: 0.033473, Accuracy: 99.53%\n",
      "Batch 210, Loss: 0.002184, Accuracy: 99.53%\n",
      "Batch 211, Loss: 0.055514, Accuracy: 99.53%\n",
      "Batch 212, Loss: 0.000844, Accuracy: 99.53%\n",
      "Batch 213, Loss: 0.068909, Accuracy: 99.52%\n",
      "Training - Epoch 34, Loss: 0.015591, Accuracy: 99.52%\n",
      "Validation Batch 1, Loss: 0.004528, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.094478, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.006024, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.001371, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.035316, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.066025, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.086449, Accuracy: 98.88%\n",
      "Validation Batch 8, Loss: 0.055920, Accuracy: 98.83%\n",
      "Validation Batch 9, Loss: 0.105510, Accuracy: 98.78%\n",
      "Validation Batch 10, Loss: 0.045684, Accuracy: 98.75%\n",
      "Validation Batch 11, Loss: 0.091296, Accuracy: 98.72%\n",
      "Validation Batch 12, Loss: 0.042996, Accuracy: 98.70%\n",
      "Validation Batch 13, Loss: 0.081317, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.016121, Accuracy: 98.77%\n",
      "Validation Batch 15, Loss: 0.070565, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.126791, Accuracy: 98.54%\n",
      "Validation Batch 17, Loss: 0.143219, Accuracy: 98.35%\n",
      "Validation Batch 18, Loss: 0.027683, Accuracy: 98.35%\n",
      "Validation Batch 19, Loss: 0.073982, Accuracy: 98.36%\n",
      "Validation Batch 20, Loss: 0.042789, Accuracy: 98.36%\n",
      "Validation Batch 21, Loss: 0.150971, Accuracy: 98.29%\n",
      "Validation Batch 22, Loss: 0.027854, Accuracy: 98.30%\n",
      "Validation Batch 23, Loss: 0.013794, Accuracy: 98.37%\n",
      "Validation Batch 24, Loss: 0.071297, Accuracy: 98.37%\n",
      "Validation Batch 25, Loss: 0.008965, Accuracy: 98.44%\n",
      "Validation Batch 26, Loss: 0.140860, Accuracy: 98.38%\n",
      "Validation Batch 27, Loss: 0.101032, Accuracy: 98.36%\n",
      "Validation - Epoch 34, Loss: 0.064179, Accuracy: 98.36%\n",
      "Patience—12\n",
      "Epoch 35\n",
      "Batch 1, Loss: 0.005778, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.005738, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.161809, Accuracy: 97.92%\n",
      "Batch 4, Loss: 0.000810, Accuracy: 98.44%\n",
      "Batch 5, Loss: 0.001322, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.024363, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.001258, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.024862, Accuracy: 98.83%\n",
      "Batch 9, Loss: 0.001729, Accuracy: 98.96%\n",
      "Batch 10, Loss: 0.118051, Accuracy: 98.75%\n",
      "Batch 11, Loss: 0.122067, Accuracy: 98.72%\n",
      "Batch 12, Loss: 0.000784, Accuracy: 98.83%\n",
      "Batch 13, Loss: 0.002257, Accuracy: 98.92%\n",
      "Batch 14, Loss: 0.131675, Accuracy: 98.66%\n",
      "Batch 15, Loss: 0.002615, Accuracy: 98.75%\n",
      "Batch 16, Loss: 0.037913, Accuracy: 98.73%\n",
      "Batch 17, Loss: 0.004793, Accuracy: 98.81%\n",
      "Batch 18, Loss: 0.005453, Accuracy: 98.87%\n",
      "Batch 19, Loss: 0.010975, Accuracy: 98.93%\n",
      "Batch 20, Loss: 0.009515, Accuracy: 98.98%\n",
      "Batch 21, Loss: 0.016665, Accuracy: 99.03%\n",
      "Batch 22, Loss: 0.011007, Accuracy: 99.08%\n",
      "Batch 23, Loss: 0.010229, Accuracy: 99.12%\n",
      "Batch 24, Loss: 0.022742, Accuracy: 99.09%\n",
      "Batch 25, Loss: 0.017762, Accuracy: 99.12%\n",
      "Batch 26, Loss: 0.006323, Accuracy: 99.16%\n",
      "Batch 27, Loss: 0.010739, Accuracy: 99.19%\n",
      "Batch 28, Loss: 0.061815, Accuracy: 99.16%\n",
      "Batch 29, Loss: 0.003171, Accuracy: 99.19%\n",
      "Batch 30, Loss: 0.009236, Accuracy: 99.22%\n",
      "Batch 31, Loss: 0.002564, Accuracy: 99.24%\n",
      "Batch 32, Loss: 0.033541, Accuracy: 99.17%\n",
      "Batch 33, Loss: 0.001689, Accuracy: 99.20%\n",
      "Batch 34, Loss: 0.001664, Accuracy: 99.22%\n",
      "Batch 35, Loss: 0.002917, Accuracy: 99.24%\n",
      "Batch 36, Loss: 0.005772, Accuracy: 99.26%\n",
      "Batch 37, Loss: 0.025521, Accuracy: 99.24%\n",
      "Batch 38, Loss: 0.001333, Accuracy: 99.26%\n",
      "Batch 39, Loss: 0.000528, Accuracy: 99.28%\n",
      "Batch 40, Loss: 0.008223, Accuracy: 99.30%\n",
      "Batch 41, Loss: 0.001760, Accuracy: 99.31%\n",
      "Batch 42, Loss: 0.017285, Accuracy: 99.29%\n",
      "Batch 43, Loss: 0.000854, Accuracy: 99.31%\n",
      "Batch 44, Loss: 0.010897, Accuracy: 99.33%\n",
      "Batch 45, Loss: 0.001146, Accuracy: 99.34%\n",
      "Batch 46, Loss: 0.001217, Accuracy: 99.35%\n",
      "Batch 47, Loss: 0.002283, Accuracy: 99.37%\n",
      "Batch 48, Loss: 0.005077, Accuracy: 99.38%\n",
      "Batch 49, Loss: 0.079904, Accuracy: 99.36%\n",
      "Batch 50, Loss: 0.025135, Accuracy: 99.34%\n",
      "Batch 51, Loss: 0.000518, Accuracy: 99.36%\n",
      "Batch 52, Loss: 0.001354, Accuracy: 99.37%\n",
      "Batch 53, Loss: 0.059621, Accuracy: 99.35%\n",
      "Batch 54, Loss: 0.001514, Accuracy: 99.36%\n",
      "Batch 55, Loss: 0.098830, Accuracy: 99.35%\n",
      "Batch 56, Loss: 0.000845, Accuracy: 99.36%\n",
      "Batch 57, Loss: 0.000949, Accuracy: 99.37%\n",
      "Batch 58, Loss: 0.000532, Accuracy: 99.38%\n",
      "Batch 59, Loss: 0.153298, Accuracy: 99.36%\n",
      "Batch 60, Loss: 0.006630, Accuracy: 99.38%\n",
      "Batch 61, Loss: 0.072726, Accuracy: 99.36%\n",
      "Batch 62, Loss: 0.010488, Accuracy: 99.37%\n",
      "Batch 63, Loss: 0.038038, Accuracy: 99.33%\n",
      "Batch 64, Loss: 0.005094, Accuracy: 99.34%\n",
      "Batch 65, Loss: 0.000929, Accuracy: 99.35%\n",
      "Batch 66, Loss: 0.000518, Accuracy: 99.36%\n",
      "Batch 67, Loss: 0.002428, Accuracy: 99.37%\n",
      "Batch 68, Loss: 0.004152, Accuracy: 99.38%\n",
      "Batch 69, Loss: 0.004273, Accuracy: 99.39%\n",
      "Batch 70, Loss: 0.039674, Accuracy: 99.38%\n",
      "Batch 71, Loss: 0.006427, Accuracy: 99.38%\n",
      "Batch 72, Loss: 0.001391, Accuracy: 99.39%\n",
      "Batch 73, Loss: 0.002436, Accuracy: 99.40%\n",
      "Batch 74, Loss: 0.002161, Accuracy: 99.41%\n",
      "Batch 75, Loss: 0.003053, Accuracy: 99.42%\n",
      "Batch 76, Loss: 0.001230, Accuracy: 99.42%\n",
      "Batch 77, Loss: 0.000672, Accuracy: 99.43%\n",
      "Batch 78, Loss: 0.004897, Accuracy: 99.44%\n",
      "Batch 79, Loss: 0.004519, Accuracy: 99.45%\n",
      "Batch 80, Loss: 0.001560, Accuracy: 99.45%\n",
      "Batch 81, Loss: 0.022847, Accuracy: 99.44%\n",
      "Batch 82, Loss: 0.001973, Accuracy: 99.45%\n",
      "Batch 83, Loss: 0.000756, Accuracy: 99.45%\n",
      "Batch 84, Loss: 0.004788, Accuracy: 99.46%\n",
      "Batch 85, Loss: 0.041578, Accuracy: 99.45%\n",
      "Batch 86, Loss: 0.000649, Accuracy: 99.45%\n",
      "Batch 87, Loss: 0.002259, Accuracy: 99.46%\n",
      "Batch 88, Loss: 0.000518, Accuracy: 99.47%\n",
      "Batch 89, Loss: 0.003175, Accuracy: 99.47%\n",
      "Batch 90, Loss: 0.005701, Accuracy: 99.48%\n",
      "Batch 91, Loss: 0.006232, Accuracy: 99.48%\n",
      "Batch 92, Loss: 0.003309, Accuracy: 99.49%\n",
      "Batch 93, Loss: 0.000716, Accuracy: 99.50%\n",
      "Batch 94, Loss: 0.000987, Accuracy: 99.50%\n",
      "Batch 95, Loss: 0.019642, Accuracy: 99.49%\n",
      "Batch 96, Loss: 0.007118, Accuracy: 99.50%\n",
      "Batch 97, Loss: 0.013437, Accuracy: 99.48%\n",
      "Batch 98, Loss: 0.000383, Accuracy: 99.49%\n",
      "Batch 99, Loss: 0.026067, Accuracy: 99.48%\n",
      "Batch 100, Loss: 0.000645, Accuracy: 99.48%\n",
      "Batch 101, Loss: 0.002937, Accuracy: 99.49%\n",
      "Batch 102, Loss: 0.000350, Accuracy: 99.49%\n",
      "Batch 103, Loss: 0.016881, Accuracy: 99.48%\n",
      "Batch 104, Loss: 0.015309, Accuracy: 99.47%\n",
      "Batch 105, Loss: 0.025922, Accuracy: 99.46%\n",
      "Batch 106, Loss: 0.000760, Accuracy: 99.47%\n",
      "Batch 107, Loss: 0.066947, Accuracy: 99.46%\n",
      "Batch 108, Loss: 0.000911, Accuracy: 99.46%\n",
      "Batch 109, Loss: 0.000754, Accuracy: 99.47%\n",
      "Batch 110, Loss: 0.001734, Accuracy: 99.47%\n",
      "Batch 111, Loss: 0.053725, Accuracy: 99.47%\n",
      "Batch 112, Loss: 0.005417, Accuracy: 99.47%\n",
      "Batch 113, Loss: 0.001444, Accuracy: 99.47%\n",
      "Batch 114, Loss: 0.001615, Accuracy: 99.48%\n",
      "Batch 115, Loss: 0.004325, Accuracy: 99.48%\n",
      "Batch 116, Loss: 0.016950, Accuracy: 99.47%\n",
      "Batch 117, Loss: 0.001107, Accuracy: 99.48%\n",
      "Batch 118, Loss: 0.045630, Accuracy: 99.47%\n",
      "Batch 119, Loss: 0.002985, Accuracy: 99.47%\n",
      "Batch 120, Loss: 0.017036, Accuracy: 99.47%\n",
      "Batch 121, Loss: 0.107772, Accuracy: 99.44%\n",
      "Batch 122, Loss: 0.000924, Accuracy: 99.45%\n",
      "Batch 123, Loss: 0.040537, Accuracy: 99.44%\n",
      "Batch 124, Loss: 0.004961, Accuracy: 99.45%\n",
      "Batch 125, Loss: 0.023285, Accuracy: 99.44%\n",
      "Batch 126, Loss: 0.004157, Accuracy: 99.44%\n",
      "Batch 127, Loss: 0.001602, Accuracy: 99.45%\n",
      "Batch 128, Loss: 0.011355, Accuracy: 99.45%\n",
      "Batch 129, Loss: 0.005570, Accuracy: 99.45%\n",
      "Batch 130, Loss: 0.010100, Accuracy: 99.46%\n",
      "Batch 131, Loss: 0.015925, Accuracy: 99.45%\n",
      "Batch 132, Loss: 0.004908, Accuracy: 99.46%\n",
      "Batch 133, Loss: 0.023856, Accuracy: 99.46%\n",
      "Batch 134, Loss: 0.044927, Accuracy: 99.45%\n",
      "Batch 135, Loss: 0.013031, Accuracy: 99.46%\n",
      "Batch 136, Loss: 0.002476, Accuracy: 99.46%\n",
      "Batch 137, Loss: 0.000780, Accuracy: 99.46%\n",
      "Batch 138, Loss: 0.003445, Accuracy: 99.47%\n",
      "Batch 139, Loss: 0.004165, Accuracy: 99.47%\n",
      "Batch 140, Loss: 0.000971, Accuracy: 99.48%\n",
      "Batch 141, Loss: 0.011676, Accuracy: 99.48%\n",
      "Batch 142, Loss: 0.022779, Accuracy: 99.47%\n",
      "Batch 143, Loss: 0.026321, Accuracy: 99.46%\n",
      "Batch 144, Loss: 0.041409, Accuracy: 99.46%\n",
      "Batch 145, Loss: 0.000356, Accuracy: 99.46%\n",
      "Batch 146, Loss: 0.005081, Accuracy: 99.46%\n",
      "Batch 147, Loss: 0.000246, Accuracy: 99.47%\n",
      "Batch 148, Loss: 0.000559, Accuracy: 99.47%\n",
      "Batch 149, Loss: 0.000418, Accuracy: 99.48%\n",
      "Batch 150, Loss: 0.000551, Accuracy: 99.48%\n",
      "Batch 151, Loss: 0.000455, Accuracy: 99.48%\n",
      "Batch 152, Loss: 0.005656, Accuracy: 99.49%\n",
      "Batch 153, Loss: 0.054045, Accuracy: 99.48%\n",
      "Batch 154, Loss: 0.000789, Accuracy: 99.48%\n",
      "Batch 155, Loss: 0.000352, Accuracy: 99.49%\n",
      "Batch 156, Loss: 0.000655, Accuracy: 99.49%\n",
      "Batch 157, Loss: 0.038640, Accuracy: 99.47%\n",
      "Batch 158, Loss: 0.063906, Accuracy: 99.47%\n",
      "Batch 159, Loss: 0.000310, Accuracy: 99.47%\n",
      "Batch 160, Loss: 0.003510, Accuracy: 99.47%\n",
      "Batch 161, Loss: 0.012524, Accuracy: 99.48%\n",
      "Batch 162, Loss: 0.012421, Accuracy: 99.48%\n",
      "Batch 163, Loss: 0.090130, Accuracy: 99.46%\n",
      "Batch 164, Loss: 0.093748, Accuracy: 99.44%\n",
      "Batch 165, Loss: 0.003777, Accuracy: 99.44%\n",
      "Batch 166, Loss: 0.009416, Accuracy: 99.44%\n",
      "Batch 167, Loss: 0.000337, Accuracy: 99.45%\n",
      "Batch 168, Loss: 0.016644, Accuracy: 99.44%\n",
      "Batch 169, Loss: 0.063635, Accuracy: 99.44%\n",
      "Batch 170, Loss: 0.002501, Accuracy: 99.44%\n",
      "Batch 171, Loss: 0.000708, Accuracy: 99.44%\n",
      "Batch 172, Loss: 0.021026, Accuracy: 99.44%\n",
      "Batch 173, Loss: 0.056506, Accuracy: 99.43%\n",
      "Batch 174, Loss: 0.026399, Accuracy: 99.43%\n",
      "Batch 175, Loss: 0.011635, Accuracy: 99.43%\n",
      "Batch 176, Loss: 0.001612, Accuracy: 99.43%\n",
      "Batch 177, Loss: 0.006488, Accuracy: 99.44%\n",
      "Batch 178, Loss: 0.000296, Accuracy: 99.44%\n",
      "Batch 179, Loss: 0.005298, Accuracy: 99.44%\n",
      "Batch 180, Loss: 0.007881, Accuracy: 99.44%\n",
      "Batch 181, Loss: 0.090422, Accuracy: 99.42%\n",
      "Batch 182, Loss: 0.089963, Accuracy: 99.41%\n",
      "Batch 183, Loss: 0.144458, Accuracy: 99.39%\n",
      "Batch 184, Loss: 0.038184, Accuracy: 99.38%\n",
      "Batch 185, Loss: 0.001804, Accuracy: 99.38%\n",
      "Batch 186, Loss: 0.003476, Accuracy: 99.39%\n",
      "Batch 187, Loss: 0.031291, Accuracy: 99.38%\n",
      "Batch 188, Loss: 0.030725, Accuracy: 99.38%\n",
      "Batch 189, Loss: 0.003832, Accuracy: 99.38%\n",
      "Batch 190, Loss: 0.029955, Accuracy: 99.38%\n",
      "Batch 191, Loss: 0.026196, Accuracy: 99.37%\n",
      "Batch 192, Loss: 0.007074, Accuracy: 99.37%\n",
      "Batch 193, Loss: 0.002063, Accuracy: 99.38%\n",
      "Batch 194, Loss: 0.158821, Accuracy: 99.36%\n",
      "Batch 195, Loss: 0.003999, Accuracy: 99.36%\n",
      "Batch 196, Loss: 0.004200, Accuracy: 99.36%\n",
      "Batch 197, Loss: 0.042642, Accuracy: 99.36%\n",
      "Batch 198, Loss: 0.003116, Accuracy: 99.36%\n",
      "Batch 199, Loss: 0.001651, Accuracy: 99.36%\n",
      "Batch 200, Loss: 0.001404, Accuracy: 99.37%\n",
      "Batch 201, Loss: 0.007991, Accuracy: 99.37%\n",
      "Batch 202, Loss: 0.002695, Accuracy: 99.37%\n",
      "Batch 203, Loss: 0.001945, Accuracy: 99.38%\n",
      "Batch 204, Loss: 0.045607, Accuracy: 99.37%\n",
      "Batch 205, Loss: 0.002742, Accuracy: 99.38%\n",
      "Batch 206, Loss: 0.030241, Accuracy: 99.37%\n",
      "Batch 207, Loss: 0.061003, Accuracy: 99.37%\n",
      "Batch 208, Loss: 0.007081, Accuracy: 99.37%\n",
      "Batch 209, Loss: 0.001266, Accuracy: 99.37%\n",
      "Batch 210, Loss: 0.034541, Accuracy: 99.36%\n",
      "Batch 211, Loss: 0.028737, Accuracy: 99.36%\n",
      "Batch 212, Loss: 0.000735, Accuracy: 99.36%\n",
      "Batch 213, Loss: 0.001728, Accuracy: 99.36%\n",
      "Training - Epoch 35, Loss: 0.018949, Accuracy: 99.36%\n",
      "Validation Batch 1, Loss: 0.001117, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.031018, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.022269, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.011274, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.004980, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.004670, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.002207, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.014496, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.023736, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.011764, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.055742, Accuracy: 99.57%\n",
      "Validation Batch 12, Loss: 0.006824, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.064947, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.001926, Accuracy: 99.44%\n",
      "Validation Batch 15, Loss: 0.064837, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.007342, Accuracy: 99.32%\n",
      "Validation Batch 17, Loss: 0.084899, Accuracy: 99.17%\n",
      "Validation Batch 18, Loss: 0.041830, Accuracy: 99.13%\n",
      "Validation Batch 19, Loss: 0.024702, Accuracy: 99.18%\n",
      "Validation Batch 20, Loss: 0.002056, Accuracy: 99.22%\n",
      "Validation Batch 21, Loss: 0.064529, Accuracy: 99.11%\n",
      "Validation Batch 22, Loss: 0.056218, Accuracy: 99.08%\n",
      "Validation Batch 23, Loss: 0.003354, Accuracy: 99.12%\n",
      "Validation Batch 24, Loss: 0.033160, Accuracy: 99.15%\n",
      "Validation Batch 25, Loss: 0.015918, Accuracy: 99.12%\n",
      "Validation Batch 26, Loss: 0.066677, Accuracy: 99.04%\n",
      "Validation Batch 27, Loss: 0.015919, Accuracy: 99.06%\n",
      "Validation - Epoch 35, Loss: 0.027349, Accuracy: 99.06%\n",
      "Patience—13\n",
      "Epoch 36\n",
      "Batch 1, Loss: 0.003834, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.005325, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.010595, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000877, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000919, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.001350, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.013640, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.005115, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.001740, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.002556, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.001923, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.002929, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.001301, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.040831, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.004909, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.004216, Accuracy: 99.90%\n",
      "Batch 17, Loss: 0.035673, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.006857, Accuracy: 99.83%\n",
      "Batch 19, Loss: 0.003463, Accuracy: 99.84%\n",
      "Batch 20, Loss: 0.001962, Accuracy: 99.84%\n",
      "Batch 21, Loss: 0.001575, Accuracy: 99.85%\n",
      "Batch 22, Loss: 0.000713, Accuracy: 99.86%\n",
      "Batch 23, Loss: 0.000704, Accuracy: 99.86%\n",
      "Batch 24, Loss: 0.001008, Accuracy: 99.87%\n",
      "Batch 25, Loss: 0.018194, Accuracy: 99.81%\n",
      "Batch 26, Loss: 0.002839, Accuracy: 99.82%\n",
      "Batch 27, Loss: 0.000462, Accuracy: 99.83%\n",
      "Batch 28, Loss: 0.003080, Accuracy: 99.83%\n",
      "Batch 29, Loss: 0.003255, Accuracy: 99.84%\n",
      "Batch 30, Loss: 0.077412, Accuracy: 99.74%\n",
      "Batch 31, Loss: 0.006813, Accuracy: 99.75%\n",
      "Batch 32, Loss: 0.024678, Accuracy: 99.71%\n",
      "Batch 33, Loss: 0.010030, Accuracy: 99.72%\n",
      "Batch 34, Loss: 0.000515, Accuracy: 99.72%\n",
      "Batch 35, Loss: 0.000781, Accuracy: 99.73%\n",
      "Batch 36, Loss: 0.002470, Accuracy: 99.74%\n",
      "Batch 37, Loss: 0.000379, Accuracy: 99.75%\n",
      "Batch 38, Loss: 0.002909, Accuracy: 99.75%\n",
      "Batch 39, Loss: 0.001398, Accuracy: 99.76%\n",
      "Batch 40, Loss: 0.085937, Accuracy: 99.73%\n",
      "Batch 41, Loss: 0.074982, Accuracy: 99.70%\n",
      "Batch 42, Loss: 0.002184, Accuracy: 99.70%\n",
      "Batch 43, Loss: 0.001985, Accuracy: 99.71%\n",
      "Batch 44, Loss: 0.008363, Accuracy: 99.72%\n",
      "Batch 45, Loss: 0.124414, Accuracy: 99.69%\n",
      "Batch 46, Loss: 0.045601, Accuracy: 99.66%\n",
      "Batch 47, Loss: 0.001096, Accuracy: 99.67%\n",
      "Batch 48, Loss: 0.000985, Accuracy: 99.67%\n",
      "Batch 49, Loss: 0.001781, Accuracy: 99.68%\n",
      "Batch 50, Loss: 0.007233, Accuracy: 99.69%\n",
      "Batch 51, Loss: 0.004106, Accuracy: 99.69%\n",
      "Batch 52, Loss: 0.001704, Accuracy: 99.70%\n",
      "Batch 53, Loss: 0.004874, Accuracy: 99.71%\n",
      "Batch 54, Loss: 0.057409, Accuracy: 99.65%\n",
      "Batch 55, Loss: 0.018820, Accuracy: 99.66%\n",
      "Batch 56, Loss: 0.003442, Accuracy: 99.67%\n",
      "Batch 57, Loss: 0.001491, Accuracy: 99.67%\n",
      "Batch 58, Loss: 0.200358, Accuracy: 99.60%\n",
      "Batch 59, Loss: 0.057683, Accuracy: 99.58%\n",
      "Batch 60, Loss: 0.015682, Accuracy: 99.56%\n",
      "Batch 61, Loss: 0.006313, Accuracy: 99.56%\n",
      "Batch 62, Loss: 0.032330, Accuracy: 99.55%\n",
      "Batch 63, Loss: 0.001538, Accuracy: 99.55%\n",
      "Batch 64, Loss: 0.001881, Accuracy: 99.56%\n",
      "Batch 65, Loss: 0.015733, Accuracy: 99.54%\n",
      "Batch 66, Loss: 0.016184, Accuracy: 99.55%\n",
      "Batch 67, Loss: 0.009028, Accuracy: 99.56%\n",
      "Batch 68, Loss: 0.101198, Accuracy: 99.54%\n",
      "Batch 69, Loss: 0.002385, Accuracy: 99.55%\n",
      "Batch 70, Loss: 0.007744, Accuracy: 99.55%\n",
      "Batch 71, Loss: 0.006937, Accuracy: 99.56%\n",
      "Batch 72, Loss: 0.004476, Accuracy: 99.57%\n",
      "Batch 73, Loss: 0.054751, Accuracy: 99.55%\n",
      "Batch 74, Loss: 0.045836, Accuracy: 99.54%\n",
      "Batch 75, Loss: 0.022146, Accuracy: 99.52%\n",
      "Batch 76, Loss: 0.005046, Accuracy: 99.53%\n",
      "Batch 77, Loss: 0.004385, Accuracy: 99.53%\n",
      "Batch 78, Loss: 0.003208, Accuracy: 99.54%\n",
      "Batch 79, Loss: 0.001630, Accuracy: 99.55%\n",
      "Batch 80, Loss: 0.004718, Accuracy: 99.55%\n",
      "Batch 81, Loss: 0.008177, Accuracy: 99.56%\n",
      "Batch 82, Loss: 0.019782, Accuracy: 99.54%\n",
      "Batch 83, Loss: 0.001688, Accuracy: 99.55%\n",
      "Batch 84, Loss: 0.005904, Accuracy: 99.55%\n",
      "Batch 85, Loss: 0.007657, Accuracy: 99.56%\n",
      "Batch 86, Loss: 0.019509, Accuracy: 99.55%\n",
      "Batch 87, Loss: 0.001171, Accuracy: 99.55%\n",
      "Batch 88, Loss: 0.000652, Accuracy: 99.56%\n",
      "Batch 89, Loss: 0.000760, Accuracy: 99.56%\n",
      "Batch 90, Loss: 0.002564, Accuracy: 99.57%\n",
      "Batch 91, Loss: 0.001279, Accuracy: 99.57%\n",
      "Batch 92, Loss: 0.036674, Accuracy: 99.56%\n",
      "Batch 93, Loss: 0.029922, Accuracy: 99.55%\n",
      "Batch 94, Loss: 0.000879, Accuracy: 99.55%\n",
      "Batch 95, Loss: 0.001840, Accuracy: 99.56%\n",
      "Batch 96, Loss: 0.004101, Accuracy: 99.56%\n",
      "Batch 97, Loss: 0.004212, Accuracy: 99.57%\n",
      "Batch 98, Loss: 0.014773, Accuracy: 99.57%\n",
      "Batch 99, Loss: 0.230150, Accuracy: 99.51%\n",
      "Batch 100, Loss: 0.037371, Accuracy: 99.48%\n",
      "Batch 101, Loss: 0.001800, Accuracy: 99.49%\n",
      "Batch 102, Loss: 0.002854, Accuracy: 99.49%\n",
      "Batch 103, Loss: 0.001255, Accuracy: 99.50%\n",
      "Batch 104, Loss: 0.008645, Accuracy: 99.50%\n",
      "Batch 105, Loss: 0.010727, Accuracy: 99.51%\n",
      "Batch 106, Loss: 0.247245, Accuracy: 99.48%\n",
      "Batch 107, Loss: 0.230810, Accuracy: 99.46%\n",
      "Batch 108, Loss: 0.015739, Accuracy: 99.45%\n",
      "Batch 109, Loss: 0.090218, Accuracy: 99.44%\n",
      "Batch 110, Loss: 0.040705, Accuracy: 99.43%\n",
      "Batch 111, Loss: 0.053590, Accuracy: 99.41%\n",
      "Batch 112, Loss: 0.256054, Accuracy: 99.36%\n",
      "Batch 113, Loss: 0.007661, Accuracy: 99.36%\n",
      "Batch 114, Loss: 0.031336, Accuracy: 99.37%\n",
      "Batch 115, Loss: 0.003505, Accuracy: 99.38%\n",
      "Batch 116, Loss: 0.089000, Accuracy: 99.37%\n",
      "Batch 117, Loss: 0.062755, Accuracy: 99.33%\n",
      "Batch 118, Loss: 0.014515, Accuracy: 99.34%\n",
      "Batch 119, Loss: 0.024344, Accuracy: 99.33%\n",
      "Batch 120, Loss: 0.080859, Accuracy: 99.32%\n",
      "Batch 121, Loss: 0.024569, Accuracy: 99.32%\n",
      "Batch 122, Loss: 0.007070, Accuracy: 99.32%\n",
      "Batch 123, Loss: 0.006977, Accuracy: 99.33%\n",
      "Batch 124, Loss: 0.038266, Accuracy: 99.32%\n",
      "Batch 125, Loss: 0.006907, Accuracy: 99.33%\n",
      "Batch 126, Loss: 0.003673, Accuracy: 99.33%\n",
      "Batch 127, Loss: 0.022244, Accuracy: 99.32%\n",
      "Batch 128, Loss: 0.010303, Accuracy: 99.33%\n",
      "Batch 129, Loss: 0.003010, Accuracy: 99.33%\n",
      "Batch 130, Loss: 0.002256, Accuracy: 99.34%\n",
      "Batch 131, Loss: 0.151296, Accuracy: 99.31%\n",
      "Batch 132, Loss: 0.000926, Accuracy: 99.31%\n",
      "Batch 133, Loss: 0.008779, Accuracy: 99.32%\n",
      "Batch 134, Loss: 0.009564, Accuracy: 99.32%\n",
      "Batch 135, Loss: 0.066964, Accuracy: 99.32%\n",
      "Batch 136, Loss: 0.000757, Accuracy: 99.32%\n",
      "Batch 137, Loss: 0.001316, Accuracy: 99.33%\n",
      "Batch 138, Loss: 0.019512, Accuracy: 99.32%\n",
      "Batch 139, Loss: 0.025096, Accuracy: 99.31%\n",
      "Batch 140, Loss: 0.001087, Accuracy: 99.32%\n",
      "Batch 141, Loss: 0.001606, Accuracy: 99.32%\n",
      "Batch 142, Loss: 0.002515, Accuracy: 99.33%\n",
      "Batch 143, Loss: 0.004711, Accuracy: 99.33%\n",
      "Batch 144, Loss: 0.000636, Accuracy: 99.34%\n",
      "Batch 145, Loss: 0.003518, Accuracy: 99.34%\n",
      "Batch 146, Loss: 0.004212, Accuracy: 99.35%\n",
      "Batch 147, Loss: 0.042917, Accuracy: 99.33%\n",
      "Batch 148, Loss: 0.001195, Accuracy: 99.33%\n",
      "Batch 149, Loss: 0.004793, Accuracy: 99.34%\n",
      "Batch 150, Loss: 0.001259, Accuracy: 99.34%\n",
      "Batch 151, Loss: 0.005504, Accuracy: 99.35%\n",
      "Batch 152, Loss: 0.002378, Accuracy: 99.35%\n",
      "Batch 153, Loss: 0.001511, Accuracy: 99.36%\n",
      "Batch 154, Loss: 0.057471, Accuracy: 99.35%\n",
      "Batch 155, Loss: 0.000975, Accuracy: 99.35%\n",
      "Batch 156, Loss: 0.007681, Accuracy: 99.36%\n",
      "Batch 157, Loss: 0.001604, Accuracy: 99.36%\n",
      "Batch 158, Loss: 0.003166, Accuracy: 99.37%\n",
      "Batch 159, Loss: 0.038354, Accuracy: 99.36%\n",
      "Batch 160, Loss: 0.002435, Accuracy: 99.37%\n",
      "Batch 161, Loss: 0.000808, Accuracy: 99.37%\n",
      "Batch 162, Loss: 0.004442, Accuracy: 99.37%\n",
      "Batch 163, Loss: 0.000705, Accuracy: 99.38%\n",
      "Batch 164, Loss: 0.000444, Accuracy: 99.38%\n",
      "Batch 165, Loss: 0.000861, Accuracy: 99.38%\n",
      "Batch 166, Loss: 0.063894, Accuracy: 99.37%\n",
      "Batch 167, Loss: 0.007951, Accuracy: 99.37%\n",
      "Batch 168, Loss: 0.006962, Accuracy: 99.38%\n",
      "Batch 169, Loss: 0.000383, Accuracy: 99.38%\n",
      "Batch 170, Loss: 0.001631, Accuracy: 99.38%\n",
      "Batch 171, Loss: 0.013323, Accuracy: 99.38%\n",
      "Batch 172, Loss: 0.001847, Accuracy: 99.38%\n",
      "Batch 173, Loss: 0.001373, Accuracy: 99.39%\n",
      "Batch 174, Loss: 0.035975, Accuracy: 99.38%\n",
      "Batch 175, Loss: 0.000929, Accuracy: 99.38%\n",
      "Batch 176, Loss: 0.004163, Accuracy: 99.39%\n",
      "Batch 177, Loss: 0.007913, Accuracy: 99.39%\n",
      "Batch 178, Loss: 0.019056, Accuracy: 99.39%\n",
      "Batch 179, Loss: 0.003536, Accuracy: 99.39%\n",
      "Batch 180, Loss: 0.002691, Accuracy: 99.39%\n",
      "Batch 181, Loss: 0.017892, Accuracy: 99.39%\n",
      "Batch 182, Loss: 0.000494, Accuracy: 99.39%\n",
      "Batch 183, Loss: 0.000450, Accuracy: 99.39%\n",
      "Batch 184, Loss: 0.044513, Accuracy: 99.39%\n",
      "Batch 185, Loss: 0.000388, Accuracy: 99.39%\n",
      "Batch 186, Loss: 0.018323, Accuracy: 99.39%\n",
      "Batch 187, Loss: 0.000414, Accuracy: 99.39%\n",
      "Batch 188, Loss: 0.000475, Accuracy: 99.39%\n",
      "Batch 189, Loss: 0.052694, Accuracy: 99.39%\n",
      "Batch 190, Loss: 0.000226, Accuracy: 99.39%\n",
      "Batch 191, Loss: 0.000742, Accuracy: 99.39%\n",
      "Batch 192, Loss: 0.001726, Accuracy: 99.40%\n",
      "Batch 193, Loss: 0.000219, Accuracy: 99.40%\n",
      "Batch 194, Loss: 0.002301, Accuracy: 99.40%\n",
      "Batch 195, Loss: 0.000280, Accuracy: 99.41%\n",
      "Batch 196, Loss: 0.001038, Accuracy: 99.41%\n",
      "Batch 197, Loss: 0.008852, Accuracy: 99.41%\n",
      "Batch 198, Loss: 0.000730, Accuracy: 99.42%\n",
      "Batch 199, Loss: 0.000692, Accuracy: 99.42%\n",
      "Batch 200, Loss: 0.003126, Accuracy: 99.42%\n",
      "Batch 201, Loss: 0.000942, Accuracy: 99.42%\n",
      "Batch 202, Loss: 0.002197, Accuracy: 99.43%\n",
      "Batch 203, Loss: 0.000517, Accuracy: 99.43%\n",
      "Batch 204, Loss: 0.000455, Accuracy: 99.43%\n",
      "Batch 205, Loss: 0.110046, Accuracy: 99.43%\n",
      "Batch 206, Loss: 0.001730, Accuracy: 99.43%\n",
      "Batch 207, Loss: 0.002203, Accuracy: 99.43%\n",
      "Batch 208, Loss: 0.000824, Accuracy: 99.44%\n",
      "Batch 209, Loss: 0.001139, Accuracy: 99.44%\n",
      "Batch 210, Loss: 0.011595, Accuracy: 99.44%\n",
      "Batch 211, Loss: 0.007305, Accuracy: 99.44%\n",
      "Batch 212, Loss: 0.001165, Accuracy: 99.45%\n",
      "Batch 213, Loss: 0.004985, Accuracy: 99.45%\n",
      "Training - Epoch 36, Loss: 0.019522, Accuracy: 99.45%\n",
      "Validation Batch 1, Loss: 0.053018, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.011572, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.071641, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.005186, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.026866, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.000672, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.004443, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.004006, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.004042, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.001963, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.145224, Accuracy: 99.29%\n",
      "Validation Batch 12, Loss: 0.007000, Accuracy: 99.35%\n",
      "Validation Batch 13, Loss: 0.002113, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.138743, Accuracy: 99.33%\n",
      "Validation Batch 15, Loss: 0.022747, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.011626, Accuracy: 99.32%\n",
      "Validation Batch 17, Loss: 0.061694, Accuracy: 99.26%\n",
      "Validation Batch 18, Loss: 0.001184, Accuracy: 99.31%\n",
      "Validation Batch 19, Loss: 0.003573, Accuracy: 99.34%\n",
      "Validation Batch 20, Loss: 0.016645, Accuracy: 99.30%\n",
      "Validation Batch 21, Loss: 0.013141, Accuracy: 99.33%\n",
      "Validation Batch 22, Loss: 0.004633, Accuracy: 99.36%\n",
      "Validation Batch 23, Loss: 0.003553, Accuracy: 99.39%\n",
      "Validation Batch 24, Loss: 0.088964, Accuracy: 99.35%\n",
      "Validation Batch 25, Loss: 0.011854, Accuracy: 99.38%\n",
      "Validation Batch 26, Loss: 0.009333, Accuracy: 99.40%\n",
      "Validation Batch 27, Loss: 0.002043, Accuracy: 99.41%\n",
      "Validation - Epoch 36, Loss: 0.026944, Accuracy: 99.41%\n",
      "Patience—14\n",
      "Epoch 37\n",
      "Batch 1, Loss: 0.002452, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.013520, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000660, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.055749, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.000677, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.004992, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.001154, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.001050, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.000550, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.000511, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.002690, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.001422, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.026504, Accuracy: 99.76%\n",
      "Batch 14, Loss: 0.000719, Accuracy: 99.78%\n",
      "Batch 15, Loss: 0.002124, Accuracy: 99.79%\n",
      "Batch 16, Loss: 0.063308, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.018680, Accuracy: 99.63%\n",
      "Batch 18, Loss: 0.069140, Accuracy: 99.48%\n",
      "Batch 19, Loss: 0.002646, Accuracy: 99.51%\n",
      "Batch 20, Loss: 0.000523, Accuracy: 99.53%\n",
      "Batch 21, Loss: 0.000608, Accuracy: 99.55%\n",
      "Batch 22, Loss: 0.004521, Accuracy: 99.57%\n",
      "Batch 23, Loss: 0.031625, Accuracy: 99.52%\n",
      "Batch 24, Loss: 0.002583, Accuracy: 99.54%\n",
      "Batch 25, Loss: 0.001984, Accuracy: 99.56%\n",
      "Batch 26, Loss: 0.000707, Accuracy: 99.58%\n",
      "Batch 27, Loss: 0.001996, Accuracy: 99.59%\n",
      "Batch 28, Loss: 0.000847, Accuracy: 99.61%\n",
      "Batch 29, Loss: 0.021162, Accuracy: 99.57%\n",
      "Batch 30, Loss: 0.006806, Accuracy: 99.58%\n",
      "Batch 31, Loss: 0.001202, Accuracy: 99.60%\n",
      "Batch 32, Loss: 0.000688, Accuracy: 99.61%\n",
      "Batch 33, Loss: 0.000542, Accuracy: 99.62%\n",
      "Batch 34, Loss: 0.037998, Accuracy: 99.59%\n",
      "Batch 35, Loss: 0.008199, Accuracy: 99.60%\n",
      "Batch 36, Loss: 0.001022, Accuracy: 99.61%\n",
      "Batch 37, Loss: 0.000924, Accuracy: 99.62%\n",
      "Batch 38, Loss: 0.001634, Accuracy: 99.63%\n",
      "Batch 39, Loss: 0.003771, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.097520, Accuracy: 99.57%\n",
      "Batch 41, Loss: 0.000897, Accuracy: 99.58%\n",
      "Batch 42, Loss: 0.122841, Accuracy: 99.55%\n",
      "Batch 43, Loss: 0.003568, Accuracy: 99.56%\n",
      "Batch 44, Loss: 0.001084, Accuracy: 99.57%\n",
      "Batch 45, Loss: 0.010172, Accuracy: 99.58%\n",
      "Batch 46, Loss: 0.001289, Accuracy: 99.59%\n",
      "Batch 47, Loss: 0.000986, Accuracy: 99.60%\n",
      "Batch 48, Loss: 0.012106, Accuracy: 99.61%\n",
      "Batch 49, Loss: 0.003224, Accuracy: 99.62%\n",
      "Batch 50, Loss: 0.039923, Accuracy: 99.59%\n",
      "Batch 51, Loss: 0.139206, Accuracy: 99.54%\n",
      "Batch 52, Loss: 0.002330, Accuracy: 99.55%\n",
      "Batch 53, Loss: 0.007091, Accuracy: 99.56%\n",
      "Batch 54, Loss: 0.001404, Accuracy: 99.57%\n",
      "Batch 55, Loss: 0.002912, Accuracy: 99.57%\n",
      "Batch 56, Loss: 0.000681, Accuracy: 99.58%\n",
      "Batch 57, Loss: 0.000593, Accuracy: 99.59%\n",
      "Batch 58, Loss: 0.000902, Accuracy: 99.60%\n",
      "Batch 59, Loss: 0.000399, Accuracy: 99.60%\n",
      "Batch 60, Loss: 0.120267, Accuracy: 99.53%\n",
      "Batch 61, Loss: 0.004790, Accuracy: 99.54%\n",
      "Batch 62, Loss: 0.036546, Accuracy: 99.52%\n",
      "Batch 63, Loss: 0.001529, Accuracy: 99.53%\n",
      "Batch 64, Loss: 0.009030, Accuracy: 99.54%\n",
      "Batch 65, Loss: 0.001750, Accuracy: 99.54%\n",
      "Batch 66, Loss: 0.001501, Accuracy: 99.55%\n",
      "Batch 67, Loss: 0.068940, Accuracy: 99.53%\n",
      "Batch 68, Loss: 0.048418, Accuracy: 99.52%\n",
      "Batch 69, Loss: 0.010884, Accuracy: 99.52%\n",
      "Batch 70, Loss: 0.016537, Accuracy: 99.51%\n",
      "Batch 71, Loss: 0.010199, Accuracy: 99.52%\n",
      "Batch 72, Loss: 0.004133, Accuracy: 99.52%\n",
      "Batch 73, Loss: 0.019581, Accuracy: 99.51%\n",
      "Batch 74, Loss: 0.002413, Accuracy: 99.51%\n",
      "Batch 75, Loss: 0.001614, Accuracy: 99.52%\n",
      "Batch 76, Loss: 0.049258, Accuracy: 99.51%\n",
      "Batch 77, Loss: 0.000988, Accuracy: 99.51%\n",
      "Batch 78, Loss: 0.001990, Accuracy: 99.52%\n",
      "Batch 79, Loss: 0.059799, Accuracy: 99.51%\n",
      "Batch 80, Loss: 0.063903, Accuracy: 99.49%\n",
      "Batch 81, Loss: 0.017937, Accuracy: 99.50%\n",
      "Batch 82, Loss: 0.033059, Accuracy: 99.49%\n",
      "Batch 83, Loss: 0.011081, Accuracy: 99.49%\n",
      "Batch 84, Loss: 0.038696, Accuracy: 99.48%\n",
      "Batch 85, Loss: 0.001339, Accuracy: 99.49%\n",
      "Batch 86, Loss: 0.001631, Accuracy: 99.49%\n",
      "Batch 87, Loss: 0.012607, Accuracy: 99.50%\n",
      "Batch 88, Loss: 0.008821, Accuracy: 99.50%\n",
      "Batch 89, Loss: 0.085076, Accuracy: 99.49%\n",
      "Batch 90, Loss: 0.002747, Accuracy: 99.50%\n",
      "Batch 91, Loss: 0.002428, Accuracy: 99.50%\n",
      "Batch 92, Loss: 0.023629, Accuracy: 99.49%\n",
      "Batch 93, Loss: 0.001634, Accuracy: 99.50%\n",
      "Batch 94, Loss: 0.002406, Accuracy: 99.50%\n",
      "Batch 95, Loss: 0.002387, Accuracy: 99.51%\n",
      "Batch 96, Loss: 0.000791, Accuracy: 99.51%\n",
      "Batch 97, Loss: 0.007124, Accuracy: 99.52%\n",
      "Batch 98, Loss: 0.005794, Accuracy: 99.52%\n",
      "Batch 99, Loss: 0.002724, Accuracy: 99.53%\n",
      "Batch 100, Loss: 0.011003, Accuracy: 99.53%\n",
      "Batch 101, Loss: 0.067078, Accuracy: 99.52%\n",
      "Batch 102, Loss: 0.068227, Accuracy: 99.51%\n",
      "Batch 103, Loss: 0.018683, Accuracy: 99.50%\n",
      "Batch 104, Loss: 0.001754, Accuracy: 99.50%\n",
      "Batch 105, Loss: 0.000607, Accuracy: 99.51%\n",
      "Batch 106, Loss: 0.043299, Accuracy: 99.50%\n",
      "Batch 107, Loss: 0.015847, Accuracy: 99.49%\n",
      "Batch 108, Loss: 0.132566, Accuracy: 99.46%\n",
      "Batch 109, Loss: 0.013646, Accuracy: 99.47%\n",
      "Batch 110, Loss: 0.027950, Accuracy: 99.46%\n",
      "Batch 111, Loss: 0.001705, Accuracy: 99.47%\n",
      "Batch 112, Loss: 0.008523, Accuracy: 99.47%\n",
      "Batch 113, Loss: 0.002039, Accuracy: 99.47%\n",
      "Batch 114, Loss: 0.028356, Accuracy: 99.47%\n",
      "Batch 115, Loss: 0.002328, Accuracy: 99.47%\n",
      "Batch 116, Loss: 0.002763, Accuracy: 99.47%\n",
      "Batch 117, Loss: 0.002895, Accuracy: 99.48%\n",
      "Batch 118, Loss: 0.004203, Accuracy: 99.48%\n",
      "Batch 119, Loss: 0.002775, Accuracy: 99.49%\n",
      "Batch 120, Loss: 0.009395, Accuracy: 99.49%\n",
      "Batch 121, Loss: 0.002910, Accuracy: 99.50%\n",
      "Batch 122, Loss: 0.117400, Accuracy: 99.49%\n",
      "Batch 123, Loss: 0.010547, Accuracy: 99.49%\n",
      "Batch 124, Loss: 0.040876, Accuracy: 99.46%\n",
      "Batch 125, Loss: 0.009333, Accuracy: 99.46%\n",
      "Batch 126, Loss: 0.017535, Accuracy: 99.45%\n",
      "Batch 127, Loss: 0.001882, Accuracy: 99.46%\n",
      "Batch 128, Loss: 0.012102, Accuracy: 99.46%\n",
      "Batch 129, Loss: 0.012800, Accuracy: 99.47%\n",
      "Batch 130, Loss: 0.039647, Accuracy: 99.46%\n",
      "Batch 131, Loss: 0.000869, Accuracy: 99.46%\n",
      "Batch 132, Loss: 0.103933, Accuracy: 99.46%\n",
      "Batch 133, Loss: 0.002219, Accuracy: 99.46%\n",
      "Batch 134, Loss: 0.001348, Accuracy: 99.46%\n",
      "Batch 135, Loss: 0.001632, Accuracy: 99.47%\n",
      "Batch 136, Loss: 0.054356, Accuracy: 99.45%\n",
      "Batch 137, Loss: 0.051175, Accuracy: 99.44%\n",
      "Batch 138, Loss: 0.003631, Accuracy: 99.45%\n",
      "Batch 139, Loss: 0.000518, Accuracy: 99.45%\n",
      "Batch 140, Loss: 0.003490, Accuracy: 99.45%\n",
      "Batch 141, Loss: 0.017141, Accuracy: 99.45%\n",
      "Batch 142, Loss: 0.025603, Accuracy: 99.44%\n",
      "Batch 143, Loss: 0.000718, Accuracy: 99.44%\n",
      "Batch 144, Loss: 0.001752, Accuracy: 99.45%\n",
      "Batch 145, Loss: 0.011074, Accuracy: 99.45%\n",
      "Batch 146, Loss: 0.005957, Accuracy: 99.45%\n",
      "Batch 147, Loss: 0.010401, Accuracy: 99.46%\n",
      "Batch 148, Loss: 0.069645, Accuracy: 99.45%\n",
      "Batch 149, Loss: 0.004413, Accuracy: 99.45%\n",
      "Batch 150, Loss: 0.004757, Accuracy: 99.46%\n",
      "Batch 151, Loss: 0.007461, Accuracy: 99.46%\n",
      "Batch 152, Loss: 0.003121, Accuracy: 99.47%\n",
      "Batch 153, Loss: 0.004182, Accuracy: 99.47%\n",
      "Batch 154, Loss: 0.001912, Accuracy: 99.47%\n",
      "Batch 155, Loss: 0.000998, Accuracy: 99.48%\n",
      "Batch 156, Loss: 0.003649, Accuracy: 99.48%\n",
      "Batch 157, Loss: 0.017465, Accuracy: 99.48%\n",
      "Batch 158, Loss: 0.001590, Accuracy: 99.49%\n",
      "Batch 159, Loss: 0.000765, Accuracy: 99.49%\n",
      "Batch 160, Loss: 0.003755, Accuracy: 99.49%\n",
      "Batch 161, Loss: 0.024508, Accuracy: 99.49%\n",
      "Batch 162, Loss: 0.005365, Accuracy: 99.49%\n",
      "Batch 163, Loss: 0.001098, Accuracy: 99.49%\n",
      "Batch 164, Loss: 0.002817, Accuracy: 99.50%\n",
      "Batch 165, Loss: 0.000790, Accuracy: 99.50%\n",
      "Batch 166, Loss: 0.036675, Accuracy: 99.49%\n",
      "Batch 167, Loss: 0.000993, Accuracy: 99.49%\n",
      "Batch 168, Loss: 0.041868, Accuracy: 99.49%\n",
      "Batch 169, Loss: 0.009903, Accuracy: 99.49%\n",
      "Batch 170, Loss: 0.000523, Accuracy: 99.49%\n",
      "Batch 171, Loss: 0.003779, Accuracy: 99.50%\n",
      "Batch 172, Loss: 0.087016, Accuracy: 99.49%\n",
      "Batch 173, Loss: 0.001447, Accuracy: 99.49%\n",
      "Batch 174, Loss: 0.000875, Accuracy: 99.50%\n",
      "Batch 175, Loss: 0.005147, Accuracy: 99.50%\n",
      "Batch 176, Loss: 0.001813, Accuracy: 99.50%\n",
      "Batch 177, Loss: 0.002655, Accuracy: 99.51%\n",
      "Batch 178, Loss: 0.000647, Accuracy: 99.51%\n",
      "Batch 179, Loss: 0.002833, Accuracy: 99.51%\n",
      "Batch 180, Loss: 0.000516, Accuracy: 99.51%\n",
      "Batch 181, Loss: 0.036719, Accuracy: 99.51%\n",
      "Batch 182, Loss: 0.017618, Accuracy: 99.51%\n",
      "Batch 183, Loss: 0.003352, Accuracy: 99.51%\n",
      "Batch 184, Loss: 0.000973, Accuracy: 99.52%\n",
      "Batch 185, Loss: 0.000623, Accuracy: 99.52%\n",
      "Batch 186, Loss: 0.000747, Accuracy: 99.52%\n",
      "Batch 187, Loss: 0.001041, Accuracy: 99.52%\n",
      "Batch 188, Loss: 0.001270, Accuracy: 99.53%\n",
      "Batch 189, Loss: 0.026141, Accuracy: 99.52%\n",
      "Batch 190, Loss: 0.001773, Accuracy: 99.52%\n",
      "Batch 191, Loss: 0.072824, Accuracy: 99.52%\n",
      "Batch 192, Loss: 0.136805, Accuracy: 99.50%\n",
      "Batch 193, Loss: 0.005507, Accuracy: 99.51%\n",
      "Batch 194, Loss: 0.004237, Accuracy: 99.51%\n",
      "Batch 195, Loss: 0.047490, Accuracy: 99.50%\n",
      "Batch 196, Loss: 0.003975, Accuracy: 99.50%\n",
      "Batch 197, Loss: 0.000488, Accuracy: 99.50%\n",
      "Batch 198, Loss: 0.006672, Accuracy: 99.50%\n",
      "Batch 199, Loss: 0.068606, Accuracy: 99.50%\n",
      "Batch 200, Loss: 0.004377, Accuracy: 99.50%\n",
      "Batch 201, Loss: 0.001640, Accuracy: 99.50%\n",
      "Batch 202, Loss: 0.002041, Accuracy: 99.50%\n",
      "Batch 203, Loss: 0.000916, Accuracy: 99.51%\n",
      "Batch 204, Loss: 0.026809, Accuracy: 99.50%\n",
      "Batch 205, Loss: 0.019175, Accuracy: 99.50%\n",
      "Batch 206, Loss: 0.023805, Accuracy: 99.49%\n",
      "Batch 207, Loss: 0.003137, Accuracy: 99.49%\n",
      "Batch 208, Loss: 0.001328, Accuracy: 99.50%\n",
      "Batch 209, Loss: 0.058666, Accuracy: 99.49%\n",
      "Batch 210, Loss: 0.005028, Accuracy: 99.49%\n",
      "Batch 211, Loss: 0.000311, Accuracy: 99.50%\n",
      "Batch 212, Loss: 0.017341, Accuracy: 99.50%\n",
      "Batch 213, Loss: 0.002053, Accuracy: 99.50%\n",
      "Training - Epoch 37, Loss: 0.017033, Accuracy: 99.50%\n",
      "Validation Batch 1, Loss: 0.001014, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.106812, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.001042, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.145233, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.054941, Accuracy: 98.44%\n",
      "Validation Batch 6, Loss: 0.022255, Accuracy: 98.44%\n",
      "Validation Batch 7, Loss: 0.035493, Accuracy: 98.21%\n",
      "Validation Batch 8, Loss: 0.010466, Accuracy: 98.44%\n",
      "Validation Batch 9, Loss: 0.029984, Accuracy: 98.44%\n",
      "Validation Batch 10, Loss: 0.000912, Accuracy: 98.59%\n",
      "Validation Batch 11, Loss: 0.006142, Accuracy: 98.72%\n",
      "Validation Batch 12, Loss: 0.013549, Accuracy: 98.83%\n",
      "Validation Batch 13, Loss: 0.002250, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.000590, Accuracy: 99.00%\n",
      "Validation Batch 15, Loss: 0.012888, Accuracy: 99.06%\n",
      "Validation Batch 16, Loss: 0.005536, Accuracy: 99.12%\n",
      "Validation Batch 17, Loss: 0.161063, Accuracy: 99.08%\n",
      "Validation Batch 18, Loss: 0.003923, Accuracy: 99.13%\n",
      "Validation Batch 19, Loss: 0.017102, Accuracy: 99.10%\n",
      "Validation Batch 20, Loss: 0.071205, Accuracy: 99.06%\n",
      "Validation Batch 21, Loss: 0.001119, Accuracy: 99.11%\n",
      "Validation Batch 22, Loss: 0.154135, Accuracy: 99.01%\n",
      "Validation Batch 23, Loss: 0.080083, Accuracy: 98.91%\n",
      "Validation Batch 24, Loss: 0.043056, Accuracy: 98.89%\n",
      "Validation Batch 25, Loss: 0.013350, Accuracy: 98.88%\n",
      "Validation Batch 26, Loss: 0.002500, Accuracy: 98.92%\n",
      "Validation Batch 27, Loss: 0.079347, Accuracy: 98.88%\n",
      "Validation - Epoch 37, Loss: 0.039851, Accuracy: 98.88%\n",
      "Patience—15\n",
      "Epoch 38\n",
      "Batch 1, Loss: 0.000521, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001134, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.002159, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.065907, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.000825, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.000500, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.010767, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.000586, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.000815, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.001151, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.002186, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.001214, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.000421, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.000630, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.000706, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.000549, Accuracy: 99.90%\n",
      "Batch 17, Loss: 0.085062, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.017960, Accuracy: 99.74%\n",
      "Batch 19, Loss: 0.015395, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.000560, Accuracy: 99.69%\n",
      "Batch 21, Loss: 0.000818, Accuracy: 99.70%\n",
      "Batch 22, Loss: 0.010038, Accuracy: 99.72%\n",
      "Batch 23, Loss: 0.001020, Accuracy: 99.73%\n",
      "Batch 24, Loss: 0.002367, Accuracy: 99.74%\n",
      "Batch 25, Loss: 0.004762, Accuracy: 99.75%\n",
      "Batch 26, Loss: 0.003423, Accuracy: 99.76%\n",
      "Batch 27, Loss: 0.043604, Accuracy: 99.65%\n",
      "Batch 28, Loss: 0.002175, Accuracy: 99.67%\n",
      "Batch 29, Loss: 0.001760, Accuracy: 99.68%\n",
      "Batch 30, Loss: 0.002572, Accuracy: 99.69%\n",
      "Batch 31, Loss: 0.026078, Accuracy: 99.65%\n",
      "Batch 32, Loss: 0.000623, Accuracy: 99.66%\n",
      "Batch 33, Loss: 0.027505, Accuracy: 99.62%\n",
      "Batch 34, Loss: 0.023585, Accuracy: 99.59%\n",
      "Batch 35, Loss: 0.073083, Accuracy: 99.55%\n",
      "Batch 36, Loss: 0.000826, Accuracy: 99.57%\n",
      "Batch 37, Loss: 0.002055, Accuracy: 99.58%\n",
      "Batch 38, Loss: 0.021314, Accuracy: 99.55%\n",
      "Batch 39, Loss: 0.004991, Accuracy: 99.56%\n",
      "Batch 40, Loss: 0.000718, Accuracy: 99.57%\n",
      "Batch 41, Loss: 0.001044, Accuracy: 99.58%\n",
      "Batch 42, Loss: 0.048095, Accuracy: 99.55%\n",
      "Batch 43, Loss: 0.020953, Accuracy: 99.53%\n",
      "Batch 44, Loss: 0.005543, Accuracy: 99.54%\n",
      "Batch 45, Loss: 0.001124, Accuracy: 99.55%\n",
      "Batch 46, Loss: 0.020824, Accuracy: 99.52%\n",
      "Batch 47, Loss: 0.001645, Accuracy: 99.53%\n",
      "Batch 48, Loss: 0.001215, Accuracy: 99.54%\n",
      "Batch 49, Loss: 0.004001, Accuracy: 99.55%\n",
      "Batch 50, Loss: 0.002982, Accuracy: 99.56%\n",
      "Batch 51, Loss: 0.004865, Accuracy: 99.57%\n",
      "Batch 52, Loss: 0.002441, Accuracy: 99.58%\n",
      "Batch 53, Loss: 0.000639, Accuracy: 99.59%\n",
      "Batch 54, Loss: 0.002175, Accuracy: 99.59%\n",
      "Batch 55, Loss: 0.002118, Accuracy: 99.60%\n",
      "Batch 56, Loss: 0.001041, Accuracy: 99.61%\n",
      "Batch 57, Loss: 0.003089, Accuracy: 99.62%\n",
      "Batch 58, Loss: 0.032027, Accuracy: 99.60%\n",
      "Batch 59, Loss: 0.000652, Accuracy: 99.60%\n",
      "Batch 60, Loss: 0.000702, Accuracy: 99.61%\n",
      "Batch 61, Loss: 0.001387, Accuracy: 99.62%\n",
      "Batch 62, Loss: 0.002491, Accuracy: 99.62%\n",
      "Batch 63, Loss: 0.000949, Accuracy: 99.63%\n",
      "Batch 64, Loss: 0.063118, Accuracy: 99.61%\n",
      "Batch 65, Loss: 0.001416, Accuracy: 99.62%\n",
      "Batch 66, Loss: 0.000558, Accuracy: 99.62%\n",
      "Batch 67, Loss: 0.000518, Accuracy: 99.63%\n",
      "Batch 68, Loss: 0.000302, Accuracy: 99.63%\n",
      "Batch 69, Loss: 0.001001, Accuracy: 99.64%\n",
      "Batch 70, Loss: 0.000526, Accuracy: 99.64%\n",
      "Batch 71, Loss: 0.015916, Accuracy: 99.63%\n",
      "Batch 72, Loss: 0.004021, Accuracy: 99.63%\n",
      "Batch 73, Loss: 0.000904, Accuracy: 99.64%\n",
      "Batch 74, Loss: 0.000625, Accuracy: 99.64%\n",
      "Batch 75, Loss: 0.001176, Accuracy: 99.65%\n",
      "Batch 76, Loss: 0.007570, Accuracy: 99.65%\n",
      "Batch 77, Loss: 0.000835, Accuracy: 99.66%\n",
      "Batch 78, Loss: 0.000930, Accuracy: 99.66%\n",
      "Batch 79, Loss: 0.000278, Accuracy: 99.66%\n",
      "Batch 80, Loss: 0.000375, Accuracy: 99.67%\n",
      "Batch 81, Loss: 0.006446, Accuracy: 99.67%\n",
      "Batch 82, Loss: 0.002778, Accuracy: 99.68%\n",
      "Batch 83, Loss: 0.063859, Accuracy: 99.66%\n",
      "Batch 84, Loss: 0.001528, Accuracy: 99.67%\n",
      "Batch 85, Loss: 0.000954, Accuracy: 99.67%\n",
      "Batch 86, Loss: 0.000534, Accuracy: 99.67%\n",
      "Batch 87, Loss: 0.001872, Accuracy: 99.68%\n",
      "Batch 88, Loss: 0.000708, Accuracy: 99.68%\n",
      "Batch 89, Loss: 0.000556, Accuracy: 99.68%\n",
      "Batch 90, Loss: 0.001494, Accuracy: 99.69%\n",
      "Batch 91, Loss: 0.000344, Accuracy: 99.69%\n",
      "Batch 92, Loss: 0.004041, Accuracy: 99.69%\n",
      "Batch 93, Loss: 0.001058, Accuracy: 99.70%\n",
      "Batch 94, Loss: 0.000747, Accuracy: 99.70%\n",
      "Batch 95, Loss: 0.029239, Accuracy: 99.69%\n",
      "Batch 96, Loss: 0.025682, Accuracy: 99.67%\n",
      "Batch 97, Loss: 0.000486, Accuracy: 99.68%\n",
      "Batch 98, Loss: 0.000366, Accuracy: 99.68%\n",
      "Batch 99, Loss: 0.000599, Accuracy: 99.68%\n",
      "Batch 100, Loss: 0.000836, Accuracy: 99.69%\n",
      "Batch 101, Loss: 0.000354, Accuracy: 99.69%\n",
      "Batch 102, Loss: 0.030263, Accuracy: 99.68%\n",
      "Batch 103, Loss: 0.000593, Accuracy: 99.68%\n",
      "Batch 104, Loss: 0.000408, Accuracy: 99.68%\n",
      "Batch 105, Loss: 0.001502, Accuracy: 99.69%\n",
      "Batch 106, Loss: 0.009589, Accuracy: 99.69%\n",
      "Batch 107, Loss: 0.000805, Accuracy: 99.69%\n",
      "Batch 108, Loss: 0.000317, Accuracy: 99.70%\n",
      "Batch 109, Loss: 0.000131, Accuracy: 99.70%\n",
      "Batch 110, Loss: 0.035497, Accuracy: 99.69%\n",
      "Batch 111, Loss: 0.000967, Accuracy: 99.69%\n",
      "Batch 112, Loss: 0.000794, Accuracy: 99.69%\n",
      "Batch 113, Loss: 0.003190, Accuracy: 99.70%\n",
      "Batch 114, Loss: 0.000204, Accuracy: 99.70%\n",
      "Batch 115, Loss: 0.011884, Accuracy: 99.69%\n",
      "Batch 116, Loss: 0.005200, Accuracy: 99.69%\n",
      "Batch 117, Loss: 0.000169, Accuracy: 99.69%\n",
      "Batch 118, Loss: 0.000261, Accuracy: 99.70%\n",
      "Batch 119, Loss: 0.000192, Accuracy: 99.70%\n",
      "Batch 120, Loss: 0.000445, Accuracy: 99.70%\n",
      "Batch 121, Loss: 0.000373, Accuracy: 99.70%\n",
      "Batch 122, Loss: 0.000325, Accuracy: 99.71%\n",
      "Batch 123, Loss: 0.001179, Accuracy: 99.71%\n",
      "Batch 124, Loss: 0.001474, Accuracy: 99.71%\n",
      "Batch 125, Loss: 0.000243, Accuracy: 99.71%\n",
      "Batch 126, Loss: 0.000977, Accuracy: 99.71%\n",
      "Batch 127, Loss: 0.000772, Accuracy: 99.72%\n",
      "Batch 128, Loss: 0.000995, Accuracy: 99.72%\n",
      "Batch 129, Loss: 0.000068, Accuracy: 99.72%\n",
      "Batch 130, Loss: 0.001922, Accuracy: 99.72%\n",
      "Batch 131, Loss: 0.000206, Accuracy: 99.73%\n",
      "Batch 132, Loss: 0.000441, Accuracy: 99.73%\n",
      "Batch 133, Loss: 0.074077, Accuracy: 99.72%\n",
      "Batch 134, Loss: 0.000169, Accuracy: 99.72%\n",
      "Batch 135, Loss: 0.001406, Accuracy: 99.72%\n",
      "Batch 136, Loss: 0.000100, Accuracy: 99.72%\n",
      "Batch 137, Loss: 0.000501, Accuracy: 99.73%\n",
      "Batch 138, Loss: 0.000116, Accuracy: 99.73%\n",
      "Batch 139, Loss: 0.035404, Accuracy: 99.72%\n",
      "Batch 140, Loss: 0.005034, Accuracy: 99.72%\n",
      "Batch 141, Loss: 0.025046, Accuracy: 99.71%\n",
      "Batch 142, Loss: 0.001849, Accuracy: 99.71%\n",
      "Batch 143, Loss: 0.000490, Accuracy: 99.72%\n",
      "Batch 144, Loss: 0.000234, Accuracy: 99.72%\n",
      "Batch 145, Loss: 0.000255, Accuracy: 99.72%\n",
      "Batch 146, Loss: 0.001304, Accuracy: 99.72%\n",
      "Batch 147, Loss: 0.018807, Accuracy: 99.71%\n",
      "Batch 148, Loss: 0.016928, Accuracy: 99.70%\n",
      "Batch 149, Loss: 0.007438, Accuracy: 99.71%\n",
      "Batch 150, Loss: 0.008272, Accuracy: 99.71%\n",
      "Batch 151, Loss: 0.000530, Accuracy: 99.71%\n",
      "Batch 152, Loss: 0.009127, Accuracy: 99.71%\n",
      "Batch 153, Loss: 0.090689, Accuracy: 99.69%\n",
      "Batch 154, Loss: 0.002119, Accuracy: 99.70%\n",
      "Batch 155, Loss: 0.144059, Accuracy: 99.67%\n",
      "Batch 156, Loss: 0.000646, Accuracy: 99.67%\n",
      "Batch 157, Loss: 0.000335, Accuracy: 99.67%\n",
      "Batch 158, Loss: 0.000369, Accuracy: 99.67%\n",
      "Batch 159, Loss: 0.002324, Accuracy: 99.68%\n",
      "Batch 160, Loss: 0.001194, Accuracy: 99.68%\n",
      "Batch 161, Loss: 0.006710, Accuracy: 99.68%\n",
      "Batch 162, Loss: 0.019634, Accuracy: 99.68%\n",
      "Batch 163, Loss: 0.032565, Accuracy: 99.67%\n",
      "Batch 164, Loss: 0.010200, Accuracy: 99.68%\n",
      "Batch 165, Loss: 0.001970, Accuracy: 99.68%\n",
      "Batch 166, Loss: 0.005945, Accuracy: 99.68%\n",
      "Batch 167, Loss: 0.001152, Accuracy: 99.68%\n",
      "Batch 168, Loss: 0.069184, Accuracy: 99.67%\n",
      "Batch 169, Loss: 0.001992, Accuracy: 99.68%\n",
      "Batch 170, Loss: 0.003988, Accuracy: 99.68%\n",
      "Batch 171, Loss: 0.007468, Accuracy: 99.68%\n",
      "Batch 172, Loss: 0.007862, Accuracy: 99.68%\n",
      "Batch 173, Loss: 0.014973, Accuracy: 99.68%\n",
      "Batch 174, Loss: 0.002542, Accuracy: 99.69%\n",
      "Batch 175, Loss: 0.002687, Accuracy: 99.69%\n",
      "Batch 176, Loss: 0.002013, Accuracy: 99.69%\n",
      "Batch 177, Loss: 0.006551, Accuracy: 99.69%\n",
      "Batch 178, Loss: 0.013144, Accuracy: 99.68%\n",
      "Batch 179, Loss: 0.000971, Accuracy: 99.69%\n",
      "Batch 180, Loss: 0.000746, Accuracy: 99.69%\n",
      "Batch 181, Loss: 0.002248, Accuracy: 99.69%\n",
      "Batch 182, Loss: 0.000417, Accuracy: 99.69%\n",
      "Batch 183, Loss: 0.000130, Accuracy: 99.69%\n",
      "Batch 184, Loss: 0.028020, Accuracy: 99.69%\n",
      "Batch 185, Loss: 0.000480, Accuracy: 99.69%\n",
      "Batch 186, Loss: 0.000259, Accuracy: 99.69%\n",
      "Batch 187, Loss: 0.078577, Accuracy: 99.68%\n",
      "Batch 188, Loss: 0.000706, Accuracy: 99.68%\n",
      "Batch 189, Loss: 0.001792, Accuracy: 99.69%\n",
      "Batch 190, Loss: 0.022415, Accuracy: 99.68%\n",
      "Batch 191, Loss: 0.001422, Accuracy: 99.68%\n",
      "Batch 192, Loss: 0.004577, Accuracy: 99.68%\n",
      "Batch 193, Loss: 0.013197, Accuracy: 99.68%\n",
      "Batch 194, Loss: 0.003902, Accuracy: 99.68%\n",
      "Batch 195, Loss: 0.007093, Accuracy: 99.68%\n",
      "Batch 196, Loss: 0.000615, Accuracy: 99.68%\n",
      "Batch 197, Loss: 0.005055, Accuracy: 99.68%\n",
      "Batch 198, Loss: 0.033303, Accuracy: 99.68%\n",
      "Batch 199, Loss: 0.010309, Accuracy: 99.68%\n",
      "Batch 200, Loss: 0.000382, Accuracy: 99.68%\n",
      "Batch 201, Loss: 0.103647, Accuracy: 99.67%\n",
      "Batch 202, Loss: 0.001074, Accuracy: 99.68%\n",
      "Batch 203, Loss: 0.000914, Accuracy: 99.68%\n",
      "Batch 204, Loss: 0.000883, Accuracy: 99.68%\n",
      "Batch 205, Loss: 0.000932, Accuracy: 99.68%\n",
      "Batch 206, Loss: 0.063885, Accuracy: 99.67%\n",
      "Batch 207, Loss: 0.004957, Accuracy: 99.68%\n",
      "Batch 208, Loss: 0.003468, Accuracy: 99.68%\n",
      "Batch 209, Loss: 0.000645, Accuracy: 99.68%\n",
      "Batch 210, Loss: 0.001215, Accuracy: 99.68%\n",
      "Batch 211, Loss: 0.020162, Accuracy: 99.67%\n",
      "Batch 212, Loss: 0.007393, Accuracy: 99.68%\n",
      "Batch 213, Loss: 0.000882, Accuracy: 99.68%\n",
      "Training - Epoch 38, Loss: 0.009701, Accuracy: 99.68%\n",
      "Validation Batch 1, Loss: 0.002056, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.075934, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.000630, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.000967, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.021806, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.003262, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.004564, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.017184, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.001803, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.002099, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.000560, Accuracy: 99.57%\n",
      "Validation Batch 12, Loss: 0.001462, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.001603, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.000744, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.005287, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.003966, Accuracy: 99.71%\n",
      "Validation Batch 17, Loss: 0.053735, Accuracy: 99.63%\n",
      "Validation Batch 18, Loss: 0.000888, Accuracy: 99.65%\n",
      "Validation Batch 19, Loss: 0.051705, Accuracy: 99.51%\n",
      "Validation Batch 20, Loss: 0.001160, Accuracy: 99.53%\n",
      "Validation Batch 21, Loss: 0.000518, Accuracy: 99.55%\n",
      "Validation Batch 22, Loss: 0.001855, Accuracy: 99.57%\n",
      "Validation Batch 23, Loss: 0.008391, Accuracy: 99.59%\n",
      "Validation Batch 24, Loss: 0.055340, Accuracy: 99.48%\n",
      "Validation Batch 25, Loss: 0.002349, Accuracy: 99.50%\n",
      "Validation Batch 26, Loss: 0.001186, Accuracy: 99.52%\n",
      "Validation Batch 27, Loss: 0.024167, Accuracy: 99.47%\n",
      "Validation - Epoch 38, Loss: 0.012786, Accuracy: 99.47%\n",
      "Patience—16\n",
      "Epoch 39\n",
      "Batch 1, Loss: 0.012057, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.000521, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.000483, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.001510, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.000539, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.005739, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.000408, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.000433, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.000345, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.002691, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.000612, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.002616, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.000413, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.000696, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.003002, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.025331, Accuracy: 99.80%\n",
      "Batch 17, Loss: 0.002748, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.001703, Accuracy: 99.83%\n",
      "Batch 19, Loss: 0.000384, Accuracy: 99.84%\n",
      "Batch 20, Loss: 0.000188, Accuracy: 99.84%\n",
      "Batch 21, Loss: 0.000256, Accuracy: 99.85%\n",
      "Batch 22, Loss: 0.002693, Accuracy: 99.86%\n",
      "Batch 23, Loss: 0.000445, Accuracy: 99.86%\n",
      "Batch 24, Loss: 0.000420, Accuracy: 99.87%\n",
      "Batch 25, Loss: 0.000377, Accuracy: 99.88%\n",
      "Batch 26, Loss: 0.016983, Accuracy: 99.82%\n",
      "Batch 27, Loss: 0.000814, Accuracy: 99.83%\n",
      "Batch 28, Loss: 0.000336, Accuracy: 99.83%\n",
      "Batch 29, Loss: 0.000282, Accuracy: 99.84%\n",
      "Batch 30, Loss: 0.000287, Accuracy: 99.84%\n",
      "Batch 31, Loss: 0.000207, Accuracy: 99.85%\n",
      "Batch 32, Loss: 0.005309, Accuracy: 99.85%\n",
      "Batch 33, Loss: 0.000679, Accuracy: 99.86%\n",
      "Batch 34, Loss: 0.001017, Accuracy: 99.86%\n",
      "Batch 35, Loss: 0.001291, Accuracy: 99.87%\n",
      "Batch 36, Loss: 0.009372, Accuracy: 99.87%\n",
      "Batch 37, Loss: 0.000739, Accuracy: 99.87%\n",
      "Batch 38, Loss: 0.000096, Accuracy: 99.88%\n",
      "Batch 39, Loss: 0.001009, Accuracy: 99.88%\n",
      "Batch 40, Loss: 0.000267, Accuracy: 99.88%\n",
      "Batch 41, Loss: 0.038940, Accuracy: 99.85%\n",
      "Batch 42, Loss: 0.000112, Accuracy: 99.85%\n",
      "Batch 43, Loss: 0.000293, Accuracy: 99.85%\n",
      "Batch 44, Loss: 0.000148, Accuracy: 99.86%\n",
      "Batch 45, Loss: 0.000204, Accuracy: 99.86%\n",
      "Batch 46, Loss: 0.000872, Accuracy: 99.86%\n",
      "Batch 47, Loss: 0.055769, Accuracy: 99.83%\n",
      "Batch 48, Loss: 0.000925, Accuracy: 99.84%\n",
      "Batch 49, Loss: 0.000194, Accuracy: 99.84%\n",
      "Batch 50, Loss: 0.001319, Accuracy: 99.84%\n",
      "Batch 51, Loss: 0.000194, Accuracy: 99.85%\n",
      "Batch 52, Loss: 0.000228, Accuracy: 99.85%\n",
      "Batch 53, Loss: 0.002392, Accuracy: 99.85%\n",
      "Batch 54, Loss: 0.005619, Accuracy: 99.86%\n",
      "Batch 55, Loss: 0.008010, Accuracy: 99.86%\n",
      "Batch 56, Loss: 0.005560, Accuracy: 99.86%\n",
      "Batch 57, Loss: 0.002855, Accuracy: 99.86%\n",
      "Batch 58, Loss: 0.000404, Accuracy: 99.87%\n",
      "Batch 59, Loss: 0.007396, Accuracy: 99.87%\n",
      "Batch 60, Loss: 0.000830, Accuracy: 99.87%\n",
      "Batch 61, Loss: 0.000594, Accuracy: 99.87%\n",
      "Batch 62, Loss: 0.000495, Accuracy: 99.87%\n",
      "Batch 63, Loss: 0.000212, Accuracy: 99.88%\n",
      "Batch 64, Loss: 0.000234, Accuracy: 99.88%\n",
      "Batch 65, Loss: 0.000372, Accuracy: 99.88%\n",
      "Batch 66, Loss: 0.000134, Accuracy: 99.88%\n",
      "Batch 67, Loss: 0.000853, Accuracy: 99.88%\n",
      "Batch 68, Loss: 0.000263, Accuracy: 99.89%\n",
      "Batch 69, Loss: 0.000126, Accuracy: 99.89%\n",
      "Batch 70, Loss: 0.000624, Accuracy: 99.89%\n",
      "Batch 71, Loss: 0.000376, Accuracy: 99.89%\n",
      "Batch 72, Loss: 0.002749, Accuracy: 99.89%\n",
      "Batch 73, Loss: 0.000222, Accuracy: 99.89%\n",
      "Batch 74, Loss: 0.000176, Accuracy: 99.89%\n",
      "Batch 75, Loss: 0.000514, Accuracy: 99.90%\n",
      "Batch 76, Loss: 0.001650, Accuracy: 99.90%\n",
      "Batch 77, Loss: 0.000505, Accuracy: 99.90%\n",
      "Batch 78, Loss: 0.000493, Accuracy: 99.90%\n",
      "Batch 79, Loss: 0.000110, Accuracy: 99.90%\n",
      "Batch 80, Loss: 0.001272, Accuracy: 99.90%\n",
      "Batch 81, Loss: 0.000149, Accuracy: 99.90%\n",
      "Batch 82, Loss: 0.000141, Accuracy: 99.90%\n",
      "Batch 83, Loss: 0.002564, Accuracy: 99.91%\n",
      "Batch 84, Loss: 0.019897, Accuracy: 99.89%\n",
      "Batch 85, Loss: 0.000112, Accuracy: 99.89%\n",
      "Batch 86, Loss: 0.000142, Accuracy: 99.89%\n",
      "Batch 87, Loss: 0.000211, Accuracy: 99.89%\n",
      "Batch 88, Loss: 0.000997, Accuracy: 99.89%\n",
      "Batch 89, Loss: 0.000158, Accuracy: 99.89%\n",
      "Batch 90, Loss: 0.000278, Accuracy: 99.90%\n",
      "Batch 91, Loss: 0.002012, Accuracy: 99.90%\n",
      "Batch 92, Loss: 0.128999, Accuracy: 99.88%\n",
      "Batch 93, Loss: 0.000389, Accuracy: 99.88%\n",
      "Batch 94, Loss: 0.000137, Accuracy: 99.88%\n",
      "Batch 95, Loss: 0.000165, Accuracy: 99.88%\n",
      "Batch 96, Loss: 0.000492, Accuracy: 99.89%\n",
      "Batch 97, Loss: 0.001135, Accuracy: 99.89%\n",
      "Batch 98, Loss: 0.000279, Accuracy: 99.89%\n",
      "Batch 99, Loss: 0.000586, Accuracy: 99.89%\n",
      "Batch 100, Loss: 0.019369, Accuracy: 99.88%\n",
      "Batch 101, Loss: 0.000245, Accuracy: 99.88%\n",
      "Batch 102, Loss: 0.032307, Accuracy: 99.86%\n",
      "Batch 103, Loss: 0.000223, Accuracy: 99.86%\n",
      "Batch 104, Loss: 0.001714, Accuracy: 99.86%\n",
      "Batch 105, Loss: 0.001707, Accuracy: 99.87%\n",
      "Batch 106, Loss: 0.015213, Accuracy: 99.85%\n",
      "Batch 107, Loss: 0.005728, Accuracy: 99.85%\n",
      "Batch 108, Loss: 0.000392, Accuracy: 99.86%\n",
      "Batch 109, Loss: 0.000255, Accuracy: 99.86%\n",
      "Batch 110, Loss: 0.000220, Accuracy: 99.86%\n",
      "Batch 111, Loss: 0.000892, Accuracy: 99.86%\n",
      "Batch 112, Loss: 0.000838, Accuracy: 99.86%\n",
      "Batch 113, Loss: 0.000385, Accuracy: 99.86%\n",
      "Batch 114, Loss: 0.012502, Accuracy: 99.85%\n",
      "Batch 115, Loss: 0.082347, Accuracy: 99.84%\n",
      "Batch 116, Loss: 0.001107, Accuracy: 99.84%\n",
      "Batch 117, Loss: 0.088648, Accuracy: 99.83%\n",
      "Batch 118, Loss: 0.004723, Accuracy: 99.83%\n",
      "Batch 119, Loss: 0.000489, Accuracy: 99.83%\n",
      "Batch 120, Loss: 0.000591, Accuracy: 99.83%\n",
      "Batch 121, Loss: 0.005915, Accuracy: 99.83%\n",
      "Batch 122, Loss: 0.001535, Accuracy: 99.83%\n",
      "Batch 123, Loss: 0.041909, Accuracy: 99.82%\n",
      "Batch 124, Loss: 0.002941, Accuracy: 99.82%\n",
      "Batch 125, Loss: 0.000621, Accuracy: 99.83%\n",
      "Batch 126, Loss: 0.000759, Accuracy: 99.83%\n",
      "Batch 127, Loss: 0.002229, Accuracy: 99.83%\n",
      "Batch 128, Loss: 0.002190, Accuracy: 99.83%\n",
      "Batch 129, Loss: 0.002452, Accuracy: 99.83%\n",
      "Batch 130, Loss: 0.009401, Accuracy: 99.83%\n",
      "Batch 131, Loss: 0.034143, Accuracy: 99.81%\n",
      "Batch 132, Loss: 0.004068, Accuracy: 99.81%\n",
      "Batch 133, Loss: 0.004415, Accuracy: 99.81%\n",
      "Batch 134, Loss: 0.024083, Accuracy: 99.80%\n",
      "Batch 135, Loss: 0.001076, Accuracy: 99.80%\n",
      "Batch 136, Loss: 0.045430, Accuracy: 99.78%\n",
      "Batch 137, Loss: 0.000979, Accuracy: 99.78%\n",
      "Batch 138, Loss: 0.004571, Accuracy: 99.78%\n",
      "Batch 139, Loss: 0.001523, Accuracy: 99.79%\n",
      "Batch 140, Loss: 0.002688, Accuracy: 99.79%\n",
      "Batch 141, Loss: 0.027102, Accuracy: 99.78%\n",
      "Batch 142, Loss: 0.001525, Accuracy: 99.78%\n",
      "Batch 143, Loss: 0.029897, Accuracy: 99.77%\n",
      "Batch 144, Loss: 0.004681, Accuracy: 99.77%\n",
      "Batch 145, Loss: 0.003641, Accuracy: 99.77%\n",
      "Batch 146, Loss: 0.000373, Accuracy: 99.78%\n",
      "Batch 147, Loss: 0.001049, Accuracy: 99.78%\n",
      "Batch 148, Loss: 0.000315, Accuracy: 99.78%\n",
      "Batch 149, Loss: 0.001020, Accuracy: 99.78%\n",
      "Batch 150, Loss: 0.000444, Accuracy: 99.78%\n",
      "Batch 151, Loss: 0.001827, Accuracy: 99.78%\n",
      "Batch 152, Loss: 0.001800, Accuracy: 99.78%\n",
      "Batch 153, Loss: 0.043016, Accuracy: 99.78%\n",
      "Batch 154, Loss: 0.000803, Accuracy: 99.78%\n",
      "Batch 155, Loss: 0.016317, Accuracy: 99.77%\n",
      "Batch 156, Loss: 0.000877, Accuracy: 99.77%\n",
      "Batch 157, Loss: 0.019389, Accuracy: 99.76%\n",
      "Batch 158, Loss: 0.000125, Accuracy: 99.76%\n",
      "Batch 159, Loss: 0.045407, Accuracy: 99.75%\n",
      "Batch 160, Loss: 0.042984, Accuracy: 99.74%\n",
      "Batch 161, Loss: 0.003414, Accuracy: 99.74%\n",
      "Batch 162, Loss: 0.001629, Accuracy: 99.74%\n",
      "Batch 163, Loss: 0.079143, Accuracy: 99.73%\n",
      "Batch 164, Loss: 0.014369, Accuracy: 99.73%\n",
      "Batch 165, Loss: 0.002050, Accuracy: 99.73%\n",
      "Batch 166, Loss: 0.041038, Accuracy: 99.73%\n",
      "Batch 167, Loss: 0.021016, Accuracy: 99.72%\n",
      "Batch 168, Loss: 0.003123, Accuracy: 99.72%\n",
      "Batch 169, Loss: 0.005201, Accuracy: 99.72%\n",
      "Batch 170, Loss: 0.001323, Accuracy: 99.72%\n",
      "Batch 171, Loss: 0.148162, Accuracy: 99.70%\n",
      "Batch 172, Loss: 0.014203, Accuracy: 99.70%\n",
      "Batch 173, Loss: 0.015314, Accuracy: 99.69%\n",
      "Batch 174, Loss: 0.009642, Accuracy: 99.69%\n",
      "Batch 175, Loss: 0.004695, Accuracy: 99.70%\n",
      "Batch 176, Loss: 0.052555, Accuracy: 99.69%\n",
      "Batch 177, Loss: 0.000770, Accuracy: 99.69%\n",
      "Batch 178, Loss: 0.039437, Accuracy: 99.68%\n",
      "Batch 179, Loss: 0.001218, Accuracy: 99.69%\n",
      "Batch 180, Loss: 0.015891, Accuracy: 99.69%\n",
      "Batch 181, Loss: 0.002370, Accuracy: 99.69%\n",
      "Batch 182, Loss: 0.001742, Accuracy: 99.69%\n",
      "Batch 183, Loss: 0.004088, Accuracy: 99.69%\n",
      "Batch 184, Loss: 0.013695, Accuracy: 99.69%\n",
      "Batch 185, Loss: 0.001303, Accuracy: 99.69%\n",
      "Batch 186, Loss: 0.001831, Accuracy: 99.69%\n",
      "Batch 187, Loss: 0.004206, Accuracy: 99.69%\n",
      "Batch 188, Loss: 0.002661, Accuracy: 99.69%\n",
      "Batch 189, Loss: 0.004754, Accuracy: 99.69%\n",
      "Batch 190, Loss: 0.012301, Accuracy: 99.69%\n",
      "Batch 191, Loss: 0.004769, Accuracy: 99.69%\n",
      "Batch 192, Loss: 0.131677, Accuracy: 99.67%\n",
      "Batch 193, Loss: 0.006076, Accuracy: 99.68%\n",
      "Batch 194, Loss: 0.008442, Accuracy: 99.68%\n",
      "Batch 195, Loss: 0.059201, Accuracy: 99.67%\n",
      "Batch 196, Loss: 0.022657, Accuracy: 99.67%\n",
      "Batch 197, Loss: 0.002699, Accuracy: 99.67%\n",
      "Batch 198, Loss: 0.045052, Accuracy: 99.66%\n",
      "Batch 199, Loss: 0.001630, Accuracy: 99.66%\n",
      "Batch 200, Loss: 0.013243, Accuracy: 99.66%\n",
      "Batch 201, Loss: 0.002568, Accuracy: 99.67%\n",
      "Batch 202, Loss: 0.004205, Accuracy: 99.67%\n",
      "Batch 203, Loss: 0.000661, Accuracy: 99.67%\n",
      "Batch 204, Loss: 0.015784, Accuracy: 99.67%\n",
      "Batch 205, Loss: 0.003239, Accuracy: 99.67%\n",
      "Batch 206, Loss: 0.013542, Accuracy: 99.67%\n",
      "Batch 207, Loss: 0.016066, Accuracy: 99.67%\n",
      "Batch 208, Loss: 0.001861, Accuracy: 99.67%\n",
      "Batch 209, Loss: 0.041441, Accuracy: 99.66%\n",
      "Batch 210, Loss: 0.001048, Accuracy: 99.67%\n",
      "Batch 211, Loss: 0.026127, Accuracy: 99.66%\n",
      "Batch 212, Loss: 0.000836, Accuracy: 99.66%\n",
      "Batch 213, Loss: 0.000710, Accuracy: 99.66%\n",
      "Training - Epoch 39, Loss: 0.009674, Accuracy: 99.66%\n",
      "Validation Batch 1, Loss: 0.000989, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.007297, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.001797, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.002316, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.001609, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.001667, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.001869, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.083018, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.001706, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.002214, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.003809, Accuracy: 99.72%\n",
      "Validation Batch 12, Loss: 0.019045, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.001977, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.001735, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.005179, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.049632, Accuracy: 99.61%\n",
      "Validation Batch 17, Loss: 0.085199, Accuracy: 99.54%\n",
      "Validation Batch 18, Loss: 0.000988, Accuracy: 99.57%\n",
      "Validation Batch 19, Loss: 0.100570, Accuracy: 99.51%\n",
      "Validation Batch 20, Loss: 0.000731, Accuracy: 99.53%\n",
      "Validation Batch 21, Loss: 0.014522, Accuracy: 99.55%\n",
      "Validation Batch 22, Loss: 0.038381, Accuracy: 99.50%\n",
      "Validation Batch 23, Loss: 0.018235, Accuracy: 99.46%\n",
      "Validation Batch 24, Loss: 0.001233, Accuracy: 99.48%\n",
      "Validation Batch 25, Loss: 0.000618, Accuracy: 99.50%\n",
      "Validation Batch 26, Loss: 0.002621, Accuracy: 99.52%\n",
      "Validation Batch 27, Loss: 0.002007, Accuracy: 99.53%\n",
      "Validation - Epoch 39, Loss: 0.016702, Accuracy: 99.53%\n",
      "Patience—17\n",
      "Epoch 40\n",
      "Batch 1, Loss: 0.000740, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000863, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000843, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.008517, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001397, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.003450, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.002570, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.008330, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.001696, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.027239, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.008873, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.000534, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.006796, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.000373, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.011917, Accuracy: 99.79%\n",
      "Batch 16, Loss: 0.000539, Accuracy: 99.80%\n",
      "Batch 17, Loss: 0.000653, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.000182, Accuracy: 99.83%\n",
      "Batch 19, Loss: 0.001272, Accuracy: 99.84%\n",
      "Batch 20, Loss: 0.000486, Accuracy: 99.84%\n",
      "Batch 21, Loss: 0.001098, Accuracy: 99.85%\n",
      "Batch 22, Loss: 0.000181, Accuracy: 99.86%\n",
      "Batch 23, Loss: 0.000349, Accuracy: 99.86%\n",
      "Batch 24, Loss: 0.008544, Accuracy: 99.87%\n",
      "Batch 25, Loss: 0.000540, Accuracy: 99.88%\n",
      "Batch 26, Loss: 0.000508, Accuracy: 99.88%\n",
      "Batch 27, Loss: 0.007308, Accuracy: 99.88%\n",
      "Batch 28, Loss: 0.000303, Accuracy: 99.89%\n",
      "Batch 29, Loss: 0.000493, Accuracy: 99.89%\n",
      "Batch 30, Loss: 0.005988, Accuracy: 99.90%\n",
      "Batch 31, Loss: 0.000203, Accuracy: 99.90%\n",
      "Batch 32, Loss: 0.000203, Accuracy: 99.90%\n",
      "Batch 33, Loss: 0.000210, Accuracy: 99.91%\n",
      "Batch 34, Loss: 0.002579, Accuracy: 99.91%\n",
      "Batch 35, Loss: 0.000185, Accuracy: 99.91%\n",
      "Batch 36, Loss: 0.000155, Accuracy: 99.91%\n",
      "Batch 37, Loss: 0.003376, Accuracy: 99.92%\n",
      "Batch 38, Loss: 0.000274, Accuracy: 99.92%\n",
      "Batch 39, Loss: 0.000432, Accuracy: 99.92%\n",
      "Batch 40, Loss: 0.000184, Accuracy: 99.92%\n",
      "Batch 41, Loss: 0.001885, Accuracy: 99.92%\n",
      "Batch 42, Loss: 0.000254, Accuracy: 99.93%\n",
      "Batch 43, Loss: 0.002270, Accuracy: 99.93%\n",
      "Batch 44, Loss: 0.000134, Accuracy: 99.93%\n",
      "Batch 45, Loss: 0.000164, Accuracy: 99.93%\n",
      "Batch 46, Loss: 0.000075, Accuracy: 99.93%\n",
      "Batch 47, Loss: 0.000197, Accuracy: 99.93%\n",
      "Batch 48, Loss: 0.000154, Accuracy: 99.93%\n",
      "Batch 49, Loss: 0.000141, Accuracy: 99.94%\n",
      "Batch 50, Loss: 0.000422, Accuracy: 99.94%\n",
      "Batch 51, Loss: 0.000286, Accuracy: 99.94%\n",
      "Batch 52, Loss: 0.006023, Accuracy: 99.94%\n",
      "Batch 53, Loss: 0.000074, Accuracy: 99.94%\n",
      "Batch 54, Loss: 0.000146, Accuracy: 99.94%\n",
      "Batch 55, Loss: 0.000123, Accuracy: 99.94%\n",
      "Batch 56, Loss: 0.003857, Accuracy: 99.94%\n",
      "Batch 57, Loss: 0.000231, Accuracy: 99.95%\n",
      "Batch 58, Loss: 0.000123, Accuracy: 99.95%\n",
      "Batch 59, Loss: 0.000108, Accuracy: 99.95%\n",
      "Batch 60, Loss: 0.000143, Accuracy: 99.95%\n",
      "Batch 61, Loss: 0.000065, Accuracy: 99.95%\n",
      "Batch 62, Loss: 0.000314, Accuracy: 99.95%\n",
      "Batch 63, Loss: 0.008174, Accuracy: 99.95%\n",
      "Batch 64, Loss: 0.000307, Accuracy: 99.95%\n",
      "Batch 65, Loss: 0.000388, Accuracy: 99.95%\n",
      "Batch 66, Loss: 0.000376, Accuracy: 99.95%\n",
      "Batch 67, Loss: 0.000081, Accuracy: 99.95%\n",
      "Batch 68, Loss: 0.001514, Accuracy: 99.95%\n",
      "Batch 69, Loss: 0.000102, Accuracy: 99.95%\n",
      "Batch 70, Loss: 0.000114, Accuracy: 99.96%\n",
      "Batch 71, Loss: 0.000082, Accuracy: 99.96%\n",
      "Batch 72, Loss: 0.000087, Accuracy: 99.96%\n",
      "Batch 73, Loss: 0.001117, Accuracy: 99.96%\n",
      "Batch 74, Loss: 0.000236, Accuracy: 99.96%\n",
      "Batch 75, Loss: 0.000685, Accuracy: 99.96%\n",
      "Batch 76, Loss: 0.000078, Accuracy: 99.96%\n",
      "Batch 77, Loss: 0.000270, Accuracy: 99.96%\n",
      "Batch 78, Loss: 0.018348, Accuracy: 99.94%\n",
      "Batch 79, Loss: 0.000469, Accuracy: 99.94%\n",
      "Batch 80, Loss: 0.003625, Accuracy: 99.94%\n",
      "Batch 81, Loss: 0.000127, Accuracy: 99.94%\n",
      "Batch 82, Loss: 0.000056, Accuracy: 99.94%\n",
      "Batch 83, Loss: 0.000119, Accuracy: 99.94%\n",
      "Batch 84, Loss: 0.000067, Accuracy: 99.94%\n",
      "Batch 85, Loss: 0.002287, Accuracy: 99.94%\n",
      "Batch 86, Loss: 0.000533, Accuracy: 99.95%\n",
      "Batch 87, Loss: 0.003401, Accuracy: 99.95%\n",
      "Batch 88, Loss: 0.000113, Accuracy: 99.95%\n",
      "Batch 89, Loss: 0.000454, Accuracy: 99.95%\n",
      "Batch 90, Loss: 0.000359, Accuracy: 99.95%\n",
      "Batch 91, Loss: 0.003365, Accuracy: 99.95%\n",
      "Batch 92, Loss: 0.000153, Accuracy: 99.95%\n",
      "Batch 93, Loss: 0.000060, Accuracy: 99.95%\n",
      "Batch 94, Loss: 0.000073, Accuracy: 99.95%\n",
      "Batch 95, Loss: 0.067213, Accuracy: 99.93%\n",
      "Batch 96, Loss: 0.000101, Accuracy: 99.93%\n",
      "Batch 97, Loss: 0.000582, Accuracy: 99.94%\n",
      "Batch 98, Loss: 0.000096, Accuracy: 99.94%\n",
      "Batch 99, Loss: 0.000060, Accuracy: 99.94%\n",
      "Batch 100, Loss: 0.120083, Accuracy: 99.92%\n",
      "Batch 101, Loss: 0.028150, Accuracy: 99.91%\n",
      "Batch 102, Loss: 0.163105, Accuracy: 99.86%\n",
      "Batch 103, Loss: 0.000362, Accuracy: 99.86%\n",
      "Batch 104, Loss: 0.000140, Accuracy: 99.86%\n",
      "Batch 105, Loss: 0.001140, Accuracy: 99.87%\n",
      "Batch 106, Loss: 0.001166, Accuracy: 99.87%\n",
      "Batch 107, Loss: 0.065085, Accuracy: 99.84%\n",
      "Batch 108, Loss: 0.002471, Accuracy: 99.84%\n",
      "Batch 109, Loss: 0.023226, Accuracy: 99.83%\n",
      "Batch 110, Loss: 0.001001, Accuracy: 99.83%\n",
      "Batch 111, Loss: 0.012630, Accuracy: 99.82%\n",
      "Batch 112, Loss: 0.022059, Accuracy: 99.82%\n",
      "Batch 113, Loss: 0.008690, Accuracy: 99.82%\n",
      "Batch 114, Loss: 0.090464, Accuracy: 99.79%\n",
      "Batch 115, Loss: 0.001544, Accuracy: 99.80%\n",
      "Batch 116, Loss: 0.013303, Accuracy: 99.80%\n",
      "Batch 117, Loss: 0.068680, Accuracy: 99.79%\n",
      "Batch 118, Loss: 0.032416, Accuracy: 99.77%\n",
      "Batch 119, Loss: 0.008137, Accuracy: 99.78%\n",
      "Batch 120, Loss: 0.003374, Accuracy: 99.78%\n",
      "Batch 121, Loss: 0.000990, Accuracy: 99.78%\n",
      "Batch 122, Loss: 0.012213, Accuracy: 99.78%\n",
      "Batch 123, Loss: 0.002626, Accuracy: 99.78%\n",
      "Batch 124, Loss: 0.014281, Accuracy: 99.77%\n",
      "Batch 125, Loss: 0.008343, Accuracy: 99.78%\n",
      "Batch 126, Loss: 0.100651, Accuracy: 99.76%\n",
      "Batch 127, Loss: 0.000906, Accuracy: 99.77%\n",
      "Batch 128, Loss: 0.005407, Accuracy: 99.77%\n",
      "Batch 129, Loss: 0.008065, Accuracy: 99.77%\n",
      "Batch 130, Loss: 0.001449, Accuracy: 99.77%\n",
      "Batch 131, Loss: 0.000455, Accuracy: 99.77%\n",
      "Batch 132, Loss: 0.000969, Accuracy: 99.78%\n",
      "Batch 133, Loss: 0.020546, Accuracy: 99.77%\n",
      "Batch 134, Loss: 0.002928, Accuracy: 99.77%\n",
      "Batch 135, Loss: 0.022602, Accuracy: 99.76%\n",
      "Batch 136, Loss: 0.012020, Accuracy: 99.76%\n",
      "Batch 137, Loss: 0.004164, Accuracy: 99.76%\n",
      "Batch 138, Loss: 0.048262, Accuracy: 99.75%\n",
      "Batch 139, Loss: 0.001802, Accuracy: 99.75%\n",
      "Batch 140, Loss: 0.066815, Accuracy: 99.74%\n",
      "Batch 141, Loss: 0.012085, Accuracy: 99.75%\n",
      "Batch 142, Loss: 0.019100, Accuracy: 99.74%\n",
      "Batch 143, Loss: 0.001346, Accuracy: 99.74%\n",
      "Batch 144, Loss: 0.003664, Accuracy: 99.74%\n",
      "Batch 145, Loss: 0.020230, Accuracy: 99.73%\n",
      "Batch 146, Loss: 0.031189, Accuracy: 99.72%\n",
      "Batch 147, Loss: 0.003739, Accuracy: 99.72%\n",
      "Batch 148, Loss: 0.001071, Accuracy: 99.73%\n",
      "Batch 149, Loss: 0.001732, Accuracy: 99.73%\n",
      "Batch 150, Loss: 0.011653, Accuracy: 99.73%\n",
      "Batch 151, Loss: 0.057883, Accuracy: 99.71%\n",
      "Batch 152, Loss: 0.001055, Accuracy: 99.71%\n",
      "Batch 153, Loss: 0.002959, Accuracy: 99.71%\n",
      "Batch 154, Loss: 0.122995, Accuracy: 99.70%\n",
      "Batch 155, Loss: 0.000873, Accuracy: 99.70%\n",
      "Batch 156, Loss: 0.002109, Accuracy: 99.70%\n",
      "Batch 157, Loss: 0.000677, Accuracy: 99.70%\n",
      "Batch 158, Loss: 0.002456, Accuracy: 99.70%\n",
      "Batch 159, Loss: 0.009872, Accuracy: 99.71%\n",
      "Batch 160, Loss: 0.025582, Accuracy: 99.70%\n",
      "Batch 161, Loss: 0.001573, Accuracy: 99.70%\n",
      "Batch 162, Loss: 0.020679, Accuracy: 99.69%\n",
      "Batch 163, Loss: 0.004818, Accuracy: 99.69%\n",
      "Batch 164, Loss: 0.012511, Accuracy: 99.69%\n",
      "Batch 165, Loss: 0.018413, Accuracy: 99.68%\n",
      "Batch 166, Loss: 0.007379, Accuracy: 99.68%\n",
      "Batch 167, Loss: 0.034531, Accuracy: 99.67%\n",
      "Batch 168, Loss: 0.031817, Accuracy: 99.67%\n",
      "Batch 169, Loss: 0.000996, Accuracy: 99.67%\n",
      "Batch 170, Loss: 0.005747, Accuracy: 99.67%\n",
      "Batch 171, Loss: 0.003029, Accuracy: 99.67%\n",
      "Batch 172, Loss: 0.007791, Accuracy: 99.67%\n",
      "Batch 173, Loss: 0.015530, Accuracy: 99.67%\n",
      "Batch 174, Loss: 0.003346, Accuracy: 99.67%\n",
      "Batch 175, Loss: 0.010252, Accuracy: 99.67%\n",
      "Batch 176, Loss: 0.001482, Accuracy: 99.67%\n",
      "Batch 177, Loss: 0.003571, Accuracy: 99.67%\n",
      "Batch 178, Loss: 0.049489, Accuracy: 99.67%\n",
      "Batch 179, Loss: 0.001134, Accuracy: 99.67%\n",
      "Batch 180, Loss: 0.001284, Accuracy: 99.67%\n",
      "Batch 181, Loss: 0.018091, Accuracy: 99.66%\n",
      "Batch 182, Loss: 0.020084, Accuracy: 99.66%\n",
      "Batch 183, Loss: 0.000408, Accuracy: 99.66%\n",
      "Batch 184, Loss: 0.014674, Accuracy: 99.66%\n",
      "Batch 185, Loss: 0.000454, Accuracy: 99.66%\n",
      "Batch 186, Loss: 0.042599, Accuracy: 99.66%\n",
      "Batch 187, Loss: 0.008152, Accuracy: 99.66%\n",
      "Batch 188, Loss: 0.026340, Accuracy: 99.65%\n",
      "Batch 189, Loss: 0.012051, Accuracy: 99.65%\n",
      "Batch 190, Loss: 0.002126, Accuracy: 99.65%\n",
      "Batch 191, Loss: 0.006794, Accuracy: 99.66%\n",
      "Batch 192, Loss: 0.001692, Accuracy: 99.66%\n",
      "Batch 193, Loss: 0.098163, Accuracy: 99.64%\n",
      "Batch 194, Loss: 0.011884, Accuracy: 99.64%\n",
      "Batch 195, Loss: 0.001184, Accuracy: 99.64%\n",
      "Batch 196, Loss: 0.022493, Accuracy: 99.63%\n",
      "Batch 197, Loss: 0.020547, Accuracy: 99.63%\n",
      "Batch 198, Loss: 0.001452, Accuracy: 99.63%\n",
      "Batch 199, Loss: 0.001613, Accuracy: 99.63%\n",
      "Batch 200, Loss: 0.000646, Accuracy: 99.63%\n",
      "Batch 201, Loss: 0.013928, Accuracy: 99.63%\n",
      "Batch 202, Loss: 0.057859, Accuracy: 99.63%\n",
      "Batch 203, Loss: 0.002779, Accuracy: 99.63%\n",
      "Batch 204, Loss: 0.080586, Accuracy: 99.62%\n",
      "Batch 205, Loss: 0.163011, Accuracy: 99.61%\n",
      "Batch 206, Loss: 0.000889, Accuracy: 99.61%\n",
      "Batch 207, Loss: 0.033787, Accuracy: 99.61%\n",
      "Batch 208, Loss: 0.025783, Accuracy: 99.60%\n",
      "Batch 209, Loss: 0.002802, Accuracy: 99.60%\n",
      "Batch 210, Loss: 0.002193, Accuracy: 99.61%\n",
      "Batch 211, Loss: 0.103062, Accuracy: 99.60%\n",
      "Batch 212, Loss: 0.028150, Accuracy: 99.59%\n",
      "Batch 213, Loss: 0.003607, Accuracy: 99.60%\n",
      "Training - Epoch 40, Loss: 0.012456, Accuracy: 99.60%\n",
      "Validation Batch 1, Loss: 0.001354, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001843, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.031881, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.068463, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.003628, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.001743, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.013383, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.002884, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.001862, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.001342, Accuracy: 99.84%\n",
      "Validation Batch 11, Loss: 0.006475, Accuracy: 99.86%\n",
      "Validation Batch 12, Loss: 0.025275, Accuracy: 99.87%\n",
      "Validation Batch 13, Loss: 0.003309, Accuracy: 99.88%\n",
      "Validation Batch 14, Loss: 0.002975, Accuracy: 99.89%\n",
      "Validation Batch 15, Loss: 0.088529, Accuracy: 99.79%\n",
      "Validation Batch 16, Loss: 0.016866, Accuracy: 99.71%\n",
      "Validation Batch 17, Loss: 0.088073, Accuracy: 99.54%\n",
      "Validation Batch 18, Loss: 0.007061, Accuracy: 99.57%\n",
      "Validation Batch 19, Loss: 0.015349, Accuracy: 99.51%\n",
      "Validation Batch 20, Loss: 0.006490, Accuracy: 99.53%\n",
      "Validation Batch 21, Loss: 0.076477, Accuracy: 99.48%\n",
      "Validation Batch 22, Loss: 0.048785, Accuracy: 99.36%\n",
      "Validation Batch 23, Loss: 0.007464, Accuracy: 99.39%\n",
      "Validation Batch 24, Loss: 0.004949, Accuracy: 99.41%\n",
      "Validation Batch 25, Loss: 0.002341, Accuracy: 99.44%\n",
      "Validation Batch 26, Loss: 0.008716, Accuracy: 99.46%\n",
      "Validation Batch 27, Loss: 0.008651, Accuracy: 99.47%\n",
      "Validation - Epoch 40, Loss: 0.020228, Accuracy: 99.47%\n",
      "Patience—18\n",
      "Epoch 41\n",
      "Batch 1, Loss: 0.008894, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.012573, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.006458, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.045760, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.002455, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.026804, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.013463, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.008241, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.003155, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.002438, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.015834, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.027538, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.080255, Accuracy: 99.40%\n",
      "Batch 14, Loss: 0.001629, Accuracy: 99.44%\n",
      "Batch 15, Loss: 0.003101, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.008865, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.003948, Accuracy: 99.54%\n",
      "Batch 18, Loss: 0.005071, Accuracy: 99.57%\n",
      "Batch 19, Loss: 0.009753, Accuracy: 99.59%\n",
      "Batch 20, Loss: 0.001532, Accuracy: 99.61%\n",
      "Batch 21, Loss: 0.008827, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.011637, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.003417, Accuracy: 99.66%\n",
      "Batch 24, Loss: 0.000843, Accuracy: 99.67%\n",
      "Batch 25, Loss: 0.003665, Accuracy: 99.69%\n",
      "Batch 26, Loss: 0.040289, Accuracy: 99.64%\n",
      "Batch 27, Loss: 0.021818, Accuracy: 99.59%\n",
      "Batch 28, Loss: 0.035126, Accuracy: 99.55%\n",
      "Batch 29, Loss: 0.005635, Accuracy: 99.57%\n",
      "Batch 30, Loss: 0.000504, Accuracy: 99.58%\n",
      "Batch 31, Loss: 0.011667, Accuracy: 99.60%\n",
      "Batch 32, Loss: 0.000889, Accuracy: 99.61%\n",
      "Batch 33, Loss: 0.080990, Accuracy: 99.57%\n",
      "Batch 34, Loss: 0.000879, Accuracy: 99.59%\n",
      "Batch 35, Loss: 0.000807, Accuracy: 99.60%\n",
      "Batch 36, Loss: 0.008854, Accuracy: 99.61%\n",
      "Batch 37, Loss: 0.011018, Accuracy: 99.62%\n",
      "Batch 38, Loss: 0.032091, Accuracy: 99.55%\n",
      "Batch 39, Loss: 0.001353, Accuracy: 99.56%\n",
      "Batch 40, Loss: 0.049145, Accuracy: 99.49%\n",
      "Batch 41, Loss: 0.000998, Accuracy: 99.50%\n",
      "Batch 42, Loss: 0.000797, Accuracy: 99.52%\n",
      "Batch 43, Loss: 0.002393, Accuracy: 99.53%\n",
      "Batch 44, Loss: 0.009950, Accuracy: 99.54%\n",
      "Batch 45, Loss: 0.003522, Accuracy: 99.55%\n",
      "Batch 46, Loss: 0.004111, Accuracy: 99.56%\n",
      "Batch 47, Loss: 0.000429, Accuracy: 99.57%\n",
      "Batch 48, Loss: 0.001031, Accuracy: 99.58%\n",
      "Batch 49, Loss: 0.030108, Accuracy: 99.52%\n",
      "Batch 50, Loss: 0.003785, Accuracy: 99.53%\n",
      "Batch 51, Loss: 0.002139, Accuracy: 99.54%\n",
      "Batch 52, Loss: 0.002456, Accuracy: 99.55%\n",
      "Batch 53, Loss: 0.001768, Accuracy: 99.56%\n",
      "Batch 54, Loss: 0.002135, Accuracy: 99.57%\n",
      "Batch 55, Loss: 0.128899, Accuracy: 99.52%\n",
      "Batch 56, Loss: 0.001564, Accuracy: 99.53%\n",
      "Batch 57, Loss: 0.038727, Accuracy: 99.51%\n",
      "Batch 58, Loss: 0.061078, Accuracy: 99.46%\n",
      "Batch 59, Loss: 0.000413, Accuracy: 99.47%\n",
      "Batch 60, Loss: 0.011234, Accuracy: 99.48%\n",
      "Batch 61, Loss: 0.001122, Accuracy: 99.49%\n",
      "Batch 62, Loss: 0.001328, Accuracy: 99.50%\n",
      "Batch 63, Loss: 0.008437, Accuracy: 99.50%\n",
      "Batch 64, Loss: 0.004278, Accuracy: 99.51%\n",
      "Batch 65, Loss: 0.171934, Accuracy: 99.45%\n",
      "Batch 66, Loss: 0.001833, Accuracy: 99.46%\n",
      "Batch 67, Loss: 0.011941, Accuracy: 99.46%\n",
      "Batch 68, Loss: 0.008275, Accuracy: 99.47%\n",
      "Batch 69, Loss: 0.005723, Accuracy: 99.48%\n",
      "Batch 70, Loss: 0.004146, Accuracy: 99.49%\n",
      "Batch 71, Loss: 0.071158, Accuracy: 99.45%\n",
      "Batch 72, Loss: 0.001735, Accuracy: 99.46%\n",
      "Batch 73, Loss: 0.002350, Accuracy: 99.46%\n",
      "Batch 74, Loss: 0.001489, Accuracy: 99.47%\n",
      "Batch 75, Loss: 0.003143, Accuracy: 99.48%\n",
      "Batch 76, Loss: 0.042606, Accuracy: 99.47%\n",
      "Batch 77, Loss: 0.032453, Accuracy: 99.45%\n",
      "Batch 78, Loss: 0.001342, Accuracy: 99.46%\n",
      "Batch 79, Loss: 0.002243, Accuracy: 99.47%\n",
      "Batch 80, Loss: 0.003937, Accuracy: 99.47%\n",
      "Batch 81, Loss: 0.001827, Accuracy: 99.48%\n",
      "Batch 82, Loss: 0.004498, Accuracy: 99.49%\n",
      "Batch 83, Loss: 0.007738, Accuracy: 99.49%\n",
      "Batch 84, Loss: 0.007749, Accuracy: 99.50%\n",
      "Batch 85, Loss: 0.001556, Accuracy: 99.50%\n",
      "Batch 86, Loss: 0.002992, Accuracy: 99.51%\n",
      "Batch 87, Loss: 0.002003, Accuracy: 99.52%\n",
      "Batch 88, Loss: 0.001505, Accuracy: 99.52%\n",
      "Batch 89, Loss: 0.026416, Accuracy: 99.51%\n",
      "Batch 90, Loss: 0.001824, Accuracy: 99.51%\n",
      "Batch 91, Loss: 0.008278, Accuracy: 99.52%\n",
      "Batch 92, Loss: 0.002489, Accuracy: 99.52%\n",
      "Batch 93, Loss: 0.007705, Accuracy: 99.53%\n",
      "Batch 94, Loss: 0.001391, Accuracy: 99.53%\n",
      "Batch 95, Loss: 0.000584, Accuracy: 99.54%\n",
      "Batch 96, Loss: 0.013674, Accuracy: 99.54%\n",
      "Batch 97, Loss: 0.009038, Accuracy: 99.55%\n",
      "Batch 98, Loss: 0.001812, Accuracy: 99.55%\n",
      "Batch 99, Loss: 0.000237, Accuracy: 99.56%\n",
      "Batch 100, Loss: 0.018492, Accuracy: 99.55%\n",
      "Batch 101, Loss: 0.001007, Accuracy: 99.55%\n",
      "Batch 102, Loss: 0.004473, Accuracy: 99.56%\n",
      "Batch 103, Loss: 0.000320, Accuracy: 99.56%\n",
      "Batch 104, Loss: 0.000719, Accuracy: 99.56%\n",
      "Batch 105, Loss: 0.002583, Accuracy: 99.57%\n",
      "Batch 106, Loss: 0.000273, Accuracy: 99.57%\n",
      "Batch 107, Loss: 0.000356, Accuracy: 99.58%\n",
      "Batch 108, Loss: 0.000157, Accuracy: 99.58%\n",
      "Batch 109, Loss: 0.041335, Accuracy: 99.57%\n",
      "Batch 110, Loss: 0.000216, Accuracy: 99.57%\n",
      "Batch 111, Loss: 0.001874, Accuracy: 99.58%\n",
      "Batch 112, Loss: 0.000265, Accuracy: 99.58%\n",
      "Batch 113, Loss: 0.000651, Accuracy: 99.59%\n",
      "Batch 114, Loss: 0.001124, Accuracy: 99.59%\n",
      "Batch 115, Loss: 0.060984, Accuracy: 99.58%\n",
      "Batch 116, Loss: 0.001048, Accuracy: 99.58%\n",
      "Batch 117, Loss: 0.000159, Accuracy: 99.59%\n",
      "Batch 118, Loss: 0.000353, Accuracy: 99.59%\n",
      "Batch 119, Loss: 0.000716, Accuracy: 99.59%\n",
      "Batch 120, Loss: 0.000563, Accuracy: 99.60%\n",
      "Batch 121, Loss: 0.003757, Accuracy: 99.60%\n",
      "Batch 122, Loss: 0.074827, Accuracy: 99.58%\n",
      "Batch 123, Loss: 0.001343, Accuracy: 99.58%\n",
      "Batch 124, Loss: 0.062663, Accuracy: 99.57%\n",
      "Batch 125, Loss: 0.003197, Accuracy: 99.58%\n",
      "Batch 126, Loss: 0.062586, Accuracy: 99.57%\n",
      "Batch 127, Loss: 0.000926, Accuracy: 99.57%\n",
      "Batch 128, Loss: 0.001380, Accuracy: 99.57%\n",
      "Batch 129, Loss: 0.000655, Accuracy: 99.58%\n",
      "Batch 130, Loss: 0.000912, Accuracy: 99.58%\n",
      "Batch 131, Loss: 0.000582, Accuracy: 99.58%\n",
      "Batch 132, Loss: 0.000772, Accuracy: 99.59%\n",
      "Batch 133, Loss: 0.001046, Accuracy: 99.59%\n",
      "Batch 134, Loss: 0.001625, Accuracy: 99.59%\n",
      "Batch 135, Loss: 0.000869, Accuracy: 99.59%\n",
      "Batch 136, Loss: 0.076377, Accuracy: 99.59%\n",
      "Batch 137, Loss: 0.007395, Accuracy: 99.59%\n",
      "Batch 138, Loss: 0.001929, Accuracy: 99.59%\n",
      "Batch 139, Loss: 0.002294, Accuracy: 99.60%\n",
      "Batch 140, Loss: 0.014153, Accuracy: 99.60%\n",
      "Batch 141, Loss: 0.048416, Accuracy: 99.59%\n",
      "Batch 142, Loss: 0.089106, Accuracy: 99.58%\n",
      "Batch 143, Loss: 0.003251, Accuracy: 99.58%\n",
      "Batch 144, Loss: 0.001460, Accuracy: 99.59%\n",
      "Batch 145, Loss: 0.005669, Accuracy: 99.59%\n",
      "Batch 146, Loss: 0.002975, Accuracy: 99.59%\n",
      "Batch 147, Loss: 0.030607, Accuracy: 99.59%\n",
      "Batch 148, Loss: 0.000880, Accuracy: 99.59%\n",
      "Batch 149, Loss: 0.043079, Accuracy: 99.57%\n",
      "Batch 150, Loss: 0.004821, Accuracy: 99.57%\n",
      "Batch 151, Loss: 0.056302, Accuracy: 99.57%\n",
      "Batch 152, Loss: 0.001265, Accuracy: 99.57%\n",
      "Batch 153, Loss: 0.059415, Accuracy: 99.56%\n",
      "Batch 154, Loss: 0.001823, Accuracy: 99.56%\n",
      "Batch 155, Loss: 0.118607, Accuracy: 99.55%\n",
      "Batch 156, Loss: 0.056794, Accuracy: 99.54%\n",
      "Batch 157, Loss: 0.003907, Accuracy: 99.54%\n",
      "Batch 158, Loss: 0.009377, Accuracy: 99.55%\n",
      "Batch 159, Loss: 0.003226, Accuracy: 99.55%\n",
      "Batch 160, Loss: 0.008884, Accuracy: 99.55%\n",
      "Batch 161, Loss: 0.058167, Accuracy: 99.54%\n",
      "Batch 162, Loss: 0.095529, Accuracy: 99.54%\n",
      "Batch 163, Loss: 0.013509, Accuracy: 99.54%\n",
      "Batch 164, Loss: 0.037490, Accuracy: 99.53%\n",
      "Batch 165, Loss: 0.015291, Accuracy: 99.53%\n",
      "Batch 166, Loss: 0.005314, Accuracy: 99.53%\n",
      "Batch 167, Loss: 0.003652, Accuracy: 99.53%\n",
      "Batch 168, Loss: 0.002912, Accuracy: 99.53%\n",
      "Batch 169, Loss: 0.006363, Accuracy: 99.54%\n",
      "Batch 170, Loss: 0.004006, Accuracy: 99.54%\n",
      "Batch 171, Loss: 0.010647, Accuracy: 99.54%\n",
      "Batch 172, Loss: 0.001595, Accuracy: 99.55%\n",
      "Batch 173, Loss: 0.004951, Accuracy: 99.55%\n",
      "Batch 174, Loss: 0.014183, Accuracy: 99.54%\n",
      "Batch 175, Loss: 0.016828, Accuracy: 99.54%\n",
      "Batch 176, Loss: 0.001491, Accuracy: 99.54%\n",
      "Batch 177, Loss: 0.001172, Accuracy: 99.54%\n",
      "Batch 178, Loss: 0.062141, Accuracy: 99.53%\n",
      "Batch 179, Loss: 0.011993, Accuracy: 99.54%\n",
      "Batch 180, Loss: 0.003998, Accuracy: 99.54%\n",
      "Batch 181, Loss: 0.008641, Accuracy: 99.54%\n",
      "Batch 182, Loss: 0.002620, Accuracy: 99.54%\n",
      "Batch 183, Loss: 0.002736, Accuracy: 99.55%\n",
      "Batch 184, Loss: 0.001632, Accuracy: 99.55%\n",
      "Batch 185, Loss: 0.000810, Accuracy: 99.55%\n",
      "Batch 186, Loss: 0.001732, Accuracy: 99.55%\n",
      "Batch 187, Loss: 0.000944, Accuracy: 99.56%\n",
      "Batch 188, Loss: 0.000920, Accuracy: 99.56%\n",
      "Batch 189, Loss: 0.000470, Accuracy: 99.56%\n",
      "Batch 190, Loss: 0.000406, Accuracy: 99.56%\n",
      "Batch 191, Loss: 0.000342, Accuracy: 99.57%\n",
      "Batch 192, Loss: 0.001727, Accuracy: 99.57%\n",
      "Batch 193, Loss: 0.001793, Accuracy: 99.57%\n",
      "Batch 194, Loss: 0.003310, Accuracy: 99.57%\n",
      "Batch 195, Loss: 0.000373, Accuracy: 99.58%\n",
      "Batch 196, Loss: 0.001374, Accuracy: 99.58%\n",
      "Batch 197, Loss: 0.000716, Accuracy: 99.58%\n",
      "Batch 198, Loss: 0.000363, Accuracy: 99.58%\n",
      "Batch 199, Loss: 0.000784, Accuracy: 99.58%\n",
      "Batch 200, Loss: 0.001876, Accuracy: 99.59%\n",
      "Batch 201, Loss: 0.000289, Accuracy: 99.59%\n",
      "Batch 202, Loss: 0.000170, Accuracy: 99.59%\n",
      "Batch 203, Loss: 0.000176, Accuracy: 99.59%\n",
      "Batch 204, Loss: 0.000996, Accuracy: 99.59%\n",
      "Batch 205, Loss: 0.000275, Accuracy: 99.60%\n",
      "Batch 206, Loss: 0.000396, Accuracy: 99.60%\n",
      "Batch 207, Loss: 0.003910, Accuracy: 99.60%\n",
      "Batch 208, Loss: 0.000293, Accuracy: 99.60%\n",
      "Batch 209, Loss: 0.000616, Accuracy: 99.60%\n",
      "Batch 210, Loss: 0.001332, Accuracy: 99.61%\n",
      "Batch 211, Loss: 0.001031, Accuracy: 99.61%\n",
      "Batch 212, Loss: 0.000247, Accuracy: 99.61%\n",
      "Batch 213, Loss: 0.000203, Accuracy: 99.61%\n",
      "Training - Epoch 41, Loss: 0.013292, Accuracy: 99.61%\n",
      "Validation Batch 1, Loss: 0.009540, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001349, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000225, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000205, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000753, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000102, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.003175, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.000151, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000347, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.002505, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000621, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.013635, Accuracy: 99.87%\n",
      "Validation Batch 13, Loss: 0.000572, Accuracy: 99.88%\n",
      "Validation Batch 14, Loss: 0.000416, Accuracy: 99.89%\n",
      "Validation Batch 15, Loss: 0.000622, Accuracy: 99.90%\n",
      "Validation Batch 16, Loss: 0.000309, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.065728, Accuracy: 99.72%\n",
      "Validation Batch 18, Loss: 0.000805, Accuracy: 99.74%\n",
      "Validation Batch 19, Loss: 0.000593, Accuracy: 99.75%\n",
      "Validation Batch 20, Loss: 0.000439, Accuracy: 99.77%\n",
      "Validation Batch 21, Loss: 0.000898, Accuracy: 99.78%\n",
      "Validation Batch 22, Loss: 0.000642, Accuracy: 99.79%\n",
      "Validation Batch 23, Loss: 0.000581, Accuracy: 99.80%\n",
      "Validation Batch 24, Loss: 0.000504, Accuracy: 99.80%\n",
      "Validation Batch 25, Loss: 0.000204, Accuracy: 99.81%\n",
      "Validation Batch 26, Loss: 0.000647, Accuracy: 99.82%\n",
      "Validation Batch 27, Loss: 0.186615, Accuracy: 99.71%\n",
      "Validation - Epoch 41, Loss: 0.010822, Accuracy: 99.71%\n",
      "Patience—19\n",
      "Epoch 42\n",
      "Batch 1, Loss: 0.000380, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000603, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000269, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000111, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000089, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000100, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000739, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000463, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000078, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000486, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000146, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.003394, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000115, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.003995, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000113, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000089, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000090, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000104, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000074, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000763, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000071, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000333, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000063, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000046, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000140, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000128, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000079, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000533, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000092, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000108, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.001238, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000098, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000091, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.001143, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000082, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000066, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000089, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000063, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.001157, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000367, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000125, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000137, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000037, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.014549, Accuracy: 99.97%\n",
      "Batch 58, Loss: 0.000571, Accuracy: 99.97%\n",
      "Batch 59, Loss: 0.000286, Accuracy: 99.97%\n",
      "Batch 60, Loss: 0.001243, Accuracy: 99.97%\n",
      "Batch 61, Loss: 0.000071, Accuracy: 99.97%\n",
      "Batch 62, Loss: 0.000196, Accuracy: 99.97%\n",
      "Batch 63, Loss: 0.000059, Accuracy: 99.98%\n",
      "Batch 64, Loss: 0.000170, Accuracy: 99.98%\n",
      "Batch 65, Loss: 0.001835, Accuracy: 99.98%\n",
      "Batch 66, Loss: 0.000073, Accuracy: 99.98%\n",
      "Batch 67, Loss: 0.001530, Accuracy: 99.98%\n",
      "Batch 68, Loss: 0.000073, Accuracy: 99.98%\n",
      "Batch 69, Loss: 0.000047, Accuracy: 99.98%\n",
      "Batch 70, Loss: 0.000070, Accuracy: 99.98%\n",
      "Batch 71, Loss: 0.000208, Accuracy: 99.98%\n",
      "Batch 72, Loss: 0.000291, Accuracy: 99.98%\n",
      "Batch 73, Loss: 0.000057, Accuracy: 99.98%\n",
      "Batch 74, Loss: 0.000045, Accuracy: 99.98%\n",
      "Batch 75, Loss: 0.000040, Accuracy: 99.98%\n",
      "Batch 76, Loss: 0.000144, Accuracy: 99.98%\n",
      "Batch 77, Loss: 0.000053, Accuracy: 99.98%\n",
      "Batch 78, Loss: 0.002651, Accuracy: 99.98%\n",
      "Batch 79, Loss: 0.000035, Accuracy: 99.98%\n",
      "Batch 80, Loss: 0.000854, Accuracy: 99.98%\n",
      "Batch 81, Loss: 0.000064, Accuracy: 99.98%\n",
      "Batch 82, Loss: 0.000040, Accuracy: 99.98%\n",
      "Batch 83, Loss: 0.000041, Accuracy: 99.98%\n",
      "Batch 84, Loss: 0.011986, Accuracy: 99.96%\n",
      "Batch 85, Loss: 0.000758, Accuracy: 99.96%\n",
      "Batch 86, Loss: 0.000037, Accuracy: 99.96%\n",
      "Batch 87, Loss: 0.001947, Accuracy: 99.96%\n",
      "Batch 88, Loss: 0.000087, Accuracy: 99.96%\n",
      "Batch 89, Loss: 0.000018, Accuracy: 99.96%\n",
      "Batch 90, Loss: 0.000039, Accuracy: 99.97%\n",
      "Batch 91, Loss: 0.000547, Accuracy: 99.97%\n",
      "Batch 92, Loss: 0.001617, Accuracy: 99.97%\n",
      "Batch 93, Loss: 0.000103, Accuracy: 99.97%\n",
      "Batch 94, Loss: 0.000100, Accuracy: 99.97%\n",
      "Batch 95, Loss: 0.025434, Accuracy: 99.95%\n",
      "Batch 96, Loss: 0.000073, Accuracy: 99.95%\n",
      "Batch 97, Loss: 0.000036, Accuracy: 99.95%\n",
      "Batch 98, Loss: 0.000569, Accuracy: 99.95%\n",
      "Batch 99, Loss: 0.000099, Accuracy: 99.95%\n",
      "Batch 100, Loss: 0.000064, Accuracy: 99.95%\n",
      "Batch 101, Loss: 0.000164, Accuracy: 99.95%\n",
      "Batch 102, Loss: 0.000088, Accuracy: 99.95%\n",
      "Batch 103, Loss: 0.000080, Accuracy: 99.95%\n",
      "Batch 104, Loss: 0.000299, Accuracy: 99.95%\n",
      "Batch 105, Loss: 0.000069, Accuracy: 99.96%\n",
      "Batch 106, Loss: 0.001177, Accuracy: 99.96%\n",
      "Batch 107, Loss: 0.000361, Accuracy: 99.96%\n",
      "Batch 108, Loss: 0.000535, Accuracy: 99.96%\n",
      "Batch 109, Loss: 0.000846, Accuracy: 99.96%\n",
      "Batch 110, Loss: 0.020831, Accuracy: 99.94%\n",
      "Batch 111, Loss: 0.003425, Accuracy: 99.94%\n",
      "Batch 112, Loss: 0.000157, Accuracy: 99.94%\n",
      "Batch 113, Loss: 0.000129, Accuracy: 99.94%\n",
      "Batch 114, Loss: 0.000235, Accuracy: 99.95%\n",
      "Batch 115, Loss: 0.001528, Accuracy: 99.95%\n",
      "Batch 116, Loss: 0.009419, Accuracy: 99.95%\n",
      "Batch 117, Loss: 0.171210, Accuracy: 99.92%\n",
      "Batch 118, Loss: 0.000058, Accuracy: 99.92%\n",
      "Batch 119, Loss: 0.000130, Accuracy: 99.92%\n",
      "Batch 120, Loss: 0.000079, Accuracy: 99.92%\n",
      "Batch 121, Loss: 0.000228, Accuracy: 99.92%\n",
      "Batch 122, Loss: 0.001347, Accuracy: 99.92%\n",
      "Batch 123, Loss: 0.018040, Accuracy: 99.91%\n",
      "Batch 124, Loss: 0.086277, Accuracy: 99.90%\n",
      "Batch 125, Loss: 0.012970, Accuracy: 99.89%\n",
      "Batch 126, Loss: 0.058985, Accuracy: 99.86%\n",
      "Batch 127, Loss: 0.004389, Accuracy: 99.86%\n",
      "Batch 128, Loss: 0.000223, Accuracy: 99.87%\n",
      "Batch 129, Loss: 0.000208, Accuracy: 99.87%\n",
      "Batch 130, Loss: 0.000388, Accuracy: 99.87%\n",
      "Batch 131, Loss: 0.000277, Accuracy: 99.87%\n",
      "Batch 132, Loss: 0.000309, Accuracy: 99.87%\n",
      "Batch 133, Loss: 0.000552, Accuracy: 99.87%\n",
      "Batch 134, Loss: 0.007320, Accuracy: 99.87%\n",
      "Batch 135, Loss: 0.000266, Accuracy: 99.87%\n",
      "Batch 136, Loss: 0.017406, Accuracy: 99.86%\n",
      "Batch 137, Loss: 0.021729, Accuracy: 99.85%\n",
      "Batch 138, Loss: 0.000269, Accuracy: 99.85%\n",
      "Batch 139, Loss: 0.009789, Accuracy: 99.85%\n",
      "Batch 140, Loss: 0.043413, Accuracy: 99.83%\n",
      "Batch 141, Loss: 0.000275, Accuracy: 99.83%\n",
      "Batch 142, Loss: 0.002134, Accuracy: 99.83%\n",
      "Batch 143, Loss: 0.008090, Accuracy: 99.84%\n",
      "Batch 144, Loss: 0.018492, Accuracy: 99.83%\n",
      "Batch 145, Loss: 0.000585, Accuracy: 99.83%\n",
      "Batch 146, Loss: 0.000671, Accuracy: 99.83%\n",
      "Batch 147, Loss: 0.001662, Accuracy: 99.83%\n",
      "Batch 148, Loss: 0.026317, Accuracy: 99.82%\n",
      "Batch 149, Loss: 0.000451, Accuracy: 99.82%\n",
      "Batch 150, Loss: 0.001604, Accuracy: 99.82%\n",
      "Batch 151, Loss: 0.000702, Accuracy: 99.82%\n",
      "Batch 152, Loss: 0.004847, Accuracy: 99.83%\n",
      "Batch 153, Loss: 0.022241, Accuracy: 99.82%\n",
      "Batch 154, Loss: 0.001055, Accuracy: 99.82%\n",
      "Batch 155, Loss: 0.000230, Accuracy: 99.82%\n",
      "Batch 156, Loss: 0.007521, Accuracy: 99.82%\n",
      "Batch 157, Loss: 0.003660, Accuracy: 99.82%\n",
      "Batch 158, Loss: 0.025199, Accuracy: 99.81%\n",
      "Batch 159, Loss: 0.000841, Accuracy: 99.81%\n",
      "Batch 160, Loss: 0.008031, Accuracy: 99.81%\n",
      "Batch 161, Loss: 0.000665, Accuracy: 99.82%\n",
      "Batch 162, Loss: 0.078031, Accuracy: 99.81%\n",
      "Batch 163, Loss: 0.004812, Accuracy: 99.81%\n",
      "Batch 164, Loss: 0.001071, Accuracy: 99.81%\n",
      "Batch 165, Loss: 0.026558, Accuracy: 99.80%\n",
      "Batch 166, Loss: 0.000381, Accuracy: 99.80%\n",
      "Batch 167, Loss: 0.006003, Accuracy: 99.80%\n",
      "Batch 168, Loss: 0.000593, Accuracy: 99.80%\n",
      "Batch 169, Loss: 0.025245, Accuracy: 99.80%\n",
      "Batch 170, Loss: 0.022864, Accuracy: 99.79%\n",
      "Batch 171, Loss: 0.000283, Accuracy: 99.79%\n",
      "Batch 172, Loss: 0.000174, Accuracy: 99.79%\n",
      "Batch 173, Loss: 0.000921, Accuracy: 99.79%\n",
      "Batch 174, Loss: 0.030125, Accuracy: 99.78%\n",
      "Batch 175, Loss: 0.034910, Accuracy: 99.78%\n",
      "Batch 176, Loss: 0.000651, Accuracy: 99.78%\n",
      "Batch 177, Loss: 0.000629, Accuracy: 99.78%\n",
      "Batch 178, Loss: 0.000202, Accuracy: 99.78%\n",
      "Batch 179, Loss: 0.000481, Accuracy: 99.78%\n",
      "Batch 180, Loss: 0.001515, Accuracy: 99.78%\n",
      "Batch 181, Loss: 0.000661, Accuracy: 99.78%\n",
      "Batch 182, Loss: 0.001658, Accuracy: 99.79%\n",
      "Batch 183, Loss: 0.000393, Accuracy: 99.79%\n",
      "Batch 184, Loss: 0.016236, Accuracy: 99.79%\n",
      "Batch 185, Loss: 0.000716, Accuracy: 99.79%\n",
      "Batch 186, Loss: 0.003009, Accuracy: 99.79%\n",
      "Batch 187, Loss: 0.000316, Accuracy: 99.79%\n",
      "Batch 188, Loss: 0.017544, Accuracy: 99.78%\n",
      "Batch 189, Loss: 0.001155, Accuracy: 99.79%\n",
      "Batch 190, Loss: 0.000322, Accuracy: 99.79%\n",
      "Batch 191, Loss: 0.001893, Accuracy: 99.79%\n",
      "Batch 192, Loss: 0.000752, Accuracy: 99.79%\n",
      "Batch 193, Loss: 0.084863, Accuracy: 99.77%\n",
      "Batch 194, Loss: 0.000313, Accuracy: 99.77%\n",
      "Batch 195, Loss: 0.002196, Accuracy: 99.78%\n",
      "Batch 196, Loss: 0.084463, Accuracy: 99.77%\n",
      "Batch 197, Loss: 0.023476, Accuracy: 99.76%\n",
      "Batch 198, Loss: 0.000663, Accuracy: 99.76%\n",
      "Batch 199, Loss: 0.002176, Accuracy: 99.76%\n",
      "Batch 200, Loss: 0.045056, Accuracy: 99.76%\n",
      "Batch 201, Loss: 0.001322, Accuracy: 99.76%\n",
      "Batch 202, Loss: 0.026566, Accuracy: 99.75%\n",
      "Batch 203, Loss: 0.001009, Accuracy: 99.75%\n",
      "Batch 204, Loss: 0.000287, Accuracy: 99.75%\n",
      "Batch 205, Loss: 0.008681, Accuracy: 99.76%\n",
      "Batch 206, Loss: 0.008216, Accuracy: 99.76%\n",
      "Batch 207, Loss: 0.028985, Accuracy: 99.75%\n",
      "Batch 208, Loss: 0.004477, Accuracy: 99.75%\n",
      "Batch 209, Loss: 0.028950, Accuracy: 99.75%\n",
      "Batch 210, Loss: 0.002130, Accuracy: 99.75%\n",
      "Batch 211, Loss: 0.009976, Accuracy: 99.75%\n",
      "Batch 212, Loss: 0.021398, Accuracy: 99.74%\n",
      "Batch 213, Loss: 0.001398, Accuracy: 99.74%\n",
      "Training - Epoch 42, Loss: 0.006515, Accuracy: 99.74%\n",
      "Validation Batch 1, Loss: 0.003667, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.016799, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.003527, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.000708, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.008995, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.056910, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.011371, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.074460, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.063016, Accuracy: 99.31%\n",
      "Validation Batch 10, Loss: 0.003781, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.000670, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.007307, Accuracy: 99.48%\n",
      "Validation Batch 13, Loss: 0.039372, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.004200, Accuracy: 99.44%\n",
      "Validation Batch 15, Loss: 0.017136, Accuracy: 99.38%\n",
      "Validation Batch 16, Loss: 0.000634, Accuracy: 99.41%\n",
      "Validation Batch 17, Loss: 0.006767, Accuracy: 99.45%\n",
      "Validation Batch 18, Loss: 0.007702, Accuracy: 99.48%\n",
      "Validation Batch 19, Loss: 0.009529, Accuracy: 99.51%\n",
      "Validation Batch 20, Loss: 0.002400, Accuracy: 99.53%\n",
      "Validation Batch 21, Loss: 0.003227, Accuracy: 99.55%\n",
      "Validation Batch 22, Loss: 0.001784, Accuracy: 99.57%\n",
      "Validation Batch 23, Loss: 0.060361, Accuracy: 99.52%\n",
      "Validation Batch 24, Loss: 0.009145, Accuracy: 99.54%\n",
      "Validation Batch 25, Loss: 0.003142, Accuracy: 99.56%\n",
      "Validation Batch 26, Loss: 0.013297, Accuracy: 99.58%\n",
      "Validation Batch 27, Loss: 0.010484, Accuracy: 99.59%\n",
      "Validation - Epoch 42, Loss: 0.016311, Accuracy: 99.59%\n",
      "Patience—20\n",
      "Early stopping at epoch 42\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 130  \n",
    "patience = 20  \n",
    "best_val_loss = float('inf')  \n",
    "best_model = None  \n",
    "\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "train_accuracy_list = list()\n",
    "val_accuracy_list = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Batch {batch_idx+1}, Loss: {loss.item():.6f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Training - Epoch {epoch+1}, Loss: {train_loss:.6f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()  \n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "            outputs = model(images) \n",
    "            loss = criterion(outputs, labels) \n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print(f\"Validation Batch {batch_idx+1}, Loss: {loss.item():.6f}, Accuracy: {100 * val_correct / val_total:.2f}%\")\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Validation - Epoch {epoch+1}, Loss: {val_loss:.6f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    print(f'Patience—{patience_counter}')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "model = best_model\n",
    "torch.save(model.state_dict(), f'{experiment}-{model_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracy_list, label='Train Accuracy')\n",
    "\n",
    "# Plotting the second graph\n",
    "plt.plot(val_accuracy_list, label='Val Accuracy')\n",
    "\n",
    "# Adding labels and a legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train vs Val Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "\n",
    "# Plotting the second graph\n",
    "plt.plot(val_loss_list, label='Val Loss')\n",
    "\n",
    "# Adding labels and a legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Val Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch 1, Loss: 0.000234, Accuracy: 100.00%\n",
      "Test Batch 2, Loss: 0.000318, Accuracy: 100.00%\n",
      "Test Batch 3, Loss: 0.000410, Accuracy: 100.00%\n",
      "Test Batch 4, Loss: 0.000079, Accuracy: 100.00%\n",
      "Test Batch 5, Loss: 0.000065, Accuracy: 100.00%\n",
      "Test Batch 6, Loss: 0.015585, Accuracy: 99.74%\n",
      "Test Batch 7, Loss: 0.000092, Accuracy: 99.78%\n",
      "Test Batch 8, Loss: 0.000087, Accuracy: 99.80%\n",
      "Test Batch 9, Loss: 0.008041, Accuracy: 99.83%\n",
      "Test Batch 10, Loss: 0.040456, Accuracy: 99.69%\n",
      "Test Batch 11, Loss: 0.000135, Accuracy: 99.72%\n",
      "Test Batch 12, Loss: 0.000142, Accuracy: 99.74%\n",
      "Test Batch 13, Loss: 0.000091, Accuracy: 99.76%\n",
      "Test Batch 14, Loss: 0.001025, Accuracy: 99.78%\n",
      "Test Batch 15, Loss: 0.000077, Accuracy: 99.79%\n",
      "Test Batch 16, Loss: 0.000118, Accuracy: 99.80%\n",
      "Test Batch 17, Loss: 0.000393, Accuracy: 99.82%\n",
      "Test Batch 18, Loss: 0.000851, Accuracy: 99.83%\n",
      "Test Batch 19, Loss: 0.000324, Accuracy: 99.84%\n",
      "Test Batch 20, Loss: 0.000198, Accuracy: 99.84%\n",
      "Test Batch 21, Loss: 0.002832, Accuracy: 99.85%\n",
      "Test Batch 22, Loss: 0.000292, Accuracy: 99.86%\n",
      "Test Batch 23, Loss: 0.107878, Accuracy: 99.80%\n",
      "Test Batch 24, Loss: 0.124685, Accuracy: 99.74%\n",
      "Test Batch 25, Loss: 0.000249, Accuracy: 99.75%\n",
      "Test Batch 26, Loss: 0.004969, Accuracy: 99.76%\n",
      "Test Batch 27, Loss: 0.047357, Accuracy: 99.71%\n",
      "Test Set - Loss: 0.013222, Accuracy: 99.71%\n",
      "Confusion Matrix:\n",
      "[[116   0   2   0]\n",
      " [  0 438   1   0]\n",
      " [  0   0 578   1]\n",
      " [  0   0   1 568]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        print(f\"Test Batch {batch_idx+1}, Loss: {loss.item():.6f}, Accuracy: {100 * test_correct / test_total:.2f}%\")\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"Test Set - Loss: {test_loss:.6f}, Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "# Calculate percentages for each element\n",
    "cm_percentage = (cm / np.sum(cm)) * 100\n",
    "\n",
    "# Plot confusion matrix with count and percentages\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=['MILD', 'MODERATE', 'NORMAL', 'SEVERE'],\n",
    "            yticklabels=['MILD', 'MODERATE', 'NORMAL', 'SEVERE'],\n",
    "            ax=ax)\n",
    "\n",
    "# Annotate each box with count and percentage\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm[0])):\n",
    "        ax.text(j + 0.5, i + 0.5, f'\\n\\n{cm_percentage[i, j]:.2f}%',\n",
    "                ha='center', va='center', color='black')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
