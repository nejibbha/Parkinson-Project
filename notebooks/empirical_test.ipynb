{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravdhoot/opt/anaconda3/envs/deep-learning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.12\n",
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "print(timm.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_5Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_5Layer, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        conv_output_size = self._get_conv_output_size(dummy_input)\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_output_size, 4, bias=True),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.l1_regularizer = nn.L1Loss()\n",
    "\n",
    "    def _get_conv_output_size(self, x):\n",
    "        with torch.no_grad():\n",
    "            conv_output = self.conv_layers(x)\n",
    "        return conv_output.view(x.size(0), -1).shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_6Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_6Layer, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        conv_output_size = self._get_conv_output_size(dummy_input)\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_output_size, 4, bias=True),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.l1_regularizer = nn.L1Loss()\n",
    "\n",
    "    def _get_conv_output_size(self, x):\n",
    "        with torch.no_grad():\n",
    "            conv_output = self.conv_layers(x)\n",
    "        return conv_output.view(x.size(0), -1).shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name):\n",
    "    if model_name == 'vit-tiny':\n",
    "        model = timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=4)\n",
    "        model_path = '../experiments/non-keyframe/vit-tiny/vit-tiny-130-epochs-early-stopping-tiny.h5'\n",
    "\n",
    "    if model_name == 'vit-small': \n",
    "        model = model = timm.create_model('vit_small_patch16_224', pretrained=False, num_classes=4)\n",
    "        model_path = '../experiments/non-keyframe/vit-small/vit-small-130-epochs-early-stopping-small.h5'\n",
    "        \n",
    "    if model_name == 'vit-base': \n",
    "        model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=4)\n",
    "        model_path = '../experiments/non-keyframe/vit-base/vit-base-130-epochs-early-stopping-base.h5'\n",
    "\n",
    "    if model_name == 'resnet-18': \n",
    "        model = timm.create_model('resnet18', pretrained=False, num_classes=4)\n",
    "        model_path = '../experiments/non-keyframe/resnet-18/resnet-18-130-epochs-early-stopping-resnet18.h5'\n",
    "    \n",
    "    if model_name == 'resnet-34': \n",
    "        model = timm.create_model('resnet34', pretrained=False, num_classes=4)\n",
    "        model_path = '../experiments/non-keyframe/resnet-34/resnet-34-130-epochs-early-stopping-resnet34.h5'\n",
    "    \n",
    "    if model_name == 'cnn-5-layer': \n",
    "        model = CNN_5Layer() \n",
    "        model_path = '../experiments/non-keyframe/cnn-5-layer/cnn-5-layer-130-epochs-early-stopping-with-regularization-5-layer'\n",
    "    \n",
    "    if model_name == 'cnn-6-layer': \n",
    "        model = CNN_6Layer()\n",
    "        model_path = '../experiments/non-keyframe/cnn-6-layer/cnn-6-layer-130-epochs-early-stopping-with-regularization-6-layer'\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../energy-images-empirical', transform=transform)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8) \n",
    "validation_size = int(total_size * 0.1) \n",
    "test_size = total_size - train_size - validation_size\n",
    "generator = torch.Generator().manual_seed(0) \n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.stack([image for image, _ in dataset], dim=0)\n",
    "labels = torch.tensor([label for _, label in dataset], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_name):\n",
    "    model = create_model(model_name)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(data_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            print(f\"Batch {batch_idx}, Loss: {loss.item():.6f}, Accuracy: {100 * test_correct / test_total:.2f}%\")\n",
    "        \n",
    "    total_accuracy += 100 * test_correct / test_total\n",
    "\n",
    "    print(f'Model — {model_name}')\n",
    "    print(f'Average Accuracy — {total_accuracy}')\n",
    "    print('+=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Batch 0, Loss: 6.461430, Accuracy: 18.75%\n",
      "Batch 1, Loss: 5.791875, Accuracy: 22.66%\n",
      "Batch 2, Loss: 5.702439, Accuracy: 22.92%\n",
      "Batch 3, Loss: 6.059984, Accuracy: 22.27%\n",
      "Batch 4, Loss: 5.459346, Accuracy: 23.44%\n",
      "Batch 5, Loss: 5.828105, Accuracy: 22.66%\n",
      "Batch 6, Loss: 5.864913, Accuracy: 22.54%\n",
      "Batch 7, Loss: 6.726446, Accuracy: 21.09%\n",
      "Batch 8, Loss: 5.603005, Accuracy: 21.18%\n",
      "Batch 9, Loss: 5.681521, Accuracy: 20.62%\n",
      "Batch 10, Loss: 5.472759, Accuracy: 21.16%\n",
      "Batch 11, Loss: 5.676647, Accuracy: 20.96%\n",
      "Batch 12, Loss: 5.940926, Accuracy: 21.03%\n",
      "Batch 13, Loss: 5.410361, Accuracy: 20.87%\n",
      "Batch 14, Loss: 5.641367, Accuracy: 20.83%\n",
      "Batch 15, Loss: 5.454420, Accuracy: 21.39%\n",
      "Batch 16, Loss: 5.836728, Accuracy: 21.32%\n",
      "Batch 17, Loss: 6.166385, Accuracy: 21.09%\n",
      "Batch 18, Loss: 5.986181, Accuracy: 20.89%\n",
      "Batch 19, Loss: 5.383593, Accuracy: 21.09%\n",
      "Batch 20, Loss: 5.188151, Accuracy: 21.35%\n",
      "Batch 21, Loss: 5.403562, Accuracy: 21.66%\n",
      "Batch 22, Loss: 5.067591, Accuracy: 22.08%\n",
      "Batch 23, Loss: 5.136250, Accuracy: 22.33%\n",
      "Batch 24, Loss: 6.092170, Accuracy: 22.44%\n",
      "Batch 25, Loss: 5.600848, Accuracy: 22.48%\n",
      "Batch 26, Loss: 5.653257, Accuracy: 22.47%\n",
      "Model — vit-tiny\n",
      "Average Accuracy — 22.467222884386175\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
      "Using device: cpu\n",
      "Batch 0, Loss: 7.568779, Accuracy: 21.88%\n",
      "Batch 1, Loss: 7.805978, Accuracy: 18.75%\n",
      "Batch 2, Loss: 7.998741, Accuracy: 18.75%\n",
      "Batch 3, Loss: 8.423573, Accuracy: 17.97%\n",
      "Batch 4, Loss: 7.805028, Accuracy: 17.81%\n",
      "Batch 5, Loss: 7.802855, Accuracy: 17.45%\n",
      "Batch 6, Loss: 7.500897, Accuracy: 17.63%\n",
      "Batch 7, Loss: 8.611555, Accuracy: 16.60%\n",
      "Batch 8, Loss: 7.813136, Accuracy: 16.32%\n",
      "Batch 9, Loss: 7.964454, Accuracy: 15.78%\n",
      "Batch 10, Loss: 7.231737, Accuracy: 16.19%\n",
      "Batch 11, Loss: 7.905833, Accuracy: 16.41%\n",
      "Batch 12, Loss: 7.606075, Accuracy: 16.71%\n",
      "Batch 13, Loss: 8.044147, Accuracy: 16.63%\n",
      "Batch 14, Loss: 8.409081, Accuracy: 16.25%\n",
      "Batch 15, Loss: 7.126869, Accuracy: 16.50%\n",
      "Batch 16, Loss: 8.492218, Accuracy: 15.99%\n",
      "Batch 17, Loss: 8.488777, Accuracy: 16.06%\n",
      "Batch 18, Loss: 7.804599, Accuracy: 16.12%\n",
      "Batch 19, Loss: 7.876325, Accuracy: 15.94%\n",
      "Batch 20, Loss: 8.595065, Accuracy: 15.70%\n",
      "Batch 21, Loss: 7.999097, Accuracy: 15.77%\n",
      "Batch 22, Loss: 7.817430, Accuracy: 15.62%\n",
      "Batch 23, Loss: 7.726305, Accuracy: 15.76%\n",
      "Batch 24, Loss: 6.655069, Accuracy: 16.12%\n",
      "Batch 25, Loss: 7.179074, Accuracy: 16.47%\n",
      "Batch 26, Loss: 9.149011, Accuracy: 16.39%\n",
      "Model — vit-small\n",
      "Average Accuracy — 16.388557806912992\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
      "Using device: cpu\n",
      "Batch 0, Loss: 7.456566, Accuracy: 25.00%\n",
      "Batch 1, Loss: 8.493906, Accuracy: 21.09%\n",
      "Batch 2, Loss: 7.602952, Accuracy: 21.88%\n",
      "Batch 3, Loss: 7.380253, Accuracy: 20.31%\n",
      "Batch 4, Loss: 7.641112, Accuracy: 20.94%\n",
      "Batch 5, Loss: 8.807877, Accuracy: 19.01%\n",
      "Batch 6, Loss: 8.347194, Accuracy: 18.53%\n",
      "Batch 7, Loss: 8.632407, Accuracy: 17.58%\n",
      "Batch 8, Loss: 7.625085, Accuracy: 17.88%\n",
      "Batch 9, Loss: 7.270136, Accuracy: 17.97%\n",
      "Batch 10, Loss: 8.255234, Accuracy: 18.61%\n",
      "Batch 11, Loss: 8.644567, Accuracy: 18.62%\n",
      "Batch 12, Loss: 7.956433, Accuracy: 18.75%\n",
      "Batch 13, Loss: 8.996915, Accuracy: 18.19%\n",
      "Batch 14, Loss: 7.958449, Accuracy: 18.12%\n",
      "Batch 15, Loss: 7.564442, Accuracy: 18.16%\n",
      "Batch 16, Loss: 7.911151, Accuracy: 18.20%\n",
      "Batch 17, Loss: 8.227623, Accuracy: 17.97%\n",
      "Batch 18, Loss: 7.554293, Accuracy: 18.09%\n",
      "Batch 19, Loss: 7.240637, Accuracy: 18.36%\n",
      "Batch 20, Loss: 7.203436, Accuracy: 18.75%\n",
      "Batch 21, Loss: 8.392941, Accuracy: 18.39%\n",
      "Batch 22, Loss: 8.127205, Accuracy: 18.41%\n",
      "Batch 23, Loss: 7.919919, Accuracy: 18.42%\n",
      "Batch 24, Loss: 7.801519, Accuracy: 18.38%\n",
      "Batch 25, Loss: 8.046364, Accuracy: 18.51%\n",
      "Batch 26, Loss: 7.846076, Accuracy: 18.53%\n",
      "Model — vit-base\n",
      "Average Accuracy — 18.533969010727056\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
      "Using device: cpu\n",
      "Batch 0, Loss: 4.258915, Accuracy: 25.00%\n",
      "Batch 1, Loss: 4.001232, Accuracy: 24.22%\n",
      "Batch 2, Loss: 4.132745, Accuracy: 25.00%\n",
      "Batch 3, Loss: 4.482739, Accuracy: 23.83%\n",
      "Batch 4, Loss: 3.868687, Accuracy: 23.75%\n",
      "Batch 5, Loss: 4.374887, Accuracy: 22.92%\n",
      "Batch 6, Loss: 4.354571, Accuracy: 22.99%\n",
      "Batch 7, Loss: 4.476202, Accuracy: 23.24%\n",
      "Batch 8, Loss: 4.767190, Accuracy: 23.78%\n",
      "Batch 9, Loss: 4.111779, Accuracy: 23.75%\n",
      "Batch 10, Loss: 5.090526, Accuracy: 23.44%\n",
      "Batch 11, Loss: 5.179917, Accuracy: 22.79%\n",
      "Batch 12, Loss: 3.813005, Accuracy: 23.32%\n",
      "Batch 13, Loss: 3.718155, Accuracy: 24.00%\n",
      "Batch 14, Loss: 5.159009, Accuracy: 23.85%\n",
      "Batch 15, Loss: 4.240510, Accuracy: 24.22%\n",
      "Batch 16, Loss: 4.952926, Accuracy: 23.81%\n",
      "Batch 17, Loss: 3.782062, Accuracy: 23.78%\n",
      "Batch 18, Loss: 4.081151, Accuracy: 23.77%\n",
      "Batch 19, Loss: 4.867231, Accuracy: 23.52%\n",
      "Batch 20, Loss: 5.024518, Accuracy: 23.36%\n",
      "Batch 21, Loss: 3.949394, Accuracy: 23.72%\n",
      "Batch 22, Loss: 4.818112, Accuracy: 23.71%\n",
      "Batch 23, Loss: 4.743103, Accuracy: 23.76%\n",
      "Batch 24, Loss: 4.648160, Accuracy: 23.75%\n",
      "Batch 25, Loss: 4.874516, Accuracy: 23.38%\n",
      "Batch 26, Loss: 3.268582, Accuracy: 23.42%\n",
      "Model — resnet-18\n",
      "Average Accuracy — 23.420738974970202\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
      "Using device: cpu\n",
      "Batch 0, Loss: 5.472705, Accuracy: 31.25%\n",
      "Batch 1, Loss: 5.351617, Accuracy: 28.91%\n",
      "Batch 2, Loss: 5.026449, Accuracy: 32.81%\n",
      "Batch 3, Loss: 4.776207, Accuracy: 32.03%\n",
      "Batch 4, Loss: 5.288635, Accuracy: 32.81%\n",
      "Batch 5, Loss: 4.289533, Accuracy: 33.59%\n",
      "Batch 6, Loss: 4.261659, Accuracy: 34.38%\n",
      "Batch 7, Loss: 6.519310, Accuracy: 32.81%\n",
      "Batch 8, Loss: 6.126914, Accuracy: 32.47%\n",
      "Batch 9, Loss: 5.994962, Accuracy: 31.56%\n",
      "Batch 10, Loss: 5.508279, Accuracy: 31.39%\n",
      "Batch 11, Loss: 4.637343, Accuracy: 32.03%\n",
      "Batch 12, Loss: 5.398433, Accuracy: 31.61%\n",
      "Batch 13, Loss: 5.543061, Accuracy: 31.92%\n",
      "Batch 14, Loss: 4.969365, Accuracy: 31.88%\n",
      "Batch 15, Loss: 5.209912, Accuracy: 31.74%\n",
      "Batch 16, Loss: 4.953549, Accuracy: 31.43%\n",
      "Batch 17, Loss: 5.945989, Accuracy: 31.16%\n",
      "Batch 18, Loss: 4.968932, Accuracy: 31.00%\n",
      "Batch 19, Loss: 5.171354, Accuracy: 30.78%\n",
      "Batch 20, Loss: 6.146213, Accuracy: 30.36%\n",
      "Batch 21, Loss: 5.421213, Accuracy: 30.26%\n",
      "Batch 22, Loss: 6.725917, Accuracy: 29.82%\n",
      "Batch 23, Loss: 5.423336, Accuracy: 29.75%\n",
      "Batch 24, Loss: 5.446038, Accuracy: 29.75%\n",
      "Batch 25, Loss: 5.278409, Accuracy: 29.99%\n",
      "Batch 26, Loss: 5.965492, Accuracy: 29.98%\n",
      "Model — resnet-34\n",
      "Average Accuracy — 29.9761620977354\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
      "Using device: cpu\n",
      "Batch 0, Loss: 1.504594, Accuracy: 20.31%\n",
      "Batch 1, Loss: 1.496068, Accuracy: 21.88%\n",
      "Batch 2, Loss: 1.513973, Accuracy: 20.31%\n",
      "Batch 3, Loss: 1.469129, Accuracy: 21.48%\n",
      "Batch 4, Loss: 1.419197, Accuracy: 22.50%\n",
      "Batch 5, Loss: 1.492764, Accuracy: 22.66%\n",
      "Batch 6, Loss: 1.438136, Accuracy: 23.44%\n",
      "Batch 7, Loss: 1.454075, Accuracy: 24.02%\n",
      "Batch 8, Loss: 1.424742, Accuracy: 24.48%\n",
      "Batch 9, Loss: 1.516279, Accuracy: 23.91%\n",
      "Batch 10, Loss: 1.487617, Accuracy: 23.72%\n",
      "Batch 11, Loss: 1.498007, Accuracy: 23.44%\n",
      "Batch 12, Loss: 1.536644, Accuracy: 22.96%\n",
      "Batch 13, Loss: 1.536366, Accuracy: 22.32%\n",
      "Batch 14, Loss: 1.406879, Accuracy: 22.92%\n",
      "Batch 15, Loss: 1.461442, Accuracy: 22.85%\n",
      "Batch 16, Loss: 1.517535, Accuracy: 22.70%\n",
      "Batch 17, Loss: 1.440029, Accuracy: 23.00%\n",
      "Batch 18, Loss: 1.523283, Accuracy: 22.86%\n",
      "Batch 19, Loss: 1.409459, Accuracy: 23.28%\n",
      "Batch 20, Loss: 1.498196, Accuracy: 23.29%\n",
      "Batch 21, Loss: 1.426709, Accuracy: 23.58%\n",
      "Batch 22, Loss: 1.448410, Accuracy: 23.85%\n",
      "Batch 23, Loss: 1.495805, Accuracy: 23.89%\n",
      "Batch 24, Loss: 1.444053, Accuracy: 24.06%\n",
      "Batch 25, Loss: 1.379206, Accuracy: 24.52%\n",
      "Batch 26, Loss: 1.396873, Accuracy: 24.61%\n",
      "Model — cnn-5-layer\n",
      "Average Accuracy — 24.612634088200238\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n",
      "Using device: cpu\n",
      "Batch 0, Loss: 1.521287, Accuracy: 17.19%\n",
      "Batch 1, Loss: 1.584950, Accuracy: 14.06%\n",
      "Batch 2, Loss: 1.504990, Accuracy: 16.15%\n",
      "Batch 3, Loss: 1.502725, Accuracy: 16.80%\n",
      "Batch 4, Loss: 1.582559, Accuracy: 15.94%\n",
      "Batch 5, Loss: 1.432122, Accuracy: 17.97%\n",
      "Batch 6, Loss: 1.503278, Accuracy: 17.86%\n",
      "Batch 7, Loss: 1.523614, Accuracy: 17.77%\n",
      "Batch 8, Loss: 1.505620, Accuracy: 18.06%\n",
      "Batch 9, Loss: 1.491628, Accuracy: 18.44%\n",
      "Batch 10, Loss: 1.481945, Accuracy: 18.89%\n",
      "Batch 11, Loss: 1.535819, Accuracy: 18.75%\n",
      "Batch 12, Loss: 1.563323, Accuracy: 18.39%\n",
      "Batch 13, Loss: 1.503799, Accuracy: 18.53%\n",
      "Batch 14, Loss: 1.505101, Accuracy: 18.65%\n",
      "Batch 15, Loss: 1.529616, Accuracy: 18.65%\n",
      "Batch 16, Loss: 1.591235, Accuracy: 18.01%\n",
      "Batch 17, Loss: 1.528043, Accuracy: 18.06%\n",
      "Batch 18, Loss: 1.462008, Accuracy: 18.50%\n",
      "Batch 19, Loss: 1.504313, Accuracy: 18.52%\n",
      "Batch 20, Loss: 1.563505, Accuracy: 18.38%\n",
      "Batch 21, Loss: 1.497799, Accuracy: 18.54%\n",
      "Batch 22, Loss: 1.582548, Accuracy: 18.21%\n",
      "Batch 23, Loss: 1.582931, Accuracy: 17.90%\n",
      "Batch 24, Loss: 1.499554, Accuracy: 18.00%\n",
      "Batch 25, Loss: 1.552162, Accuracy: 17.79%\n",
      "Batch 26, Loss: 1.410123, Accuracy: 17.88%\n",
      "Model — cnn-6-layer\n",
      "Average Accuracy — 17.878426698450536\n",
      "+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=\n"
     ]
    }
   ],
   "source": [
    "model_types = ['vit-tiny', 'vit-small', 'vit-base', 'resnet-18', 'resnet-34', 'cnn-5-layer', 'cnn-6-layer']\n",
    "for model in model_types:\n",
    "    test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
