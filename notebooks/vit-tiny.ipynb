{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in /home/ubuntu/.local/lib/python3.10/site-packages (0.9.16)\n",
      "Requirement already satisfied: torch in /usr/lib/python3/dist-packages (from timm) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /usr/lib/python3/dist-packages (from timm) (0.15.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: huggingface_hub in /home/ubuntu/.local/lib/python3.10/site-packages (from timm) (0.21.3)\n",
      "Requirement already satisfied: safetensors in /home/ubuntu/.local/lib/python3.10/site-packages (from timm) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface_hub->timm) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/lib/python3/dist-packages (from huggingface_hub->timm) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub->timm) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub->timm) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub->timm) (2020.6.20)\n",
      "\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.16\n",
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "print(timm.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit(model_name):\n",
    "    if model_name == 'tiny': model = timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=4)\n",
    "    if model_name == 'small': model = timm.create_model('vit_small_patch16_224', pretrained=False, num_classes=4)\n",
    "    if model_name == 'base': model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=4)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='/home/ubuntu/Parkinson-Project/non-keyframes/energy_images', transform=transform)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.8) \n",
    "validation_size = int(total_size * 0.1) \n",
    "test_size = total_size - train_size - validation_size\n",
    "generator = torch.Generator().manual_seed(0) \n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size], generator=generator)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'vit-tiny-130-epochs-early-stopping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (patch_drop): Identity()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Linear(in_features=192, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_type = 'tiny'\n",
    "model = create_vit(model_type)\n",
    "\n",
    "# Model summary to check architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Epoch 1\n",
      "Batch 1, Loss: 1.408022, Accuracy: 18.75%\n",
      "Batch 2, Loss: 1.514790, Accuracy: 27.34%\n",
      "Batch 3, Loss: 1.423060, Accuracy: 28.12%\n",
      "Batch 4, Loss: 1.287449, Accuracy: 30.86%\n",
      "Batch 5, Loss: 1.372656, Accuracy: 30.31%\n",
      "Batch 6, Loss: 1.214050, Accuracy: 31.51%\n",
      "Batch 7, Loss: 1.265800, Accuracy: 30.58%\n",
      "Batch 8, Loss: 1.267545, Accuracy: 29.10%\n",
      "Batch 9, Loss: 1.325170, Accuracy: 30.21%\n",
      "Batch 10, Loss: 1.353290, Accuracy: 30.16%\n",
      "Batch 11, Loss: 1.234784, Accuracy: 30.40%\n",
      "Batch 12, Loss: 1.351267, Accuracy: 30.99%\n",
      "Batch 13, Loss: 1.265854, Accuracy: 31.01%\n",
      "Batch 14, Loss: 1.321154, Accuracy: 30.92%\n",
      "Batch 15, Loss: 1.214875, Accuracy: 31.25%\n",
      "Batch 16, Loss: 1.309605, Accuracy: 31.35%\n",
      "Batch 17, Loss: 1.359040, Accuracy: 31.25%\n",
      "Batch 18, Loss: 1.295241, Accuracy: 31.68%\n",
      "Batch 19, Loss: 1.264220, Accuracy: 31.91%\n",
      "Batch 20, Loss: 1.316950, Accuracy: 32.11%\n",
      "Batch 21, Loss: 1.427047, Accuracy: 31.47%\n",
      "Batch 22, Loss: 1.228476, Accuracy: 31.68%\n",
      "Batch 23, Loss: 1.234161, Accuracy: 32.00%\n",
      "Batch 24, Loss: 1.298727, Accuracy: 32.10%\n",
      "Batch 25, Loss: 1.290901, Accuracy: 32.25%\n",
      "Batch 26, Loss: 1.327903, Accuracy: 32.39%\n",
      "Batch 27, Loss: 1.252679, Accuracy: 32.29%\n",
      "Batch 28, Loss: 1.312792, Accuracy: 32.31%\n",
      "Batch 29, Loss: 1.267314, Accuracy: 32.38%\n",
      "Batch 30, Loss: 1.267540, Accuracy: 32.40%\n",
      "Batch 31, Loss: 1.303555, Accuracy: 32.41%\n",
      "Batch 32, Loss: 1.213891, Accuracy: 32.52%\n",
      "Batch 33, Loss: 1.255157, Accuracy: 32.29%\n",
      "Batch 34, Loss: 1.279223, Accuracy: 32.17%\n",
      "Batch 35, Loss: 1.232382, Accuracy: 32.23%\n",
      "Batch 36, Loss: 1.307083, Accuracy: 32.34%\n",
      "Batch 37, Loss: 1.310336, Accuracy: 32.43%\n",
      "Batch 38, Loss: 1.248201, Accuracy: 32.65%\n",
      "Batch 39, Loss: 1.249617, Accuracy: 32.61%\n",
      "Batch 40, Loss: 1.195160, Accuracy: 32.73%\n",
      "Batch 41, Loss: 1.242669, Accuracy: 33.00%\n",
      "Batch 42, Loss: 1.310649, Accuracy: 33.00%\n",
      "Batch 43, Loss: 1.214249, Accuracy: 33.28%\n",
      "Batch 44, Loss: 1.240120, Accuracy: 33.38%\n",
      "Batch 45, Loss: 1.249233, Accuracy: 33.44%\n",
      "Batch 46, Loss: 1.202139, Accuracy: 33.42%\n",
      "Batch 47, Loss: 1.218526, Accuracy: 33.28%\n",
      "Batch 48, Loss: 1.170829, Accuracy: 33.17%\n",
      "Batch 49, Loss: 1.194999, Accuracy: 33.13%\n",
      "Batch 50, Loss: 1.315467, Accuracy: 33.00%\n",
      "Batch 51, Loss: 1.168442, Accuracy: 33.00%\n",
      "Batch 52, Loss: 1.285662, Accuracy: 33.14%\n",
      "Batch 53, Loss: 1.277901, Accuracy: 33.17%\n",
      "Batch 54, Loss: 1.362155, Accuracy: 33.25%\n",
      "Batch 55, Loss: 1.237267, Accuracy: 33.27%\n",
      "Batch 56, Loss: 1.373388, Accuracy: 33.12%\n",
      "Batch 57, Loss: 1.242341, Accuracy: 33.22%\n",
      "Batch 58, Loss: 1.416715, Accuracy: 33.08%\n",
      "Batch 59, Loss: 1.223603, Accuracy: 33.10%\n",
      "Batch 60, Loss: 1.380587, Accuracy: 32.97%\n",
      "Batch 61, Loss: 1.271631, Accuracy: 33.07%\n",
      "Batch 62, Loss: 1.287063, Accuracy: 32.96%\n",
      "Batch 63, Loss: 1.195752, Accuracy: 33.06%\n",
      "Batch 64, Loss: 1.302379, Accuracy: 33.23%\n",
      "Batch 65, Loss: 1.225202, Accuracy: 33.20%\n",
      "Batch 66, Loss: 1.301051, Accuracy: 33.19%\n",
      "Batch 67, Loss: 1.240499, Accuracy: 33.33%\n",
      "Batch 68, Loss: 1.342042, Accuracy: 33.36%\n",
      "Batch 69, Loss: 1.289622, Accuracy: 33.33%\n",
      "Batch 70, Loss: 1.320347, Accuracy: 33.37%\n",
      "Batch 71, Loss: 1.225317, Accuracy: 33.38%\n",
      "Batch 72, Loss: 1.306915, Accuracy: 33.22%\n",
      "Batch 73, Loss: 1.314985, Accuracy: 33.18%\n",
      "Batch 74, Loss: 1.227303, Accuracy: 33.21%\n",
      "Batch 75, Loss: 1.231584, Accuracy: 33.19%\n",
      "Batch 76, Loss: 1.283302, Accuracy: 33.18%\n",
      "Batch 77, Loss: 1.268037, Accuracy: 33.20%\n",
      "Batch 78, Loss: 1.246567, Accuracy: 33.33%\n",
      "Batch 79, Loss: 1.253858, Accuracy: 33.48%\n",
      "Batch 80, Loss: 1.300731, Accuracy: 33.38%\n",
      "Batch 81, Loss: 1.308564, Accuracy: 33.33%\n",
      "Batch 82, Loss: 1.295357, Accuracy: 33.40%\n",
      "Batch 83, Loss: 1.273052, Accuracy: 33.32%\n",
      "Batch 84, Loss: 1.226956, Accuracy: 33.30%\n",
      "Batch 85, Loss: 1.226988, Accuracy: 33.25%\n",
      "Batch 86, Loss: 1.211774, Accuracy: 33.32%\n",
      "Batch 87, Loss: 1.255283, Accuracy: 33.24%\n",
      "Batch 88, Loss: 1.299597, Accuracy: 33.17%\n",
      "Batch 89, Loss: 1.219847, Accuracy: 33.06%\n",
      "Batch 90, Loss: 1.286770, Accuracy: 33.04%\n",
      "Batch 91, Loss: 1.206211, Accuracy: 33.04%\n",
      "Batch 92, Loss: 1.302420, Accuracy: 32.98%\n",
      "Batch 93, Loss: 1.348684, Accuracy: 32.98%\n",
      "Batch 94, Loss: 1.359864, Accuracy: 32.95%\n",
      "Batch 95, Loss: 1.307291, Accuracy: 32.98%\n",
      "Batch 96, Loss: 1.357282, Accuracy: 33.01%\n",
      "Batch 97, Loss: 1.294619, Accuracy: 33.02%\n",
      "Batch 98, Loss: 1.319042, Accuracy: 33.05%\n",
      "Batch 99, Loss: 1.307936, Accuracy: 33.02%\n",
      "Batch 100, Loss: 1.215729, Accuracy: 33.16%\n",
      "Batch 101, Loss: 1.337026, Accuracy: 33.08%\n",
      "Batch 102, Loss: 1.195276, Accuracy: 33.09%\n",
      "Batch 103, Loss: 1.240811, Accuracy: 33.13%\n",
      "Batch 104, Loss: 1.168537, Accuracy: 33.23%\n",
      "Batch 105, Loss: 1.275523, Accuracy: 33.18%\n",
      "Batch 106, Loss: 1.232354, Accuracy: 33.27%\n",
      "Batch 107, Loss: 1.240154, Accuracy: 33.35%\n",
      "Batch 108, Loss: 1.201647, Accuracy: 33.41%\n",
      "Batch 109, Loss: 1.253700, Accuracy: 33.39%\n",
      "Batch 110, Loss: 1.253264, Accuracy: 33.34%\n",
      "Batch 111, Loss: 1.310591, Accuracy: 33.29%\n",
      "Batch 112, Loss: 1.209517, Accuracy: 33.40%\n",
      "Batch 113, Loss: 1.298328, Accuracy: 33.43%\n",
      "Batch 114, Loss: 1.331190, Accuracy: 33.46%\n",
      "Batch 115, Loss: 1.297951, Accuracy: 33.46%\n",
      "Batch 116, Loss: 1.247998, Accuracy: 33.50%\n",
      "Batch 117, Loss: 1.311830, Accuracy: 33.48%\n",
      "Batch 118, Loss: 1.203868, Accuracy: 33.46%\n",
      "Batch 119, Loss: 1.180940, Accuracy: 33.48%\n",
      "Batch 120, Loss: 1.273276, Accuracy: 33.52%\n",
      "Batch 121, Loss: 1.297663, Accuracy: 33.46%\n",
      "Batch 122, Loss: 1.217347, Accuracy: 33.52%\n",
      "Batch 123, Loss: 1.215653, Accuracy: 33.55%\n",
      "Batch 124, Loss: 1.334214, Accuracy: 33.53%\n",
      "Batch 125, Loss: 1.235755, Accuracy: 33.59%\n",
      "Batch 126, Loss: 1.213941, Accuracy: 33.61%\n",
      "Batch 127, Loss: 1.154361, Accuracy: 33.65%\n",
      "Batch 128, Loss: 1.245321, Accuracy: 33.63%\n",
      "Batch 129, Loss: 1.246610, Accuracy: 33.61%\n",
      "Batch 130, Loss: 1.235502, Accuracy: 33.62%\n",
      "Batch 131, Loss: 1.266009, Accuracy: 33.59%\n",
      "Batch 132, Loss: 1.244478, Accuracy: 33.64%\n",
      "Batch 133, Loss: 1.333623, Accuracy: 33.61%\n",
      "Batch 134, Loss: 1.225138, Accuracy: 33.61%\n",
      "Batch 135, Loss: 1.230409, Accuracy: 33.60%\n",
      "Batch 136, Loss: 1.285487, Accuracy: 33.58%\n",
      "Batch 137, Loss: 1.334113, Accuracy: 33.52%\n",
      "Batch 138, Loss: 1.359985, Accuracy: 33.51%\n",
      "Batch 139, Loss: 1.199875, Accuracy: 33.54%\n",
      "Batch 140, Loss: 1.267597, Accuracy: 33.54%\n",
      "Batch 141, Loss: 1.169848, Accuracy: 33.58%\n",
      "Batch 142, Loss: 1.326216, Accuracy: 33.54%\n",
      "Batch 143, Loss: 1.266274, Accuracy: 33.51%\n",
      "Batch 144, Loss: 1.406252, Accuracy: 33.46%\n",
      "Batch 145, Loss: 1.260729, Accuracy: 33.47%\n",
      "Batch 146, Loss: 1.238805, Accuracy: 33.42%\n",
      "Batch 147, Loss: 1.238887, Accuracy: 33.38%\n",
      "Batch 148, Loss: 1.217134, Accuracy: 33.48%\n",
      "Batch 149, Loss: 1.239292, Accuracy: 33.43%\n",
      "Batch 150, Loss: 1.271012, Accuracy: 33.49%\n",
      "Batch 151, Loss: 1.277442, Accuracy: 33.52%\n",
      "Batch 152, Loss: 1.242485, Accuracy: 33.52%\n",
      "Batch 153, Loss: 1.300459, Accuracy: 33.51%\n",
      "Batch 154, Loss: 1.272592, Accuracy: 33.49%\n",
      "Batch 155, Loss: 1.220309, Accuracy: 33.57%\n",
      "Batch 156, Loss: 1.298129, Accuracy: 33.52%\n",
      "Batch 157, Loss: 1.223884, Accuracy: 33.54%\n",
      "Batch 158, Loss: 1.323321, Accuracy: 33.59%\n",
      "Batch 159, Loss: 1.341411, Accuracy: 33.53%\n",
      "Batch 160, Loss: 1.210516, Accuracy: 33.54%\n",
      "Batch 161, Loss: 1.222120, Accuracy: 33.53%\n",
      "Batch 162, Loss: 1.206304, Accuracy: 33.58%\n",
      "Batch 163, Loss: 1.262961, Accuracy: 33.57%\n",
      "Batch 164, Loss: 1.230478, Accuracy: 33.68%\n",
      "Batch 165, Loss: 1.305021, Accuracy: 33.70%\n",
      "Batch 166, Loss: 1.227441, Accuracy: 33.73%\n",
      "Batch 167, Loss: 1.154789, Accuracy: 33.78%\n",
      "Batch 168, Loss: 1.275492, Accuracy: 33.73%\n",
      "Batch 169, Loss: 1.205673, Accuracy: 33.75%\n",
      "Batch 170, Loss: 1.343477, Accuracy: 33.77%\n",
      "Batch 171, Loss: 1.225788, Accuracy: 33.77%\n",
      "Batch 172, Loss: 1.250133, Accuracy: 33.78%\n",
      "Batch 173, Loss: 1.256274, Accuracy: 33.80%\n",
      "Batch 174, Loss: 1.260421, Accuracy: 33.84%\n",
      "Batch 175, Loss: 1.226110, Accuracy: 33.79%\n",
      "Batch 176, Loss: 1.223482, Accuracy: 33.84%\n",
      "Batch 177, Loss: 1.254066, Accuracy: 33.87%\n",
      "Batch 178, Loss: 1.289746, Accuracy: 33.87%\n",
      "Batch 179, Loss: 1.276466, Accuracy: 33.93%\n",
      "Batch 180, Loss: 1.258521, Accuracy: 33.92%\n",
      "Batch 181, Loss: 1.285724, Accuracy: 33.91%\n",
      "Batch 182, Loss: 1.263566, Accuracy: 33.91%\n",
      "Batch 183, Loss: 1.167721, Accuracy: 33.93%\n",
      "Batch 184, Loss: 1.229189, Accuracy: 33.99%\n",
      "Batch 185, Loss: 1.262555, Accuracy: 34.01%\n",
      "Batch 186, Loss: 1.221776, Accuracy: 34.03%\n",
      "Batch 187, Loss: 1.182338, Accuracy: 34.04%\n",
      "Batch 188, Loss: 1.194551, Accuracy: 34.12%\n",
      "Batch 189, Loss: 1.372340, Accuracy: 34.11%\n",
      "Batch 190, Loss: 1.323511, Accuracy: 34.11%\n",
      "Batch 191, Loss: 1.347162, Accuracy: 34.09%\n",
      "Batch 192, Loss: 1.230225, Accuracy: 34.11%\n",
      "Batch 193, Loss: 1.339704, Accuracy: 34.12%\n",
      "Batch 194, Loss: 1.153639, Accuracy: 34.13%\n",
      "Batch 195, Loss: 1.277267, Accuracy: 34.12%\n",
      "Batch 196, Loss: 1.211655, Accuracy: 34.17%\n",
      "Batch 197, Loss: 1.308189, Accuracy: 34.18%\n",
      "Batch 198, Loss: 1.315128, Accuracy: 34.20%\n",
      "Batch 199, Loss: 1.240430, Accuracy: 34.21%\n",
      "Batch 200, Loss: 1.203412, Accuracy: 34.26%\n",
      "Batch 201, Loss: 1.347483, Accuracy: 34.31%\n",
      "Batch 202, Loss: 1.225630, Accuracy: 34.34%\n",
      "Batch 203, Loss: 1.218971, Accuracy: 34.45%\n",
      "Batch 204, Loss: 1.210595, Accuracy: 34.51%\n",
      "Batch 205, Loss: 1.205524, Accuracy: 34.60%\n",
      "Batch 206, Loss: 1.224241, Accuracy: 34.63%\n",
      "Batch 207, Loss: 1.274709, Accuracy: 34.69%\n",
      "Batch 208, Loss: 1.188275, Accuracy: 34.74%\n",
      "Batch 209, Loss: 1.207805, Accuracy: 34.76%\n",
      "Batch 210, Loss: 1.193624, Accuracy: 34.75%\n",
      "Batch 211, Loss: 1.193586, Accuracy: 34.82%\n",
      "Batch 212, Loss: 1.193293, Accuracy: 34.87%\n",
      "Batch 213, Loss: 1.253731, Accuracy: 34.89%\n",
      "Training - Epoch 1, Loss: 1.266787, Accuracy: 34.89%\n",
      "Validation Batch 1, Loss: 1.193866, Accuracy: 40.62%\n",
      "Validation Batch 2, Loss: 1.194017, Accuracy: 40.62%\n",
      "Validation Batch 3, Loss: 1.297046, Accuracy: 39.06%\n",
      "Validation Batch 4, Loss: 1.166125, Accuracy: 41.80%\n",
      "Validation Batch 5, Loss: 1.141878, Accuracy: 41.56%\n",
      "Validation Batch 6, Loss: 1.164252, Accuracy: 41.67%\n",
      "Validation Batch 7, Loss: 1.226812, Accuracy: 41.29%\n",
      "Validation Batch 8, Loss: 1.279930, Accuracy: 41.02%\n",
      "Validation Batch 9, Loss: 1.260969, Accuracy: 40.45%\n",
      "Validation Batch 10, Loss: 1.196696, Accuracy: 40.47%\n",
      "Validation Batch 11, Loss: 1.195218, Accuracy: 41.05%\n",
      "Validation Batch 12, Loss: 1.149582, Accuracy: 41.28%\n",
      "Validation Batch 13, Loss: 1.244115, Accuracy: 41.59%\n",
      "Validation Batch 14, Loss: 1.218160, Accuracy: 41.96%\n",
      "Validation Batch 15, Loss: 1.194364, Accuracy: 42.29%\n",
      "Validation Batch 16, Loss: 1.218363, Accuracy: 42.38%\n",
      "Validation Batch 17, Loss: 1.271313, Accuracy: 42.56%\n",
      "Validation Batch 18, Loss: 1.202786, Accuracy: 42.62%\n",
      "Validation Batch 19, Loss: 1.265089, Accuracy: 42.52%\n",
      "Validation Batch 20, Loss: 1.121251, Accuracy: 42.81%\n",
      "Validation Batch 21, Loss: 1.159995, Accuracy: 42.56%\n",
      "Validation Batch 22, Loss: 1.225545, Accuracy: 42.61%\n",
      "Validation Batch 23, Loss: 1.175206, Accuracy: 42.87%\n",
      "Validation Batch 24, Loss: 1.236451, Accuracy: 42.84%\n",
      "Validation Batch 25, Loss: 1.127460, Accuracy: 43.06%\n",
      "Validation Batch 26, Loss: 1.191897, Accuracy: 43.39%\n",
      "Validation Batch 27, Loss: 1.128099, Accuracy: 43.51%\n",
      "Validation - Epoch 1, Loss: 1.201722, Accuracy: 43.51%\n",
      "Patience—0\n",
      "Epoch 2\n",
      "Batch 1, Loss: 1.202251, Accuracy: 42.19%\n",
      "Batch 2, Loss: 1.344704, Accuracy: 36.72%\n",
      "Batch 3, Loss: 1.275955, Accuracy: 37.50%\n",
      "Batch 4, Loss: 1.176133, Accuracy: 37.89%\n",
      "Batch 5, Loss: 1.193053, Accuracy: 41.56%\n",
      "Batch 6, Loss: 1.132330, Accuracy: 43.75%\n",
      "Batch 7, Loss: 1.132644, Accuracy: 43.75%\n",
      "Batch 8, Loss: 1.218212, Accuracy: 44.34%\n",
      "Batch 9, Loss: 1.171922, Accuracy: 44.10%\n",
      "Batch 10, Loss: 1.290797, Accuracy: 44.22%\n",
      "Batch 11, Loss: 1.132710, Accuracy: 44.89%\n",
      "Batch 12, Loss: 1.373969, Accuracy: 43.88%\n",
      "Batch 13, Loss: 1.229427, Accuracy: 44.23%\n",
      "Batch 14, Loss: 1.299585, Accuracy: 44.20%\n",
      "Batch 15, Loss: 1.091082, Accuracy: 45.00%\n",
      "Batch 16, Loss: 1.194306, Accuracy: 45.51%\n",
      "Batch 17, Loss: 1.149321, Accuracy: 45.68%\n",
      "Batch 18, Loss: 1.229951, Accuracy: 44.97%\n",
      "Batch 19, Loss: 1.198475, Accuracy: 44.82%\n",
      "Batch 20, Loss: 1.359584, Accuracy: 43.83%\n",
      "Batch 21, Loss: 1.188227, Accuracy: 43.53%\n",
      "Batch 22, Loss: 1.224873, Accuracy: 43.68%\n",
      "Batch 23, Loss: 1.265169, Accuracy: 43.14%\n",
      "Batch 24, Loss: 1.249088, Accuracy: 42.77%\n",
      "Batch 25, Loss: 1.159396, Accuracy: 42.56%\n",
      "Batch 26, Loss: 1.273167, Accuracy: 42.43%\n",
      "Batch 27, Loss: 1.247375, Accuracy: 42.94%\n",
      "Batch 28, Loss: 1.182595, Accuracy: 43.08%\n",
      "Batch 29, Loss: 1.093520, Accuracy: 43.53%\n",
      "Batch 30, Loss: 1.211766, Accuracy: 43.44%\n",
      "Batch 31, Loss: 1.363190, Accuracy: 43.25%\n",
      "Batch 32, Loss: 1.083055, Accuracy: 43.55%\n",
      "Batch 33, Loss: 1.283188, Accuracy: 43.51%\n",
      "Batch 34, Loss: 1.115645, Accuracy: 43.75%\n",
      "Batch 35, Loss: 1.192676, Accuracy: 43.79%\n",
      "Batch 36, Loss: 1.264977, Accuracy: 43.49%\n",
      "Batch 37, Loss: 1.181540, Accuracy: 43.67%\n",
      "Batch 38, Loss: 1.221219, Accuracy: 43.46%\n",
      "Batch 39, Loss: 1.217829, Accuracy: 43.55%\n",
      "Batch 40, Loss: 1.183757, Accuracy: 43.63%\n",
      "Batch 41, Loss: 1.209205, Accuracy: 43.60%\n",
      "Batch 42, Loss: 1.152953, Accuracy: 43.42%\n",
      "Batch 43, Loss: 1.147997, Accuracy: 43.68%\n",
      "Batch 44, Loss: 1.198770, Accuracy: 43.79%\n",
      "Batch 45, Loss: 1.156291, Accuracy: 44.10%\n",
      "Batch 46, Loss: 1.139664, Accuracy: 44.43%\n",
      "Batch 47, Loss: 1.203940, Accuracy: 44.55%\n",
      "Batch 48, Loss: 1.216307, Accuracy: 44.53%\n",
      "Batch 49, Loss: 1.082271, Accuracy: 44.52%\n",
      "Batch 50, Loss: 1.216286, Accuracy: 44.50%\n",
      "Batch 51, Loss: 1.183572, Accuracy: 44.58%\n",
      "Batch 52, Loss: 1.032971, Accuracy: 44.77%\n",
      "Batch 53, Loss: 1.137277, Accuracy: 44.81%\n",
      "Batch 54, Loss: 1.276175, Accuracy: 44.73%\n",
      "Batch 55, Loss: 1.115771, Accuracy: 44.74%\n",
      "Batch 56, Loss: 1.169230, Accuracy: 44.78%\n",
      "Batch 57, Loss: 1.115312, Accuracy: 44.79%\n",
      "Batch 58, Loss: 1.239752, Accuracy: 44.88%\n",
      "Batch 59, Loss: 0.982033, Accuracy: 45.18%\n",
      "Batch 60, Loss: 1.026364, Accuracy: 45.36%\n",
      "Batch 61, Loss: 1.236105, Accuracy: 45.31%\n",
      "Batch 62, Loss: 0.979954, Accuracy: 45.51%\n",
      "Batch 63, Loss: 1.145536, Accuracy: 45.49%\n",
      "Batch 64, Loss: 1.182939, Accuracy: 45.53%\n",
      "Batch 65, Loss: 1.220241, Accuracy: 45.38%\n",
      "Batch 66, Loss: 1.098988, Accuracy: 45.45%\n",
      "Batch 67, Loss: 1.122217, Accuracy: 45.59%\n",
      "Batch 68, Loss: 1.074690, Accuracy: 45.80%\n",
      "Batch 69, Loss: 1.220571, Accuracy: 45.90%\n",
      "Batch 70, Loss: 1.114092, Accuracy: 46.00%\n",
      "Batch 71, Loss: 1.113617, Accuracy: 46.17%\n",
      "Batch 72, Loss: 1.291267, Accuracy: 46.16%\n",
      "Batch 73, Loss: 1.113238, Accuracy: 46.17%\n",
      "Batch 74, Loss: 1.143017, Accuracy: 46.22%\n",
      "Batch 75, Loss: 1.140556, Accuracy: 46.33%\n",
      "Batch 76, Loss: 1.131779, Accuracy: 46.36%\n",
      "Batch 77, Loss: 1.143529, Accuracy: 46.45%\n",
      "Batch 78, Loss: 1.076208, Accuracy: 46.69%\n",
      "Batch 79, Loss: 1.078171, Accuracy: 46.78%\n",
      "Batch 80, Loss: 1.094014, Accuracy: 46.86%\n",
      "Batch 81, Loss: 1.158991, Accuracy: 46.93%\n",
      "Batch 82, Loss: 1.165281, Accuracy: 47.05%\n",
      "Batch 83, Loss: 1.025594, Accuracy: 47.21%\n",
      "Batch 84, Loss: 1.037235, Accuracy: 47.34%\n",
      "Batch 85, Loss: 1.034495, Accuracy: 47.48%\n",
      "Batch 86, Loss: 1.051149, Accuracy: 47.60%\n",
      "Batch 87, Loss: 1.088286, Accuracy: 47.68%\n",
      "Batch 88, Loss: 1.312064, Accuracy: 47.64%\n",
      "Batch 89, Loss: 1.069468, Accuracy: 47.79%\n",
      "Batch 90, Loss: 1.033032, Accuracy: 47.83%\n",
      "Batch 91, Loss: 0.969056, Accuracy: 48.01%\n",
      "Batch 92, Loss: 1.076014, Accuracy: 48.06%\n",
      "Batch 93, Loss: 1.090228, Accuracy: 48.10%\n",
      "Batch 94, Loss: 0.934961, Accuracy: 48.25%\n",
      "Batch 95, Loss: 1.070457, Accuracy: 48.36%\n",
      "Batch 96, Loss: 0.940388, Accuracy: 48.50%\n",
      "Batch 97, Loss: 1.041615, Accuracy: 48.55%\n",
      "Batch 98, Loss: 1.137626, Accuracy: 48.60%\n",
      "Batch 99, Loss: 1.056342, Accuracy: 48.64%\n",
      "Batch 100, Loss: 1.089748, Accuracy: 48.67%\n",
      "Batch 101, Loss: 1.140575, Accuracy: 48.72%\n",
      "Batch 102, Loss: 1.131762, Accuracy: 48.73%\n",
      "Batch 103, Loss: 1.125262, Accuracy: 48.73%\n",
      "Batch 104, Loss: 0.918400, Accuracy: 48.86%\n",
      "Batch 105, Loss: 1.142834, Accuracy: 48.93%\n",
      "Batch 106, Loss: 0.954561, Accuracy: 49.06%\n",
      "Batch 107, Loss: 1.074941, Accuracy: 49.12%\n",
      "Batch 108, Loss: 1.037619, Accuracy: 49.20%\n",
      "Batch 109, Loss: 0.921754, Accuracy: 49.27%\n",
      "Batch 110, Loss: 0.924476, Accuracy: 49.38%\n",
      "Batch 111, Loss: 0.978833, Accuracy: 49.48%\n",
      "Batch 112, Loss: 1.108505, Accuracy: 49.47%\n",
      "Batch 113, Loss: 1.000679, Accuracy: 49.61%\n",
      "Batch 114, Loss: 0.905371, Accuracy: 49.71%\n",
      "Batch 115, Loss: 0.932495, Accuracy: 49.85%\n",
      "Batch 116, Loss: 0.945024, Accuracy: 49.89%\n",
      "Batch 117, Loss: 1.043936, Accuracy: 49.95%\n",
      "Batch 118, Loss: 0.973745, Accuracy: 50.04%\n",
      "Batch 119, Loss: 0.990659, Accuracy: 50.11%\n",
      "Batch 120, Loss: 1.102963, Accuracy: 50.10%\n",
      "Batch 121, Loss: 0.815885, Accuracy: 50.30%\n",
      "Batch 122, Loss: 1.181323, Accuracy: 50.35%\n",
      "Batch 123, Loss: 1.081222, Accuracy: 50.39%\n",
      "Batch 124, Loss: 0.828949, Accuracy: 50.52%\n",
      "Batch 125, Loss: 0.937967, Accuracy: 50.58%\n",
      "Batch 126, Loss: 1.201789, Accuracy: 50.57%\n",
      "Batch 127, Loss: 0.929427, Accuracy: 50.64%\n",
      "Batch 128, Loss: 0.989605, Accuracy: 50.73%\n",
      "Batch 129, Loss: 0.968114, Accuracy: 50.81%\n",
      "Batch 130, Loss: 0.927466, Accuracy: 50.91%\n",
      "Batch 131, Loss: 1.076294, Accuracy: 50.93%\n",
      "Batch 132, Loss: 1.011438, Accuracy: 50.98%\n",
      "Batch 133, Loss: 0.959221, Accuracy: 51.05%\n",
      "Batch 134, Loss: 1.042912, Accuracy: 51.10%\n",
      "Batch 135, Loss: 1.075982, Accuracy: 51.11%\n",
      "Batch 136, Loss: 1.030487, Accuracy: 51.10%\n",
      "Batch 137, Loss: 1.055755, Accuracy: 51.16%\n",
      "Batch 138, Loss: 0.953913, Accuracy: 51.26%\n",
      "Batch 139, Loss: 0.931308, Accuracy: 51.35%\n",
      "Batch 140, Loss: 0.928297, Accuracy: 51.40%\n",
      "Batch 141, Loss: 0.935286, Accuracy: 51.46%\n",
      "Batch 142, Loss: 0.843531, Accuracy: 51.58%\n",
      "Batch 143, Loss: 1.039121, Accuracy: 51.66%\n",
      "Batch 144, Loss: 1.033772, Accuracy: 51.69%\n",
      "Batch 145, Loss: 0.915712, Accuracy: 51.77%\n",
      "Batch 146, Loss: 0.982408, Accuracy: 51.83%\n",
      "Batch 147, Loss: 0.790101, Accuracy: 51.91%\n",
      "Batch 148, Loss: 0.901894, Accuracy: 52.03%\n",
      "Batch 149, Loss: 0.866992, Accuracy: 52.13%\n",
      "Batch 150, Loss: 0.892872, Accuracy: 52.18%\n",
      "Batch 151, Loss: 0.930025, Accuracy: 52.22%\n",
      "Batch 152, Loss: 1.027738, Accuracy: 52.28%\n",
      "Batch 153, Loss: 0.930106, Accuracy: 52.35%\n",
      "Batch 154, Loss: 1.012312, Accuracy: 52.40%\n",
      "Batch 155, Loss: 0.764120, Accuracy: 52.52%\n",
      "Batch 156, Loss: 0.967100, Accuracy: 52.56%\n",
      "Batch 157, Loss: 1.102292, Accuracy: 52.55%\n",
      "Batch 158, Loss: 0.877951, Accuracy: 52.63%\n",
      "Batch 159, Loss: 0.839560, Accuracy: 52.68%\n",
      "Batch 160, Loss: 0.878260, Accuracy: 52.77%\n",
      "Batch 161, Loss: 0.847302, Accuracy: 52.88%\n",
      "Batch 162, Loss: 0.777962, Accuracy: 53.00%\n",
      "Batch 163, Loss: 0.986306, Accuracy: 53.04%\n",
      "Batch 164, Loss: 0.956455, Accuracy: 53.05%\n",
      "Batch 165, Loss: 1.123208, Accuracy: 53.05%\n",
      "Batch 166, Loss: 0.832210, Accuracy: 53.16%\n",
      "Batch 167, Loss: 0.846718, Accuracy: 53.26%\n",
      "Batch 168, Loss: 0.881747, Accuracy: 53.33%\n",
      "Batch 169, Loss: 0.915301, Accuracy: 53.36%\n",
      "Batch 170, Loss: 0.974950, Accuracy: 53.37%\n",
      "Batch 171, Loss: 0.826700, Accuracy: 53.48%\n",
      "Batch 172, Loss: 0.820353, Accuracy: 53.52%\n",
      "Batch 173, Loss: 0.983191, Accuracy: 53.57%\n",
      "Batch 174, Loss: 0.918126, Accuracy: 53.62%\n",
      "Batch 175, Loss: 0.946752, Accuracy: 53.66%\n",
      "Batch 176, Loss: 0.757525, Accuracy: 53.76%\n",
      "Batch 177, Loss: 1.020327, Accuracy: 53.79%\n",
      "Batch 178, Loss: 0.864436, Accuracy: 53.89%\n",
      "Batch 179, Loss: 0.900582, Accuracy: 53.94%\n",
      "Batch 180, Loss: 0.834872, Accuracy: 54.00%\n",
      "Batch 181, Loss: 0.883413, Accuracy: 54.07%\n",
      "Batch 182, Loss: 0.695853, Accuracy: 54.19%\n",
      "Batch 183, Loss: 0.867068, Accuracy: 54.29%\n",
      "Batch 184, Loss: 0.822295, Accuracy: 54.32%\n",
      "Batch 185, Loss: 0.711173, Accuracy: 54.43%\n",
      "Batch 186, Loss: 0.764256, Accuracy: 54.51%\n",
      "Batch 187, Loss: 1.049477, Accuracy: 54.54%\n",
      "Batch 188, Loss: 0.903509, Accuracy: 54.59%\n",
      "Batch 189, Loss: 0.937933, Accuracy: 54.63%\n",
      "Batch 190, Loss: 0.841451, Accuracy: 54.71%\n",
      "Batch 191, Loss: 0.886882, Accuracy: 54.77%\n",
      "Batch 192, Loss: 0.839649, Accuracy: 54.84%\n",
      "Batch 193, Loss: 0.913436, Accuracy: 54.87%\n",
      "Batch 194, Loss: 0.837297, Accuracy: 54.93%\n",
      "Batch 195, Loss: 0.799111, Accuracy: 55.00%\n",
      "Batch 196, Loss: 0.885193, Accuracy: 55.03%\n",
      "Batch 197, Loss: 0.787852, Accuracy: 55.10%\n",
      "Batch 198, Loss: 1.040960, Accuracy: 55.10%\n",
      "Batch 199, Loss: 0.731698, Accuracy: 55.21%\n",
      "Batch 200, Loss: 0.772936, Accuracy: 55.30%\n",
      "Batch 201, Loss: 0.887453, Accuracy: 55.34%\n",
      "Batch 202, Loss: 1.002327, Accuracy: 55.36%\n",
      "Batch 203, Loss: 0.837795, Accuracy: 55.45%\n",
      "Batch 204, Loss: 0.762102, Accuracy: 55.55%\n",
      "Batch 205, Loss: 0.890543, Accuracy: 55.60%\n",
      "Batch 206, Loss: 0.730335, Accuracy: 55.72%\n",
      "Batch 207, Loss: 0.723628, Accuracy: 55.80%\n",
      "Batch 208, Loss: 0.794389, Accuracy: 55.87%\n",
      "Batch 209, Loss: 0.930217, Accuracy: 55.91%\n",
      "Batch 210, Loss: 0.765099, Accuracy: 55.97%\n",
      "Batch 211, Loss: 0.814120, Accuracy: 56.03%\n",
      "Batch 212, Loss: 0.792335, Accuracy: 56.10%\n",
      "Batch 213, Loss: 0.750165, Accuracy: 56.16%\n",
      "Training - Epoch 2, Loss: 1.033725, Accuracy: 56.16%\n",
      "Validation Batch 1, Loss: 0.835278, Accuracy: 70.31%\n",
      "Validation Batch 2, Loss: 0.857800, Accuracy: 68.75%\n",
      "Validation Batch 3, Loss: 0.798971, Accuracy: 67.71%\n",
      "Validation Batch 4, Loss: 0.608452, Accuracy: 70.31%\n",
      "Validation Batch 5, Loss: 0.788634, Accuracy: 70.62%\n",
      "Validation Batch 6, Loss: 0.724480, Accuracy: 71.35%\n",
      "Validation Batch 7, Loss: 0.714973, Accuracy: 71.65%\n",
      "Validation Batch 8, Loss: 0.999978, Accuracy: 70.70%\n",
      "Validation Batch 9, Loss: 0.859647, Accuracy: 70.31%\n",
      "Validation Batch 10, Loss: 0.797770, Accuracy: 70.47%\n",
      "Validation Batch 11, Loss: 0.710150, Accuracy: 70.45%\n",
      "Validation Batch 12, Loss: 0.740054, Accuracy: 70.18%\n",
      "Validation Batch 13, Loss: 0.850163, Accuracy: 69.47%\n",
      "Validation Batch 14, Loss: 0.956206, Accuracy: 69.31%\n",
      "Validation Batch 15, Loss: 0.931488, Accuracy: 68.23%\n",
      "Validation Batch 16, Loss: 0.943634, Accuracy: 68.16%\n",
      "Validation Batch 17, Loss: 1.053001, Accuracy: 67.65%\n",
      "Validation Batch 18, Loss: 0.794527, Accuracy: 67.80%\n",
      "Validation Batch 19, Loss: 0.852678, Accuracy: 67.76%\n",
      "Validation Batch 20, Loss: 0.785527, Accuracy: 67.66%\n",
      "Validation Batch 21, Loss: 0.812418, Accuracy: 67.71%\n",
      "Validation Batch 22, Loss: 0.866462, Accuracy: 67.68%\n",
      "Validation Batch 23, Loss: 0.996850, Accuracy: 67.46%\n",
      "Validation Batch 24, Loss: 0.748227, Accuracy: 67.77%\n",
      "Validation Batch 25, Loss: 0.665863, Accuracy: 67.88%\n",
      "Validation Batch 26, Loss: 0.740780, Accuracy: 68.09%\n",
      "Validation Batch 27, Loss: 0.827033, Accuracy: 68.17%\n",
      "Validation - Epoch 2, Loss: 0.824483, Accuracy: 68.17%\n",
      "Patience—0\n",
      "Epoch 3\n",
      "Batch 1, Loss: 0.789407, Accuracy: 67.19%\n",
      "Batch 2, Loss: 0.785723, Accuracy: 65.62%\n",
      "Batch 3, Loss: 0.762950, Accuracy: 67.19%\n",
      "Batch 4, Loss: 0.656180, Accuracy: 69.14%\n",
      "Batch 5, Loss: 0.671266, Accuracy: 70.31%\n",
      "Batch 6, Loss: 0.856642, Accuracy: 69.53%\n",
      "Batch 7, Loss: 0.809365, Accuracy: 69.87%\n",
      "Batch 8, Loss: 1.014357, Accuracy: 69.53%\n",
      "Batch 9, Loss: 0.788835, Accuracy: 69.27%\n",
      "Batch 10, Loss: 0.831985, Accuracy: 69.38%\n",
      "Batch 11, Loss: 0.727590, Accuracy: 69.46%\n",
      "Batch 12, Loss: 0.616129, Accuracy: 70.18%\n",
      "Batch 13, Loss: 0.797565, Accuracy: 70.31%\n",
      "Batch 14, Loss: 0.882906, Accuracy: 69.75%\n",
      "Batch 15, Loss: 0.853270, Accuracy: 69.27%\n",
      "Batch 16, Loss: 0.737813, Accuracy: 69.73%\n",
      "Batch 17, Loss: 0.695438, Accuracy: 70.22%\n",
      "Batch 18, Loss: 0.681366, Accuracy: 70.57%\n",
      "Batch 19, Loss: 0.699634, Accuracy: 70.64%\n",
      "Batch 20, Loss: 0.676015, Accuracy: 70.94%\n",
      "Batch 21, Loss: 0.636674, Accuracy: 71.06%\n",
      "Batch 22, Loss: 0.833803, Accuracy: 70.95%\n",
      "Batch 23, Loss: 0.540629, Accuracy: 71.67%\n",
      "Batch 24, Loss: 0.807702, Accuracy: 71.55%\n",
      "Batch 25, Loss: 0.677951, Accuracy: 71.62%\n",
      "Batch 26, Loss: 0.832439, Accuracy: 71.51%\n",
      "Batch 27, Loss: 0.838078, Accuracy: 71.47%\n",
      "Batch 28, Loss: 0.550320, Accuracy: 71.71%\n",
      "Batch 29, Loss: 0.838190, Accuracy: 71.71%\n",
      "Batch 30, Loss: 0.897318, Accuracy: 71.51%\n",
      "Batch 31, Loss: 0.799397, Accuracy: 71.52%\n",
      "Batch 32, Loss: 0.758710, Accuracy: 71.44%\n",
      "Batch 33, Loss: 0.843565, Accuracy: 71.26%\n",
      "Batch 34, Loss: 0.952669, Accuracy: 71.09%\n",
      "Batch 35, Loss: 0.737849, Accuracy: 71.03%\n",
      "Batch 36, Loss: 0.766474, Accuracy: 71.01%\n",
      "Batch 37, Loss: 0.679371, Accuracy: 71.07%\n",
      "Batch 38, Loss: 0.710362, Accuracy: 71.01%\n",
      "Batch 39, Loss: 0.852589, Accuracy: 70.95%\n",
      "Batch 40, Loss: 0.692783, Accuracy: 70.98%\n",
      "Batch 41, Loss: 0.742873, Accuracy: 71.04%\n",
      "Batch 42, Loss: 0.720811, Accuracy: 71.02%\n",
      "Batch 43, Loss: 0.667644, Accuracy: 71.08%\n",
      "Batch 44, Loss: 0.881473, Accuracy: 71.06%\n",
      "Batch 45, Loss: 0.675596, Accuracy: 71.15%\n",
      "Batch 46, Loss: 0.813729, Accuracy: 71.16%\n",
      "Batch 47, Loss: 0.728482, Accuracy: 71.21%\n",
      "Batch 48, Loss: 0.621353, Accuracy: 71.29%\n",
      "Batch 49, Loss: 0.706968, Accuracy: 71.43%\n",
      "Batch 50, Loss: 0.642354, Accuracy: 71.53%\n",
      "Batch 51, Loss: 0.639947, Accuracy: 71.66%\n",
      "Batch 52, Loss: 0.653199, Accuracy: 71.69%\n",
      "Batch 53, Loss: 0.743097, Accuracy: 71.58%\n",
      "Batch 54, Loss: 0.857383, Accuracy: 71.47%\n",
      "Batch 55, Loss: 0.600317, Accuracy: 71.59%\n",
      "Batch 56, Loss: 0.695071, Accuracy: 71.60%\n",
      "Batch 57, Loss: 0.862953, Accuracy: 71.52%\n",
      "Batch 58, Loss: 0.544015, Accuracy: 71.71%\n",
      "Batch 59, Loss: 0.602988, Accuracy: 71.85%\n",
      "Batch 60, Loss: 0.686899, Accuracy: 71.90%\n",
      "Batch 61, Loss: 0.713711, Accuracy: 71.82%\n",
      "Batch 62, Loss: 0.722944, Accuracy: 71.82%\n",
      "Batch 63, Loss: 0.622752, Accuracy: 71.88%\n",
      "Batch 64, Loss: 0.729835, Accuracy: 71.88%\n",
      "Batch 65, Loss: 0.687246, Accuracy: 71.92%\n",
      "Batch 66, Loss: 0.672778, Accuracy: 71.95%\n",
      "Batch 67, Loss: 0.679355, Accuracy: 71.97%\n",
      "Batch 68, Loss: 0.698100, Accuracy: 72.01%\n",
      "Batch 69, Loss: 0.750768, Accuracy: 71.97%\n",
      "Batch 70, Loss: 0.573209, Accuracy: 72.08%\n",
      "Batch 71, Loss: 0.791873, Accuracy: 72.12%\n",
      "Batch 72, Loss: 0.631685, Accuracy: 72.24%\n",
      "Batch 73, Loss: 0.672102, Accuracy: 72.28%\n",
      "Batch 74, Loss: 0.627986, Accuracy: 72.30%\n",
      "Batch 75, Loss: 0.588043, Accuracy: 72.40%\n",
      "Batch 76, Loss: 0.473768, Accuracy: 72.53%\n",
      "Batch 77, Loss: 0.683191, Accuracy: 72.65%\n",
      "Batch 78, Loss: 0.717960, Accuracy: 72.66%\n",
      "Batch 79, Loss: 0.714240, Accuracy: 72.61%\n",
      "Batch 80, Loss: 0.568685, Accuracy: 72.71%\n",
      "Batch 81, Loss: 0.819860, Accuracy: 72.69%\n",
      "Batch 82, Loss: 0.552041, Accuracy: 72.75%\n",
      "Batch 83, Loss: 0.539246, Accuracy: 72.87%\n",
      "Batch 84, Loss: 0.714618, Accuracy: 72.88%\n",
      "Batch 85, Loss: 0.701746, Accuracy: 72.83%\n",
      "Batch 86, Loss: 0.709007, Accuracy: 72.82%\n",
      "Batch 87, Loss: 0.650459, Accuracy: 72.84%\n",
      "Batch 88, Loss: 0.625468, Accuracy: 72.92%\n",
      "Batch 89, Loss: 0.603370, Accuracy: 72.96%\n",
      "Batch 90, Loss: 0.843136, Accuracy: 72.93%\n",
      "Batch 91, Loss: 0.687023, Accuracy: 72.96%\n",
      "Batch 92, Loss: 0.598250, Accuracy: 73.05%\n",
      "Batch 93, Loss: 0.745095, Accuracy: 73.07%\n",
      "Batch 94, Loss: 0.490457, Accuracy: 73.15%\n",
      "Batch 95, Loss: 0.692077, Accuracy: 73.16%\n",
      "Batch 96, Loss: 0.540965, Accuracy: 73.24%\n",
      "Batch 97, Loss: 0.614707, Accuracy: 73.29%\n",
      "Batch 98, Loss: 0.720791, Accuracy: 73.25%\n",
      "Batch 99, Loss: 0.539579, Accuracy: 73.31%\n",
      "Batch 100, Loss: 0.862058, Accuracy: 73.22%\n",
      "Batch 101, Loss: 0.803227, Accuracy: 73.24%\n",
      "Batch 102, Loss: 0.733488, Accuracy: 73.24%\n",
      "Batch 103, Loss: 0.804331, Accuracy: 73.21%\n",
      "Batch 104, Loss: 0.687503, Accuracy: 73.20%\n",
      "Batch 105, Loss: 0.724268, Accuracy: 73.17%\n",
      "Batch 106, Loss: 0.832630, Accuracy: 73.19%\n",
      "Batch 107, Loss: 0.704433, Accuracy: 73.19%\n",
      "Batch 108, Loss: 0.636069, Accuracy: 73.23%\n",
      "Batch 109, Loss: 0.727186, Accuracy: 73.25%\n",
      "Batch 110, Loss: 0.644659, Accuracy: 73.31%\n",
      "Batch 111, Loss: 0.670226, Accuracy: 73.37%\n",
      "Batch 112, Loss: 0.620664, Accuracy: 73.40%\n",
      "Batch 113, Loss: 0.692370, Accuracy: 73.40%\n",
      "Batch 114, Loss: 0.649711, Accuracy: 73.45%\n",
      "Batch 115, Loss: 0.588515, Accuracy: 73.48%\n",
      "Batch 116, Loss: 0.734061, Accuracy: 73.45%\n",
      "Batch 117, Loss: 0.544731, Accuracy: 73.54%\n",
      "Batch 118, Loss: 0.498313, Accuracy: 73.61%\n",
      "Batch 119, Loss: 0.579917, Accuracy: 73.66%\n",
      "Batch 120, Loss: 0.542042, Accuracy: 73.71%\n",
      "Batch 121, Loss: 0.655579, Accuracy: 73.71%\n",
      "Batch 122, Loss: 0.827990, Accuracy: 73.67%\n",
      "Batch 123, Loss: 0.588959, Accuracy: 73.73%\n",
      "Batch 124, Loss: 0.672788, Accuracy: 73.74%\n",
      "Batch 125, Loss: 0.728656, Accuracy: 73.75%\n",
      "Batch 126, Loss: 0.733778, Accuracy: 73.75%\n",
      "Batch 127, Loss: 0.630643, Accuracy: 73.73%\n",
      "Batch 128, Loss: 0.494940, Accuracy: 73.79%\n",
      "Batch 129, Loss: 0.766794, Accuracy: 73.78%\n",
      "Batch 130, Loss: 0.458793, Accuracy: 73.85%\n",
      "Batch 131, Loss: 0.554530, Accuracy: 73.88%\n",
      "Batch 132, Loss: 0.496400, Accuracy: 73.96%\n",
      "Batch 133, Loss: 0.521598, Accuracy: 74.05%\n",
      "Batch 134, Loss: 0.631205, Accuracy: 74.10%\n",
      "Batch 135, Loss: 0.525919, Accuracy: 74.16%\n",
      "Batch 136, Loss: 0.674948, Accuracy: 74.17%\n",
      "Batch 137, Loss: 0.591475, Accuracy: 74.20%\n",
      "Batch 138, Loss: 0.654810, Accuracy: 74.22%\n",
      "Batch 139, Loss: 0.646172, Accuracy: 74.19%\n",
      "Batch 140, Loss: 0.449685, Accuracy: 74.26%\n",
      "Batch 141, Loss: 0.609479, Accuracy: 74.29%\n",
      "Batch 142, Loss: 0.637357, Accuracy: 74.32%\n",
      "Batch 143, Loss: 0.603287, Accuracy: 74.37%\n",
      "Batch 144, Loss: 0.732015, Accuracy: 74.38%\n",
      "Batch 145, Loss: 0.455279, Accuracy: 74.45%\n",
      "Batch 146, Loss: 0.762955, Accuracy: 74.43%\n",
      "Batch 147, Loss: 0.622332, Accuracy: 74.45%\n",
      "Batch 148, Loss: 0.618447, Accuracy: 74.45%\n",
      "Batch 149, Loss: 0.642005, Accuracy: 74.48%\n",
      "Batch 150, Loss: 0.366593, Accuracy: 74.58%\n",
      "Batch 151, Loss: 0.553039, Accuracy: 74.62%\n",
      "Batch 152, Loss: 0.617833, Accuracy: 74.65%\n",
      "Batch 153, Loss: 0.437626, Accuracy: 74.70%\n",
      "Batch 154, Loss: 0.452037, Accuracy: 74.79%\n",
      "Batch 155, Loss: 0.581141, Accuracy: 74.83%\n",
      "Batch 156, Loss: 0.564096, Accuracy: 74.86%\n",
      "Batch 157, Loss: 0.529896, Accuracy: 74.91%\n",
      "Batch 158, Loss: 0.534297, Accuracy: 74.98%\n",
      "Batch 159, Loss: 0.595906, Accuracy: 75.00%\n",
      "Batch 160, Loss: 0.514806, Accuracy: 75.07%\n",
      "Batch 161, Loss: 0.540728, Accuracy: 75.10%\n",
      "Batch 162, Loss: 0.418507, Accuracy: 75.16%\n",
      "Batch 163, Loss: 0.569611, Accuracy: 75.20%\n",
      "Batch 164, Loss: 0.623374, Accuracy: 75.20%\n",
      "Batch 165, Loss: 0.604438, Accuracy: 75.20%\n",
      "Batch 166, Loss: 0.793437, Accuracy: 75.18%\n",
      "Batch 167, Loss: 0.626412, Accuracy: 75.20%\n",
      "Batch 168, Loss: 0.595182, Accuracy: 75.20%\n",
      "Batch 169, Loss: 0.647583, Accuracy: 75.19%\n",
      "Batch 170, Loss: 0.552836, Accuracy: 75.22%\n",
      "Batch 171, Loss: 0.656282, Accuracy: 75.20%\n",
      "Batch 172, Loss: 0.635280, Accuracy: 75.25%\n",
      "Batch 173, Loss: 0.546912, Accuracy: 75.27%\n",
      "Batch 174, Loss: 0.589097, Accuracy: 75.29%\n",
      "Batch 175, Loss: 0.622898, Accuracy: 75.29%\n",
      "Batch 176, Loss: 0.586142, Accuracy: 75.31%\n",
      "Batch 177, Loss: 0.746468, Accuracy: 75.32%\n",
      "Batch 178, Loss: 0.562081, Accuracy: 75.36%\n",
      "Batch 179, Loss: 0.403001, Accuracy: 75.45%\n",
      "Batch 180, Loss: 0.639112, Accuracy: 75.44%\n",
      "Batch 181, Loss: 0.753261, Accuracy: 75.42%\n",
      "Batch 182, Loss: 0.591209, Accuracy: 75.45%\n",
      "Batch 183, Loss: 0.473180, Accuracy: 75.48%\n",
      "Batch 184, Loss: 0.539695, Accuracy: 75.53%\n",
      "Batch 185, Loss: 0.529496, Accuracy: 75.57%\n",
      "Batch 186, Loss: 0.547541, Accuracy: 75.58%\n",
      "Batch 187, Loss: 0.545802, Accuracy: 75.61%\n",
      "Batch 188, Loss: 0.850352, Accuracy: 75.57%\n",
      "Batch 189, Loss: 0.439139, Accuracy: 75.62%\n",
      "Batch 190, Loss: 0.428940, Accuracy: 75.68%\n",
      "Batch 191, Loss: 0.481320, Accuracy: 75.72%\n",
      "Batch 192, Loss: 0.511516, Accuracy: 75.75%\n",
      "Batch 193, Loss: 0.586631, Accuracy: 75.76%\n",
      "Batch 194, Loss: 0.520815, Accuracy: 75.80%\n",
      "Batch 195, Loss: 0.482194, Accuracy: 75.83%\n",
      "Batch 196, Loss: 0.517174, Accuracy: 75.85%\n",
      "Batch 197, Loss: 0.525914, Accuracy: 75.86%\n",
      "Batch 198, Loss: 0.507852, Accuracy: 75.90%\n",
      "Batch 199, Loss: 0.490210, Accuracy: 75.94%\n",
      "Batch 200, Loss: 0.498093, Accuracy: 75.96%\n",
      "Batch 201, Loss: 0.561820, Accuracy: 75.99%\n",
      "Batch 202, Loss: 0.498806, Accuracy: 76.01%\n",
      "Batch 203, Loss: 0.347837, Accuracy: 76.09%\n",
      "Batch 204, Loss: 0.566966, Accuracy: 76.10%\n",
      "Batch 205, Loss: 0.566663, Accuracy: 76.11%\n",
      "Batch 206, Loss: 0.475027, Accuracy: 76.12%\n",
      "Batch 207, Loss: 0.456500, Accuracy: 76.15%\n",
      "Batch 208, Loss: 0.697237, Accuracy: 76.16%\n",
      "Batch 209, Loss: 0.828038, Accuracy: 76.13%\n",
      "Batch 210, Loss: 0.462540, Accuracy: 76.18%\n",
      "Batch 211, Loss: 0.508746, Accuracy: 76.20%\n",
      "Batch 212, Loss: 0.450847, Accuracy: 76.22%\n",
      "Batch 213, Loss: 0.704045, Accuracy: 76.20%\n",
      "Training - Epoch 3, Loss: 0.649286, Accuracy: 76.20%\n",
      "Validation Batch 1, Loss: 0.532104, Accuracy: 78.12%\n",
      "Validation Batch 2, Loss: 0.649609, Accuracy: 76.56%\n",
      "Validation Batch 3, Loss: 0.486431, Accuracy: 78.65%\n",
      "Validation Batch 4, Loss: 0.420064, Accuracy: 80.08%\n",
      "Validation Batch 5, Loss: 0.496823, Accuracy: 79.69%\n",
      "Validation Batch 6, Loss: 0.424185, Accuracy: 80.21%\n",
      "Validation Batch 7, Loss: 0.395181, Accuracy: 80.58%\n",
      "Validation Batch 8, Loss: 0.697792, Accuracy: 79.88%\n",
      "Validation Batch 9, Loss: 0.638834, Accuracy: 79.69%\n",
      "Validation Batch 10, Loss: 0.481122, Accuracy: 79.84%\n",
      "Validation Batch 11, Loss: 0.433022, Accuracy: 80.40%\n",
      "Validation Batch 12, Loss: 0.486256, Accuracy: 80.34%\n",
      "Validation Batch 13, Loss: 0.481859, Accuracy: 80.29%\n",
      "Validation Batch 14, Loss: 0.736541, Accuracy: 79.91%\n",
      "Validation Batch 15, Loss: 0.551616, Accuracy: 79.69%\n",
      "Validation Batch 16, Loss: 0.479260, Accuracy: 80.08%\n",
      "Validation Batch 17, Loss: 0.679542, Accuracy: 79.69%\n",
      "Validation Batch 18, Loss: 0.532645, Accuracy: 79.43%\n",
      "Validation Batch 19, Loss: 0.515784, Accuracy: 79.77%\n",
      "Validation Batch 20, Loss: 0.407410, Accuracy: 80.16%\n",
      "Validation Batch 21, Loss: 0.599782, Accuracy: 79.84%\n",
      "Validation Batch 22, Loss: 0.630689, Accuracy: 79.40%\n",
      "Validation Batch 23, Loss: 0.692411, Accuracy: 79.14%\n",
      "Validation Batch 24, Loss: 0.488489, Accuracy: 79.30%\n",
      "Validation Batch 25, Loss: 0.383770, Accuracy: 79.69%\n",
      "Validation Batch 26, Loss: 0.567160, Accuracy: 79.63%\n",
      "Validation Batch 27, Loss: 0.506375, Accuracy: 79.86%\n",
      "Validation - Epoch 3, Loss: 0.533139, Accuracy: 79.86%\n",
      "Patience—0\n",
      "Epoch 4\n",
      "Batch 1, Loss: 0.529665, Accuracy: 81.25%\n",
      "Batch 2, Loss: 0.400129, Accuracy: 83.59%\n",
      "Batch 3, Loss: 0.460141, Accuracy: 82.81%\n",
      "Batch 4, Loss: 0.664199, Accuracy: 80.47%\n",
      "Batch 5, Loss: 0.517055, Accuracy: 81.25%\n",
      "Batch 6, Loss: 0.630894, Accuracy: 80.21%\n",
      "Batch 7, Loss: 0.536560, Accuracy: 80.80%\n",
      "Batch 8, Loss: 0.462039, Accuracy: 81.64%\n",
      "Batch 9, Loss: 0.453155, Accuracy: 82.12%\n",
      "Batch 10, Loss: 0.623754, Accuracy: 81.56%\n",
      "Batch 11, Loss: 0.623118, Accuracy: 81.39%\n",
      "Batch 12, Loss: 0.396290, Accuracy: 81.77%\n",
      "Batch 13, Loss: 0.486228, Accuracy: 82.21%\n",
      "Batch 14, Loss: 0.355399, Accuracy: 82.70%\n",
      "Batch 15, Loss: 0.358194, Accuracy: 82.81%\n",
      "Batch 16, Loss: 0.431231, Accuracy: 83.11%\n",
      "Batch 17, Loss: 0.407739, Accuracy: 83.46%\n",
      "Batch 18, Loss: 0.322173, Accuracy: 83.85%\n",
      "Batch 19, Loss: 0.496123, Accuracy: 83.88%\n",
      "Batch 20, Loss: 0.354095, Accuracy: 84.14%\n",
      "Batch 21, Loss: 0.325185, Accuracy: 84.45%\n",
      "Batch 22, Loss: 0.333940, Accuracy: 84.73%\n",
      "Batch 23, Loss: 0.462360, Accuracy: 84.65%\n",
      "Batch 24, Loss: 0.355247, Accuracy: 84.70%\n",
      "Batch 25, Loss: 0.293438, Accuracy: 85.06%\n",
      "Batch 26, Loss: 0.526895, Accuracy: 85.04%\n",
      "Batch 27, Loss: 0.462853, Accuracy: 85.01%\n",
      "Batch 28, Loss: 0.332662, Accuracy: 85.10%\n",
      "Batch 29, Loss: 0.557235, Accuracy: 84.97%\n",
      "Batch 30, Loss: 0.454183, Accuracy: 85.00%\n",
      "Batch 31, Loss: 0.560345, Accuracy: 84.93%\n",
      "Batch 32, Loss: 0.496852, Accuracy: 84.91%\n",
      "Batch 33, Loss: 0.426015, Accuracy: 84.85%\n",
      "Batch 34, Loss: 0.297828, Accuracy: 85.11%\n",
      "Batch 35, Loss: 0.343070, Accuracy: 85.22%\n",
      "Batch 36, Loss: 0.581032, Accuracy: 85.07%\n",
      "Batch 37, Loss: 0.325939, Accuracy: 85.18%\n",
      "Batch 38, Loss: 0.366491, Accuracy: 85.20%\n",
      "Batch 39, Loss: 0.368826, Accuracy: 85.34%\n",
      "Batch 40, Loss: 0.416933, Accuracy: 85.43%\n",
      "Batch 41, Loss: 0.449675, Accuracy: 85.44%\n",
      "Batch 42, Loss: 0.401306, Accuracy: 85.42%\n",
      "Batch 43, Loss: 0.625571, Accuracy: 85.28%\n",
      "Batch 44, Loss: 0.396931, Accuracy: 85.37%\n",
      "Batch 45, Loss: 0.735518, Accuracy: 85.07%\n",
      "Batch 46, Loss: 0.396485, Accuracy: 85.12%\n",
      "Batch 47, Loss: 0.416221, Accuracy: 85.11%\n",
      "Batch 48, Loss: 0.250395, Accuracy: 85.25%\n",
      "Batch 49, Loss: 0.419723, Accuracy: 85.33%\n",
      "Batch 50, Loss: 0.278699, Accuracy: 85.47%\n",
      "Batch 51, Loss: 0.524846, Accuracy: 85.36%\n",
      "Batch 52, Loss: 0.424814, Accuracy: 85.37%\n",
      "Batch 53, Loss: 0.474311, Accuracy: 85.32%\n",
      "Batch 54, Loss: 0.655043, Accuracy: 85.04%\n",
      "Batch 55, Loss: 0.551983, Accuracy: 84.86%\n",
      "Batch 56, Loss: 0.498557, Accuracy: 84.88%\n",
      "Batch 57, Loss: 0.413256, Accuracy: 84.90%\n",
      "Batch 58, Loss: 0.528313, Accuracy: 84.81%\n",
      "Batch 59, Loss: 0.348706, Accuracy: 84.85%\n",
      "Batch 60, Loss: 0.476426, Accuracy: 84.82%\n",
      "Batch 61, Loss: 0.336390, Accuracy: 84.91%\n",
      "Batch 62, Loss: 0.614464, Accuracy: 84.78%\n",
      "Batch 63, Loss: 0.615957, Accuracy: 84.67%\n",
      "Batch 64, Loss: 0.382982, Accuracy: 84.69%\n",
      "Batch 65, Loss: 0.291715, Accuracy: 84.83%\n",
      "Batch 66, Loss: 0.540585, Accuracy: 84.82%\n",
      "Batch 67, Loss: 0.302756, Accuracy: 84.91%\n",
      "Batch 68, Loss: 0.361150, Accuracy: 85.02%\n",
      "Batch 69, Loss: 0.341969, Accuracy: 85.08%\n",
      "Batch 70, Loss: 0.392977, Accuracy: 85.13%\n",
      "Batch 71, Loss: 0.435939, Accuracy: 85.15%\n",
      "Batch 72, Loss: 0.388362, Accuracy: 85.18%\n",
      "Batch 73, Loss: 0.357357, Accuracy: 85.23%\n",
      "Batch 74, Loss: 0.412685, Accuracy: 85.22%\n",
      "Batch 75, Loss: 0.523512, Accuracy: 85.17%\n",
      "Batch 76, Loss: 0.518156, Accuracy: 85.12%\n",
      "Batch 77, Loss: 0.459866, Accuracy: 85.04%\n",
      "Batch 78, Loss: 0.510745, Accuracy: 85.00%\n",
      "Batch 79, Loss: 0.322562, Accuracy: 85.05%\n",
      "Batch 80, Loss: 0.311927, Accuracy: 85.08%\n",
      "Batch 81, Loss: 0.349597, Accuracy: 85.11%\n",
      "Batch 82, Loss: 0.494205, Accuracy: 85.16%\n",
      "Batch 83, Loss: 0.235590, Accuracy: 85.30%\n",
      "Batch 84, Loss: 0.426113, Accuracy: 85.29%\n",
      "Batch 85, Loss: 0.420967, Accuracy: 85.28%\n",
      "Batch 86, Loss: 0.475616, Accuracy: 85.21%\n",
      "Batch 87, Loss: 0.625300, Accuracy: 85.13%\n",
      "Batch 88, Loss: 0.336658, Accuracy: 85.17%\n",
      "Batch 89, Loss: 0.451582, Accuracy: 85.22%\n",
      "Batch 90, Loss: 0.494995, Accuracy: 85.17%\n",
      "Batch 91, Loss: 0.478182, Accuracy: 85.15%\n",
      "Batch 92, Loss: 0.386625, Accuracy: 85.21%\n",
      "Batch 93, Loss: 0.429561, Accuracy: 85.22%\n",
      "Batch 94, Loss: 0.319343, Accuracy: 85.27%\n",
      "Batch 95, Loss: 0.403647, Accuracy: 85.23%\n",
      "Batch 96, Loss: 0.521658, Accuracy: 85.11%\n",
      "Batch 97, Loss: 0.507315, Accuracy: 85.07%\n",
      "Batch 98, Loss: 0.433646, Accuracy: 85.03%\n",
      "Batch 99, Loss: 0.450198, Accuracy: 85.01%\n",
      "Batch 100, Loss: 0.487485, Accuracy: 85.02%\n",
      "Batch 101, Loss: 0.424581, Accuracy: 85.01%\n",
      "Batch 102, Loss: 0.640308, Accuracy: 84.94%\n",
      "Batch 103, Loss: 0.320389, Accuracy: 85.03%\n",
      "Batch 104, Loss: 0.568671, Accuracy: 84.99%\n",
      "Batch 105, Loss: 0.381211, Accuracy: 84.97%\n",
      "Batch 106, Loss: 0.638631, Accuracy: 84.86%\n",
      "Batch 107, Loss: 0.270004, Accuracy: 84.93%\n",
      "Batch 108, Loss: 0.377131, Accuracy: 84.97%\n",
      "Batch 109, Loss: 0.384768, Accuracy: 84.99%\n",
      "Batch 110, Loss: 0.479500, Accuracy: 84.96%\n",
      "Batch 111, Loss: 0.362391, Accuracy: 85.01%\n",
      "Batch 112, Loss: 0.372142, Accuracy: 85.03%\n",
      "Batch 113, Loss: 0.279247, Accuracy: 85.09%\n",
      "Batch 114, Loss: 0.252879, Accuracy: 85.17%\n",
      "Batch 115, Loss: 0.354475, Accuracy: 85.19%\n",
      "Batch 116, Loss: 0.533769, Accuracy: 85.14%\n",
      "Batch 117, Loss: 0.498991, Accuracy: 85.12%\n",
      "Batch 118, Loss: 0.378424, Accuracy: 85.12%\n",
      "Batch 119, Loss: 0.341797, Accuracy: 85.15%\n",
      "Batch 120, Loss: 0.508056, Accuracy: 85.16%\n",
      "Batch 121, Loss: 0.455035, Accuracy: 85.18%\n",
      "Batch 122, Loss: 0.378995, Accuracy: 85.19%\n",
      "Batch 123, Loss: 0.365910, Accuracy: 85.21%\n",
      "Batch 124, Loss: 0.238839, Accuracy: 85.27%\n",
      "Batch 125, Loss: 0.521859, Accuracy: 85.22%\n",
      "Batch 126, Loss: 0.498474, Accuracy: 85.18%\n",
      "Batch 127, Loss: 0.500202, Accuracy: 85.20%\n",
      "Batch 128, Loss: 0.419839, Accuracy: 85.22%\n",
      "Batch 129, Loss: 0.665400, Accuracy: 85.15%\n",
      "Batch 130, Loss: 0.365540, Accuracy: 85.18%\n",
      "Batch 131, Loss: 0.257052, Accuracy: 85.23%\n",
      "Batch 132, Loss: 0.389174, Accuracy: 85.25%\n",
      "Batch 133, Loss: 0.562055, Accuracy: 85.24%\n",
      "Batch 134, Loss: 0.336247, Accuracy: 85.26%\n",
      "Batch 135, Loss: 0.438871, Accuracy: 85.27%\n",
      "Batch 136, Loss: 0.486166, Accuracy: 85.24%\n",
      "Batch 137, Loss: 0.297985, Accuracy: 85.25%\n",
      "Batch 138, Loss: 0.469460, Accuracy: 85.22%\n",
      "Batch 139, Loss: 0.387857, Accuracy: 85.24%\n",
      "Batch 140, Loss: 0.382010, Accuracy: 85.26%\n",
      "Batch 141, Loss: 0.368110, Accuracy: 85.22%\n",
      "Batch 142, Loss: 0.425705, Accuracy: 85.23%\n",
      "Batch 143, Loss: 0.418834, Accuracy: 85.24%\n",
      "Batch 144, Loss: 0.361717, Accuracy: 85.26%\n",
      "Batch 145, Loss: 0.400679, Accuracy: 85.28%\n",
      "Batch 146, Loss: 0.430511, Accuracy: 85.27%\n",
      "Batch 147, Loss: 0.531560, Accuracy: 85.27%\n",
      "Batch 148, Loss: 0.536239, Accuracy: 85.22%\n",
      "Batch 149, Loss: 0.320367, Accuracy: 85.25%\n",
      "Batch 150, Loss: 0.446661, Accuracy: 85.21%\n",
      "Batch 151, Loss: 0.600923, Accuracy: 85.17%\n",
      "Batch 152, Loss: 0.566696, Accuracy: 85.15%\n",
      "Batch 153, Loss: 0.510830, Accuracy: 85.12%\n",
      "Batch 154, Loss: 0.379076, Accuracy: 85.10%\n",
      "Batch 155, Loss: 0.320480, Accuracy: 85.11%\n",
      "Batch 156, Loss: 0.360864, Accuracy: 85.13%\n",
      "Batch 157, Loss: 0.345219, Accuracy: 85.15%\n",
      "Batch 158, Loss: 0.342925, Accuracy: 85.17%\n",
      "Batch 159, Loss: 0.337534, Accuracy: 85.19%\n",
      "Batch 160, Loss: 0.508736, Accuracy: 85.18%\n",
      "Batch 161, Loss: 0.488725, Accuracy: 85.16%\n",
      "Batch 162, Loss: 0.395617, Accuracy: 85.17%\n",
      "Batch 163, Loss: 0.427103, Accuracy: 85.17%\n",
      "Batch 164, Loss: 0.298527, Accuracy: 85.20%\n",
      "Batch 165, Loss: 0.447915, Accuracy: 85.19%\n",
      "Batch 166, Loss: 0.281652, Accuracy: 85.20%\n",
      "Batch 167, Loss: 0.289403, Accuracy: 85.25%\n",
      "Batch 168, Loss: 0.347927, Accuracy: 85.25%\n",
      "Batch 169, Loss: 0.478425, Accuracy: 85.23%\n",
      "Batch 170, Loss: 0.249693, Accuracy: 85.29%\n",
      "Batch 171, Loss: 0.441923, Accuracy: 85.30%\n",
      "Batch 172, Loss: 0.234270, Accuracy: 85.34%\n",
      "Batch 173, Loss: 0.340068, Accuracy: 85.37%\n",
      "Batch 174, Loss: 0.343782, Accuracy: 85.39%\n",
      "Batch 175, Loss: 0.323034, Accuracy: 85.41%\n",
      "Batch 176, Loss: 0.283818, Accuracy: 85.45%\n",
      "Batch 177, Loss: 0.239549, Accuracy: 85.49%\n",
      "Batch 178, Loss: 0.191892, Accuracy: 85.55%\n",
      "Batch 179, Loss: 0.281509, Accuracy: 85.58%\n",
      "Batch 180, Loss: 0.402101, Accuracy: 85.61%\n",
      "Batch 181, Loss: 0.191300, Accuracy: 85.68%\n",
      "Batch 182, Loss: 0.382668, Accuracy: 85.67%\n",
      "Batch 183, Loss: 0.199449, Accuracy: 85.72%\n",
      "Batch 184, Loss: 0.387195, Accuracy: 85.73%\n",
      "Batch 185, Loss: 0.241277, Accuracy: 85.76%\n",
      "Batch 186, Loss: 0.494691, Accuracy: 85.74%\n",
      "Batch 187, Loss: 0.379276, Accuracy: 85.75%\n",
      "Batch 188, Loss: 0.264517, Accuracy: 85.75%\n",
      "Batch 189, Loss: 0.431772, Accuracy: 85.76%\n",
      "Batch 190, Loss: 0.302511, Accuracy: 85.78%\n",
      "Batch 191, Loss: 0.435607, Accuracy: 85.77%\n",
      "Batch 192, Loss: 0.261434, Accuracy: 85.80%\n",
      "Batch 193, Loss: 0.406900, Accuracy: 85.81%\n",
      "Batch 194, Loss: 0.336617, Accuracy: 85.82%\n",
      "Batch 195, Loss: 0.304874, Accuracy: 85.86%\n",
      "Batch 196, Loss: 0.252286, Accuracy: 85.89%\n",
      "Batch 197, Loss: 0.203162, Accuracy: 85.94%\n",
      "Batch 198, Loss: 0.358144, Accuracy: 85.95%\n",
      "Batch 199, Loss: 0.401356, Accuracy: 85.96%\n",
      "Batch 200, Loss: 0.220424, Accuracy: 86.01%\n",
      "Batch 201, Loss: 0.289310, Accuracy: 86.02%\n",
      "Batch 202, Loss: 0.535337, Accuracy: 86.00%\n",
      "Batch 203, Loss: 0.311313, Accuracy: 86.01%\n",
      "Batch 204, Loss: 0.346260, Accuracy: 86.04%\n",
      "Batch 205, Loss: 0.377755, Accuracy: 86.04%\n",
      "Batch 206, Loss: 0.476958, Accuracy: 86.02%\n",
      "Batch 207, Loss: 0.294609, Accuracy: 86.04%\n",
      "Batch 208, Loss: 0.480959, Accuracy: 86.01%\n",
      "Batch 209, Loss: 0.305702, Accuracy: 86.03%\n",
      "Batch 210, Loss: 0.219354, Accuracy: 86.06%\n",
      "Batch 211, Loss: 0.229545, Accuracy: 86.09%\n",
      "Batch 212, Loss: 0.224388, Accuracy: 86.11%\n",
      "Batch 213, Loss: 0.237870, Accuracy: 86.13%\n",
      "Training - Epoch 4, Loss: 0.408837, Accuracy: 86.13%\n",
      "Validation Batch 1, Loss: 0.231207, Accuracy: 92.19%\n",
      "Validation Batch 2, Loss: 0.363050, Accuracy: 90.62%\n",
      "Validation Batch 3, Loss: 0.155462, Accuracy: 92.71%\n",
      "Validation Batch 4, Loss: 0.173690, Accuracy: 93.75%\n",
      "Validation Batch 5, Loss: 0.361644, Accuracy: 92.19%\n",
      "Validation Batch 6, Loss: 0.164417, Accuracy: 92.97%\n",
      "Validation Batch 7, Loss: 0.275742, Accuracy: 92.63%\n",
      "Validation Batch 8, Loss: 0.488929, Accuracy: 91.99%\n",
      "Validation Batch 9, Loss: 0.492927, Accuracy: 91.15%\n",
      "Validation Batch 10, Loss: 0.206821, Accuracy: 91.56%\n",
      "Validation Batch 11, Loss: 0.310987, Accuracy: 91.62%\n",
      "Validation Batch 12, Loss: 0.280487, Accuracy: 91.67%\n",
      "Validation Batch 13, Loss: 0.379529, Accuracy: 91.35%\n",
      "Validation Batch 14, Loss: 0.368014, Accuracy: 90.96%\n",
      "Validation Batch 15, Loss: 0.263346, Accuracy: 91.04%\n",
      "Validation Batch 16, Loss: 0.325807, Accuracy: 90.92%\n",
      "Validation Batch 17, Loss: 0.483061, Accuracy: 90.44%\n",
      "Validation Batch 18, Loss: 0.248406, Accuracy: 90.45%\n",
      "Validation Batch 19, Loss: 0.328749, Accuracy: 90.38%\n",
      "Validation Batch 20, Loss: 0.263838, Accuracy: 90.55%\n",
      "Validation Batch 21, Loss: 0.205078, Accuracy: 90.70%\n",
      "Validation Batch 22, Loss: 0.398456, Accuracy: 90.55%\n",
      "Validation Batch 23, Loss: 0.518208, Accuracy: 90.15%\n",
      "Validation Batch 24, Loss: 0.339991, Accuracy: 90.04%\n",
      "Validation Batch 25, Loss: 0.219306, Accuracy: 90.06%\n",
      "Validation Batch 26, Loss: 0.333644, Accuracy: 90.08%\n",
      "Validation Batch 27, Loss: 0.255279, Accuracy: 90.08%\n",
      "Validation - Epoch 4, Loss: 0.312447, Accuracy: 90.08%\n",
      "Patience—0\n",
      "Epoch 5\n",
      "Batch 1, Loss: 0.271238, Accuracy: 92.19%\n",
      "Batch 2, Loss: 0.404383, Accuracy: 88.28%\n",
      "Batch 3, Loss: 0.195602, Accuracy: 89.58%\n",
      "Batch 4, Loss: 0.423208, Accuracy: 89.06%\n",
      "Batch 5, Loss: 0.233128, Accuracy: 89.69%\n",
      "Batch 6, Loss: 0.291001, Accuracy: 89.58%\n",
      "Batch 7, Loss: 0.300029, Accuracy: 89.73%\n",
      "Batch 8, Loss: 0.229896, Accuracy: 90.23%\n",
      "Batch 9, Loss: 0.294277, Accuracy: 90.10%\n",
      "Batch 10, Loss: 0.197233, Accuracy: 90.62%\n",
      "Batch 11, Loss: 0.241864, Accuracy: 90.62%\n",
      "Batch 12, Loss: 0.291931, Accuracy: 90.62%\n",
      "Batch 13, Loss: 0.336579, Accuracy: 90.75%\n",
      "Batch 14, Loss: 0.282152, Accuracy: 90.74%\n",
      "Batch 15, Loss: 0.300283, Accuracy: 90.94%\n",
      "Batch 16, Loss: 0.179498, Accuracy: 91.21%\n",
      "Batch 17, Loss: 0.190458, Accuracy: 91.27%\n",
      "Batch 18, Loss: 0.231754, Accuracy: 91.32%\n",
      "Batch 19, Loss: 0.252705, Accuracy: 91.20%\n",
      "Batch 20, Loss: 0.253808, Accuracy: 91.17%\n",
      "Batch 21, Loss: 0.314553, Accuracy: 91.00%\n",
      "Batch 22, Loss: 0.194525, Accuracy: 91.12%\n",
      "Batch 23, Loss: 0.347854, Accuracy: 91.03%\n",
      "Batch 24, Loss: 0.201830, Accuracy: 91.08%\n",
      "Batch 25, Loss: 0.330619, Accuracy: 90.88%\n",
      "Batch 26, Loss: 0.255020, Accuracy: 90.99%\n",
      "Batch 27, Loss: 0.297074, Accuracy: 90.97%\n",
      "Batch 28, Loss: 0.281551, Accuracy: 91.02%\n",
      "Batch 29, Loss: 0.236125, Accuracy: 91.00%\n",
      "Batch 30, Loss: 0.240821, Accuracy: 91.04%\n",
      "Batch 31, Loss: 0.412314, Accuracy: 90.98%\n",
      "Batch 32, Loss: 0.261556, Accuracy: 91.02%\n",
      "Batch 33, Loss: 0.301866, Accuracy: 91.05%\n",
      "Batch 34, Loss: 0.190153, Accuracy: 91.18%\n",
      "Batch 35, Loss: 0.217461, Accuracy: 91.21%\n",
      "Batch 36, Loss: 0.173142, Accuracy: 91.28%\n",
      "Batch 37, Loss: 0.372897, Accuracy: 91.09%\n",
      "Batch 38, Loss: 0.334897, Accuracy: 91.00%\n",
      "Batch 39, Loss: 0.380540, Accuracy: 90.87%\n",
      "Batch 40, Loss: 0.191980, Accuracy: 90.94%\n",
      "Batch 41, Loss: 0.241909, Accuracy: 90.93%\n",
      "Batch 42, Loss: 0.287633, Accuracy: 90.92%\n",
      "Batch 43, Loss: 0.485948, Accuracy: 90.73%\n",
      "Batch 44, Loss: 0.228098, Accuracy: 90.70%\n",
      "Batch 45, Loss: 0.203987, Accuracy: 90.76%\n",
      "Batch 46, Loss: 0.395638, Accuracy: 90.66%\n",
      "Batch 47, Loss: 0.194858, Accuracy: 90.72%\n",
      "Batch 48, Loss: 0.274514, Accuracy: 90.79%\n",
      "Batch 49, Loss: 0.261731, Accuracy: 90.85%\n",
      "Batch 50, Loss: 0.176224, Accuracy: 90.94%\n",
      "Batch 51, Loss: 0.193705, Accuracy: 90.99%\n",
      "Batch 52, Loss: 0.182101, Accuracy: 91.05%\n",
      "Batch 53, Loss: 0.363392, Accuracy: 91.01%\n",
      "Batch 54, Loss: 0.197708, Accuracy: 91.06%\n",
      "Batch 55, Loss: 0.217522, Accuracy: 91.08%\n",
      "Batch 56, Loss: 0.209543, Accuracy: 91.16%\n",
      "Batch 57, Loss: 0.236794, Accuracy: 91.17%\n",
      "Batch 58, Loss: 0.212420, Accuracy: 91.24%\n",
      "Batch 59, Loss: 0.258621, Accuracy: 91.21%\n",
      "Batch 60, Loss: 0.264979, Accuracy: 91.17%\n",
      "Batch 61, Loss: 0.179989, Accuracy: 91.21%\n",
      "Batch 62, Loss: 0.239534, Accuracy: 91.28%\n",
      "Batch 63, Loss: 0.395452, Accuracy: 91.15%\n",
      "Batch 64, Loss: 0.340571, Accuracy: 91.09%\n",
      "Batch 65, Loss: 0.303689, Accuracy: 91.11%\n",
      "Batch 66, Loss: 0.333521, Accuracy: 91.00%\n",
      "Batch 67, Loss: 0.220864, Accuracy: 91.04%\n",
      "Batch 68, Loss: 0.400948, Accuracy: 90.99%\n",
      "Batch 69, Loss: 0.286727, Accuracy: 90.96%\n",
      "Batch 70, Loss: 0.509700, Accuracy: 90.87%\n",
      "Batch 71, Loss: 0.615465, Accuracy: 90.62%\n",
      "Batch 72, Loss: 0.265904, Accuracy: 90.65%\n",
      "Batch 73, Loss: 0.240205, Accuracy: 90.62%\n",
      "Batch 74, Loss: 0.456169, Accuracy: 90.56%\n",
      "Batch 75, Loss: 0.250695, Accuracy: 90.60%\n",
      "Batch 76, Loss: 0.399251, Accuracy: 90.56%\n",
      "Batch 77, Loss: 0.312996, Accuracy: 90.52%\n",
      "Batch 78, Loss: 0.229340, Accuracy: 90.54%\n",
      "Batch 79, Loss: 0.304035, Accuracy: 90.51%\n",
      "Batch 80, Loss: 0.425072, Accuracy: 90.47%\n",
      "Batch 81, Loss: 0.401430, Accuracy: 90.43%\n",
      "Batch 82, Loss: 0.318019, Accuracy: 90.42%\n",
      "Batch 83, Loss: 0.325005, Accuracy: 90.36%\n",
      "Batch 84, Loss: 0.305348, Accuracy: 90.36%\n",
      "Batch 85, Loss: 0.396021, Accuracy: 90.31%\n",
      "Batch 86, Loss: 0.371436, Accuracy: 90.32%\n",
      "Batch 87, Loss: 0.421292, Accuracy: 90.25%\n",
      "Batch 88, Loss: 0.283834, Accuracy: 90.23%\n",
      "Batch 89, Loss: 0.317447, Accuracy: 90.24%\n",
      "Batch 90, Loss: 0.463473, Accuracy: 90.19%\n",
      "Batch 91, Loss: 0.237759, Accuracy: 90.21%\n",
      "Batch 92, Loss: 0.240649, Accuracy: 90.23%\n",
      "Batch 93, Loss: 0.311368, Accuracy: 90.22%\n",
      "Batch 94, Loss: 0.262246, Accuracy: 90.23%\n",
      "Batch 95, Loss: 0.233794, Accuracy: 90.26%\n",
      "Batch 96, Loss: 0.397493, Accuracy: 90.19%\n",
      "Batch 97, Loss: 0.383641, Accuracy: 90.16%\n",
      "Batch 98, Loss: 0.264106, Accuracy: 90.21%\n",
      "Batch 99, Loss: 0.183620, Accuracy: 90.28%\n",
      "Batch 100, Loss: 0.295369, Accuracy: 90.27%\n",
      "Batch 101, Loss: 0.297915, Accuracy: 90.25%\n",
      "Batch 102, Loss: 0.236809, Accuracy: 90.29%\n",
      "Batch 103, Loss: 0.322037, Accuracy: 90.31%\n",
      "Batch 104, Loss: 0.478308, Accuracy: 90.25%\n",
      "Batch 105, Loss: 0.272378, Accuracy: 90.25%\n",
      "Batch 106, Loss: 0.291199, Accuracy: 90.24%\n",
      "Batch 107, Loss: 0.310804, Accuracy: 90.23%\n",
      "Batch 108, Loss: 0.215257, Accuracy: 90.23%\n",
      "Batch 109, Loss: 0.201143, Accuracy: 90.25%\n",
      "Batch 110, Loss: 0.265078, Accuracy: 90.27%\n",
      "Batch 111, Loss: 0.132778, Accuracy: 90.33%\n",
      "Batch 112, Loss: 0.168067, Accuracy: 90.39%\n",
      "Batch 113, Loss: 0.218971, Accuracy: 90.43%\n",
      "Batch 114, Loss: 0.464898, Accuracy: 90.35%\n",
      "Batch 115, Loss: 0.192051, Accuracy: 90.41%\n",
      "Batch 116, Loss: 0.396123, Accuracy: 90.38%\n",
      "Batch 117, Loss: 0.379578, Accuracy: 90.33%\n",
      "Batch 118, Loss: 0.341776, Accuracy: 90.32%\n",
      "Batch 119, Loss: 0.181018, Accuracy: 90.35%\n",
      "Batch 120, Loss: 0.285927, Accuracy: 90.36%\n",
      "Batch 121, Loss: 0.248690, Accuracy: 90.38%\n",
      "Batch 122, Loss: 0.271099, Accuracy: 90.37%\n",
      "Batch 123, Loss: 0.534913, Accuracy: 90.31%\n",
      "Batch 124, Loss: 0.157001, Accuracy: 90.36%\n",
      "Batch 125, Loss: 0.187668, Accuracy: 90.40%\n",
      "Batch 126, Loss: 0.349600, Accuracy: 90.35%\n",
      "Batch 127, Loss: 0.192407, Accuracy: 90.37%\n",
      "Batch 128, Loss: 0.269430, Accuracy: 90.38%\n",
      "Batch 129, Loss: 0.283097, Accuracy: 90.38%\n",
      "Batch 130, Loss: 0.260621, Accuracy: 90.41%\n",
      "Batch 131, Loss: 0.210808, Accuracy: 90.43%\n",
      "Batch 132, Loss: 0.373652, Accuracy: 90.39%\n",
      "Batch 133, Loss: 0.194679, Accuracy: 90.40%\n",
      "Batch 134, Loss: 0.240176, Accuracy: 90.43%\n",
      "Batch 135, Loss: 0.452178, Accuracy: 90.38%\n",
      "Batch 136, Loss: 0.240533, Accuracy: 90.38%\n",
      "Batch 137, Loss: 0.239925, Accuracy: 90.41%\n",
      "Batch 138, Loss: 0.217242, Accuracy: 90.43%\n",
      "Batch 139, Loss: 0.423632, Accuracy: 90.37%\n",
      "Batch 140, Loss: 0.186170, Accuracy: 90.40%\n",
      "Batch 141, Loss: 0.289975, Accuracy: 90.39%\n",
      "Batch 142, Loss: 0.221461, Accuracy: 90.42%\n",
      "Batch 143, Loss: 0.254780, Accuracy: 90.44%\n",
      "Batch 144, Loss: 0.196113, Accuracy: 90.47%\n",
      "Batch 145, Loss: 0.243888, Accuracy: 90.50%\n",
      "Batch 146, Loss: 0.208041, Accuracy: 90.53%\n",
      "Batch 147, Loss: 0.216686, Accuracy: 90.56%\n",
      "Batch 148, Loss: 0.475358, Accuracy: 90.52%\n",
      "Batch 149, Loss: 0.258905, Accuracy: 90.52%\n",
      "Batch 150, Loss: 0.249604, Accuracy: 90.52%\n",
      "Batch 151, Loss: 0.326241, Accuracy: 90.49%\n",
      "Batch 152, Loss: 0.273579, Accuracy: 90.48%\n",
      "Batch 153, Loss: 0.278630, Accuracy: 90.48%\n",
      "Batch 154, Loss: 0.206216, Accuracy: 90.51%\n",
      "Batch 155, Loss: 0.174074, Accuracy: 90.55%\n",
      "Batch 156, Loss: 0.347553, Accuracy: 90.52%\n",
      "Batch 157, Loss: 0.072149, Accuracy: 90.59%\n",
      "Batch 158, Loss: 0.252671, Accuracy: 90.60%\n",
      "Batch 159, Loss: 0.250631, Accuracy: 90.62%\n",
      "Batch 160, Loss: 0.255073, Accuracy: 90.62%\n",
      "Batch 161, Loss: 0.269894, Accuracy: 90.64%\n",
      "Batch 162, Loss: 0.260116, Accuracy: 90.63%\n",
      "Batch 163, Loss: 0.254608, Accuracy: 90.66%\n",
      "Batch 164, Loss: 0.187224, Accuracy: 90.69%\n",
      "Batch 165, Loss: 0.210745, Accuracy: 90.70%\n",
      "Batch 166, Loss: 0.294827, Accuracy: 90.67%\n",
      "Batch 167, Loss: 0.352415, Accuracy: 90.65%\n",
      "Batch 168, Loss: 0.297989, Accuracy: 90.66%\n",
      "Batch 169, Loss: 0.156605, Accuracy: 90.69%\n",
      "Batch 170, Loss: 0.117506, Accuracy: 90.73%\n",
      "Batch 171, Loss: 0.151364, Accuracy: 90.76%\n",
      "Batch 172, Loss: 0.192702, Accuracy: 90.76%\n",
      "Batch 173, Loss: 0.263501, Accuracy: 90.75%\n",
      "Batch 174, Loss: 0.235748, Accuracy: 90.75%\n",
      "Batch 175, Loss: 0.230881, Accuracy: 90.76%\n",
      "Batch 176, Loss: 0.262043, Accuracy: 90.77%\n",
      "Batch 177, Loss: 0.185480, Accuracy: 90.78%\n",
      "Batch 178, Loss: 0.240690, Accuracy: 90.77%\n",
      "Batch 179, Loss: 0.401101, Accuracy: 90.75%\n",
      "Batch 180, Loss: 0.138259, Accuracy: 90.78%\n",
      "Batch 181, Loss: 0.104216, Accuracy: 90.81%\n",
      "Batch 182, Loss: 0.282639, Accuracy: 90.81%\n",
      "Batch 183, Loss: 0.345218, Accuracy: 90.80%\n",
      "Batch 184, Loss: 0.212766, Accuracy: 90.80%\n",
      "Batch 185, Loss: 0.241559, Accuracy: 90.81%\n",
      "Batch 186, Loss: 0.316348, Accuracy: 90.81%\n",
      "Batch 187, Loss: 0.276440, Accuracy: 90.81%\n",
      "Batch 188, Loss: 0.239553, Accuracy: 90.82%\n",
      "Batch 189, Loss: 0.299130, Accuracy: 90.82%\n",
      "Batch 190, Loss: 0.210734, Accuracy: 90.81%\n",
      "Batch 191, Loss: 0.143322, Accuracy: 90.85%\n",
      "Batch 192, Loss: 0.261284, Accuracy: 90.84%\n",
      "Batch 193, Loss: 0.252481, Accuracy: 90.85%\n",
      "Batch 194, Loss: 0.238784, Accuracy: 90.85%\n",
      "Batch 195, Loss: 0.244570, Accuracy: 90.85%\n",
      "Batch 196, Loss: 0.205924, Accuracy: 90.86%\n",
      "Batch 197, Loss: 0.365408, Accuracy: 90.86%\n",
      "Batch 198, Loss: 0.126694, Accuracy: 90.89%\n",
      "Batch 199, Loss: 0.191335, Accuracy: 90.90%\n",
      "Batch 200, Loss: 0.275256, Accuracy: 90.88%\n",
      "Batch 201, Loss: 0.228850, Accuracy: 90.90%\n",
      "Batch 202, Loss: 0.196936, Accuracy: 90.90%\n",
      "Batch 203, Loss: 0.305928, Accuracy: 90.89%\n",
      "Batch 204, Loss: 0.188342, Accuracy: 90.89%\n",
      "Batch 205, Loss: 0.245630, Accuracy: 90.90%\n",
      "Batch 206, Loss: 0.279179, Accuracy: 90.89%\n",
      "Batch 207, Loss: 0.207547, Accuracy: 90.91%\n",
      "Batch 208, Loss: 0.174965, Accuracy: 90.93%\n",
      "Batch 209, Loss: 0.166823, Accuracy: 90.95%\n",
      "Batch 210, Loss: 0.115228, Accuracy: 90.97%\n",
      "Batch 211, Loss: 0.190461, Accuracy: 90.99%\n",
      "Batch 212, Loss: 0.238368, Accuracy: 90.99%\n",
      "Batch 213, Loss: 0.241172, Accuracy: 91.01%\n",
      "Training - Epoch 5, Loss: 0.270904, Accuracy: 91.01%\n",
      "Validation Batch 1, Loss: 0.219856, Accuracy: 90.62%\n",
      "Validation Batch 2, Loss: 0.246925, Accuracy: 92.19%\n",
      "Validation Batch 3, Loss: 0.148334, Accuracy: 92.71%\n",
      "Validation Batch 4, Loss: 0.093616, Accuracy: 94.14%\n",
      "Validation Batch 5, Loss: 0.175402, Accuracy: 94.06%\n",
      "Validation Batch 6, Loss: 0.125862, Accuracy: 94.79%\n",
      "Validation Batch 7, Loss: 0.193378, Accuracy: 94.42%\n",
      "Validation Batch 8, Loss: 0.391806, Accuracy: 93.36%\n",
      "Validation Batch 9, Loss: 0.325138, Accuracy: 93.06%\n",
      "Validation Batch 10, Loss: 0.119482, Accuracy: 93.44%\n",
      "Validation Batch 11, Loss: 0.182550, Accuracy: 93.32%\n",
      "Validation Batch 12, Loss: 0.180841, Accuracy: 93.36%\n",
      "Validation Batch 13, Loss: 0.359162, Accuracy: 92.67%\n",
      "Validation Batch 14, Loss: 0.238309, Accuracy: 92.52%\n",
      "Validation Batch 15, Loss: 0.147843, Accuracy: 92.81%\n",
      "Validation Batch 16, Loss: 0.295533, Accuracy: 92.77%\n",
      "Validation Batch 17, Loss: 0.412074, Accuracy: 92.46%\n",
      "Validation Batch 18, Loss: 0.171131, Accuracy: 92.62%\n",
      "Validation Batch 19, Loss: 0.192517, Accuracy: 92.60%\n",
      "Validation Batch 20, Loss: 0.157781, Accuracy: 92.81%\n",
      "Validation Batch 21, Loss: 0.120835, Accuracy: 92.93%\n",
      "Validation Batch 22, Loss: 0.335579, Accuracy: 92.68%\n",
      "Validation Batch 23, Loss: 0.314428, Accuracy: 92.46%\n",
      "Validation Batch 24, Loss: 0.300956, Accuracy: 92.25%\n",
      "Validation Batch 25, Loss: 0.085931, Accuracy: 92.44%\n",
      "Validation Batch 26, Loss: 0.250106, Accuracy: 92.49%\n",
      "Validation Batch 27, Loss: 0.133357, Accuracy: 92.60%\n",
      "Validation - Epoch 5, Loss: 0.219212, Accuracy: 92.60%\n",
      "Patience—0\n",
      "Epoch 6\n",
      "Batch 1, Loss: 0.145699, Accuracy: 95.31%\n",
      "Batch 2, Loss: 0.156885, Accuracy: 95.31%\n",
      "Batch 3, Loss: 0.148221, Accuracy: 95.83%\n",
      "Batch 4, Loss: 0.163288, Accuracy: 96.09%\n",
      "Batch 5, Loss: 0.233412, Accuracy: 95.31%\n",
      "Batch 6, Loss: 0.308491, Accuracy: 94.01%\n",
      "Batch 7, Loss: 0.074656, Accuracy: 94.87%\n",
      "Batch 8, Loss: 0.256166, Accuracy: 94.73%\n",
      "Batch 9, Loss: 0.221794, Accuracy: 94.44%\n",
      "Batch 10, Loss: 0.177305, Accuracy: 94.53%\n",
      "Batch 11, Loss: 0.175556, Accuracy: 94.74%\n",
      "Batch 12, Loss: 0.231629, Accuracy: 94.79%\n",
      "Batch 13, Loss: 0.224473, Accuracy: 94.71%\n",
      "Batch 14, Loss: 0.174689, Accuracy: 94.87%\n",
      "Batch 15, Loss: 0.242549, Accuracy: 94.69%\n",
      "Batch 16, Loss: 0.077727, Accuracy: 94.92%\n",
      "Batch 17, Loss: 0.172273, Accuracy: 94.85%\n",
      "Batch 18, Loss: 0.065175, Accuracy: 95.14%\n",
      "Batch 19, Loss: 0.193059, Accuracy: 94.98%\n",
      "Batch 20, Loss: 0.273196, Accuracy: 94.77%\n",
      "Batch 21, Loss: 0.147878, Accuracy: 94.79%\n",
      "Batch 22, Loss: 0.221683, Accuracy: 94.74%\n",
      "Batch 23, Loss: 0.102757, Accuracy: 94.90%\n",
      "Batch 24, Loss: 0.199280, Accuracy: 94.86%\n",
      "Batch 25, Loss: 0.238689, Accuracy: 94.88%\n",
      "Batch 26, Loss: 0.120915, Accuracy: 95.01%\n",
      "Batch 27, Loss: 0.381946, Accuracy: 94.79%\n",
      "Batch 28, Loss: 0.163985, Accuracy: 94.70%\n",
      "Batch 29, Loss: 0.278625, Accuracy: 94.45%\n",
      "Batch 30, Loss: 0.309792, Accuracy: 94.32%\n",
      "Batch 31, Loss: 0.168655, Accuracy: 94.35%\n",
      "Batch 32, Loss: 0.238092, Accuracy: 94.29%\n",
      "Batch 33, Loss: 0.228151, Accuracy: 94.27%\n",
      "Batch 34, Loss: 0.180635, Accuracy: 94.30%\n",
      "Batch 35, Loss: 0.124447, Accuracy: 94.38%\n",
      "Batch 36, Loss: 0.145955, Accuracy: 94.44%\n",
      "Batch 37, Loss: 0.181290, Accuracy: 94.38%\n",
      "Batch 38, Loss: 0.217753, Accuracy: 94.28%\n",
      "Batch 39, Loss: 0.230745, Accuracy: 94.27%\n",
      "Batch 40, Loss: 0.254550, Accuracy: 94.18%\n",
      "Batch 41, Loss: 0.229201, Accuracy: 94.21%\n",
      "Batch 42, Loss: 0.297498, Accuracy: 94.12%\n",
      "Batch 43, Loss: 0.188209, Accuracy: 94.08%\n",
      "Batch 44, Loss: 0.213616, Accuracy: 94.00%\n",
      "Batch 45, Loss: 0.117265, Accuracy: 94.10%\n",
      "Batch 46, Loss: 0.266224, Accuracy: 94.02%\n",
      "Batch 47, Loss: 0.148358, Accuracy: 94.02%\n",
      "Batch 48, Loss: 0.396051, Accuracy: 93.82%\n",
      "Batch 49, Loss: 0.315961, Accuracy: 93.78%\n",
      "Batch 50, Loss: 0.293056, Accuracy: 93.72%\n",
      "Batch 51, Loss: 0.330259, Accuracy: 93.63%\n",
      "Batch 52, Loss: 0.385563, Accuracy: 93.45%\n",
      "Batch 53, Loss: 0.186019, Accuracy: 93.51%\n",
      "Batch 54, Loss: 0.140869, Accuracy: 93.58%\n",
      "Batch 55, Loss: 0.257409, Accuracy: 93.58%\n",
      "Batch 56, Loss: 0.118657, Accuracy: 93.64%\n",
      "Batch 57, Loss: 0.113338, Accuracy: 93.72%\n",
      "Batch 58, Loss: 0.104297, Accuracy: 93.80%\n",
      "Batch 59, Loss: 0.274037, Accuracy: 93.75%\n",
      "Batch 60, Loss: 0.157100, Accuracy: 93.78%\n",
      "Batch 61, Loss: 0.215480, Accuracy: 93.78%\n",
      "Batch 62, Loss: 0.245143, Accuracy: 93.70%\n",
      "Batch 63, Loss: 0.222059, Accuracy: 93.65%\n",
      "Batch 64, Loss: 0.223698, Accuracy: 93.63%\n",
      "Batch 65, Loss: 0.118423, Accuracy: 93.65%\n",
      "Batch 66, Loss: 0.273379, Accuracy: 93.66%\n",
      "Batch 67, Loss: 0.143858, Accuracy: 93.68%\n",
      "Batch 68, Loss: 0.169082, Accuracy: 93.68%\n",
      "Batch 69, Loss: 0.139909, Accuracy: 93.70%\n",
      "Batch 70, Loss: 0.133270, Accuracy: 93.73%\n",
      "Batch 71, Loss: 0.340255, Accuracy: 93.64%\n",
      "Batch 72, Loss: 0.291259, Accuracy: 93.60%\n",
      "Batch 73, Loss: 0.140094, Accuracy: 93.62%\n",
      "Batch 74, Loss: 0.184521, Accuracy: 93.64%\n",
      "Batch 75, Loss: 0.105353, Accuracy: 93.69%\n",
      "Batch 76, Loss: 0.333844, Accuracy: 93.56%\n",
      "Batch 77, Loss: 0.119463, Accuracy: 93.59%\n",
      "Batch 78, Loss: 0.198527, Accuracy: 93.63%\n",
      "Batch 79, Loss: 0.300511, Accuracy: 93.63%\n",
      "Batch 80, Loss: 0.166837, Accuracy: 93.63%\n",
      "Batch 81, Loss: 0.173249, Accuracy: 93.61%\n",
      "Batch 82, Loss: 0.258295, Accuracy: 93.58%\n",
      "Batch 83, Loss: 0.061965, Accuracy: 93.66%\n",
      "Batch 84, Loss: 0.236508, Accuracy: 93.62%\n",
      "Batch 85, Loss: 0.182343, Accuracy: 93.62%\n",
      "Batch 86, Loss: 0.214631, Accuracy: 93.60%\n",
      "Batch 87, Loss: 0.091268, Accuracy: 93.64%\n",
      "Batch 88, Loss: 0.160835, Accuracy: 93.64%\n",
      "Batch 89, Loss: 0.209793, Accuracy: 93.61%\n",
      "Batch 90, Loss: 0.136558, Accuracy: 93.63%\n",
      "Batch 91, Loss: 0.211531, Accuracy: 93.63%\n",
      "Batch 92, Loss: 0.126223, Accuracy: 93.67%\n",
      "Batch 93, Loss: 0.059256, Accuracy: 93.72%\n",
      "Batch 94, Loss: 0.102279, Accuracy: 93.77%\n",
      "Batch 95, Loss: 0.189657, Accuracy: 93.80%\n",
      "Batch 96, Loss: 0.110937, Accuracy: 93.85%\n",
      "Batch 97, Loss: 0.077232, Accuracy: 93.89%\n",
      "Batch 98, Loss: 0.139447, Accuracy: 93.91%\n",
      "Batch 99, Loss: 0.125541, Accuracy: 93.92%\n",
      "Batch 100, Loss: 0.144187, Accuracy: 93.92%\n",
      "Batch 101, Loss: 0.270711, Accuracy: 93.89%\n",
      "Batch 102, Loss: 0.130568, Accuracy: 93.93%\n",
      "Batch 103, Loss: 0.111670, Accuracy: 93.98%\n",
      "Batch 104, Loss: 0.236115, Accuracy: 93.96%\n",
      "Batch 105, Loss: 0.137222, Accuracy: 93.99%\n",
      "Batch 106, Loss: 0.041672, Accuracy: 94.04%\n",
      "Batch 107, Loss: 0.375885, Accuracy: 94.01%\n",
      "Batch 108, Loss: 0.168596, Accuracy: 94.01%\n",
      "Batch 109, Loss: 0.139482, Accuracy: 94.04%\n",
      "Batch 110, Loss: 0.080641, Accuracy: 94.08%\n",
      "Batch 111, Loss: 0.167809, Accuracy: 94.03%\n",
      "Batch 112, Loss: 0.170090, Accuracy: 94.04%\n",
      "Batch 113, Loss: 0.139680, Accuracy: 94.07%\n",
      "Batch 114, Loss: 0.044224, Accuracy: 94.12%\n",
      "Batch 115, Loss: 0.215727, Accuracy: 94.12%\n",
      "Batch 116, Loss: 0.175913, Accuracy: 94.13%\n",
      "Batch 117, Loss: 0.202655, Accuracy: 94.12%\n",
      "Batch 118, Loss: 0.221779, Accuracy: 94.09%\n",
      "Batch 119, Loss: 0.242194, Accuracy: 94.07%\n",
      "Batch 120, Loss: 0.134870, Accuracy: 94.10%\n",
      "Batch 121, Loss: 0.114238, Accuracy: 94.12%\n",
      "Batch 122, Loss: 0.294103, Accuracy: 94.10%\n",
      "Batch 123, Loss: 0.112590, Accuracy: 94.12%\n",
      "Batch 124, Loss: 0.077936, Accuracy: 94.15%\n",
      "Batch 125, Loss: 0.381866, Accuracy: 94.09%\n",
      "Batch 126, Loss: 0.373817, Accuracy: 94.02%\n",
      "Batch 127, Loss: 0.229795, Accuracy: 94.00%\n",
      "Batch 128, Loss: 0.267143, Accuracy: 93.97%\n",
      "Batch 129, Loss: 0.237437, Accuracy: 93.94%\n",
      "Batch 130, Loss: 0.216755, Accuracy: 93.94%\n",
      "Batch 131, Loss: 0.149681, Accuracy: 93.94%\n",
      "Batch 132, Loss: 0.067515, Accuracy: 93.97%\n",
      "Batch 133, Loss: 0.115637, Accuracy: 94.00%\n",
      "Batch 134, Loss: 0.234136, Accuracy: 93.99%\n",
      "Batch 135, Loss: 0.193197, Accuracy: 93.97%\n",
      "Batch 136, Loss: 0.193386, Accuracy: 93.98%\n",
      "Batch 137, Loss: 0.092860, Accuracy: 93.99%\n",
      "Batch 138, Loss: 0.117458, Accuracy: 94.01%\n",
      "Batch 139, Loss: 0.279646, Accuracy: 94.00%\n",
      "Batch 140, Loss: 0.192078, Accuracy: 94.00%\n",
      "Batch 141, Loss: 0.131438, Accuracy: 94.02%\n",
      "Batch 142, Loss: 0.123045, Accuracy: 94.04%\n",
      "Batch 143, Loss: 0.072535, Accuracy: 94.07%\n",
      "Batch 144, Loss: 0.195544, Accuracy: 94.05%\n",
      "Batch 145, Loss: 0.262567, Accuracy: 94.05%\n",
      "Batch 146, Loss: 0.096756, Accuracy: 94.08%\n",
      "Batch 147, Loss: 0.080345, Accuracy: 94.11%\n",
      "Batch 148, Loss: 0.121486, Accuracy: 94.12%\n",
      "Batch 149, Loss: 0.075623, Accuracy: 94.15%\n",
      "Batch 150, Loss: 0.114831, Accuracy: 94.17%\n",
      "Batch 151, Loss: 0.271005, Accuracy: 94.13%\n",
      "Batch 152, Loss: 0.154474, Accuracy: 94.12%\n",
      "Batch 153, Loss: 0.078144, Accuracy: 94.14%\n",
      "Batch 154, Loss: 0.184699, Accuracy: 94.15%\n",
      "Batch 155, Loss: 0.190069, Accuracy: 94.11%\n",
      "Batch 156, Loss: 0.186158, Accuracy: 94.11%\n",
      "Batch 157, Loss: 0.112441, Accuracy: 94.13%\n",
      "Batch 158, Loss: 0.216103, Accuracy: 94.14%\n",
      "Batch 159, Loss: 0.121884, Accuracy: 94.14%\n",
      "Batch 160, Loss: 0.302603, Accuracy: 94.13%\n",
      "Batch 161, Loss: 0.197235, Accuracy: 94.14%\n",
      "Batch 162, Loss: 0.240142, Accuracy: 94.14%\n",
      "Batch 163, Loss: 0.284805, Accuracy: 94.10%\n",
      "Batch 164, Loss: 0.130331, Accuracy: 94.12%\n",
      "Batch 165, Loss: 0.212649, Accuracy: 94.12%\n",
      "Batch 166, Loss: 0.126952, Accuracy: 94.14%\n",
      "Batch 167, Loss: 0.243695, Accuracy: 94.11%\n",
      "Batch 168, Loss: 0.228923, Accuracy: 94.11%\n",
      "Batch 169, Loss: 0.132027, Accuracy: 94.14%\n",
      "Batch 170, Loss: 0.145295, Accuracy: 94.15%\n",
      "Batch 171, Loss: 0.319706, Accuracy: 94.14%\n",
      "Batch 172, Loss: 0.231458, Accuracy: 94.14%\n",
      "Batch 173, Loss: 0.154674, Accuracy: 94.16%\n",
      "Batch 174, Loss: 0.113435, Accuracy: 94.16%\n",
      "Batch 175, Loss: 0.147354, Accuracy: 94.18%\n",
      "Batch 176, Loss: 0.207758, Accuracy: 94.17%\n",
      "Batch 177, Loss: 0.234371, Accuracy: 94.16%\n",
      "Batch 178, Loss: 0.200930, Accuracy: 94.15%\n",
      "Batch 179, Loss: 0.166932, Accuracy: 94.15%\n",
      "Batch 180, Loss: 0.142126, Accuracy: 94.16%\n",
      "Batch 181, Loss: 0.092059, Accuracy: 94.18%\n",
      "Batch 182, Loss: 0.105149, Accuracy: 94.21%\n",
      "Batch 183, Loss: 0.223405, Accuracy: 94.19%\n",
      "Batch 184, Loss: 0.254386, Accuracy: 94.17%\n",
      "Batch 185, Loss: 0.119972, Accuracy: 94.17%\n",
      "Batch 186, Loss: 0.274902, Accuracy: 94.16%\n",
      "Batch 187, Loss: 0.150939, Accuracy: 94.16%\n",
      "Batch 188, Loss: 0.194963, Accuracy: 94.16%\n",
      "Batch 189, Loss: 0.143608, Accuracy: 94.16%\n",
      "Batch 190, Loss: 0.145625, Accuracy: 94.14%\n",
      "Batch 191, Loss: 0.075513, Accuracy: 94.17%\n",
      "Batch 192, Loss: 0.161871, Accuracy: 94.16%\n",
      "Batch 193, Loss: 0.080783, Accuracy: 94.18%\n",
      "Batch 194, Loss: 0.188282, Accuracy: 94.18%\n",
      "Batch 195, Loss: 0.134886, Accuracy: 94.19%\n",
      "Batch 196, Loss: 0.134624, Accuracy: 94.20%\n",
      "Batch 197, Loss: 0.274442, Accuracy: 94.18%\n",
      "Batch 198, Loss: 0.260850, Accuracy: 94.18%\n",
      "Batch 199, Loss: 0.235146, Accuracy: 94.17%\n",
      "Batch 200, Loss: 0.150320, Accuracy: 94.18%\n",
      "Batch 201, Loss: 0.147592, Accuracy: 94.18%\n",
      "Batch 202, Loss: 0.271198, Accuracy: 94.17%\n",
      "Batch 203, Loss: 0.131540, Accuracy: 94.18%\n",
      "Batch 204, Loss: 0.088899, Accuracy: 94.19%\n",
      "Batch 205, Loss: 0.172942, Accuracy: 94.20%\n",
      "Batch 206, Loss: 0.283544, Accuracy: 94.19%\n",
      "Batch 207, Loss: 0.227608, Accuracy: 94.18%\n",
      "Batch 208, Loss: 0.201053, Accuracy: 94.18%\n",
      "Batch 209, Loss: 0.178648, Accuracy: 94.17%\n",
      "Batch 210, Loss: 0.199233, Accuracy: 94.16%\n",
      "Batch 211, Loss: 0.338573, Accuracy: 94.13%\n",
      "Batch 212, Loss: 0.156582, Accuracy: 94.13%\n",
      "Batch 213, Loss: 0.225098, Accuracy: 94.11%\n",
      "Training - Epoch 6, Loss: 0.186795, Accuracy: 94.11%\n",
      "Validation Batch 1, Loss: 0.147047, Accuracy: 93.75%\n",
      "Validation Batch 2, Loss: 0.299692, Accuracy: 92.19%\n",
      "Validation Batch 3, Loss: 0.157981, Accuracy: 93.23%\n",
      "Validation Batch 4, Loss: 0.153591, Accuracy: 93.75%\n",
      "Validation Batch 5, Loss: 0.129009, Accuracy: 94.06%\n",
      "Validation Batch 6, Loss: 0.135486, Accuracy: 93.75%\n",
      "Validation Batch 7, Loss: 0.132360, Accuracy: 93.75%\n",
      "Validation Batch 8, Loss: 0.416621, Accuracy: 92.97%\n",
      "Validation Batch 9, Loss: 0.414565, Accuracy: 92.36%\n",
      "Validation Batch 10, Loss: 0.112717, Accuracy: 92.81%\n",
      "Validation Batch 11, Loss: 0.147582, Accuracy: 93.04%\n",
      "Validation Batch 12, Loss: 0.168279, Accuracy: 93.23%\n",
      "Validation Batch 13, Loss: 0.374741, Accuracy: 92.67%\n",
      "Validation Batch 14, Loss: 0.164717, Accuracy: 92.86%\n",
      "Validation Batch 15, Loss: 0.148919, Accuracy: 93.02%\n",
      "Validation Batch 16, Loss: 0.255179, Accuracy: 92.87%\n",
      "Validation Batch 17, Loss: 0.388473, Accuracy: 92.56%\n",
      "Validation Batch 18, Loss: 0.218506, Accuracy: 92.62%\n",
      "Validation Batch 19, Loss: 0.275341, Accuracy: 92.60%\n",
      "Validation Batch 20, Loss: 0.107339, Accuracy: 92.89%\n",
      "Validation Batch 21, Loss: 0.141814, Accuracy: 93.08%\n",
      "Validation Batch 22, Loss: 0.330760, Accuracy: 92.90%\n",
      "Validation Batch 23, Loss: 0.201386, Accuracy: 92.87%\n",
      "Validation Batch 24, Loss: 0.196045, Accuracy: 92.84%\n",
      "Validation Batch 25, Loss: 0.084710, Accuracy: 93.06%\n",
      "Validation Batch 26, Loss: 0.182170, Accuracy: 93.09%\n",
      "Validation Batch 27, Loss: 0.071424, Accuracy: 93.19%\n",
      "Validation - Epoch 6, Loss: 0.205795, Accuracy: 93.19%\n",
      "Patience—0\n",
      "Epoch 7\n",
      "Batch 1, Loss: 0.184676, Accuracy: 95.31%\n",
      "Batch 2, Loss: 0.154787, Accuracy: 96.09%\n",
      "Batch 3, Loss: 0.077128, Accuracy: 97.40%\n",
      "Batch 4, Loss: 0.101955, Accuracy: 97.27%\n",
      "Batch 5, Loss: 0.050668, Accuracy: 97.81%\n",
      "Batch 6, Loss: 0.149264, Accuracy: 97.66%\n",
      "Batch 7, Loss: 0.204451, Accuracy: 97.10%\n",
      "Batch 8, Loss: 0.140509, Accuracy: 97.07%\n",
      "Batch 9, Loss: 0.165397, Accuracy: 96.70%\n",
      "Batch 10, Loss: 0.211892, Accuracy: 96.25%\n",
      "Batch 11, Loss: 0.302921, Accuracy: 95.60%\n",
      "Batch 12, Loss: 0.170588, Accuracy: 95.70%\n",
      "Batch 13, Loss: 0.235193, Accuracy: 95.19%\n",
      "Batch 14, Loss: 0.048878, Accuracy: 95.54%\n",
      "Batch 15, Loss: 0.080407, Accuracy: 95.73%\n",
      "Batch 16, Loss: 0.224107, Accuracy: 95.51%\n",
      "Batch 17, Loss: 0.119762, Accuracy: 95.50%\n",
      "Batch 18, Loss: 0.268205, Accuracy: 95.31%\n",
      "Batch 19, Loss: 0.164843, Accuracy: 95.15%\n",
      "Batch 20, Loss: 0.152453, Accuracy: 95.16%\n",
      "Batch 21, Loss: 0.251591, Accuracy: 95.01%\n",
      "Batch 22, Loss: 0.122840, Accuracy: 95.10%\n",
      "Batch 23, Loss: 0.101366, Accuracy: 95.24%\n",
      "Batch 24, Loss: 0.280229, Accuracy: 95.05%\n",
      "Batch 25, Loss: 0.168566, Accuracy: 95.06%\n",
      "Batch 26, Loss: 0.154866, Accuracy: 95.07%\n",
      "Batch 27, Loss: 0.182143, Accuracy: 95.08%\n",
      "Batch 28, Loss: 0.112976, Accuracy: 95.20%\n",
      "Batch 29, Loss: 0.120756, Accuracy: 95.26%\n",
      "Batch 30, Loss: 0.117690, Accuracy: 95.36%\n",
      "Batch 31, Loss: 0.221401, Accuracy: 95.31%\n",
      "Batch 32, Loss: 0.181076, Accuracy: 95.26%\n",
      "Batch 33, Loss: 0.123178, Accuracy: 95.36%\n",
      "Batch 34, Loss: 0.122056, Accuracy: 95.31%\n",
      "Batch 35, Loss: 0.042153, Accuracy: 95.45%\n",
      "Batch 36, Loss: 0.196565, Accuracy: 95.44%\n",
      "Batch 37, Loss: 0.051469, Accuracy: 95.57%\n",
      "Batch 38, Loss: 0.103804, Accuracy: 95.56%\n",
      "Batch 39, Loss: 0.129863, Accuracy: 95.59%\n",
      "Batch 40, Loss: 0.062882, Accuracy: 95.66%\n",
      "Batch 41, Loss: 0.147619, Accuracy: 95.69%\n",
      "Batch 42, Loss: 0.242898, Accuracy: 95.65%\n",
      "Batch 43, Loss: 0.278122, Accuracy: 95.60%\n",
      "Batch 44, Loss: 0.143958, Accuracy: 95.63%\n",
      "Batch 45, Loss: 0.196176, Accuracy: 95.56%\n",
      "Batch 46, Loss: 0.147220, Accuracy: 95.55%\n",
      "Batch 47, Loss: 0.052592, Accuracy: 95.61%\n",
      "Batch 48, Loss: 0.132726, Accuracy: 95.61%\n",
      "Batch 49, Loss: 0.078772, Accuracy: 95.63%\n",
      "Batch 50, Loss: 0.064676, Accuracy: 95.66%\n",
      "Batch 51, Loss: 0.106314, Accuracy: 95.65%\n",
      "Batch 52, Loss: 0.313660, Accuracy: 95.55%\n",
      "Batch 53, Loss: 0.059746, Accuracy: 95.61%\n",
      "Batch 54, Loss: 0.128604, Accuracy: 95.63%\n",
      "Batch 55, Loss: 0.194018, Accuracy: 95.57%\n",
      "Batch 56, Loss: 0.121923, Accuracy: 95.59%\n",
      "Batch 57, Loss: 0.053612, Accuracy: 95.67%\n",
      "Batch 58, Loss: 0.178810, Accuracy: 95.61%\n",
      "Batch 59, Loss: 0.075006, Accuracy: 95.66%\n",
      "Batch 60, Loss: 0.222936, Accuracy: 95.55%\n",
      "Batch 61, Loss: 0.151481, Accuracy: 95.54%\n",
      "Batch 62, Loss: 0.190924, Accuracy: 95.51%\n",
      "Batch 63, Loss: 0.099255, Accuracy: 95.56%\n",
      "Batch 64, Loss: 0.205832, Accuracy: 95.53%\n",
      "Batch 65, Loss: 0.045773, Accuracy: 95.60%\n",
      "Batch 66, Loss: 0.038552, Accuracy: 95.67%\n",
      "Batch 67, Loss: 0.161005, Accuracy: 95.64%\n",
      "Batch 68, Loss: 0.087753, Accuracy: 95.68%\n",
      "Batch 69, Loss: 0.145421, Accuracy: 95.67%\n",
      "Batch 70, Loss: 0.098660, Accuracy: 95.67%\n",
      "Batch 71, Loss: 0.088006, Accuracy: 95.69%\n",
      "Batch 72, Loss: 0.151919, Accuracy: 95.68%\n",
      "Batch 73, Loss: 0.069379, Accuracy: 95.74%\n",
      "Batch 74, Loss: 0.121671, Accuracy: 95.76%\n",
      "Batch 75, Loss: 0.093741, Accuracy: 95.77%\n",
      "Batch 76, Loss: 0.175006, Accuracy: 95.79%\n",
      "Batch 77, Loss: 0.103762, Accuracy: 95.80%\n",
      "Batch 78, Loss: 0.067553, Accuracy: 95.83%\n",
      "Batch 79, Loss: 0.119611, Accuracy: 95.85%\n",
      "Batch 80, Loss: 0.198615, Accuracy: 95.84%\n",
      "Batch 81, Loss: 0.054674, Accuracy: 95.87%\n",
      "Batch 82, Loss: 0.161378, Accuracy: 95.87%\n",
      "Batch 83, Loss: 0.090327, Accuracy: 95.90%\n",
      "Batch 84, Loss: 0.141909, Accuracy: 95.91%\n",
      "Batch 85, Loss: 0.158605, Accuracy: 95.90%\n",
      "Batch 86, Loss: 0.234903, Accuracy: 95.86%\n",
      "Batch 87, Loss: 0.209057, Accuracy: 95.80%\n",
      "Batch 88, Loss: 0.075001, Accuracy: 95.83%\n",
      "Batch 89, Loss: 0.128037, Accuracy: 95.80%\n",
      "Batch 90, Loss: 0.148653, Accuracy: 95.80%\n",
      "Batch 91, Loss: 0.200104, Accuracy: 95.74%\n",
      "Batch 92, Loss: 0.079152, Accuracy: 95.77%\n",
      "Batch 93, Loss: 0.083319, Accuracy: 95.78%\n",
      "Batch 94, Loss: 0.134630, Accuracy: 95.79%\n",
      "Batch 95, Loss: 0.152974, Accuracy: 95.79%\n",
      "Batch 96, Loss: 0.053795, Accuracy: 95.82%\n",
      "Batch 97, Loss: 0.201540, Accuracy: 95.83%\n",
      "Batch 98, Loss: 0.095134, Accuracy: 95.84%\n",
      "Batch 99, Loss: 0.232484, Accuracy: 95.82%\n",
      "Batch 100, Loss: 0.076682, Accuracy: 95.84%\n",
      "Batch 101, Loss: 0.218651, Accuracy: 95.84%\n",
      "Batch 102, Loss: 0.103830, Accuracy: 95.86%\n",
      "Batch 103, Loss: 0.042328, Accuracy: 95.90%\n",
      "Batch 104, Loss: 0.168339, Accuracy: 95.88%\n",
      "Batch 105, Loss: 0.122423, Accuracy: 95.91%\n",
      "Batch 106, Loss: 0.077395, Accuracy: 95.93%\n",
      "Batch 107, Loss: 0.109274, Accuracy: 95.94%\n",
      "Batch 108, Loss: 0.097982, Accuracy: 95.96%\n",
      "Batch 109, Loss: 0.083095, Accuracy: 95.97%\n",
      "Batch 110, Loss: 0.095687, Accuracy: 95.99%\n",
      "Batch 111, Loss: 0.169899, Accuracy: 95.99%\n",
      "Batch 112, Loss: 0.133232, Accuracy: 95.97%\n",
      "Batch 113, Loss: 0.094160, Accuracy: 95.98%\n",
      "Batch 114, Loss: 0.048575, Accuracy: 96.01%\n",
      "Batch 115, Loss: 0.092085, Accuracy: 96.03%\n",
      "Batch 116, Loss: 0.089168, Accuracy: 96.05%\n",
      "Batch 117, Loss: 0.162278, Accuracy: 96.05%\n",
      "Batch 118, Loss: 0.200088, Accuracy: 96.01%\n",
      "Batch 119, Loss: 0.142968, Accuracy: 96.00%\n",
      "Batch 120, Loss: 0.142767, Accuracy: 95.99%\n",
      "Batch 121, Loss: 0.184338, Accuracy: 95.98%\n",
      "Batch 122, Loss: 0.139267, Accuracy: 95.97%\n",
      "Batch 123, Loss: 0.182078, Accuracy: 95.93%\n",
      "Batch 124, Loss: 0.104042, Accuracy: 95.94%\n",
      "Batch 125, Loss: 0.060698, Accuracy: 95.96%\n",
      "Batch 126, Loss: 0.130661, Accuracy: 95.97%\n",
      "Batch 127, Loss: 0.155797, Accuracy: 95.96%\n",
      "Batch 128, Loss: 0.157131, Accuracy: 95.96%\n",
      "Batch 129, Loss: 0.132806, Accuracy: 95.95%\n",
      "Batch 130, Loss: 0.142057, Accuracy: 95.95%\n",
      "Batch 131, Loss: 0.091465, Accuracy: 95.97%\n",
      "Batch 132, Loss: 0.062515, Accuracy: 95.99%\n",
      "Batch 133, Loss: 0.087492, Accuracy: 95.99%\n",
      "Batch 134, Loss: 0.130816, Accuracy: 95.99%\n",
      "Batch 135, Loss: 0.044473, Accuracy: 96.02%\n",
      "Batch 136, Loss: 0.075238, Accuracy: 96.04%\n",
      "Batch 137, Loss: 0.063238, Accuracy: 96.05%\n",
      "Batch 138, Loss: 0.096635, Accuracy: 96.07%\n",
      "Batch 139, Loss: 0.205266, Accuracy: 96.07%\n",
      "Batch 140, Loss: 0.048062, Accuracy: 96.08%\n",
      "Batch 141, Loss: 0.151891, Accuracy: 96.05%\n",
      "Batch 142, Loss: 0.225943, Accuracy: 96.05%\n",
      "Batch 143, Loss: 0.159947, Accuracy: 96.06%\n",
      "Batch 144, Loss: 0.153598, Accuracy: 96.05%\n",
      "Batch 145, Loss: 0.115412, Accuracy: 96.03%\n",
      "Batch 146, Loss: 0.090221, Accuracy: 96.04%\n",
      "Batch 147, Loss: 0.114100, Accuracy: 96.02%\n",
      "Batch 148, Loss: 0.216084, Accuracy: 96.01%\n",
      "Batch 149, Loss: 0.040980, Accuracy: 96.03%\n",
      "Batch 150, Loss: 0.210683, Accuracy: 96.01%\n",
      "Batch 151, Loss: 0.101437, Accuracy: 96.02%\n",
      "Batch 152, Loss: 0.234310, Accuracy: 95.98%\n",
      "Batch 153, Loss: 0.059556, Accuracy: 96.00%\n",
      "Batch 154, Loss: 0.185145, Accuracy: 95.97%\n",
      "Batch 155, Loss: 0.149986, Accuracy: 95.97%\n",
      "Batch 156, Loss: 0.134324, Accuracy: 95.95%\n",
      "Batch 157, Loss: 0.100470, Accuracy: 95.97%\n",
      "Batch 158, Loss: 0.127664, Accuracy: 95.97%\n",
      "Batch 159, Loss: 0.109911, Accuracy: 95.96%\n",
      "Batch 160, Loss: 0.110062, Accuracy: 95.97%\n",
      "Batch 161, Loss: 0.141985, Accuracy: 95.96%\n",
      "Batch 162, Loss: 0.181583, Accuracy: 95.96%\n",
      "Batch 163, Loss: 0.237000, Accuracy: 95.94%\n",
      "Batch 164, Loss: 0.099311, Accuracy: 95.93%\n",
      "Batch 165, Loss: 0.195063, Accuracy: 95.93%\n",
      "Batch 166, Loss: 0.101543, Accuracy: 95.93%\n",
      "Batch 167, Loss: 0.125072, Accuracy: 95.93%\n",
      "Batch 168, Loss: 0.133517, Accuracy: 95.92%\n",
      "Batch 169, Loss: 0.154730, Accuracy: 95.90%\n",
      "Batch 170, Loss: 0.159965, Accuracy: 95.89%\n",
      "Batch 171, Loss: 0.246832, Accuracy: 95.88%\n",
      "Batch 172, Loss: 0.195053, Accuracy: 95.86%\n",
      "Batch 173, Loss: 0.074534, Accuracy: 95.86%\n",
      "Batch 174, Loss: 0.151079, Accuracy: 95.87%\n",
      "Batch 175, Loss: 0.195513, Accuracy: 95.86%\n",
      "Batch 176, Loss: 0.084679, Accuracy: 95.87%\n",
      "Batch 177, Loss: 0.094867, Accuracy: 95.88%\n",
      "Batch 178, Loss: 0.082671, Accuracy: 95.88%\n",
      "Batch 179, Loss: 0.203219, Accuracy: 95.87%\n",
      "Batch 180, Loss: 0.137471, Accuracy: 95.86%\n",
      "Batch 181, Loss: 0.191766, Accuracy: 95.85%\n",
      "Batch 182, Loss: 0.111336, Accuracy: 95.85%\n",
      "Batch 183, Loss: 0.204604, Accuracy: 95.83%\n",
      "Batch 184, Loss: 0.164712, Accuracy: 95.81%\n",
      "Batch 185, Loss: 0.089010, Accuracy: 95.83%\n",
      "Batch 186, Loss: 0.148730, Accuracy: 95.81%\n",
      "Batch 187, Loss: 0.095897, Accuracy: 95.82%\n",
      "Batch 188, Loss: 0.069664, Accuracy: 95.84%\n",
      "Batch 189, Loss: 0.026744, Accuracy: 95.86%\n",
      "Batch 190, Loss: 0.138750, Accuracy: 95.86%\n",
      "Batch 191, Loss: 0.083007, Accuracy: 95.87%\n",
      "Batch 192, Loss: 0.130468, Accuracy: 95.87%\n",
      "Batch 193, Loss: 0.177463, Accuracy: 95.86%\n",
      "Batch 194, Loss: 0.035703, Accuracy: 95.88%\n",
      "Batch 195, Loss: 0.132532, Accuracy: 95.88%\n",
      "Batch 196, Loss: 0.081484, Accuracy: 95.89%\n",
      "Batch 197, Loss: 0.082528, Accuracy: 95.90%\n",
      "Batch 198, Loss: 0.081341, Accuracy: 95.91%\n",
      "Batch 199, Loss: 0.169831, Accuracy: 95.91%\n",
      "Batch 200, Loss: 0.050393, Accuracy: 95.93%\n",
      "Batch 201, Loss: 0.086943, Accuracy: 95.94%\n",
      "Batch 202, Loss: 0.064552, Accuracy: 95.95%\n",
      "Batch 203, Loss: 0.118925, Accuracy: 95.95%\n",
      "Batch 204, Loss: 0.112341, Accuracy: 95.95%\n",
      "Batch 205, Loss: 0.128084, Accuracy: 95.94%\n",
      "Batch 206, Loss: 0.181806, Accuracy: 95.93%\n",
      "Batch 207, Loss: 0.079920, Accuracy: 95.93%\n",
      "Batch 208, Loss: 0.157977, Accuracy: 95.92%\n",
      "Batch 209, Loss: 0.031245, Accuracy: 95.94%\n",
      "Batch 210, Loss: 0.083328, Accuracy: 95.95%\n",
      "Batch 211, Loss: 0.057153, Accuracy: 95.96%\n",
      "Batch 212, Loss: 0.035303, Accuracy: 95.98%\n",
      "Batch 213, Loss: 0.037838, Accuracy: 96.00%\n",
      "Training - Epoch 7, Loss: 0.131635, Accuracy: 96.00%\n",
      "Validation Batch 1, Loss: 0.126610, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.078331, Accuracy: 96.88%\n",
      "Validation Batch 3, Loss: 0.096547, Accuracy: 96.35%\n",
      "Validation Batch 4, Loss: 0.206587, Accuracy: 95.31%\n",
      "Validation Batch 5, Loss: 0.156829, Accuracy: 95.00%\n",
      "Validation Batch 6, Loss: 0.082879, Accuracy: 95.57%\n",
      "Validation Batch 7, Loss: 0.123805, Accuracy: 95.98%\n",
      "Validation Batch 8, Loss: 0.183687, Accuracy: 95.51%\n",
      "Validation Batch 9, Loss: 0.273055, Accuracy: 95.31%\n",
      "Validation Batch 10, Loss: 0.072383, Accuracy: 95.62%\n",
      "Validation Batch 11, Loss: 0.099576, Accuracy: 95.60%\n",
      "Validation Batch 12, Loss: 0.182232, Accuracy: 95.44%\n",
      "Validation Batch 13, Loss: 0.137720, Accuracy: 95.55%\n",
      "Validation Batch 14, Loss: 0.225468, Accuracy: 95.31%\n",
      "Validation Batch 15, Loss: 0.156348, Accuracy: 95.31%\n",
      "Validation Batch 16, Loss: 0.156567, Accuracy: 95.12%\n",
      "Validation Batch 17, Loss: 0.173970, Accuracy: 95.22%\n",
      "Validation Batch 18, Loss: 0.119433, Accuracy: 95.31%\n",
      "Validation Batch 19, Loss: 0.154100, Accuracy: 95.31%\n",
      "Validation Batch 20, Loss: 0.182093, Accuracy: 95.16%\n",
      "Validation Batch 21, Loss: 0.168499, Accuracy: 95.09%\n",
      "Validation Batch 22, Loss: 0.175743, Accuracy: 95.03%\n",
      "Validation Batch 23, Loss: 0.090219, Accuracy: 95.18%\n",
      "Validation Batch 24, Loss: 0.158074, Accuracy: 95.18%\n",
      "Validation Batch 25, Loss: 0.041030, Accuracy: 95.38%\n",
      "Validation Batch 26, Loss: 0.084399, Accuracy: 95.43%\n",
      "Validation Batch 27, Loss: 0.068290, Accuracy: 95.48%\n",
      "Validation - Epoch 7, Loss: 0.139795, Accuracy: 95.48%\n",
      "Patience—0\n",
      "Epoch 8\n",
      "Batch 1, Loss: 0.058486, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.035649, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.121086, Accuracy: 97.92%\n",
      "Batch 4, Loss: 0.088705, Accuracy: 97.27%\n",
      "Batch 5, Loss: 0.040614, Accuracy: 97.81%\n",
      "Batch 6, Loss: 0.042144, Accuracy: 97.92%\n",
      "Batch 7, Loss: 0.155372, Accuracy: 97.32%\n",
      "Batch 8, Loss: 0.123364, Accuracy: 97.27%\n",
      "Batch 9, Loss: 0.063501, Accuracy: 97.40%\n",
      "Batch 10, Loss: 0.230956, Accuracy: 96.88%\n",
      "Batch 11, Loss: 0.122326, Accuracy: 96.73%\n",
      "Batch 12, Loss: 0.045833, Accuracy: 97.01%\n",
      "Batch 13, Loss: 0.098243, Accuracy: 97.00%\n",
      "Batch 14, Loss: 0.165182, Accuracy: 96.99%\n",
      "Batch 15, Loss: 0.034298, Accuracy: 97.08%\n",
      "Batch 16, Loss: 0.039570, Accuracy: 97.27%\n",
      "Batch 17, Loss: 0.033980, Accuracy: 97.43%\n",
      "Batch 18, Loss: 0.186158, Accuracy: 97.22%\n",
      "Batch 19, Loss: 0.121189, Accuracy: 97.20%\n",
      "Batch 20, Loss: 0.066814, Accuracy: 97.19%\n",
      "Batch 21, Loss: 0.214338, Accuracy: 97.02%\n",
      "Batch 22, Loss: 0.043700, Accuracy: 97.09%\n",
      "Batch 23, Loss: 0.098764, Accuracy: 97.08%\n",
      "Batch 24, Loss: 0.032806, Accuracy: 97.20%\n",
      "Batch 25, Loss: 0.029737, Accuracy: 97.31%\n",
      "Batch 26, Loss: 0.037338, Accuracy: 97.42%\n",
      "Batch 27, Loss: 0.165276, Accuracy: 97.22%\n",
      "Batch 28, Loss: 0.111947, Accuracy: 97.27%\n",
      "Batch 29, Loss: 0.036395, Accuracy: 97.36%\n",
      "Batch 30, Loss: 0.021024, Accuracy: 97.45%\n",
      "Batch 31, Loss: 0.074005, Accuracy: 97.48%\n",
      "Batch 32, Loss: 0.059024, Accuracy: 97.51%\n",
      "Batch 33, Loss: 0.030144, Accuracy: 97.59%\n",
      "Batch 34, Loss: 0.041347, Accuracy: 97.66%\n",
      "Batch 35, Loss: 0.028866, Accuracy: 97.72%\n",
      "Batch 36, Loss: 0.046962, Accuracy: 97.79%\n",
      "Batch 37, Loss: 0.065720, Accuracy: 97.76%\n",
      "Batch 38, Loss: 0.040045, Accuracy: 97.82%\n",
      "Batch 39, Loss: 0.114050, Accuracy: 97.80%\n",
      "Batch 40, Loss: 0.089442, Accuracy: 97.77%\n",
      "Batch 41, Loss: 0.036183, Accuracy: 97.79%\n",
      "Batch 42, Loss: 0.132347, Accuracy: 97.73%\n",
      "Batch 43, Loss: 0.044655, Accuracy: 97.75%\n",
      "Batch 44, Loss: 0.115590, Accuracy: 97.76%\n",
      "Batch 45, Loss: 0.037436, Accuracy: 97.78%\n",
      "Batch 46, Loss: 0.019023, Accuracy: 97.83%\n",
      "Batch 47, Loss: 0.211597, Accuracy: 97.71%\n",
      "Batch 48, Loss: 0.066536, Accuracy: 97.69%\n",
      "Batch 49, Loss: 0.067708, Accuracy: 97.67%\n",
      "Batch 50, Loss: 0.025571, Accuracy: 97.72%\n",
      "Batch 51, Loss: 0.054388, Accuracy: 97.76%\n",
      "Batch 52, Loss: 0.074331, Accuracy: 97.75%\n",
      "Batch 53, Loss: 0.043151, Accuracy: 97.79%\n",
      "Batch 54, Loss: 0.133953, Accuracy: 97.80%\n",
      "Batch 55, Loss: 0.041521, Accuracy: 97.84%\n",
      "Batch 56, Loss: 0.073772, Accuracy: 97.82%\n",
      "Batch 57, Loss: 0.063653, Accuracy: 97.78%\n",
      "Batch 58, Loss: 0.124513, Accuracy: 97.71%\n",
      "Batch 59, Loss: 0.025563, Accuracy: 97.75%\n",
      "Batch 60, Loss: 0.091893, Accuracy: 97.76%\n",
      "Batch 61, Loss: 0.108799, Accuracy: 97.75%\n",
      "Batch 62, Loss: 0.049602, Accuracy: 97.76%\n",
      "Batch 63, Loss: 0.065617, Accuracy: 97.77%\n",
      "Batch 64, Loss: 0.149711, Accuracy: 97.75%\n",
      "Batch 65, Loss: 0.090252, Accuracy: 97.74%\n",
      "Batch 66, Loss: 0.034126, Accuracy: 97.75%\n",
      "Batch 67, Loss: 0.037318, Accuracy: 97.76%\n",
      "Batch 68, Loss: 0.084124, Accuracy: 97.77%\n",
      "Batch 69, Loss: 0.067368, Accuracy: 97.78%\n",
      "Batch 70, Loss: 0.077235, Accuracy: 97.77%\n",
      "Batch 71, Loss: 0.196442, Accuracy: 97.71%\n",
      "Batch 72, Loss: 0.047095, Accuracy: 97.72%\n",
      "Batch 73, Loss: 0.156818, Accuracy: 97.69%\n",
      "Batch 74, Loss: 0.143290, Accuracy: 97.64%\n",
      "Batch 75, Loss: 0.220696, Accuracy: 97.56%\n",
      "Batch 76, Loss: 0.097413, Accuracy: 97.55%\n",
      "Batch 77, Loss: 0.073310, Accuracy: 97.56%\n",
      "Batch 78, Loss: 0.109761, Accuracy: 97.54%\n",
      "Batch 79, Loss: 0.131165, Accuracy: 97.51%\n",
      "Batch 80, Loss: 0.182075, Accuracy: 97.46%\n",
      "Batch 81, Loss: 0.136653, Accuracy: 97.45%\n",
      "Batch 82, Loss: 0.156203, Accuracy: 97.41%\n",
      "Batch 83, Loss: 0.098531, Accuracy: 97.40%\n",
      "Batch 84, Loss: 0.188180, Accuracy: 97.36%\n",
      "Batch 85, Loss: 0.198447, Accuracy: 97.35%\n",
      "Batch 86, Loss: 0.132934, Accuracy: 97.35%\n",
      "Batch 87, Loss: 0.299314, Accuracy: 97.27%\n",
      "Batch 88, Loss: 0.045290, Accuracy: 97.28%\n",
      "Batch 89, Loss: 0.207402, Accuracy: 97.23%\n",
      "Batch 90, Loss: 0.169535, Accuracy: 97.17%\n",
      "Batch 91, Loss: 0.252435, Accuracy: 97.13%\n",
      "Batch 92, Loss: 0.262771, Accuracy: 97.08%\n",
      "Batch 93, Loss: 0.071111, Accuracy: 97.11%\n",
      "Batch 94, Loss: 0.184492, Accuracy: 97.04%\n",
      "Batch 95, Loss: 0.038328, Accuracy: 97.07%\n",
      "Batch 96, Loss: 0.104029, Accuracy: 97.05%\n",
      "Batch 97, Loss: 0.190461, Accuracy: 97.02%\n",
      "Batch 98, Loss: 0.204105, Accuracy: 96.95%\n",
      "Batch 99, Loss: 0.216110, Accuracy: 96.91%\n",
      "Batch 100, Loss: 0.155030, Accuracy: 96.88%\n",
      "Batch 101, Loss: 0.144061, Accuracy: 96.88%\n",
      "Batch 102, Loss: 0.220486, Accuracy: 96.84%\n",
      "Batch 103, Loss: 0.143407, Accuracy: 96.84%\n",
      "Batch 104, Loss: 0.215581, Accuracy: 96.80%\n",
      "Batch 105, Loss: 0.222086, Accuracy: 96.76%\n",
      "Batch 106, Loss: 0.291742, Accuracy: 96.70%\n",
      "Batch 107, Loss: 0.130916, Accuracy: 96.69%\n",
      "Batch 108, Loss: 0.213176, Accuracy: 96.64%\n",
      "Batch 109, Loss: 0.130579, Accuracy: 96.62%\n",
      "Batch 110, Loss: 0.133984, Accuracy: 96.62%\n",
      "Batch 111, Loss: 0.058936, Accuracy: 96.64%\n",
      "Batch 112, Loss: 0.073633, Accuracy: 96.65%\n",
      "Batch 113, Loss: 0.111172, Accuracy: 96.64%\n",
      "Batch 114, Loss: 0.085492, Accuracy: 96.66%\n",
      "Batch 115, Loss: 0.196405, Accuracy: 96.64%\n",
      "Batch 116, Loss: 0.068085, Accuracy: 96.66%\n",
      "Batch 117, Loss: 0.067425, Accuracy: 96.67%\n",
      "Batch 118, Loss: 0.121532, Accuracy: 96.68%\n",
      "Batch 119, Loss: 0.063030, Accuracy: 96.70%\n",
      "Batch 120, Loss: 0.080585, Accuracy: 96.71%\n",
      "Batch 121, Loss: 0.090346, Accuracy: 96.71%\n",
      "Batch 122, Loss: 0.145334, Accuracy: 96.68%\n",
      "Batch 123, Loss: 0.246078, Accuracy: 96.65%\n",
      "Batch 124, Loss: 0.089615, Accuracy: 96.65%\n",
      "Batch 125, Loss: 0.196204, Accuracy: 96.62%\n",
      "Batch 126, Loss: 0.114901, Accuracy: 96.61%\n",
      "Batch 127, Loss: 0.139165, Accuracy: 96.60%\n",
      "Batch 128, Loss: 0.043688, Accuracy: 96.63%\n",
      "Batch 129, Loss: 0.161785, Accuracy: 96.62%\n",
      "Batch 130, Loss: 0.236902, Accuracy: 96.59%\n",
      "Batch 131, Loss: 0.069898, Accuracy: 96.59%\n",
      "Batch 132, Loss: 0.107746, Accuracy: 96.58%\n",
      "Batch 133, Loss: 0.040971, Accuracy: 96.59%\n",
      "Batch 134, Loss: 0.037141, Accuracy: 96.62%\n",
      "Batch 135, Loss: 0.097084, Accuracy: 96.62%\n",
      "Batch 136, Loss: 0.241447, Accuracy: 96.59%\n",
      "Batch 137, Loss: 0.145001, Accuracy: 96.58%\n",
      "Batch 138, Loss: 0.108958, Accuracy: 96.58%\n",
      "Batch 139, Loss: 0.201934, Accuracy: 96.56%\n",
      "Batch 140, Loss: 0.098051, Accuracy: 96.56%\n",
      "Batch 141, Loss: 0.176097, Accuracy: 96.52%\n",
      "Batch 142, Loss: 0.204192, Accuracy: 96.48%\n",
      "Batch 143, Loss: 0.114283, Accuracy: 96.49%\n",
      "Batch 144, Loss: 0.101305, Accuracy: 96.48%\n",
      "Batch 145, Loss: 0.215556, Accuracy: 96.47%\n",
      "Batch 146, Loss: 0.071016, Accuracy: 96.49%\n",
      "Batch 147, Loss: 0.146324, Accuracy: 96.49%\n",
      "Batch 148, Loss: 0.050041, Accuracy: 96.52%\n",
      "Batch 149, Loss: 0.157843, Accuracy: 96.50%\n",
      "Batch 150, Loss: 0.052433, Accuracy: 96.51%\n",
      "Batch 151, Loss: 0.082736, Accuracy: 96.51%\n",
      "Batch 152, Loss: 0.183090, Accuracy: 96.49%\n",
      "Batch 153, Loss: 0.093058, Accuracy: 96.51%\n",
      "Batch 154, Loss: 0.123843, Accuracy: 96.51%\n",
      "Batch 155, Loss: 0.090523, Accuracy: 96.51%\n",
      "Batch 156, Loss: 0.072174, Accuracy: 96.52%\n",
      "Batch 157, Loss: 0.128376, Accuracy: 96.52%\n",
      "Batch 158, Loss: 0.048169, Accuracy: 96.52%\n",
      "Batch 159, Loss: 0.084949, Accuracy: 96.53%\n",
      "Batch 160, Loss: 0.087688, Accuracy: 96.54%\n",
      "Batch 161, Loss: 0.111628, Accuracy: 96.54%\n",
      "Batch 162, Loss: 0.047919, Accuracy: 96.55%\n",
      "Batch 163, Loss: 0.030485, Accuracy: 96.57%\n",
      "Batch 164, Loss: 0.073244, Accuracy: 96.58%\n",
      "Batch 165, Loss: 0.105794, Accuracy: 96.57%\n",
      "Batch 166, Loss: 0.050776, Accuracy: 96.58%\n",
      "Batch 167, Loss: 0.153177, Accuracy: 96.58%\n",
      "Batch 168, Loss: 0.072453, Accuracy: 96.58%\n",
      "Batch 169, Loss: 0.177736, Accuracy: 96.54%\n",
      "Batch 170, Loss: 0.111362, Accuracy: 96.54%\n",
      "Batch 171, Loss: 0.227706, Accuracy: 96.52%\n",
      "Batch 172, Loss: 0.218350, Accuracy: 96.50%\n",
      "Batch 173, Loss: 0.108845, Accuracy: 96.50%\n",
      "Batch 174, Loss: 0.138323, Accuracy: 96.49%\n",
      "Batch 175, Loss: 0.081440, Accuracy: 96.50%\n",
      "Batch 176, Loss: 0.159577, Accuracy: 96.48%\n",
      "Batch 177, Loss: 0.090550, Accuracy: 96.48%\n",
      "Batch 178, Loss: 0.057897, Accuracy: 96.48%\n",
      "Batch 179, Loss: 0.107042, Accuracy: 96.48%\n",
      "Batch 180, Loss: 0.049088, Accuracy: 96.49%\n",
      "Batch 181, Loss: 0.253309, Accuracy: 96.48%\n",
      "Batch 182, Loss: 0.090379, Accuracy: 96.48%\n",
      "Batch 183, Loss: 0.083484, Accuracy: 96.49%\n",
      "Batch 184, Loss: 0.040465, Accuracy: 96.51%\n",
      "Batch 185, Loss: 0.098111, Accuracy: 96.51%\n",
      "Batch 186, Loss: 0.137477, Accuracy: 96.50%\n",
      "Batch 187, Loss: 0.072171, Accuracy: 96.50%\n",
      "Batch 188, Loss: 0.080713, Accuracy: 96.51%\n",
      "Batch 189, Loss: 0.069961, Accuracy: 96.52%\n",
      "Batch 190, Loss: 0.070527, Accuracy: 96.53%\n",
      "Batch 191, Loss: 0.071074, Accuracy: 96.54%\n",
      "Batch 192, Loss: 0.085117, Accuracy: 96.54%\n",
      "Batch 193, Loss: 0.029087, Accuracy: 96.56%\n",
      "Batch 194, Loss: 0.278555, Accuracy: 96.52%\n",
      "Batch 195, Loss: 0.082215, Accuracy: 96.53%\n",
      "Batch 196, Loss: 0.098296, Accuracy: 96.52%\n",
      "Batch 197, Loss: 0.095450, Accuracy: 96.52%\n",
      "Batch 198, Loss: 0.128376, Accuracy: 96.53%\n",
      "Batch 199, Loss: 0.085307, Accuracy: 96.54%\n",
      "Batch 200, Loss: 0.110194, Accuracy: 96.53%\n",
      "Batch 201, Loss: 0.084238, Accuracy: 96.53%\n",
      "Batch 202, Loss: 0.099291, Accuracy: 96.53%\n",
      "Batch 203, Loss: 0.074090, Accuracy: 96.53%\n",
      "Batch 204, Loss: 0.164997, Accuracy: 96.52%\n",
      "Batch 205, Loss: 0.100125, Accuracy: 96.52%\n",
      "Batch 206, Loss: 0.067451, Accuracy: 96.53%\n",
      "Batch 207, Loss: 0.038619, Accuracy: 96.54%\n",
      "Batch 208, Loss: 0.048329, Accuracy: 96.55%\n",
      "Batch 209, Loss: 0.227850, Accuracy: 96.53%\n",
      "Batch 210, Loss: 0.111099, Accuracy: 96.53%\n",
      "Batch 211, Loss: 0.047907, Accuracy: 96.54%\n",
      "Batch 212, Loss: 0.101079, Accuracy: 96.54%\n",
      "Batch 213, Loss: 0.077115, Accuracy: 96.54%\n",
      "Training - Epoch 8, Loss: 0.109462, Accuracy: 96.54%\n",
      "Validation Batch 1, Loss: 0.136893, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.118494, Accuracy: 96.09%\n",
      "Validation Batch 3, Loss: 0.088117, Accuracy: 96.35%\n",
      "Validation Batch 4, Loss: 0.113187, Accuracy: 96.09%\n",
      "Validation Batch 5, Loss: 0.156832, Accuracy: 95.31%\n",
      "Validation Batch 6, Loss: 0.106091, Accuracy: 95.31%\n",
      "Validation Batch 7, Loss: 0.031641, Accuracy: 95.98%\n",
      "Validation Batch 8, Loss: 0.188561, Accuracy: 95.70%\n",
      "Validation Batch 9, Loss: 0.185382, Accuracy: 95.66%\n",
      "Validation Batch 10, Loss: 0.023320, Accuracy: 96.09%\n",
      "Validation Batch 11, Loss: 0.050502, Accuracy: 96.31%\n",
      "Validation Batch 12, Loss: 0.133408, Accuracy: 96.35%\n",
      "Validation Batch 13, Loss: 0.152191, Accuracy: 96.15%\n",
      "Validation Batch 14, Loss: 0.156746, Accuracy: 95.98%\n",
      "Validation Batch 15, Loss: 0.110180, Accuracy: 96.04%\n",
      "Validation Batch 16, Loss: 0.117004, Accuracy: 96.09%\n",
      "Validation Batch 17, Loss: 0.109237, Accuracy: 96.05%\n",
      "Validation Batch 18, Loss: 0.048118, Accuracy: 96.18%\n",
      "Validation Batch 19, Loss: 0.037336, Accuracy: 96.30%\n",
      "Validation Batch 20, Loss: 0.031551, Accuracy: 96.41%\n",
      "Validation Batch 21, Loss: 0.084602, Accuracy: 96.35%\n",
      "Validation Batch 22, Loss: 0.183024, Accuracy: 96.09%\n",
      "Validation Batch 23, Loss: 0.060437, Accuracy: 96.20%\n",
      "Validation Batch 24, Loss: 0.107090, Accuracy: 96.22%\n",
      "Validation Batch 25, Loss: 0.092981, Accuracy: 96.19%\n",
      "Validation Batch 26, Loss: 0.054160, Accuracy: 96.27%\n",
      "Validation Batch 27, Loss: 0.114803, Accuracy: 96.24%\n",
      "Validation - Epoch 8, Loss: 0.103403, Accuracy: 96.24%\n",
      "Patience—0\n",
      "Epoch 9\n",
      "Batch 1, Loss: 0.031980, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.027137, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.115752, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.041386, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.097538, Accuracy: 99.06%\n",
      "Batch 6, Loss: 0.122474, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.083430, Accuracy: 98.66%\n",
      "Batch 8, Loss: 0.114308, Accuracy: 98.24%\n",
      "Batch 9, Loss: 0.150709, Accuracy: 97.74%\n",
      "Batch 10, Loss: 0.020192, Accuracy: 97.97%\n",
      "Batch 11, Loss: 0.045062, Accuracy: 98.01%\n",
      "Batch 12, Loss: 0.079758, Accuracy: 98.05%\n",
      "Batch 13, Loss: 0.073193, Accuracy: 97.96%\n",
      "Batch 14, Loss: 0.079158, Accuracy: 97.88%\n",
      "Batch 15, Loss: 0.028723, Accuracy: 98.02%\n",
      "Batch 16, Loss: 0.048301, Accuracy: 97.95%\n",
      "Batch 17, Loss: 0.073455, Accuracy: 97.89%\n",
      "Batch 18, Loss: 0.037952, Accuracy: 98.00%\n",
      "Batch 19, Loss: 0.037369, Accuracy: 98.03%\n",
      "Batch 20, Loss: 0.106769, Accuracy: 97.89%\n",
      "Batch 21, Loss: 0.021038, Accuracy: 97.99%\n",
      "Batch 22, Loss: 0.017648, Accuracy: 98.08%\n",
      "Batch 23, Loss: 0.045586, Accuracy: 98.17%\n",
      "Batch 24, Loss: 0.034719, Accuracy: 98.24%\n",
      "Batch 25, Loss: 0.026505, Accuracy: 98.31%\n",
      "Batch 26, Loss: 0.044287, Accuracy: 98.32%\n",
      "Batch 27, Loss: 0.022334, Accuracy: 98.38%\n",
      "Batch 28, Loss: 0.034293, Accuracy: 98.38%\n",
      "Batch 29, Loss: 0.034250, Accuracy: 98.38%\n",
      "Batch 30, Loss: 0.158799, Accuracy: 98.28%\n",
      "Batch 31, Loss: 0.061434, Accuracy: 98.29%\n",
      "Batch 32, Loss: 0.036240, Accuracy: 98.34%\n",
      "Batch 33, Loss: 0.036877, Accuracy: 98.34%\n",
      "Batch 34, Loss: 0.020491, Accuracy: 98.39%\n",
      "Batch 35, Loss: 0.160560, Accuracy: 98.35%\n",
      "Batch 36, Loss: 0.070902, Accuracy: 98.31%\n",
      "Batch 37, Loss: 0.079623, Accuracy: 98.31%\n",
      "Batch 38, Loss: 0.023106, Accuracy: 98.36%\n",
      "Batch 39, Loss: 0.070132, Accuracy: 98.32%\n",
      "Batch 40, Loss: 0.025037, Accuracy: 98.36%\n",
      "Batch 41, Loss: 0.041778, Accuracy: 98.36%\n",
      "Batch 42, Loss: 0.064429, Accuracy: 98.33%\n",
      "Batch 43, Loss: 0.115481, Accuracy: 98.33%\n",
      "Batch 44, Loss: 0.099013, Accuracy: 98.33%\n",
      "Batch 45, Loss: 0.052895, Accuracy: 98.33%\n",
      "Batch 46, Loss: 0.087494, Accuracy: 98.34%\n",
      "Batch 47, Loss: 0.085228, Accuracy: 98.27%\n",
      "Batch 48, Loss: 0.016808, Accuracy: 98.31%\n",
      "Batch 49, Loss: 0.021067, Accuracy: 98.34%\n",
      "Batch 50, Loss: 0.174559, Accuracy: 98.28%\n",
      "Batch 51, Loss: 0.040796, Accuracy: 98.28%\n",
      "Batch 52, Loss: 0.066987, Accuracy: 98.26%\n",
      "Batch 53, Loss: 0.035563, Accuracy: 98.29%\n",
      "Batch 54, Loss: 0.025500, Accuracy: 98.32%\n",
      "Batch 55, Loss: 0.051489, Accuracy: 98.32%\n",
      "Batch 56, Loss: 0.063726, Accuracy: 98.33%\n",
      "Batch 57, Loss: 0.101639, Accuracy: 98.33%\n",
      "Batch 58, Loss: 0.200034, Accuracy: 98.28%\n",
      "Batch 59, Loss: 0.093012, Accuracy: 98.25%\n",
      "Batch 60, Loss: 0.059151, Accuracy: 98.26%\n",
      "Batch 61, Loss: 0.036979, Accuracy: 98.26%\n",
      "Batch 62, Loss: 0.069787, Accuracy: 98.26%\n",
      "Batch 63, Loss: 0.053300, Accuracy: 98.26%\n",
      "Batch 64, Loss: 0.081679, Accuracy: 98.27%\n",
      "Batch 65, Loss: 0.018246, Accuracy: 98.29%\n",
      "Batch 66, Loss: 0.034106, Accuracy: 98.32%\n",
      "Batch 67, Loss: 0.157020, Accuracy: 98.23%\n",
      "Batch 68, Loss: 0.055074, Accuracy: 98.23%\n",
      "Batch 69, Loss: 0.085201, Accuracy: 98.21%\n",
      "Batch 70, Loss: 0.050943, Accuracy: 98.21%\n",
      "Batch 71, Loss: 0.079605, Accuracy: 98.22%\n",
      "Batch 72, Loss: 0.031621, Accuracy: 98.22%\n",
      "Batch 73, Loss: 0.049775, Accuracy: 98.20%\n",
      "Batch 74, Loss: 0.022345, Accuracy: 98.23%\n",
      "Batch 75, Loss: 0.090263, Accuracy: 98.23%\n",
      "Batch 76, Loss: 0.022218, Accuracy: 98.25%\n",
      "Batch 77, Loss: 0.122141, Accuracy: 98.25%\n",
      "Batch 78, Loss: 0.056227, Accuracy: 98.24%\n",
      "Batch 79, Loss: 0.101098, Accuracy: 98.20%\n",
      "Batch 80, Loss: 0.049532, Accuracy: 98.20%\n",
      "Batch 81, Loss: 0.024989, Accuracy: 98.23%\n",
      "Batch 82, Loss: 0.114977, Accuracy: 98.23%\n",
      "Batch 83, Loss: 0.080517, Accuracy: 98.23%\n",
      "Batch 84, Loss: 0.029611, Accuracy: 98.25%\n",
      "Batch 85, Loss: 0.067342, Accuracy: 98.25%\n",
      "Batch 86, Loss: 0.041049, Accuracy: 98.26%\n",
      "Batch 87, Loss: 0.098117, Accuracy: 98.22%\n",
      "Batch 88, Loss: 0.101903, Accuracy: 98.21%\n",
      "Batch 89, Loss: 0.017322, Accuracy: 98.23%\n",
      "Batch 90, Loss: 0.031703, Accuracy: 98.25%\n",
      "Batch 91, Loss: 0.048138, Accuracy: 98.25%\n",
      "Batch 92, Loss: 0.176641, Accuracy: 98.22%\n",
      "Batch 93, Loss: 0.022494, Accuracy: 98.24%\n",
      "Batch 94, Loss: 0.090687, Accuracy: 98.19%\n",
      "Batch 95, Loss: 0.021203, Accuracy: 98.21%\n",
      "Batch 96, Loss: 0.191464, Accuracy: 98.18%\n",
      "Batch 97, Loss: 0.044772, Accuracy: 98.18%\n",
      "Batch 98, Loss: 0.156592, Accuracy: 98.13%\n",
      "Batch 99, Loss: 0.093116, Accuracy: 98.12%\n",
      "Batch 100, Loss: 0.056512, Accuracy: 98.12%\n",
      "Batch 101, Loss: 0.083377, Accuracy: 98.10%\n",
      "Batch 102, Loss: 0.050478, Accuracy: 98.12%\n",
      "Batch 103, Loss: 0.043293, Accuracy: 98.13%\n",
      "Batch 104, Loss: 0.029484, Accuracy: 98.15%\n",
      "Batch 105, Loss: 0.056090, Accuracy: 98.15%\n",
      "Batch 106, Loss: 0.043495, Accuracy: 98.16%\n",
      "Batch 107, Loss: 0.132319, Accuracy: 98.15%\n",
      "Batch 108, Loss: 0.065810, Accuracy: 98.15%\n",
      "Batch 109, Loss: 0.116775, Accuracy: 98.12%\n",
      "Batch 110, Loss: 0.143236, Accuracy: 98.10%\n",
      "Batch 111, Loss: 0.041425, Accuracy: 98.10%\n",
      "Batch 112, Loss: 0.033471, Accuracy: 98.12%\n",
      "Batch 113, Loss: 0.095189, Accuracy: 98.12%\n",
      "Batch 114, Loss: 0.030838, Accuracy: 98.14%\n",
      "Batch 115, Loss: 0.068316, Accuracy: 98.14%\n",
      "Batch 116, Loss: 0.168416, Accuracy: 98.11%\n",
      "Batch 117, Loss: 0.092471, Accuracy: 98.10%\n",
      "Batch 118, Loss: 0.026204, Accuracy: 98.12%\n",
      "Batch 119, Loss: 0.235027, Accuracy: 98.07%\n",
      "Batch 120, Loss: 0.136544, Accuracy: 98.05%\n",
      "Batch 121, Loss: 0.034291, Accuracy: 98.06%\n",
      "Batch 122, Loss: 0.030791, Accuracy: 98.08%\n",
      "Batch 123, Loss: 0.066190, Accuracy: 98.07%\n",
      "Batch 124, Loss: 0.047042, Accuracy: 98.07%\n",
      "Batch 125, Loss: 0.127387, Accuracy: 98.06%\n",
      "Batch 126, Loss: 0.050164, Accuracy: 98.07%\n",
      "Batch 127, Loss: 0.144934, Accuracy: 98.04%\n",
      "Batch 128, Loss: 0.032921, Accuracy: 98.06%\n",
      "Batch 129, Loss: 0.049623, Accuracy: 98.06%\n",
      "Batch 130, Loss: 0.113672, Accuracy: 98.04%\n",
      "Batch 131, Loss: 0.031855, Accuracy: 98.04%\n",
      "Batch 132, Loss: 0.036617, Accuracy: 98.06%\n",
      "Batch 133, Loss: 0.076227, Accuracy: 98.05%\n",
      "Batch 134, Loss: 0.109961, Accuracy: 98.03%\n",
      "Batch 135, Loss: 0.047080, Accuracy: 98.03%\n",
      "Batch 136, Loss: 0.101824, Accuracy: 98.04%\n",
      "Batch 137, Loss: 0.118654, Accuracy: 98.02%\n",
      "Batch 138, Loss: 0.085498, Accuracy: 98.01%\n",
      "Batch 139, Loss: 0.074663, Accuracy: 98.01%\n",
      "Batch 140, Loss: 0.067303, Accuracy: 98.00%\n",
      "Batch 141, Loss: 0.076343, Accuracy: 97.99%\n",
      "Batch 142, Loss: 0.166012, Accuracy: 97.96%\n",
      "Batch 143, Loss: 0.075137, Accuracy: 97.97%\n",
      "Batch 144, Loss: 0.024063, Accuracy: 97.98%\n",
      "Batch 145, Loss: 0.025890, Accuracy: 98.00%\n",
      "Batch 146, Loss: 0.137326, Accuracy: 97.98%\n",
      "Batch 147, Loss: 0.035853, Accuracy: 97.99%\n",
      "Batch 148, Loss: 0.161312, Accuracy: 97.98%\n",
      "Batch 149, Loss: 0.114235, Accuracy: 97.98%\n",
      "Batch 150, Loss: 0.109364, Accuracy: 97.98%\n",
      "Batch 151, Loss: 0.052734, Accuracy: 97.97%\n",
      "Batch 152, Loss: 0.052678, Accuracy: 97.97%\n",
      "Batch 153, Loss: 0.100112, Accuracy: 97.97%\n",
      "Batch 154, Loss: 0.189900, Accuracy: 97.94%\n",
      "Batch 155, Loss: 0.052707, Accuracy: 97.94%\n",
      "Batch 156, Loss: 0.039195, Accuracy: 97.96%\n",
      "Batch 157, Loss: 0.018765, Accuracy: 97.97%\n",
      "Batch 158, Loss: 0.263591, Accuracy: 97.94%\n",
      "Batch 159, Loss: 0.244515, Accuracy: 97.92%\n",
      "Batch 160, Loss: 0.117959, Accuracy: 97.90%\n",
      "Batch 161, Loss: 0.150156, Accuracy: 97.88%\n",
      "Batch 162, Loss: 0.148642, Accuracy: 97.86%\n",
      "Batch 163, Loss: 0.076248, Accuracy: 97.84%\n",
      "Batch 164, Loss: 0.048145, Accuracy: 97.85%\n",
      "Batch 165, Loss: 0.048994, Accuracy: 97.85%\n",
      "Batch 166, Loss: 0.039838, Accuracy: 97.85%\n",
      "Batch 167, Loss: 0.111400, Accuracy: 97.85%\n",
      "Batch 168, Loss: 0.135059, Accuracy: 97.84%\n",
      "Batch 169, Loss: 0.137936, Accuracy: 97.83%\n",
      "Batch 170, Loss: 0.165771, Accuracy: 97.81%\n",
      "Batch 171, Loss: 0.017554, Accuracy: 97.83%\n",
      "Batch 172, Loss: 0.031632, Accuracy: 97.83%\n",
      "Batch 173, Loss: 0.152941, Accuracy: 97.81%\n",
      "Batch 174, Loss: 0.018926, Accuracy: 97.83%\n",
      "Batch 175, Loss: 0.130729, Accuracy: 97.82%\n",
      "Batch 176, Loss: 0.148967, Accuracy: 97.82%\n",
      "Batch 177, Loss: 0.050304, Accuracy: 97.83%\n",
      "Batch 178, Loss: 0.092761, Accuracy: 97.81%\n",
      "Batch 179, Loss: 0.033244, Accuracy: 97.82%\n",
      "Batch 180, Loss: 0.024700, Accuracy: 97.83%\n",
      "Batch 181, Loss: 0.034924, Accuracy: 97.83%\n",
      "Batch 182, Loss: 0.019584, Accuracy: 97.85%\n",
      "Batch 183, Loss: 0.079381, Accuracy: 97.85%\n",
      "Batch 184, Loss: 0.045525, Accuracy: 97.85%\n",
      "Batch 185, Loss: 0.015815, Accuracy: 97.86%\n",
      "Batch 186, Loss: 0.046492, Accuracy: 97.87%\n",
      "Batch 187, Loss: 0.063205, Accuracy: 97.86%\n",
      "Batch 188, Loss: 0.018083, Accuracy: 97.87%\n",
      "Batch 189, Loss: 0.093401, Accuracy: 97.87%\n",
      "Batch 190, Loss: 0.045513, Accuracy: 97.88%\n",
      "Batch 191, Loss: 0.060481, Accuracy: 97.88%\n",
      "Batch 192, Loss: 0.039424, Accuracy: 97.88%\n",
      "Batch 193, Loss: 0.026470, Accuracy: 97.90%\n",
      "Batch 194, Loss: 0.138782, Accuracy: 97.89%\n",
      "Batch 195, Loss: 0.030938, Accuracy: 97.90%\n",
      "Batch 196, Loss: 0.101563, Accuracy: 97.90%\n",
      "Batch 197, Loss: 0.045846, Accuracy: 97.90%\n",
      "Batch 198, Loss: 0.085185, Accuracy: 97.90%\n",
      "Batch 199, Loss: 0.164402, Accuracy: 97.89%\n",
      "Batch 200, Loss: 0.073252, Accuracy: 97.88%\n",
      "Batch 201, Loss: 0.102541, Accuracy: 97.88%\n",
      "Batch 202, Loss: 0.162986, Accuracy: 97.87%\n",
      "Batch 203, Loss: 0.039513, Accuracy: 97.87%\n",
      "Batch 204, Loss: 0.098863, Accuracy: 97.87%\n",
      "Batch 205, Loss: 0.072858, Accuracy: 97.87%\n",
      "Batch 206, Loss: 0.073016, Accuracy: 97.86%\n",
      "Batch 207, Loss: 0.079953, Accuracy: 97.86%\n",
      "Batch 208, Loss: 0.026702, Accuracy: 97.87%\n",
      "Batch 209, Loss: 0.186011, Accuracy: 97.87%\n",
      "Batch 210, Loss: 0.107873, Accuracy: 97.86%\n",
      "Batch 211, Loss: 0.069723, Accuracy: 97.86%\n",
      "Batch 212, Loss: 0.039046, Accuracy: 97.86%\n",
      "Batch 213, Loss: 0.090977, Accuracy: 97.87%\n",
      "Training - Epoch 9, Loss: 0.075354, Accuracy: 97.87%\n",
      "Validation Batch 1, Loss: 0.079024, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.145217, Accuracy: 95.31%\n",
      "Validation Batch 3, Loss: 0.104199, Accuracy: 95.31%\n",
      "Validation Batch 4, Loss: 0.106231, Accuracy: 95.70%\n",
      "Validation Batch 5, Loss: 0.141715, Accuracy: 95.94%\n",
      "Validation Batch 6, Loss: 0.011974, Accuracy: 96.61%\n",
      "Validation Batch 7, Loss: 0.117738, Accuracy: 96.65%\n",
      "Validation Batch 8, Loss: 0.059510, Accuracy: 96.68%\n",
      "Validation Batch 9, Loss: 0.334385, Accuracy: 95.83%\n",
      "Validation Batch 10, Loss: 0.069409, Accuracy: 96.09%\n",
      "Validation Batch 11, Loss: 0.197911, Accuracy: 95.88%\n",
      "Validation Batch 12, Loss: 0.122057, Accuracy: 95.96%\n",
      "Validation Batch 13, Loss: 0.167882, Accuracy: 95.79%\n",
      "Validation Batch 14, Loss: 0.210020, Accuracy: 95.65%\n",
      "Validation Batch 15, Loss: 0.118942, Accuracy: 95.62%\n",
      "Validation Batch 16, Loss: 0.160852, Accuracy: 95.70%\n",
      "Validation Batch 17, Loss: 0.134900, Accuracy: 95.68%\n",
      "Validation Batch 18, Loss: 0.103271, Accuracy: 95.83%\n",
      "Validation Batch 19, Loss: 0.101701, Accuracy: 95.81%\n",
      "Validation Batch 20, Loss: 0.224458, Accuracy: 95.70%\n",
      "Validation Batch 21, Loss: 0.097643, Accuracy: 95.83%\n",
      "Validation Batch 22, Loss: 0.140516, Accuracy: 95.74%\n",
      "Validation Batch 23, Loss: 0.108133, Accuracy: 95.79%\n",
      "Validation Batch 24, Loss: 0.158411, Accuracy: 95.83%\n",
      "Validation Batch 25, Loss: 0.017346, Accuracy: 96.00%\n",
      "Validation Batch 26, Loss: 0.044431, Accuracy: 96.09%\n",
      "Validation Batch 27, Loss: 0.013748, Accuracy: 96.18%\n",
      "Validation - Epoch 9, Loss: 0.121912, Accuracy: 96.18%\n",
      "Patience—1\n",
      "Epoch 10\n",
      "Batch 1, Loss: 0.073236, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.015672, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.157044, Accuracy: 96.88%\n",
      "Batch 4, Loss: 0.068590, Accuracy: 96.88%\n",
      "Batch 5, Loss: 0.185201, Accuracy: 95.62%\n",
      "Batch 6, Loss: 0.051614, Accuracy: 95.83%\n",
      "Batch 7, Loss: 0.270399, Accuracy: 95.54%\n",
      "Batch 8, Loss: 0.210876, Accuracy: 94.92%\n",
      "Batch 9, Loss: 0.035317, Accuracy: 95.31%\n",
      "Batch 10, Loss: 0.084099, Accuracy: 95.62%\n",
      "Batch 11, Loss: 0.120380, Accuracy: 95.45%\n",
      "Batch 12, Loss: 0.073133, Accuracy: 95.57%\n",
      "Batch 13, Loss: 0.023553, Accuracy: 95.91%\n",
      "Batch 14, Loss: 0.081697, Accuracy: 95.98%\n",
      "Batch 15, Loss: 0.057132, Accuracy: 96.04%\n",
      "Batch 16, Loss: 0.130041, Accuracy: 96.00%\n",
      "Batch 17, Loss: 0.087152, Accuracy: 95.96%\n",
      "Batch 18, Loss: 0.054795, Accuracy: 96.09%\n",
      "Batch 19, Loss: 0.053419, Accuracy: 96.30%\n",
      "Batch 20, Loss: 0.126145, Accuracy: 96.33%\n",
      "Batch 21, Loss: 0.029795, Accuracy: 96.50%\n",
      "Batch 22, Loss: 0.068903, Accuracy: 96.52%\n",
      "Batch 23, Loss: 0.019146, Accuracy: 96.67%\n",
      "Batch 24, Loss: 0.047957, Accuracy: 96.74%\n",
      "Batch 25, Loss: 0.036596, Accuracy: 96.88%\n",
      "Batch 26, Loss: 0.133230, Accuracy: 96.88%\n",
      "Batch 27, Loss: 0.049420, Accuracy: 96.93%\n",
      "Batch 28, Loss: 0.106623, Accuracy: 96.93%\n",
      "Batch 29, Loss: 0.093495, Accuracy: 96.93%\n",
      "Batch 30, Loss: 0.108762, Accuracy: 96.88%\n",
      "Batch 31, Loss: 0.058603, Accuracy: 96.88%\n",
      "Batch 32, Loss: 0.154841, Accuracy: 96.88%\n",
      "Batch 33, Loss: 0.074325, Accuracy: 96.92%\n",
      "Batch 34, Loss: 0.045889, Accuracy: 96.97%\n",
      "Batch 35, Loss: 0.105120, Accuracy: 97.01%\n",
      "Batch 36, Loss: 0.041582, Accuracy: 97.05%\n",
      "Batch 37, Loss: 0.074394, Accuracy: 97.09%\n",
      "Batch 38, Loss: 0.109271, Accuracy: 97.08%\n",
      "Batch 39, Loss: 0.024133, Accuracy: 97.16%\n",
      "Batch 40, Loss: 0.065780, Accuracy: 97.19%\n",
      "Batch 41, Loss: 0.055413, Accuracy: 97.22%\n",
      "Batch 42, Loss: 0.088744, Accuracy: 97.21%\n",
      "Batch 43, Loss: 0.027953, Accuracy: 97.27%\n",
      "Batch 44, Loss: 0.173086, Accuracy: 97.19%\n",
      "Batch 45, Loss: 0.023475, Accuracy: 97.26%\n",
      "Batch 46, Loss: 0.114429, Accuracy: 97.25%\n",
      "Batch 47, Loss: 0.022812, Accuracy: 97.31%\n",
      "Batch 48, Loss: 0.130367, Accuracy: 97.23%\n",
      "Batch 49, Loss: 0.061732, Accuracy: 97.23%\n",
      "Batch 50, Loss: 0.147800, Accuracy: 97.22%\n",
      "Batch 51, Loss: 0.230717, Accuracy: 97.15%\n",
      "Batch 52, Loss: 0.022408, Accuracy: 97.21%\n",
      "Batch 53, Loss: 0.052525, Accuracy: 97.23%\n",
      "Batch 54, Loss: 0.026348, Accuracy: 97.28%\n",
      "Batch 55, Loss: 0.064616, Accuracy: 97.30%\n",
      "Batch 56, Loss: 0.036668, Accuracy: 97.35%\n",
      "Batch 57, Loss: 0.028105, Accuracy: 97.40%\n",
      "Batch 58, Loss: 0.056336, Accuracy: 97.41%\n",
      "Batch 59, Loss: 0.067878, Accuracy: 97.43%\n",
      "Batch 60, Loss: 0.062059, Accuracy: 97.45%\n",
      "Batch 61, Loss: 0.136051, Accuracy: 97.41%\n",
      "Batch 62, Loss: 0.127948, Accuracy: 97.40%\n",
      "Batch 63, Loss: 0.073572, Accuracy: 97.42%\n",
      "Batch 64, Loss: 0.052456, Accuracy: 97.41%\n",
      "Batch 65, Loss: 0.058473, Accuracy: 97.43%\n",
      "Batch 66, Loss: 0.064652, Accuracy: 97.44%\n",
      "Batch 67, Loss: 0.043183, Accuracy: 97.46%\n",
      "Batch 68, Loss: 0.017982, Accuracy: 97.50%\n",
      "Batch 69, Loss: 0.113895, Accuracy: 97.49%\n",
      "Batch 70, Loss: 0.093240, Accuracy: 97.48%\n",
      "Batch 71, Loss: 0.108030, Accuracy: 97.47%\n",
      "Batch 72, Loss: 0.148857, Accuracy: 97.44%\n",
      "Batch 73, Loss: 0.019639, Accuracy: 97.47%\n",
      "Batch 74, Loss: 0.190471, Accuracy: 97.45%\n",
      "Batch 75, Loss: 0.088186, Accuracy: 97.46%\n",
      "Batch 76, Loss: 0.036910, Accuracy: 97.49%\n",
      "Batch 77, Loss: 0.103144, Accuracy: 97.44%\n",
      "Batch 78, Loss: 0.016555, Accuracy: 97.48%\n",
      "Batch 79, Loss: 0.155338, Accuracy: 97.45%\n",
      "Batch 80, Loss: 0.019392, Accuracy: 97.48%\n",
      "Batch 81, Loss: 0.094398, Accuracy: 97.47%\n",
      "Batch 82, Loss: 0.025080, Accuracy: 97.50%\n",
      "Batch 83, Loss: 0.148096, Accuracy: 97.48%\n",
      "Batch 84, Loss: 0.069036, Accuracy: 97.49%\n",
      "Batch 85, Loss: 0.034832, Accuracy: 97.50%\n",
      "Batch 86, Loss: 0.161314, Accuracy: 97.46%\n",
      "Batch 87, Loss: 0.088285, Accuracy: 97.45%\n",
      "Batch 88, Loss: 0.124455, Accuracy: 97.43%\n",
      "Batch 89, Loss: 0.069271, Accuracy: 97.42%\n",
      "Batch 90, Loss: 0.074174, Accuracy: 97.43%\n",
      "Batch 91, Loss: 0.019710, Accuracy: 97.46%\n",
      "Batch 92, Loss: 0.096403, Accuracy: 97.47%\n",
      "Batch 93, Loss: 0.016750, Accuracy: 97.50%\n",
      "Batch 94, Loss: 0.075156, Accuracy: 97.49%\n",
      "Batch 95, Loss: 0.067500, Accuracy: 97.50%\n",
      "Batch 96, Loss: 0.072125, Accuracy: 97.49%\n",
      "Batch 97, Loss: 0.084645, Accuracy: 97.49%\n",
      "Batch 98, Loss: 0.026824, Accuracy: 97.51%\n",
      "Batch 99, Loss: 0.045092, Accuracy: 97.54%\n",
      "Batch 100, Loss: 0.091677, Accuracy: 97.55%\n",
      "Batch 101, Loss: 0.028864, Accuracy: 97.57%\n",
      "Batch 102, Loss: 0.041714, Accuracy: 97.58%\n",
      "Batch 103, Loss: 0.037512, Accuracy: 97.60%\n",
      "Batch 104, Loss: 0.055259, Accuracy: 97.60%\n",
      "Batch 105, Loss: 0.102540, Accuracy: 97.59%\n",
      "Batch 106, Loss: 0.019020, Accuracy: 97.61%\n",
      "Batch 107, Loss: 0.044134, Accuracy: 97.62%\n",
      "Batch 108, Loss: 0.133161, Accuracy: 97.61%\n",
      "Batch 109, Loss: 0.016598, Accuracy: 97.63%\n",
      "Batch 110, Loss: 0.010453, Accuracy: 97.66%\n",
      "Batch 111, Loss: 0.021758, Accuracy: 97.68%\n",
      "Batch 112, Loss: 0.030179, Accuracy: 97.68%\n",
      "Batch 113, Loss: 0.016622, Accuracy: 97.70%\n",
      "Batch 114, Loss: 0.013776, Accuracy: 97.72%\n",
      "Batch 115, Loss: 0.064853, Accuracy: 97.73%\n",
      "Batch 116, Loss: 0.057041, Accuracy: 97.72%\n",
      "Batch 117, Loss: 0.047547, Accuracy: 97.73%\n",
      "Batch 118, Loss: 0.044562, Accuracy: 97.74%\n",
      "Batch 119, Loss: 0.051304, Accuracy: 97.74%\n",
      "Batch 120, Loss: 0.010831, Accuracy: 97.76%\n",
      "Batch 121, Loss: 0.048817, Accuracy: 97.77%\n",
      "Batch 122, Loss: 0.143525, Accuracy: 97.72%\n",
      "Batch 123, Loss: 0.091210, Accuracy: 97.71%\n",
      "Batch 124, Loss: 0.017334, Accuracy: 97.73%\n",
      "Batch 125, Loss: 0.068278, Accuracy: 97.74%\n",
      "Batch 126, Loss: 0.081666, Accuracy: 97.73%\n",
      "Batch 127, Loss: 0.071838, Accuracy: 97.71%\n",
      "Batch 128, Loss: 0.105249, Accuracy: 97.71%\n",
      "Batch 129, Loss: 0.036907, Accuracy: 97.72%\n",
      "Batch 130, Loss: 0.023752, Accuracy: 97.74%\n",
      "Batch 131, Loss: 0.074309, Accuracy: 97.73%\n",
      "Batch 132, Loss: 0.081882, Accuracy: 97.74%\n",
      "Batch 133, Loss: 0.017826, Accuracy: 97.76%\n",
      "Batch 134, Loss: 0.093656, Accuracy: 97.74%\n",
      "Batch 135, Loss: 0.051269, Accuracy: 97.74%\n",
      "Batch 136, Loss: 0.179711, Accuracy: 97.73%\n",
      "Batch 137, Loss: 0.050151, Accuracy: 97.73%\n",
      "Batch 138, Loss: 0.081622, Accuracy: 97.74%\n",
      "Batch 139, Loss: 0.151376, Accuracy: 97.72%\n",
      "Batch 140, Loss: 0.040855, Accuracy: 97.72%\n",
      "Batch 141, Loss: 0.049662, Accuracy: 97.73%\n",
      "Batch 142, Loss: 0.206310, Accuracy: 97.70%\n",
      "Batch 143, Loss: 0.036567, Accuracy: 97.72%\n",
      "Batch 144, Loss: 0.015253, Accuracy: 97.73%\n",
      "Batch 145, Loss: 0.144005, Accuracy: 97.73%\n",
      "Batch 146, Loss: 0.018401, Accuracy: 97.74%\n",
      "Batch 147, Loss: 0.124540, Accuracy: 97.74%\n",
      "Batch 148, Loss: 0.292262, Accuracy: 97.70%\n",
      "Batch 149, Loss: 0.228227, Accuracy: 97.66%\n",
      "Batch 150, Loss: 0.147691, Accuracy: 97.64%\n",
      "Batch 151, Loss: 0.162126, Accuracy: 97.61%\n",
      "Batch 152, Loss: 0.116249, Accuracy: 97.60%\n",
      "Batch 153, Loss: 0.046913, Accuracy: 97.62%\n",
      "Batch 154, Loss: 0.187119, Accuracy: 97.58%\n",
      "Batch 155, Loss: 0.109684, Accuracy: 97.57%\n",
      "Batch 156, Loss: 0.069945, Accuracy: 97.57%\n",
      "Batch 157, Loss: 0.023725, Accuracy: 97.58%\n",
      "Batch 158, Loss: 0.132296, Accuracy: 97.57%\n",
      "Batch 159, Loss: 0.048767, Accuracy: 97.57%\n",
      "Batch 160, Loss: 0.089290, Accuracy: 97.57%\n",
      "Batch 161, Loss: 0.043182, Accuracy: 97.57%\n",
      "Batch 162, Loss: 0.102166, Accuracy: 97.56%\n",
      "Batch 163, Loss: 0.026853, Accuracy: 97.57%\n",
      "Batch 164, Loss: 0.072093, Accuracy: 97.56%\n",
      "Batch 165, Loss: 0.052642, Accuracy: 97.57%\n",
      "Batch 166, Loss: 0.069641, Accuracy: 97.57%\n",
      "Batch 167, Loss: 0.096552, Accuracy: 97.57%\n",
      "Batch 168, Loss: 0.050925, Accuracy: 97.56%\n",
      "Batch 169, Loss: 0.114900, Accuracy: 97.56%\n",
      "Batch 170, Loss: 0.052194, Accuracy: 97.56%\n",
      "Batch 171, Loss: 0.102964, Accuracy: 97.56%\n",
      "Batch 172, Loss: 0.094230, Accuracy: 97.56%\n",
      "Batch 173, Loss: 0.065619, Accuracy: 97.55%\n",
      "Batch 174, Loss: 0.024074, Accuracy: 97.57%\n",
      "Batch 175, Loss: 0.083791, Accuracy: 97.57%\n",
      "Batch 176, Loss: 0.074518, Accuracy: 97.57%\n",
      "Batch 177, Loss: 0.050659, Accuracy: 97.57%\n",
      "Batch 178, Loss: 0.063620, Accuracy: 97.58%\n",
      "Batch 179, Loss: 0.059754, Accuracy: 97.58%\n",
      "Batch 180, Loss: 0.030487, Accuracy: 97.60%\n",
      "Batch 181, Loss: 0.033620, Accuracy: 97.60%\n",
      "Batch 182, Loss: 0.080724, Accuracy: 97.60%\n",
      "Batch 183, Loss: 0.016886, Accuracy: 97.61%\n",
      "Batch 184, Loss: 0.058263, Accuracy: 97.61%\n",
      "Batch 185, Loss: 0.046814, Accuracy: 97.61%\n",
      "Batch 186, Loss: 0.113539, Accuracy: 97.61%\n",
      "Batch 187, Loss: 0.134051, Accuracy: 97.60%\n",
      "Batch 188, Loss: 0.040925, Accuracy: 97.61%\n",
      "Batch 189, Loss: 0.097935, Accuracy: 97.60%\n",
      "Batch 190, Loss: 0.116186, Accuracy: 97.60%\n",
      "Batch 191, Loss: 0.197220, Accuracy: 97.59%\n",
      "Batch 192, Loss: 0.016592, Accuracy: 97.61%\n",
      "Batch 193, Loss: 0.054592, Accuracy: 97.61%\n",
      "Batch 194, Loss: 0.159354, Accuracy: 97.61%\n",
      "Batch 195, Loss: 0.205002, Accuracy: 97.60%\n",
      "Batch 196, Loss: 0.098928, Accuracy: 97.60%\n",
      "Batch 197, Loss: 0.049695, Accuracy: 97.60%\n",
      "Batch 198, Loss: 0.055130, Accuracy: 97.60%\n",
      "Batch 199, Loss: 0.039918, Accuracy: 97.61%\n",
      "Batch 200, Loss: 0.109921, Accuracy: 97.59%\n",
      "Batch 201, Loss: 0.114770, Accuracy: 97.59%\n",
      "Batch 202, Loss: 0.046581, Accuracy: 97.59%\n",
      "Batch 203, Loss: 0.072943, Accuracy: 97.58%\n",
      "Batch 204, Loss: 0.096469, Accuracy: 97.58%\n",
      "Batch 205, Loss: 0.024685, Accuracy: 97.59%\n",
      "Batch 206, Loss: 0.080276, Accuracy: 97.59%\n",
      "Batch 207, Loss: 0.169955, Accuracy: 97.58%\n",
      "Batch 208, Loss: 0.109665, Accuracy: 97.57%\n",
      "Batch 209, Loss: 0.052200, Accuracy: 97.57%\n",
      "Batch 210, Loss: 0.112119, Accuracy: 97.55%\n",
      "Batch 211, Loss: 0.116065, Accuracy: 97.53%\n",
      "Batch 212, Loss: 0.130370, Accuracy: 97.53%\n",
      "Batch 213, Loss: 0.041453, Accuracy: 97.53%\n",
      "Training - Epoch 10, Loss: 0.079274, Accuracy: 97.53%\n",
      "Validation Batch 1, Loss: 0.106899, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.133111, Accuracy: 96.09%\n",
      "Validation Batch 3, Loss: 0.043493, Accuracy: 96.88%\n",
      "Validation Batch 4, Loss: 0.090641, Accuracy: 96.88%\n",
      "Validation Batch 5, Loss: 0.096114, Accuracy: 96.56%\n",
      "Validation Batch 6, Loss: 0.113511, Accuracy: 96.35%\n",
      "Validation Batch 7, Loss: 0.011711, Accuracy: 96.88%\n",
      "Validation Batch 8, Loss: 0.163065, Accuracy: 96.68%\n",
      "Validation Batch 9, Loss: 0.164491, Accuracy: 96.70%\n",
      "Validation Batch 10, Loss: 0.023213, Accuracy: 97.03%\n",
      "Validation Batch 11, Loss: 0.018780, Accuracy: 97.30%\n",
      "Validation Batch 12, Loss: 0.102458, Accuracy: 97.27%\n",
      "Validation Batch 13, Loss: 0.215135, Accuracy: 97.00%\n",
      "Validation Batch 14, Loss: 0.138524, Accuracy: 96.65%\n",
      "Validation Batch 15, Loss: 0.074719, Accuracy: 96.67%\n",
      "Validation Batch 16, Loss: 0.112451, Accuracy: 96.48%\n",
      "Validation Batch 17, Loss: 0.123397, Accuracy: 96.51%\n",
      "Validation Batch 18, Loss: 0.086581, Accuracy: 96.61%\n",
      "Validation Batch 19, Loss: 0.023066, Accuracy: 96.79%\n",
      "Validation Batch 20, Loss: 0.037822, Accuracy: 96.88%\n",
      "Validation Batch 21, Loss: 0.107663, Accuracy: 96.80%\n",
      "Validation Batch 22, Loss: 0.063446, Accuracy: 96.80%\n",
      "Validation Batch 23, Loss: 0.102267, Accuracy: 96.81%\n",
      "Validation Batch 24, Loss: 0.095861, Accuracy: 96.88%\n",
      "Validation Batch 25, Loss: 0.067199, Accuracy: 96.88%\n",
      "Validation Batch 26, Loss: 0.088569, Accuracy: 96.94%\n",
      "Validation Batch 27, Loss: 0.027387, Accuracy: 97.01%\n",
      "Validation - Epoch 10, Loss: 0.090058, Accuracy: 97.01%\n",
      "Patience—0\n",
      "Epoch 11\n",
      "Batch 1, Loss: 0.054253, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.122262, Accuracy: 97.66%\n",
      "Batch 3, Loss: 0.214600, Accuracy: 96.35%\n",
      "Batch 4, Loss: 0.036492, Accuracy: 97.27%\n",
      "Batch 5, Loss: 0.095673, Accuracy: 97.19%\n",
      "Batch 6, Loss: 0.104780, Accuracy: 97.14%\n",
      "Batch 7, Loss: 0.077936, Accuracy: 97.32%\n",
      "Batch 8, Loss: 0.068865, Accuracy: 97.46%\n",
      "Batch 9, Loss: 0.133578, Accuracy: 97.05%\n",
      "Batch 10, Loss: 0.214983, Accuracy: 96.41%\n",
      "Batch 11, Loss: 0.072644, Accuracy: 96.45%\n",
      "Batch 12, Loss: 0.076618, Accuracy: 96.48%\n",
      "Batch 13, Loss: 0.218842, Accuracy: 96.15%\n",
      "Batch 14, Loss: 0.135732, Accuracy: 95.98%\n",
      "Batch 15, Loss: 0.053986, Accuracy: 96.25%\n",
      "Batch 16, Loss: 0.105703, Accuracy: 96.39%\n",
      "Batch 17, Loss: 0.071355, Accuracy: 96.42%\n",
      "Batch 18, Loss: 0.071053, Accuracy: 96.44%\n",
      "Batch 19, Loss: 0.059332, Accuracy: 96.46%\n",
      "Batch 20, Loss: 0.098673, Accuracy: 96.48%\n",
      "Batch 21, Loss: 0.029111, Accuracy: 96.65%\n",
      "Batch 22, Loss: 0.042716, Accuracy: 96.73%\n",
      "Batch 23, Loss: 0.112765, Accuracy: 96.60%\n",
      "Batch 24, Loss: 0.074058, Accuracy: 96.68%\n",
      "Batch 25, Loss: 0.071795, Accuracy: 96.69%\n",
      "Batch 26, Loss: 0.105738, Accuracy: 96.63%\n",
      "Batch 27, Loss: 0.017248, Accuracy: 96.76%\n",
      "Batch 28, Loss: 0.055776, Accuracy: 96.76%\n",
      "Batch 29, Loss: 0.032949, Accuracy: 96.82%\n",
      "Batch 30, Loss: 0.083120, Accuracy: 96.88%\n",
      "Batch 31, Loss: 0.016426, Accuracy: 96.98%\n",
      "Batch 32, Loss: 0.141852, Accuracy: 96.88%\n",
      "Batch 33, Loss: 0.063041, Accuracy: 96.92%\n",
      "Batch 34, Loss: 0.102105, Accuracy: 96.92%\n",
      "Batch 35, Loss: 0.056015, Accuracy: 96.96%\n",
      "Batch 36, Loss: 0.049524, Accuracy: 97.01%\n",
      "Batch 37, Loss: 0.022246, Accuracy: 97.09%\n",
      "Batch 38, Loss: 0.131996, Accuracy: 96.96%\n",
      "Batch 39, Loss: 0.124619, Accuracy: 96.96%\n",
      "Batch 40, Loss: 0.168055, Accuracy: 96.88%\n",
      "Batch 41, Loss: 0.052742, Accuracy: 96.91%\n",
      "Batch 42, Loss: 0.079451, Accuracy: 96.91%\n",
      "Batch 43, Loss: 0.023355, Accuracy: 96.98%\n",
      "Batch 44, Loss: 0.067845, Accuracy: 96.98%\n",
      "Batch 45, Loss: 0.115030, Accuracy: 96.94%\n",
      "Batch 46, Loss: 0.101894, Accuracy: 96.98%\n",
      "Batch 47, Loss: 0.094706, Accuracy: 96.97%\n",
      "Batch 48, Loss: 0.061600, Accuracy: 96.97%\n",
      "Batch 49, Loss: 0.044299, Accuracy: 97.00%\n",
      "Batch 50, Loss: 0.063752, Accuracy: 97.03%\n",
      "Batch 51, Loss: 0.102400, Accuracy: 97.00%\n",
      "Batch 52, Loss: 0.050048, Accuracy: 97.03%\n",
      "Batch 53, Loss: 0.047444, Accuracy: 97.05%\n",
      "Batch 54, Loss: 0.127481, Accuracy: 97.05%\n",
      "Batch 55, Loss: 0.077953, Accuracy: 97.05%\n",
      "Batch 56, Loss: 0.050387, Accuracy: 97.04%\n",
      "Batch 57, Loss: 0.038630, Accuracy: 97.04%\n",
      "Batch 58, Loss: 0.213000, Accuracy: 97.01%\n",
      "Batch 59, Loss: 0.134035, Accuracy: 96.98%\n",
      "Batch 60, Loss: 0.080614, Accuracy: 97.01%\n",
      "Batch 61, Loss: 0.046031, Accuracy: 97.03%\n",
      "Batch 62, Loss: 0.052476, Accuracy: 97.05%\n",
      "Batch 63, Loss: 0.042613, Accuracy: 97.07%\n",
      "Batch 64, Loss: 0.163005, Accuracy: 97.05%\n",
      "Batch 65, Loss: 0.025203, Accuracy: 97.09%\n",
      "Batch 66, Loss: 0.058186, Accuracy: 97.11%\n",
      "Batch 67, Loss: 0.113232, Accuracy: 97.08%\n",
      "Batch 68, Loss: 0.056321, Accuracy: 97.10%\n",
      "Batch 69, Loss: 0.092328, Accuracy: 97.10%\n",
      "Batch 70, Loss: 0.013114, Accuracy: 97.14%\n",
      "Batch 71, Loss: 0.079266, Accuracy: 97.16%\n",
      "Batch 72, Loss: 0.048068, Accuracy: 97.18%\n",
      "Batch 73, Loss: 0.032029, Accuracy: 97.20%\n",
      "Batch 74, Loss: 0.057723, Accuracy: 97.21%\n",
      "Batch 75, Loss: 0.133219, Accuracy: 97.19%\n",
      "Batch 76, Loss: 0.012893, Accuracy: 97.22%\n",
      "Batch 77, Loss: 0.081289, Accuracy: 97.24%\n",
      "Batch 78, Loss: 0.044375, Accuracy: 97.26%\n",
      "Batch 79, Loss: 0.027391, Accuracy: 97.29%\n",
      "Batch 80, Loss: 0.117038, Accuracy: 97.29%\n",
      "Batch 81, Loss: 0.038084, Accuracy: 97.30%\n",
      "Batch 82, Loss: 0.078342, Accuracy: 97.29%\n",
      "Batch 83, Loss: 0.122620, Accuracy: 97.29%\n",
      "Batch 84, Loss: 0.172218, Accuracy: 97.27%\n",
      "Batch 85, Loss: 0.106897, Accuracy: 97.28%\n",
      "Batch 86, Loss: 0.061444, Accuracy: 97.29%\n",
      "Batch 87, Loss: 0.030845, Accuracy: 97.32%\n",
      "Batch 88, Loss: 0.099578, Accuracy: 97.34%\n",
      "Batch 89, Loss: 0.080332, Accuracy: 97.35%\n",
      "Batch 90, Loss: 0.139642, Accuracy: 97.33%\n",
      "Batch 91, Loss: 0.040120, Accuracy: 97.34%\n",
      "Batch 92, Loss: 0.016302, Accuracy: 97.37%\n",
      "Batch 93, Loss: 0.072721, Accuracy: 97.38%\n",
      "Batch 94, Loss: 0.162877, Accuracy: 97.34%\n",
      "Batch 95, Loss: 0.099717, Accuracy: 97.30%\n",
      "Batch 96, Loss: 0.030882, Accuracy: 97.31%\n",
      "Batch 97, Loss: 0.048335, Accuracy: 97.33%\n",
      "Batch 98, Loss: 0.021874, Accuracy: 97.35%\n",
      "Batch 99, Loss: 0.096461, Accuracy: 97.36%\n",
      "Batch 100, Loss: 0.134260, Accuracy: 97.38%\n",
      "Batch 101, Loss: 0.078212, Accuracy: 97.39%\n",
      "Batch 102, Loss: 0.033005, Accuracy: 97.41%\n",
      "Batch 103, Loss: 0.059117, Accuracy: 97.39%\n",
      "Batch 104, Loss: 0.057573, Accuracy: 97.40%\n",
      "Batch 105, Loss: 0.068038, Accuracy: 97.41%\n",
      "Batch 106, Loss: 0.092537, Accuracy: 97.41%\n",
      "Batch 107, Loss: 0.153776, Accuracy: 97.37%\n",
      "Batch 108, Loss: 0.021029, Accuracy: 97.40%\n",
      "Batch 109, Loss: 0.116481, Accuracy: 97.38%\n",
      "Batch 110, Loss: 0.010770, Accuracy: 97.40%\n",
      "Batch 111, Loss: 0.030431, Accuracy: 97.42%\n",
      "Batch 112, Loss: 0.194652, Accuracy: 97.38%\n",
      "Batch 113, Loss: 0.019305, Accuracy: 97.40%\n",
      "Batch 114, Loss: 0.162135, Accuracy: 97.38%\n",
      "Batch 115, Loss: 0.074998, Accuracy: 97.39%\n",
      "Batch 116, Loss: 0.095617, Accuracy: 97.37%\n",
      "Batch 117, Loss: 0.073892, Accuracy: 97.37%\n",
      "Batch 118, Loss: 0.126729, Accuracy: 97.36%\n",
      "Batch 119, Loss: 0.020209, Accuracy: 97.39%\n",
      "Batch 120, Loss: 0.025822, Accuracy: 97.41%\n",
      "Batch 121, Loss: 0.030488, Accuracy: 97.42%\n",
      "Batch 122, Loss: 0.028839, Accuracy: 97.44%\n",
      "Batch 123, Loss: 0.018866, Accuracy: 97.46%\n",
      "Batch 124, Loss: 0.024480, Accuracy: 97.48%\n",
      "Batch 125, Loss: 0.066950, Accuracy: 97.47%\n",
      "Batch 126, Loss: 0.023718, Accuracy: 97.50%\n",
      "Batch 127, Loss: 0.057752, Accuracy: 97.49%\n",
      "Batch 128, Loss: 0.073623, Accuracy: 97.50%\n",
      "Batch 129, Loss: 0.078564, Accuracy: 97.50%\n",
      "Batch 130, Loss: 0.030751, Accuracy: 97.51%\n",
      "Batch 131, Loss: 0.022176, Accuracy: 97.53%\n",
      "Batch 132, Loss: 0.028632, Accuracy: 97.54%\n",
      "Batch 133, Loss: 0.029216, Accuracy: 97.54%\n",
      "Batch 134, Loss: 0.085810, Accuracy: 97.54%\n",
      "Batch 135, Loss: 0.057956, Accuracy: 97.55%\n",
      "Batch 136, Loss: 0.024526, Accuracy: 97.56%\n",
      "Batch 137, Loss: 0.053574, Accuracy: 97.56%\n",
      "Batch 138, Loss: 0.011375, Accuracy: 97.58%\n",
      "Batch 139, Loss: 0.047006, Accuracy: 97.58%\n",
      "Batch 140, Loss: 0.028831, Accuracy: 97.59%\n",
      "Batch 141, Loss: 0.027331, Accuracy: 97.60%\n",
      "Batch 142, Loss: 0.031952, Accuracy: 97.60%\n",
      "Batch 143, Loss: 0.010208, Accuracy: 97.62%\n",
      "Batch 144, Loss: 0.035788, Accuracy: 97.62%\n",
      "Batch 145, Loss: 0.085332, Accuracy: 97.62%\n",
      "Batch 146, Loss: 0.038838, Accuracy: 97.62%\n",
      "Batch 147, Loss: 0.015426, Accuracy: 97.64%\n",
      "Batch 148, Loss: 0.016608, Accuracy: 97.66%\n",
      "Batch 149, Loss: 0.008131, Accuracy: 97.67%\n",
      "Batch 150, Loss: 0.032279, Accuracy: 97.68%\n",
      "Batch 151, Loss: 0.063500, Accuracy: 97.68%\n",
      "Batch 152, Loss: 0.061959, Accuracy: 97.67%\n",
      "Batch 153, Loss: 0.019466, Accuracy: 97.68%\n",
      "Batch 154, Loss: 0.106216, Accuracy: 97.68%\n",
      "Batch 155, Loss: 0.030779, Accuracy: 97.68%\n",
      "Batch 156, Loss: 0.012685, Accuracy: 97.70%\n",
      "Batch 157, Loss: 0.051733, Accuracy: 97.69%\n",
      "Batch 158, Loss: 0.115452, Accuracy: 97.70%\n",
      "Batch 159, Loss: 0.041212, Accuracy: 97.70%\n",
      "Batch 160, Loss: 0.066749, Accuracy: 97.71%\n",
      "Batch 161, Loss: 0.006796, Accuracy: 97.72%\n",
      "Batch 162, Loss: 0.050124, Accuracy: 97.71%\n",
      "Batch 163, Loss: 0.026177, Accuracy: 97.72%\n",
      "Batch 164, Loss: 0.013786, Accuracy: 97.73%\n",
      "Batch 165, Loss: 0.044816, Accuracy: 97.73%\n",
      "Batch 166, Loss: 0.069790, Accuracy: 97.72%\n",
      "Batch 167, Loss: 0.021532, Accuracy: 97.73%\n",
      "Batch 168, Loss: 0.042565, Accuracy: 97.73%\n",
      "Batch 169, Loss: 0.026579, Accuracy: 97.73%\n",
      "Batch 170, Loss: 0.008771, Accuracy: 97.75%\n",
      "Batch 171, Loss: 0.037027, Accuracy: 97.75%\n",
      "Batch 172, Loss: 0.081609, Accuracy: 97.76%\n",
      "Batch 173, Loss: 0.050651, Accuracy: 97.76%\n",
      "Batch 174, Loss: 0.142267, Accuracy: 97.74%\n",
      "Batch 175, Loss: 0.009111, Accuracy: 97.75%\n",
      "Batch 176, Loss: 0.039345, Accuracy: 97.75%\n",
      "Batch 177, Loss: 0.090177, Accuracy: 97.74%\n",
      "Batch 178, Loss: 0.023514, Accuracy: 97.75%\n",
      "Batch 179, Loss: 0.016760, Accuracy: 97.77%\n",
      "Batch 180, Loss: 0.012646, Accuracy: 97.78%\n",
      "Batch 181, Loss: 0.072965, Accuracy: 97.78%\n",
      "Batch 182, Loss: 0.044815, Accuracy: 97.79%\n",
      "Batch 183, Loss: 0.055046, Accuracy: 97.79%\n",
      "Batch 184, Loss: 0.030078, Accuracy: 97.80%\n",
      "Batch 185, Loss: 0.123269, Accuracy: 97.80%\n",
      "Batch 186, Loss: 0.013530, Accuracy: 97.82%\n",
      "Batch 187, Loss: 0.019057, Accuracy: 97.83%\n",
      "Batch 188, Loss: 0.010711, Accuracy: 97.84%\n",
      "Batch 189, Loss: 0.028049, Accuracy: 97.85%\n",
      "Batch 190, Loss: 0.032777, Accuracy: 97.85%\n",
      "Batch 191, Loss: 0.017068, Accuracy: 97.86%\n",
      "Batch 192, Loss: 0.037279, Accuracy: 97.87%\n",
      "Batch 193, Loss: 0.016879, Accuracy: 97.88%\n",
      "Batch 194, Loss: 0.067834, Accuracy: 97.87%\n",
      "Batch 195, Loss: 0.065431, Accuracy: 97.88%\n",
      "Batch 196, Loss: 0.079752, Accuracy: 97.88%\n",
      "Batch 197, Loss: 0.030960, Accuracy: 97.89%\n",
      "Batch 198, Loss: 0.037914, Accuracy: 97.89%\n",
      "Batch 199, Loss: 0.091729, Accuracy: 97.88%\n",
      "Batch 200, Loss: 0.009148, Accuracy: 97.89%\n",
      "Batch 201, Loss: 0.043016, Accuracy: 97.89%\n",
      "Batch 202, Loss: 0.009124, Accuracy: 97.90%\n",
      "Batch 203, Loss: 0.013918, Accuracy: 97.91%\n",
      "Batch 204, Loss: 0.045426, Accuracy: 97.92%\n",
      "Batch 205, Loss: 0.034789, Accuracy: 97.92%\n",
      "Batch 206, Loss: 0.051226, Accuracy: 97.92%\n",
      "Batch 207, Loss: 0.035047, Accuracy: 97.92%\n",
      "Batch 208, Loss: 0.233288, Accuracy: 97.92%\n",
      "Batch 209, Loss: 0.125574, Accuracy: 97.90%\n",
      "Batch 210, Loss: 0.048995, Accuracy: 97.90%\n",
      "Batch 211, Loss: 0.012234, Accuracy: 97.91%\n",
      "Batch 212, Loss: 0.015371, Accuracy: 97.92%\n",
      "Batch 213, Loss: 0.016227, Accuracy: 97.93%\n",
      "Training - Epoch 11, Loss: 0.064583, Accuracy: 97.93%\n",
      "Validation Batch 1, Loss: 0.085017, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.091094, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.118899, Accuracy: 96.88%\n",
      "Validation Batch 4, Loss: 0.147258, Accuracy: 96.48%\n",
      "Validation Batch 5, Loss: 0.103603, Accuracy: 96.56%\n",
      "Validation Batch 6, Loss: 0.044976, Accuracy: 96.88%\n",
      "Validation Batch 7, Loss: 0.069642, Accuracy: 97.10%\n",
      "Validation Batch 8, Loss: 0.172191, Accuracy: 96.68%\n",
      "Validation Batch 9, Loss: 0.251184, Accuracy: 96.35%\n",
      "Validation Batch 10, Loss: 0.045540, Accuracy: 96.56%\n",
      "Validation Batch 11, Loss: 0.065781, Accuracy: 96.59%\n",
      "Validation Batch 12, Loss: 0.229417, Accuracy: 96.22%\n",
      "Validation Batch 13, Loss: 0.170212, Accuracy: 96.03%\n",
      "Validation Batch 14, Loss: 0.247913, Accuracy: 95.87%\n",
      "Validation Batch 15, Loss: 0.152674, Accuracy: 95.83%\n",
      "Validation Batch 16, Loss: 0.127083, Accuracy: 95.90%\n",
      "Validation Batch 17, Loss: 0.087525, Accuracy: 95.96%\n",
      "Validation Batch 18, Loss: 0.039107, Accuracy: 96.09%\n",
      "Validation Batch 19, Loss: 0.028210, Accuracy: 96.22%\n",
      "Validation Batch 20, Loss: 0.098625, Accuracy: 96.25%\n",
      "Validation Batch 21, Loss: 0.077048, Accuracy: 96.28%\n",
      "Validation Batch 22, Loss: 0.234139, Accuracy: 96.09%\n",
      "Validation Batch 23, Loss: 0.119249, Accuracy: 96.06%\n",
      "Validation Batch 24, Loss: 0.158298, Accuracy: 96.03%\n",
      "Validation Batch 25, Loss: 0.020470, Accuracy: 96.19%\n",
      "Validation Batch 26, Loss: 0.144084, Accuracy: 96.09%\n",
      "Validation Batch 27, Loss: 0.116456, Accuracy: 96.07%\n",
      "Validation - Epoch 11, Loss: 0.120211, Accuracy: 96.07%\n",
      "Patience—1\n",
      "Epoch 12\n",
      "Batch 1, Loss: 0.106053, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.067701, Accuracy: 96.88%\n",
      "Batch 3, Loss: 0.161303, Accuracy: 95.31%\n",
      "Batch 4, Loss: 0.054572, Accuracy: 96.09%\n",
      "Batch 5, Loss: 0.071008, Accuracy: 96.56%\n",
      "Batch 6, Loss: 0.017280, Accuracy: 97.14%\n",
      "Batch 7, Loss: 0.068868, Accuracy: 97.32%\n",
      "Batch 8, Loss: 0.022879, Accuracy: 97.66%\n",
      "Batch 9, Loss: 0.024122, Accuracy: 97.92%\n",
      "Batch 10, Loss: 0.026205, Accuracy: 98.12%\n",
      "Batch 11, Loss: 0.016939, Accuracy: 98.30%\n",
      "Batch 12, Loss: 0.121832, Accuracy: 98.05%\n",
      "Batch 13, Loss: 0.046225, Accuracy: 98.08%\n",
      "Batch 14, Loss: 0.178998, Accuracy: 97.66%\n",
      "Batch 15, Loss: 0.133660, Accuracy: 97.60%\n",
      "Batch 16, Loss: 0.078327, Accuracy: 97.66%\n",
      "Batch 17, Loss: 0.060758, Accuracy: 97.70%\n",
      "Batch 18, Loss: 0.029864, Accuracy: 97.83%\n",
      "Batch 19, Loss: 0.067267, Accuracy: 97.86%\n",
      "Batch 20, Loss: 0.114221, Accuracy: 97.81%\n",
      "Batch 21, Loss: 0.041848, Accuracy: 97.84%\n",
      "Batch 22, Loss: 0.029870, Accuracy: 97.94%\n",
      "Batch 23, Loss: 0.174705, Accuracy: 97.83%\n",
      "Batch 24, Loss: 0.039832, Accuracy: 97.85%\n",
      "Batch 25, Loss: 0.038530, Accuracy: 97.88%\n",
      "Batch 26, Loss: 0.075027, Accuracy: 97.84%\n",
      "Batch 27, Loss: 0.019104, Accuracy: 97.92%\n",
      "Batch 28, Loss: 0.139192, Accuracy: 97.88%\n",
      "Batch 29, Loss: 0.047474, Accuracy: 97.90%\n",
      "Batch 30, Loss: 0.021985, Accuracy: 97.97%\n",
      "Batch 31, Loss: 0.181940, Accuracy: 97.78%\n",
      "Batch 32, Loss: 0.023192, Accuracy: 97.85%\n",
      "Batch 33, Loss: 0.077131, Accuracy: 97.82%\n",
      "Batch 34, Loss: 0.055399, Accuracy: 97.79%\n",
      "Batch 35, Loss: 0.078893, Accuracy: 97.77%\n",
      "Batch 36, Loss: 0.011788, Accuracy: 97.83%\n",
      "Batch 37, Loss: 0.038134, Accuracy: 97.89%\n",
      "Batch 38, Loss: 0.053073, Accuracy: 97.90%\n",
      "Batch 39, Loss: 0.083006, Accuracy: 97.92%\n",
      "Batch 40, Loss: 0.049198, Accuracy: 97.93%\n",
      "Batch 41, Loss: 0.015448, Accuracy: 97.98%\n",
      "Batch 42, Loss: 0.045833, Accuracy: 97.99%\n",
      "Batch 43, Loss: 0.041496, Accuracy: 98.04%\n",
      "Batch 44, Loss: 0.113084, Accuracy: 98.01%\n",
      "Batch 45, Loss: 0.030792, Accuracy: 98.02%\n",
      "Batch 46, Loss: 0.027886, Accuracy: 98.03%\n",
      "Batch 47, Loss: 0.018801, Accuracy: 98.07%\n",
      "Batch 48, Loss: 0.018859, Accuracy: 98.11%\n",
      "Batch 49, Loss: 0.092436, Accuracy: 98.05%\n",
      "Batch 50, Loss: 0.114138, Accuracy: 98.00%\n",
      "Batch 51, Loss: 0.042061, Accuracy: 98.01%\n",
      "Batch 52, Loss: 0.072465, Accuracy: 98.02%\n",
      "Batch 53, Loss: 0.125354, Accuracy: 98.00%\n",
      "Batch 54, Loss: 0.022540, Accuracy: 98.03%\n",
      "Batch 55, Loss: 0.072710, Accuracy: 98.01%\n",
      "Batch 56, Loss: 0.012266, Accuracy: 98.05%\n",
      "Batch 57, Loss: 0.031803, Accuracy: 98.05%\n",
      "Batch 58, Loss: 0.116672, Accuracy: 98.01%\n",
      "Batch 59, Loss: 0.013686, Accuracy: 98.04%\n",
      "Batch 60, Loss: 0.097338, Accuracy: 97.99%\n",
      "Batch 61, Loss: 0.010031, Accuracy: 98.03%\n",
      "Batch 62, Loss: 0.016445, Accuracy: 98.06%\n",
      "Batch 63, Loss: 0.030132, Accuracy: 98.07%\n",
      "Batch 64, Loss: 0.016250, Accuracy: 98.10%\n",
      "Batch 65, Loss: 0.070592, Accuracy: 98.08%\n",
      "Batch 66, Loss: 0.024610, Accuracy: 98.11%\n",
      "Batch 67, Loss: 0.067546, Accuracy: 98.09%\n",
      "Batch 68, Loss: 0.018329, Accuracy: 98.12%\n",
      "Batch 69, Loss: 0.040236, Accuracy: 98.12%\n",
      "Batch 70, Loss: 0.081600, Accuracy: 98.10%\n",
      "Batch 71, Loss: 0.132452, Accuracy: 98.09%\n",
      "Batch 72, Loss: 0.205366, Accuracy: 98.00%\n",
      "Batch 73, Loss: 0.015556, Accuracy: 98.03%\n",
      "Batch 74, Loss: 0.034521, Accuracy: 98.06%\n",
      "Batch 75, Loss: 0.091482, Accuracy: 98.02%\n",
      "Batch 76, Loss: 0.013184, Accuracy: 98.05%\n",
      "Batch 77, Loss: 0.009563, Accuracy: 98.07%\n",
      "Batch 78, Loss: 0.013285, Accuracy: 98.10%\n",
      "Batch 79, Loss: 0.119316, Accuracy: 98.10%\n",
      "Batch 80, Loss: 0.028507, Accuracy: 98.12%\n",
      "Batch 81, Loss: 0.037122, Accuracy: 98.13%\n",
      "Batch 82, Loss: 0.094422, Accuracy: 98.13%\n",
      "Batch 83, Loss: 0.048601, Accuracy: 98.12%\n",
      "Batch 84, Loss: 0.070261, Accuracy: 98.12%\n",
      "Batch 85, Loss: 0.087547, Accuracy: 98.07%\n",
      "Batch 86, Loss: 0.102151, Accuracy: 98.02%\n",
      "Batch 87, Loss: 0.013718, Accuracy: 98.04%\n",
      "Batch 88, Loss: 0.021718, Accuracy: 98.06%\n",
      "Batch 89, Loss: 0.218621, Accuracy: 98.03%\n",
      "Batch 90, Loss: 0.090699, Accuracy: 98.00%\n",
      "Batch 91, Loss: 0.063609, Accuracy: 98.01%\n",
      "Batch 92, Loss: 0.074253, Accuracy: 98.00%\n",
      "Batch 93, Loss: 0.058937, Accuracy: 98.00%\n",
      "Batch 94, Loss: 0.027155, Accuracy: 98.01%\n",
      "Batch 95, Loss: 0.073784, Accuracy: 97.99%\n",
      "Batch 96, Loss: 0.017136, Accuracy: 98.01%\n",
      "Batch 97, Loss: 0.078961, Accuracy: 98.00%\n",
      "Batch 98, Loss: 0.098533, Accuracy: 97.99%\n",
      "Batch 99, Loss: 0.013324, Accuracy: 98.01%\n",
      "Batch 100, Loss: 0.037141, Accuracy: 98.02%\n",
      "Batch 101, Loss: 0.097275, Accuracy: 98.00%\n",
      "Batch 102, Loss: 0.106556, Accuracy: 97.96%\n",
      "Batch 103, Loss: 0.019871, Accuracy: 97.97%\n",
      "Batch 104, Loss: 0.094533, Accuracy: 97.96%\n",
      "Batch 105, Loss: 0.033447, Accuracy: 97.96%\n",
      "Batch 106, Loss: 0.083277, Accuracy: 97.97%\n",
      "Batch 107, Loss: 0.119103, Accuracy: 97.96%\n",
      "Batch 108, Loss: 0.015886, Accuracy: 97.97%\n",
      "Batch 109, Loss: 0.063479, Accuracy: 97.96%\n",
      "Batch 110, Loss: 0.028103, Accuracy: 97.97%\n",
      "Batch 111, Loss: 0.061801, Accuracy: 97.96%\n",
      "Batch 112, Loss: 0.030017, Accuracy: 97.98%\n",
      "Batch 113, Loss: 0.181586, Accuracy: 97.97%\n",
      "Batch 114, Loss: 0.024285, Accuracy: 97.99%\n",
      "Batch 115, Loss: 0.135490, Accuracy: 97.96%\n",
      "Batch 116, Loss: 0.170781, Accuracy: 97.94%\n",
      "Batch 117, Loss: 0.109065, Accuracy: 97.93%\n",
      "Batch 118, Loss: 0.046122, Accuracy: 97.93%\n",
      "Batch 119, Loss: 0.053136, Accuracy: 97.93%\n",
      "Batch 120, Loss: 0.093986, Accuracy: 97.93%\n",
      "Batch 121, Loss: 0.080418, Accuracy: 97.93%\n",
      "Batch 122, Loss: 0.084938, Accuracy: 97.93%\n",
      "Batch 123, Loss: 0.275908, Accuracy: 97.85%\n",
      "Batch 124, Loss: 0.258241, Accuracy: 97.81%\n",
      "Batch 125, Loss: 0.097568, Accuracy: 97.80%\n",
      "Batch 126, Loss: 0.182244, Accuracy: 97.76%\n",
      "Batch 127, Loss: 0.092393, Accuracy: 97.75%\n",
      "Batch 128, Loss: 0.147530, Accuracy: 97.74%\n",
      "Batch 129, Loss: 0.049715, Accuracy: 97.75%\n",
      "Batch 130, Loss: 0.052454, Accuracy: 97.75%\n",
      "Batch 131, Loss: 0.043428, Accuracy: 97.75%\n",
      "Batch 132, Loss: 0.055874, Accuracy: 97.75%\n",
      "Batch 133, Loss: 0.048268, Accuracy: 97.76%\n",
      "Batch 134, Loss: 0.034231, Accuracy: 97.77%\n",
      "Batch 135, Loss: 0.068874, Accuracy: 97.77%\n",
      "Batch 136, Loss: 0.042829, Accuracy: 97.76%\n",
      "Batch 137, Loss: 0.040225, Accuracy: 97.76%\n",
      "Batch 138, Loss: 0.070096, Accuracy: 97.76%\n",
      "Batch 139, Loss: 0.038481, Accuracy: 97.75%\n",
      "Batch 140, Loss: 0.082485, Accuracy: 97.75%\n",
      "Batch 141, Loss: 0.008787, Accuracy: 97.76%\n",
      "Batch 142, Loss: 0.013576, Accuracy: 97.78%\n",
      "Batch 143, Loss: 0.016861, Accuracy: 97.79%\n",
      "Batch 144, Loss: 0.041068, Accuracy: 97.80%\n",
      "Batch 145, Loss: 0.010589, Accuracy: 97.81%\n",
      "Batch 146, Loss: 0.057063, Accuracy: 97.81%\n",
      "Batch 147, Loss: 0.018254, Accuracy: 97.82%\n",
      "Batch 148, Loss: 0.025913, Accuracy: 97.84%\n",
      "Batch 149, Loss: 0.023189, Accuracy: 97.85%\n",
      "Batch 150, Loss: 0.028858, Accuracy: 97.86%\n",
      "Batch 151, Loss: 0.121091, Accuracy: 97.86%\n",
      "Batch 152, Loss: 0.077789, Accuracy: 97.86%\n",
      "Batch 153, Loss: 0.050364, Accuracy: 97.87%\n",
      "Batch 154, Loss: 0.010742, Accuracy: 97.88%\n",
      "Batch 155, Loss: 0.033708, Accuracy: 97.88%\n",
      "Batch 156, Loss: 0.035654, Accuracy: 97.89%\n",
      "Batch 157, Loss: 0.012147, Accuracy: 97.90%\n",
      "Batch 158, Loss: 0.051958, Accuracy: 97.89%\n",
      "Batch 159, Loss: 0.022706, Accuracy: 97.90%\n",
      "Batch 160, Loss: 0.011800, Accuracy: 97.91%\n",
      "Batch 161, Loss: 0.014040, Accuracy: 97.92%\n",
      "Batch 162, Loss: 0.150378, Accuracy: 97.90%\n",
      "Batch 163, Loss: 0.011112, Accuracy: 97.91%\n",
      "Batch 164, Loss: 0.049537, Accuracy: 97.91%\n",
      "Batch 165, Loss: 0.068794, Accuracy: 97.91%\n",
      "Batch 166, Loss: 0.013804, Accuracy: 97.92%\n",
      "Batch 167, Loss: 0.012362, Accuracy: 97.93%\n",
      "Batch 168, Loss: 0.061562, Accuracy: 97.93%\n",
      "Batch 169, Loss: 0.054626, Accuracy: 97.92%\n",
      "Batch 170, Loss: 0.034061, Accuracy: 97.91%\n",
      "Batch 171, Loss: 0.024486, Accuracy: 97.93%\n",
      "Batch 172, Loss: 0.018720, Accuracy: 97.94%\n",
      "Batch 173, Loss: 0.110405, Accuracy: 97.93%\n",
      "Batch 174, Loss: 0.094936, Accuracy: 97.93%\n",
      "Batch 175, Loss: 0.115932, Accuracy: 97.92%\n",
      "Batch 176, Loss: 0.088008, Accuracy: 97.90%\n",
      "Batch 177, Loss: 0.021432, Accuracy: 97.92%\n",
      "Batch 178, Loss: 0.031614, Accuracy: 97.92%\n",
      "Batch 179, Loss: 0.011654, Accuracy: 97.93%\n",
      "Batch 180, Loss: 0.040930, Accuracy: 97.93%\n",
      "Batch 181, Loss: 0.047693, Accuracy: 97.92%\n",
      "Batch 182, Loss: 0.026500, Accuracy: 97.93%\n",
      "Batch 183, Loss: 0.022483, Accuracy: 97.94%\n",
      "Batch 184, Loss: 0.136984, Accuracy: 97.94%\n",
      "Batch 185, Loss: 0.093487, Accuracy: 97.93%\n",
      "Batch 186, Loss: 0.023107, Accuracy: 97.94%\n",
      "Batch 187, Loss: 0.097809, Accuracy: 97.93%\n",
      "Batch 188, Loss: 0.071717, Accuracy: 97.93%\n",
      "Batch 189, Loss: 0.028130, Accuracy: 97.94%\n",
      "Batch 190, Loss: 0.071409, Accuracy: 97.94%\n",
      "Batch 191, Loss: 0.105797, Accuracy: 97.93%\n",
      "Batch 192, Loss: 0.022972, Accuracy: 97.94%\n",
      "Batch 193, Loss: 0.026825, Accuracy: 97.95%\n",
      "Batch 194, Loss: 0.032299, Accuracy: 97.95%\n",
      "Batch 195, Loss: 0.103662, Accuracy: 97.95%\n",
      "Batch 196, Loss: 0.097143, Accuracy: 97.94%\n",
      "Batch 197, Loss: 0.020388, Accuracy: 97.95%\n",
      "Batch 198, Loss: 0.010037, Accuracy: 97.96%\n",
      "Batch 199, Loss: 0.023759, Accuracy: 97.96%\n",
      "Batch 200, Loss: 0.014750, Accuracy: 97.97%\n",
      "Batch 201, Loss: 0.010008, Accuracy: 97.98%\n",
      "Batch 202, Loss: 0.051644, Accuracy: 97.98%\n",
      "Batch 203, Loss: 0.014648, Accuracy: 97.99%\n",
      "Batch 204, Loss: 0.022829, Accuracy: 98.00%\n",
      "Batch 205, Loss: 0.014877, Accuracy: 98.01%\n",
      "Batch 206, Loss: 0.109228, Accuracy: 98.01%\n",
      "Batch 207, Loss: 0.013267, Accuracy: 98.02%\n",
      "Batch 208, Loss: 0.129181, Accuracy: 98.00%\n",
      "Batch 209, Loss: 0.034471, Accuracy: 98.00%\n",
      "Batch 210, Loss: 0.021889, Accuracy: 98.01%\n",
      "Batch 211, Loss: 0.055324, Accuracy: 98.01%\n",
      "Batch 212, Loss: 0.020667, Accuracy: 98.02%\n",
      "Batch 213, Loss: 0.091997, Accuracy: 98.02%\n",
      "Training - Epoch 12, Loss: 0.061133, Accuracy: 98.02%\n",
      "Validation Batch 1, Loss: 0.122640, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.044421, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.038540, Accuracy: 97.92%\n",
      "Validation Batch 4, Loss: 0.032573, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.089454, Accuracy: 98.12%\n",
      "Validation Batch 6, Loss: 0.032674, Accuracy: 98.44%\n",
      "Validation Batch 7, Loss: 0.017021, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.030187, Accuracy: 98.63%\n",
      "Validation Batch 9, Loss: 0.127308, Accuracy: 98.44%\n",
      "Validation Batch 10, Loss: 0.038395, Accuracy: 98.44%\n",
      "Validation Batch 11, Loss: 0.096609, Accuracy: 98.15%\n",
      "Validation Batch 12, Loss: 0.121208, Accuracy: 97.92%\n",
      "Validation Batch 13, Loss: 0.105486, Accuracy: 97.60%\n",
      "Validation Batch 14, Loss: 0.132485, Accuracy: 97.54%\n",
      "Validation Batch 15, Loss: 0.096926, Accuracy: 97.50%\n",
      "Validation Batch 16, Loss: 0.038633, Accuracy: 97.56%\n",
      "Validation Batch 17, Loss: 0.086144, Accuracy: 97.52%\n",
      "Validation Batch 18, Loss: 0.017288, Accuracy: 97.66%\n",
      "Validation Batch 19, Loss: 0.027766, Accuracy: 97.70%\n",
      "Validation Batch 20, Loss: 0.121626, Accuracy: 97.66%\n",
      "Validation Batch 21, Loss: 0.031809, Accuracy: 97.69%\n",
      "Validation Batch 22, Loss: 0.051027, Accuracy: 97.66%\n",
      "Validation Batch 23, Loss: 0.056470, Accuracy: 97.69%\n",
      "Validation Batch 24, Loss: 0.095706, Accuracy: 97.72%\n",
      "Validation Batch 25, Loss: 0.059458, Accuracy: 97.75%\n",
      "Validation Batch 26, Loss: 0.112143, Accuracy: 97.66%\n",
      "Validation Batch 27, Loss: 0.027116, Accuracy: 97.71%\n",
      "Validation - Epoch 12, Loss: 0.068560, Accuracy: 97.71%\n",
      "Patience—0\n",
      "Epoch 13\n",
      "Batch 1, Loss: 0.011709, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.018962, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.027088, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.027583, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.044958, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.005822, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.010691, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.012625, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.060714, Accuracy: 99.48%\n",
      "Batch 10, Loss: 0.014258, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.010726, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.015248, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.100172, Accuracy: 99.40%\n",
      "Batch 14, Loss: 0.026784, Accuracy: 99.33%\n",
      "Batch 15, Loss: 0.017573, Accuracy: 99.38%\n",
      "Batch 16, Loss: 0.111890, Accuracy: 99.12%\n",
      "Batch 17, Loss: 0.006913, Accuracy: 99.17%\n",
      "Batch 18, Loss: 0.012868, Accuracy: 99.22%\n",
      "Batch 19, Loss: 0.017561, Accuracy: 99.26%\n",
      "Batch 20, Loss: 0.052579, Accuracy: 99.22%\n",
      "Batch 21, Loss: 0.074220, Accuracy: 99.11%\n",
      "Batch 22, Loss: 0.110548, Accuracy: 99.01%\n",
      "Batch 23, Loss: 0.023762, Accuracy: 99.05%\n",
      "Batch 24, Loss: 0.042581, Accuracy: 99.02%\n",
      "Batch 25, Loss: 0.012487, Accuracy: 99.06%\n",
      "Batch 26, Loss: 0.025555, Accuracy: 99.10%\n",
      "Batch 27, Loss: 0.085939, Accuracy: 99.02%\n",
      "Batch 28, Loss: 0.035490, Accuracy: 99.00%\n",
      "Batch 29, Loss: 0.044770, Accuracy: 98.98%\n",
      "Batch 30, Loss: 0.037424, Accuracy: 98.96%\n",
      "Batch 31, Loss: 0.064729, Accuracy: 98.94%\n",
      "Batch 32, Loss: 0.016778, Accuracy: 98.97%\n",
      "Batch 33, Loss: 0.016677, Accuracy: 99.01%\n",
      "Batch 34, Loss: 0.103260, Accuracy: 98.94%\n",
      "Batch 35, Loss: 0.039133, Accuracy: 98.93%\n",
      "Batch 36, Loss: 0.148487, Accuracy: 98.87%\n",
      "Batch 37, Loss: 0.025434, Accuracy: 98.90%\n",
      "Batch 38, Loss: 0.036979, Accuracy: 98.89%\n",
      "Batch 39, Loss: 0.007593, Accuracy: 98.92%\n",
      "Batch 40, Loss: 0.009003, Accuracy: 98.95%\n",
      "Batch 41, Loss: 0.151554, Accuracy: 98.89%\n",
      "Batch 42, Loss: 0.018374, Accuracy: 98.92%\n",
      "Batch 43, Loss: 0.206044, Accuracy: 98.69%\n",
      "Batch 44, Loss: 0.010653, Accuracy: 98.72%\n",
      "Batch 45, Loss: 0.030589, Accuracy: 98.72%\n",
      "Batch 46, Loss: 0.097789, Accuracy: 98.71%\n",
      "Batch 47, Loss: 0.012365, Accuracy: 98.74%\n",
      "Batch 48, Loss: 0.008726, Accuracy: 98.76%\n",
      "Batch 49, Loss: 0.014237, Accuracy: 98.79%\n",
      "Batch 50, Loss: 0.191576, Accuracy: 98.69%\n",
      "Batch 51, Loss: 0.016191, Accuracy: 98.71%\n",
      "Batch 52, Loss: 0.062111, Accuracy: 98.71%\n",
      "Batch 53, Loss: 0.081805, Accuracy: 98.70%\n",
      "Batch 54, Loss: 0.009400, Accuracy: 98.73%\n",
      "Batch 55, Loss: 0.023424, Accuracy: 98.75%\n",
      "Batch 56, Loss: 0.006243, Accuracy: 98.77%\n",
      "Batch 57, Loss: 0.054114, Accuracy: 98.77%\n",
      "Batch 58, Loss: 0.040861, Accuracy: 98.76%\n",
      "Batch 59, Loss: 0.081620, Accuracy: 98.73%\n",
      "Batch 60, Loss: 0.087458, Accuracy: 98.67%\n",
      "Batch 61, Loss: 0.078331, Accuracy: 98.64%\n",
      "Batch 62, Loss: 0.016991, Accuracy: 98.66%\n",
      "Batch 63, Loss: 0.056956, Accuracy: 98.66%\n",
      "Batch 64, Loss: 0.111084, Accuracy: 98.63%\n",
      "Batch 65, Loss: 0.041571, Accuracy: 98.63%\n",
      "Batch 66, Loss: 0.026537, Accuracy: 98.63%\n",
      "Batch 67, Loss: 0.005946, Accuracy: 98.65%\n",
      "Batch 68, Loss: 0.167623, Accuracy: 98.60%\n",
      "Batch 69, Loss: 0.197929, Accuracy: 98.51%\n",
      "Batch 70, Loss: 0.024178, Accuracy: 98.53%\n",
      "Batch 71, Loss: 0.050163, Accuracy: 98.53%\n",
      "Batch 72, Loss: 0.047871, Accuracy: 98.52%\n",
      "Batch 73, Loss: 0.085505, Accuracy: 98.50%\n",
      "Batch 74, Loss: 0.016682, Accuracy: 98.52%\n",
      "Batch 75, Loss: 0.009494, Accuracy: 98.54%\n",
      "Batch 76, Loss: 0.010003, Accuracy: 98.56%\n",
      "Batch 77, Loss: 0.105629, Accuracy: 98.54%\n",
      "Batch 78, Loss: 0.017329, Accuracy: 98.56%\n",
      "Batch 79, Loss: 0.026035, Accuracy: 98.56%\n",
      "Batch 80, Loss: 0.041070, Accuracy: 98.55%\n",
      "Batch 81, Loss: 0.013359, Accuracy: 98.57%\n",
      "Batch 82, Loss: 0.022723, Accuracy: 98.57%\n",
      "Batch 83, Loss: 0.109791, Accuracy: 98.57%\n",
      "Batch 84, Loss: 0.007105, Accuracy: 98.59%\n",
      "Batch 85, Loss: 0.073414, Accuracy: 98.58%\n",
      "Batch 86, Loss: 0.011483, Accuracy: 98.60%\n",
      "Batch 87, Loss: 0.032375, Accuracy: 98.60%\n",
      "Batch 88, Loss: 0.081631, Accuracy: 98.56%\n",
      "Batch 89, Loss: 0.011770, Accuracy: 98.58%\n",
      "Batch 90, Loss: 0.013477, Accuracy: 98.59%\n",
      "Batch 91, Loss: 0.054906, Accuracy: 98.57%\n",
      "Batch 92, Loss: 0.015484, Accuracy: 98.59%\n",
      "Batch 93, Loss: 0.023611, Accuracy: 98.61%\n",
      "Batch 94, Loss: 0.011349, Accuracy: 98.62%\n",
      "Batch 95, Loss: 0.018095, Accuracy: 98.63%\n",
      "Batch 96, Loss: 0.008387, Accuracy: 98.65%\n",
      "Batch 97, Loss: 0.009088, Accuracy: 98.66%\n",
      "Batch 98, Loss: 0.040685, Accuracy: 98.66%\n",
      "Batch 99, Loss: 0.010583, Accuracy: 98.67%\n",
      "Batch 100, Loss: 0.014528, Accuracy: 98.69%\n",
      "Batch 101, Loss: 0.007420, Accuracy: 98.70%\n",
      "Batch 102, Loss: 0.019782, Accuracy: 98.71%\n",
      "Batch 103, Loss: 0.022629, Accuracy: 98.73%\n",
      "Batch 104, Loss: 0.062158, Accuracy: 98.71%\n",
      "Batch 105, Loss: 0.024370, Accuracy: 98.71%\n",
      "Batch 106, Loss: 0.018682, Accuracy: 98.72%\n",
      "Batch 107, Loss: 0.121610, Accuracy: 98.70%\n",
      "Batch 108, Loss: 0.011107, Accuracy: 98.71%\n",
      "Batch 109, Loss: 0.007049, Accuracy: 98.72%\n",
      "Batch 110, Loss: 0.034691, Accuracy: 98.72%\n",
      "Batch 111, Loss: 0.009673, Accuracy: 98.73%\n",
      "Batch 112, Loss: 0.008484, Accuracy: 98.74%\n",
      "Batch 113, Loss: 0.045206, Accuracy: 98.74%\n",
      "Batch 114, Loss: 0.118506, Accuracy: 98.71%\n",
      "Batch 115, Loss: 0.262087, Accuracy: 98.68%\n",
      "Batch 116, Loss: 0.011338, Accuracy: 98.69%\n",
      "Batch 117, Loss: 0.070754, Accuracy: 98.69%\n",
      "Batch 118, Loss: 0.112651, Accuracy: 98.68%\n",
      "Batch 119, Loss: 0.033453, Accuracy: 98.67%\n",
      "Batch 120, Loss: 0.107728, Accuracy: 98.66%\n",
      "Batch 121, Loss: 0.008123, Accuracy: 98.67%\n",
      "Batch 122, Loss: 0.044261, Accuracy: 98.67%\n",
      "Batch 123, Loss: 0.011532, Accuracy: 98.68%\n",
      "Batch 124, Loss: 0.024813, Accuracy: 98.69%\n",
      "Batch 125, Loss: 0.014512, Accuracy: 98.70%\n",
      "Batch 126, Loss: 0.041216, Accuracy: 98.70%\n",
      "Batch 127, Loss: 0.062557, Accuracy: 98.70%\n",
      "Batch 128, Loss: 0.036890, Accuracy: 98.69%\n",
      "Batch 129, Loss: 0.053046, Accuracy: 98.69%\n",
      "Batch 130, Loss: 0.055287, Accuracy: 98.69%\n",
      "Batch 131, Loss: 0.015866, Accuracy: 98.70%\n",
      "Batch 132, Loss: 0.015270, Accuracy: 98.71%\n",
      "Batch 133, Loss: 0.012843, Accuracy: 98.72%\n",
      "Batch 134, Loss: 0.046710, Accuracy: 98.72%\n",
      "Batch 135, Loss: 0.017660, Accuracy: 98.73%\n",
      "Batch 136, Loss: 0.049547, Accuracy: 98.72%\n",
      "Batch 137, Loss: 0.161442, Accuracy: 98.69%\n",
      "Batch 138, Loss: 0.008489, Accuracy: 98.70%\n",
      "Batch 139, Loss: 0.114919, Accuracy: 98.68%\n",
      "Batch 140, Loss: 0.034813, Accuracy: 98.68%\n",
      "Batch 141, Loss: 0.062854, Accuracy: 98.67%\n",
      "Batch 142, Loss: 0.031005, Accuracy: 98.68%\n",
      "Batch 143, Loss: 0.037070, Accuracy: 98.68%\n",
      "Batch 144, Loss: 0.075996, Accuracy: 98.68%\n",
      "Batch 145, Loss: 0.059516, Accuracy: 98.67%\n",
      "Batch 146, Loss: 0.108371, Accuracy: 98.65%\n",
      "Batch 147, Loss: 0.107282, Accuracy: 98.64%\n",
      "Batch 148, Loss: 0.012168, Accuracy: 98.65%\n",
      "Batch 149, Loss: 0.034268, Accuracy: 98.65%\n",
      "Batch 150, Loss: 0.079203, Accuracy: 98.62%\n",
      "Batch 151, Loss: 0.025344, Accuracy: 98.63%\n",
      "Batch 152, Loss: 0.027305, Accuracy: 98.63%\n",
      "Batch 153, Loss: 0.014835, Accuracy: 98.64%\n",
      "Batch 154, Loss: 0.087079, Accuracy: 98.63%\n",
      "Batch 155, Loss: 0.019919, Accuracy: 98.64%\n",
      "Batch 156, Loss: 0.071546, Accuracy: 98.63%\n",
      "Batch 157, Loss: 0.020248, Accuracy: 98.64%\n",
      "Batch 158, Loss: 0.026886, Accuracy: 98.64%\n",
      "Batch 159, Loss: 0.011977, Accuracy: 98.64%\n",
      "Batch 160, Loss: 0.053493, Accuracy: 98.64%\n",
      "Batch 161, Loss: 0.021836, Accuracy: 98.65%\n",
      "Batch 162, Loss: 0.081552, Accuracy: 98.64%\n",
      "Batch 163, Loss: 0.036981, Accuracy: 98.64%\n",
      "Batch 164, Loss: 0.007605, Accuracy: 98.65%\n",
      "Batch 165, Loss: 0.041389, Accuracy: 98.65%\n",
      "Batch 166, Loss: 0.008265, Accuracy: 98.65%\n",
      "Batch 167, Loss: 0.026872, Accuracy: 98.65%\n",
      "Batch 168, Loss: 0.005244, Accuracy: 98.66%\n",
      "Batch 169, Loss: 0.048565, Accuracy: 98.66%\n",
      "Batch 170, Loss: 0.007441, Accuracy: 98.67%\n",
      "Batch 171, Loss: 0.043210, Accuracy: 98.67%\n",
      "Batch 172, Loss: 0.014123, Accuracy: 98.67%\n",
      "Batch 173, Loss: 0.011613, Accuracy: 98.68%\n",
      "Batch 174, Loss: 0.017860, Accuracy: 98.69%\n",
      "Batch 175, Loss: 0.005407, Accuracy: 98.70%\n",
      "Batch 176, Loss: 0.062305, Accuracy: 98.69%\n",
      "Batch 177, Loss: 0.007164, Accuracy: 98.69%\n",
      "Batch 178, Loss: 0.081068, Accuracy: 98.69%\n",
      "Batch 179, Loss: 0.041892, Accuracy: 98.69%\n",
      "Batch 180, Loss: 0.071273, Accuracy: 98.69%\n",
      "Batch 181, Loss: 0.083114, Accuracy: 98.69%\n",
      "Batch 182, Loss: 0.016924, Accuracy: 98.70%\n",
      "Batch 183, Loss: 0.019020, Accuracy: 98.70%\n",
      "Batch 184, Loss: 0.055418, Accuracy: 98.70%\n",
      "Batch 185, Loss: 0.058546, Accuracy: 98.70%\n",
      "Batch 186, Loss: 0.032402, Accuracy: 98.70%\n",
      "Batch 187, Loss: 0.050243, Accuracy: 98.70%\n",
      "Batch 188, Loss: 0.049049, Accuracy: 98.70%\n",
      "Batch 189, Loss: 0.139168, Accuracy: 98.67%\n",
      "Batch 190, Loss: 0.038678, Accuracy: 98.68%\n",
      "Batch 191, Loss: 0.014216, Accuracy: 98.68%\n",
      "Batch 192, Loss: 0.033889, Accuracy: 98.68%\n",
      "Batch 193, Loss: 0.016235, Accuracy: 98.69%\n",
      "Batch 194, Loss: 0.023395, Accuracy: 98.69%\n",
      "Batch 195, Loss: 0.041027, Accuracy: 98.69%\n",
      "Batch 196, Loss: 0.136868, Accuracy: 98.68%\n",
      "Batch 197, Loss: 0.018180, Accuracy: 98.68%\n",
      "Batch 198, Loss: 0.167764, Accuracy: 98.64%\n",
      "Batch 199, Loss: 0.076666, Accuracy: 98.63%\n",
      "Batch 200, Loss: 0.053907, Accuracy: 98.63%\n",
      "Batch 201, Loss: 0.029151, Accuracy: 98.63%\n",
      "Batch 202, Loss: 0.052958, Accuracy: 98.63%\n",
      "Batch 203, Loss: 0.147396, Accuracy: 98.61%\n",
      "Batch 204, Loss: 0.144911, Accuracy: 98.60%\n",
      "Batch 205, Loss: 0.030489, Accuracy: 98.60%\n",
      "Batch 206, Loss: 0.122373, Accuracy: 98.59%\n",
      "Batch 207, Loss: 0.025124, Accuracy: 98.59%\n",
      "Batch 208, Loss: 0.029621, Accuracy: 98.60%\n",
      "Batch 209, Loss: 0.057000, Accuracy: 98.59%\n",
      "Batch 210, Loss: 0.090043, Accuracy: 98.59%\n",
      "Batch 211, Loss: 0.067464, Accuracy: 98.59%\n",
      "Batch 212, Loss: 0.030231, Accuracy: 98.58%\n",
      "Batch 213, Loss: 0.024598, Accuracy: 98.59%\n",
      "Training - Epoch 13, Loss: 0.047027, Accuracy: 98.59%\n",
      "Validation Batch 1, Loss: 0.088754, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.054705, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.034072, Accuracy: 97.92%\n",
      "Validation Batch 4, Loss: 0.063263, Accuracy: 98.05%\n",
      "Validation Batch 5, Loss: 0.030068, Accuracy: 98.12%\n",
      "Validation Batch 6, Loss: 0.027087, Accuracy: 98.18%\n",
      "Validation Batch 7, Loss: 0.079858, Accuracy: 97.99%\n",
      "Validation Batch 8, Loss: 0.118102, Accuracy: 97.85%\n",
      "Validation Batch 9, Loss: 0.148902, Accuracy: 97.57%\n",
      "Validation Batch 10, Loss: 0.012453, Accuracy: 97.81%\n",
      "Validation Batch 11, Loss: 0.040856, Accuracy: 97.87%\n",
      "Validation Batch 12, Loss: 0.011272, Accuracy: 98.05%\n",
      "Validation Batch 13, Loss: 0.064067, Accuracy: 97.96%\n",
      "Validation Batch 14, Loss: 0.150486, Accuracy: 97.66%\n",
      "Validation Batch 15, Loss: 0.027425, Accuracy: 97.81%\n",
      "Validation Batch 16, Loss: 0.118481, Accuracy: 97.85%\n",
      "Validation Batch 17, Loss: 0.039335, Accuracy: 97.89%\n",
      "Validation Batch 18, Loss: 0.007930, Accuracy: 98.00%\n",
      "Validation Batch 19, Loss: 0.039003, Accuracy: 98.03%\n",
      "Validation Batch 20, Loss: 0.094105, Accuracy: 98.05%\n",
      "Validation Batch 21, Loss: 0.078534, Accuracy: 97.99%\n",
      "Validation Batch 22, Loss: 0.029939, Accuracy: 98.01%\n",
      "Validation Batch 23, Loss: 0.088870, Accuracy: 97.96%\n",
      "Validation Batch 24, Loss: 0.118353, Accuracy: 97.92%\n",
      "Validation Batch 25, Loss: 0.009245, Accuracy: 98.00%\n",
      "Validation Batch 26, Loss: 0.051890, Accuracy: 98.02%\n",
      "Validation Batch 27, Loss: 0.016390, Accuracy: 98.06%\n",
      "Validation - Epoch 13, Loss: 0.060868, Accuracy: 98.06%\n",
      "Patience—0\n",
      "Epoch 14\n",
      "Batch 1, Loss: 0.031837, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.032537, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.086171, Accuracy: 97.92%\n",
      "Batch 4, Loss: 0.010395, Accuracy: 98.44%\n",
      "Batch 5, Loss: 0.012199, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.090174, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.090550, Accuracy: 98.21%\n",
      "Batch 8, Loss: 0.013684, Accuracy: 98.44%\n",
      "Batch 9, Loss: 0.022721, Accuracy: 98.44%\n",
      "Batch 10, Loss: 0.060931, Accuracy: 98.28%\n",
      "Batch 11, Loss: 0.033392, Accuracy: 98.30%\n",
      "Batch 12, Loss: 0.026663, Accuracy: 98.44%\n",
      "Batch 13, Loss: 0.077861, Accuracy: 98.44%\n",
      "Batch 14, Loss: 0.014991, Accuracy: 98.55%\n",
      "Batch 15, Loss: 0.082720, Accuracy: 98.23%\n",
      "Batch 16, Loss: 0.068764, Accuracy: 98.14%\n",
      "Batch 17, Loss: 0.072360, Accuracy: 97.98%\n",
      "Batch 18, Loss: 0.122322, Accuracy: 98.00%\n",
      "Batch 19, Loss: 0.011958, Accuracy: 98.11%\n",
      "Batch 20, Loss: 0.146037, Accuracy: 98.05%\n",
      "Batch 21, Loss: 0.016931, Accuracy: 98.14%\n",
      "Batch 22, Loss: 0.150878, Accuracy: 97.94%\n",
      "Batch 23, Loss: 0.043618, Accuracy: 97.96%\n",
      "Batch 24, Loss: 0.149167, Accuracy: 97.72%\n",
      "Batch 25, Loss: 0.049751, Accuracy: 97.75%\n",
      "Batch 26, Loss: 0.017987, Accuracy: 97.84%\n",
      "Batch 27, Loss: 0.022922, Accuracy: 97.92%\n",
      "Batch 28, Loss: 0.006367, Accuracy: 97.99%\n",
      "Batch 29, Loss: 0.065292, Accuracy: 97.95%\n",
      "Batch 30, Loss: 0.011985, Accuracy: 98.02%\n",
      "Batch 31, Loss: 0.141636, Accuracy: 97.88%\n",
      "Batch 32, Loss: 0.029578, Accuracy: 97.90%\n",
      "Batch 33, Loss: 0.010038, Accuracy: 97.96%\n",
      "Batch 34, Loss: 0.023772, Accuracy: 98.02%\n",
      "Batch 35, Loss: 0.040108, Accuracy: 98.04%\n",
      "Batch 36, Loss: 0.016806, Accuracy: 98.09%\n",
      "Batch 37, Loss: 0.109733, Accuracy: 98.06%\n",
      "Batch 38, Loss: 0.012760, Accuracy: 98.11%\n",
      "Batch 39, Loss: 0.098553, Accuracy: 98.04%\n",
      "Batch 40, Loss: 0.023982, Accuracy: 98.05%\n",
      "Batch 41, Loss: 0.066959, Accuracy: 98.06%\n",
      "Batch 42, Loss: 0.037793, Accuracy: 98.07%\n",
      "Batch 43, Loss: 0.069999, Accuracy: 98.04%\n",
      "Batch 44, Loss: 0.025612, Accuracy: 98.08%\n",
      "Batch 45, Loss: 0.017091, Accuracy: 98.12%\n",
      "Batch 46, Loss: 0.061641, Accuracy: 98.13%\n",
      "Batch 47, Loss: 0.009700, Accuracy: 98.17%\n",
      "Batch 48, Loss: 0.011800, Accuracy: 98.21%\n",
      "Batch 49, Loss: 0.015213, Accuracy: 98.25%\n",
      "Batch 50, Loss: 0.098178, Accuracy: 98.22%\n",
      "Batch 51, Loss: 0.063851, Accuracy: 98.22%\n",
      "Batch 52, Loss: 0.021245, Accuracy: 98.26%\n",
      "Batch 53, Loss: 0.021491, Accuracy: 98.26%\n",
      "Batch 54, Loss: 0.042746, Accuracy: 98.23%\n",
      "Batch 55, Loss: 0.112271, Accuracy: 98.21%\n",
      "Batch 56, Loss: 0.051754, Accuracy: 98.21%\n",
      "Batch 57, Loss: 0.030183, Accuracy: 98.22%\n",
      "Batch 58, Loss: 0.021831, Accuracy: 98.22%\n",
      "Batch 59, Loss: 0.052780, Accuracy: 98.20%\n",
      "Batch 60, Loss: 0.013747, Accuracy: 98.23%\n",
      "Batch 61, Loss: 0.073114, Accuracy: 98.23%\n",
      "Batch 62, Loss: 0.038949, Accuracy: 98.24%\n",
      "Batch 63, Loss: 0.055503, Accuracy: 98.24%\n",
      "Batch 64, Loss: 0.024742, Accuracy: 98.27%\n",
      "Batch 65, Loss: 0.008904, Accuracy: 98.29%\n",
      "Batch 66, Loss: 0.012093, Accuracy: 98.32%\n",
      "Batch 67, Loss: 0.062632, Accuracy: 98.30%\n",
      "Batch 68, Loss: 0.013480, Accuracy: 98.32%\n",
      "Batch 69, Loss: 0.064337, Accuracy: 98.32%\n",
      "Batch 70, Loss: 0.021605, Accuracy: 98.35%\n",
      "Batch 71, Loss: 0.006134, Accuracy: 98.37%\n",
      "Batch 72, Loss: 0.008866, Accuracy: 98.39%\n",
      "Batch 73, Loss: 0.069456, Accuracy: 98.39%\n",
      "Batch 74, Loss: 0.011211, Accuracy: 98.42%\n",
      "Batch 75, Loss: 0.007338, Accuracy: 98.44%\n",
      "Batch 76, Loss: 0.008809, Accuracy: 98.46%\n",
      "Batch 77, Loss: 0.007147, Accuracy: 98.48%\n",
      "Batch 78, Loss: 0.055267, Accuracy: 98.46%\n",
      "Batch 79, Loss: 0.007163, Accuracy: 98.48%\n",
      "Batch 80, Loss: 0.014696, Accuracy: 98.50%\n",
      "Batch 81, Loss: 0.043467, Accuracy: 98.50%\n",
      "Batch 82, Loss: 0.015957, Accuracy: 98.51%\n",
      "Batch 83, Loss: 0.013480, Accuracy: 98.53%\n",
      "Batch 84, Loss: 0.006441, Accuracy: 98.55%\n",
      "Batch 85, Loss: 0.029433, Accuracy: 98.55%\n",
      "Batch 86, Loss: 0.013356, Accuracy: 98.56%\n",
      "Batch 87, Loss: 0.070739, Accuracy: 98.55%\n",
      "Batch 88, Loss: 0.057839, Accuracy: 98.54%\n",
      "Batch 89, Loss: 0.022956, Accuracy: 98.54%\n",
      "Batch 90, Loss: 0.010426, Accuracy: 98.56%\n",
      "Batch 91, Loss: 0.043277, Accuracy: 98.54%\n",
      "Batch 92, Loss: 0.004876, Accuracy: 98.56%\n",
      "Batch 93, Loss: 0.015058, Accuracy: 98.57%\n",
      "Batch 94, Loss: 0.018967, Accuracy: 98.59%\n",
      "Batch 95, Loss: 0.158042, Accuracy: 98.54%\n",
      "Batch 96, Loss: 0.009367, Accuracy: 98.55%\n",
      "Batch 97, Loss: 0.014195, Accuracy: 98.57%\n",
      "Batch 98, Loss: 0.008597, Accuracy: 98.58%\n",
      "Batch 99, Loss: 0.009130, Accuracy: 98.60%\n",
      "Batch 100, Loss: 0.120206, Accuracy: 98.59%\n",
      "Batch 101, Loss: 0.007095, Accuracy: 98.61%\n",
      "Batch 102, Loss: 0.016015, Accuracy: 98.62%\n",
      "Batch 103, Loss: 0.009321, Accuracy: 98.63%\n",
      "Batch 104, Loss: 0.043340, Accuracy: 98.63%\n",
      "Batch 105, Loss: 0.033681, Accuracy: 98.63%\n",
      "Batch 106, Loss: 0.064035, Accuracy: 98.63%\n",
      "Batch 107, Loss: 0.024241, Accuracy: 98.63%\n",
      "Batch 108, Loss: 0.099867, Accuracy: 98.61%\n",
      "Batch 109, Loss: 0.006432, Accuracy: 98.62%\n",
      "Batch 110, Loss: 0.012816, Accuracy: 98.64%\n",
      "Batch 111, Loss: 0.031110, Accuracy: 98.63%\n",
      "Batch 112, Loss: 0.019166, Accuracy: 98.63%\n",
      "Batch 113, Loss: 0.022616, Accuracy: 98.63%\n",
      "Batch 114, Loss: 0.006035, Accuracy: 98.64%\n",
      "Batch 115, Loss: 0.035772, Accuracy: 98.64%\n",
      "Batch 116, Loss: 0.064122, Accuracy: 98.64%\n",
      "Batch 117, Loss: 0.007296, Accuracy: 98.65%\n",
      "Batch 118, Loss: 0.031635, Accuracy: 98.65%\n",
      "Batch 119, Loss: 0.006374, Accuracy: 98.66%\n",
      "Batch 120, Loss: 0.008381, Accuracy: 98.67%\n",
      "Batch 121, Loss: 0.015220, Accuracy: 98.68%\n",
      "Batch 122, Loss: 0.038472, Accuracy: 98.68%\n",
      "Batch 123, Loss: 0.151832, Accuracy: 98.65%\n",
      "Batch 124, Loss: 0.029475, Accuracy: 98.65%\n",
      "Batch 125, Loss: 0.085522, Accuracy: 98.65%\n",
      "Batch 126, Loss: 0.017599, Accuracy: 98.66%\n",
      "Batch 127, Loss: 0.008258, Accuracy: 98.67%\n",
      "Batch 128, Loss: 0.035099, Accuracy: 98.67%\n",
      "Batch 129, Loss: 0.009368, Accuracy: 98.68%\n",
      "Batch 130, Loss: 0.035794, Accuracy: 98.68%\n",
      "Batch 131, Loss: 0.039549, Accuracy: 98.68%\n",
      "Batch 132, Loss: 0.095868, Accuracy: 98.66%\n",
      "Batch 133, Loss: 0.008242, Accuracy: 98.67%\n",
      "Batch 134, Loss: 0.009346, Accuracy: 98.68%\n",
      "Batch 135, Loss: 0.033276, Accuracy: 98.68%\n",
      "Batch 136, Loss: 0.031526, Accuracy: 98.68%\n",
      "Batch 137, Loss: 0.026578, Accuracy: 98.68%\n",
      "Batch 138, Loss: 0.008030, Accuracy: 98.69%\n",
      "Batch 139, Loss: 0.012996, Accuracy: 98.70%\n",
      "Batch 140, Loss: 0.016912, Accuracy: 98.71%\n",
      "Batch 141, Loss: 0.015298, Accuracy: 98.70%\n",
      "Batch 142, Loss: 0.006769, Accuracy: 98.71%\n",
      "Batch 143, Loss: 0.007160, Accuracy: 98.72%\n",
      "Batch 144, Loss: 0.018189, Accuracy: 98.73%\n",
      "Batch 145, Loss: 0.009189, Accuracy: 98.74%\n",
      "Batch 146, Loss: 0.009735, Accuracy: 98.75%\n",
      "Batch 147, Loss: 0.025358, Accuracy: 98.75%\n",
      "Batch 148, Loss: 0.036077, Accuracy: 98.74%\n",
      "Batch 149, Loss: 0.009451, Accuracy: 98.75%\n",
      "Batch 150, Loss: 0.011925, Accuracy: 98.76%\n",
      "Batch 151, Loss: 0.019928, Accuracy: 98.77%\n",
      "Batch 152, Loss: 0.042427, Accuracy: 98.77%\n",
      "Batch 153, Loss: 0.006113, Accuracy: 98.77%\n",
      "Batch 154, Loss: 0.004682, Accuracy: 98.78%\n",
      "Batch 155, Loss: 0.086130, Accuracy: 98.78%\n",
      "Batch 156, Loss: 0.007795, Accuracy: 98.79%\n",
      "Batch 157, Loss: 0.007252, Accuracy: 98.80%\n",
      "Batch 158, Loss: 0.012658, Accuracy: 98.80%\n",
      "Batch 159, Loss: 0.029243, Accuracy: 98.80%\n",
      "Batch 160, Loss: 0.009838, Accuracy: 98.81%\n",
      "Batch 161, Loss: 0.005302, Accuracy: 98.82%\n",
      "Batch 162, Loss: 0.007467, Accuracy: 98.82%\n",
      "Batch 163, Loss: 0.008916, Accuracy: 98.83%\n",
      "Batch 164, Loss: 0.005813, Accuracy: 98.84%\n",
      "Batch 165, Loss: 0.004856, Accuracy: 98.84%\n",
      "Batch 166, Loss: 0.008659, Accuracy: 98.85%\n",
      "Batch 167, Loss: 0.008290, Accuracy: 98.86%\n",
      "Batch 168, Loss: 0.009654, Accuracy: 98.87%\n",
      "Batch 169, Loss: 0.012508, Accuracy: 98.87%\n",
      "Batch 170, Loss: 0.010050, Accuracy: 98.88%\n",
      "Batch 171, Loss: 0.003842, Accuracy: 98.89%\n",
      "Batch 172, Loss: 0.009041, Accuracy: 98.89%\n",
      "Batch 173, Loss: 0.081335, Accuracy: 98.89%\n",
      "Batch 174, Loss: 0.007047, Accuracy: 98.90%\n",
      "Batch 175, Loss: 0.006533, Accuracy: 98.90%\n",
      "Batch 176, Loss: 0.005228, Accuracy: 98.91%\n",
      "Batch 177, Loss: 0.005771, Accuracy: 98.91%\n",
      "Batch 178, Loss: 0.025097, Accuracy: 98.91%\n",
      "Batch 179, Loss: 0.026745, Accuracy: 98.91%\n",
      "Batch 180, Loss: 0.006902, Accuracy: 98.91%\n",
      "Batch 181, Loss: 0.008390, Accuracy: 98.92%\n",
      "Batch 182, Loss: 0.014523, Accuracy: 98.93%\n",
      "Batch 183, Loss: 0.009210, Accuracy: 98.93%\n",
      "Batch 184, Loss: 0.003481, Accuracy: 98.94%\n",
      "Batch 185, Loss: 0.048576, Accuracy: 98.94%\n",
      "Batch 186, Loss: 0.025119, Accuracy: 98.93%\n",
      "Batch 187, Loss: 0.003496, Accuracy: 98.94%\n",
      "Batch 188, Loss: 0.011961, Accuracy: 98.94%\n",
      "Batch 189, Loss: 0.025888, Accuracy: 98.94%\n",
      "Batch 190, Loss: 0.007713, Accuracy: 98.95%\n",
      "Batch 191, Loss: 0.008492, Accuracy: 98.95%\n",
      "Batch 192, Loss: 0.059620, Accuracy: 98.95%\n",
      "Batch 193, Loss: 0.019109, Accuracy: 98.95%\n",
      "Batch 194, Loss: 0.087397, Accuracy: 98.93%\n",
      "Batch 195, Loss: 0.003977, Accuracy: 98.93%\n",
      "Batch 196, Loss: 0.008184, Accuracy: 98.94%\n",
      "Batch 197, Loss: 0.013391, Accuracy: 98.95%\n",
      "Batch 198, Loss: 0.031318, Accuracy: 98.94%\n",
      "Batch 199, Loss: 0.004234, Accuracy: 98.95%\n",
      "Batch 200, Loss: 0.054426, Accuracy: 98.95%\n",
      "Batch 201, Loss: 0.020188, Accuracy: 98.95%\n",
      "Batch 202, Loss: 0.005950, Accuracy: 98.96%\n",
      "Batch 203, Loss: 0.007953, Accuracy: 98.96%\n",
      "Batch 204, Loss: 0.006462, Accuracy: 98.97%\n",
      "Batch 205, Loss: 0.012514, Accuracy: 98.97%\n",
      "Batch 206, Loss: 0.003862, Accuracy: 98.98%\n",
      "Batch 207, Loss: 0.041177, Accuracy: 98.97%\n",
      "Batch 208, Loss: 0.019690, Accuracy: 98.97%\n",
      "Batch 209, Loss: 0.100491, Accuracy: 98.97%\n",
      "Batch 210, Loss: 0.004285, Accuracy: 98.97%\n",
      "Batch 211, Loss: 0.057484, Accuracy: 98.97%\n",
      "Batch 212, Loss: 0.013848, Accuracy: 98.98%\n",
      "Batch 213, Loss: 0.065177, Accuracy: 98.97%\n",
      "Training - Epoch 14, Loss: 0.032645, Accuracy: 98.97%\n",
      "Validation Batch 1, Loss: 0.012646, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.081979, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.009057, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.006082, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.005576, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.045583, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.042225, Accuracy: 99.11%\n",
      "Validation Batch 8, Loss: 0.012288, Accuracy: 99.22%\n",
      "Validation Batch 9, Loss: 0.189239, Accuracy: 98.78%\n",
      "Validation Batch 10, Loss: 0.005932, Accuracy: 98.91%\n",
      "Validation Batch 11, Loss: 0.008440, Accuracy: 99.01%\n",
      "Validation Batch 12, Loss: 0.025098, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.066139, Accuracy: 98.80%\n",
      "Validation Batch 14, Loss: 0.097758, Accuracy: 98.55%\n",
      "Validation Batch 15, Loss: 0.010938, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.076706, Accuracy: 98.63%\n",
      "Validation Batch 17, Loss: 0.012244, Accuracy: 98.71%\n",
      "Validation Batch 18, Loss: 0.018925, Accuracy: 98.70%\n",
      "Validation Batch 19, Loss: 0.014260, Accuracy: 98.77%\n",
      "Validation Batch 20, Loss: 0.021258, Accuracy: 98.75%\n",
      "Validation Batch 21, Loss: 0.048179, Accuracy: 98.66%\n",
      "Validation Batch 22, Loss: 0.015250, Accuracy: 98.72%\n",
      "Validation Batch 23, Loss: 0.008587, Accuracy: 98.78%\n",
      "Validation Batch 24, Loss: 0.112458, Accuracy: 98.76%\n",
      "Validation Batch 25, Loss: 0.013167, Accuracy: 98.81%\n",
      "Validation Batch 26, Loss: 0.006074, Accuracy: 98.86%\n",
      "Validation Batch 27, Loss: 0.005441, Accuracy: 98.88%\n",
      "Validation - Epoch 14, Loss: 0.035983, Accuracy: 98.88%\n",
      "Patience—0\n",
      "Epoch 15\n",
      "Batch 1, Loss: 0.003645, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.005066, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.004985, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.006182, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.005672, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.007552, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.006297, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.016413, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.037917, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.007719, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.011056, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.043807, Accuracy: 99.74%\n",
      "Batch 13, Loss: 0.014750, Accuracy: 99.76%\n",
      "Batch 14, Loss: 0.072704, Accuracy: 99.44%\n",
      "Batch 15, Loss: 0.013947, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.017819, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.007882, Accuracy: 99.54%\n",
      "Batch 18, Loss: 0.059899, Accuracy: 99.48%\n",
      "Batch 19, Loss: 0.008342, Accuracy: 99.51%\n",
      "Batch 20, Loss: 0.005589, Accuracy: 99.53%\n",
      "Batch 21, Loss: 0.005830, Accuracy: 99.55%\n",
      "Batch 22, Loss: 0.026795, Accuracy: 99.50%\n",
      "Batch 23, Loss: 0.004499, Accuracy: 99.52%\n",
      "Batch 24, Loss: 0.015133, Accuracy: 99.54%\n",
      "Batch 25, Loss: 0.013587, Accuracy: 99.56%\n",
      "Batch 26, Loss: 0.012095, Accuracy: 99.58%\n",
      "Batch 27, Loss: 0.078745, Accuracy: 99.54%\n",
      "Batch 28, Loss: 0.017285, Accuracy: 99.55%\n",
      "Batch 29, Loss: 0.023335, Accuracy: 99.52%\n",
      "Batch 30, Loss: 0.011409, Accuracy: 99.53%\n",
      "Batch 31, Loss: 0.004690, Accuracy: 99.55%\n",
      "Batch 32, Loss: 0.008840, Accuracy: 99.56%\n",
      "Batch 33, Loss: 0.011397, Accuracy: 99.57%\n",
      "Batch 34, Loss: 0.084885, Accuracy: 99.54%\n",
      "Batch 35, Loss: 0.027432, Accuracy: 99.51%\n",
      "Batch 36, Loss: 0.004232, Accuracy: 99.52%\n",
      "Batch 37, Loss: 0.011963, Accuracy: 99.54%\n",
      "Batch 38, Loss: 0.010825, Accuracy: 99.55%\n",
      "Batch 39, Loss: 0.004485, Accuracy: 99.56%\n",
      "Batch 40, Loss: 0.016405, Accuracy: 99.57%\n",
      "Batch 41, Loss: 0.149561, Accuracy: 99.43%\n",
      "Batch 42, Loss: 0.009169, Accuracy: 99.44%\n",
      "Batch 43, Loss: 0.006270, Accuracy: 99.45%\n",
      "Batch 44, Loss: 0.006605, Accuracy: 99.47%\n",
      "Batch 45, Loss: 0.088111, Accuracy: 99.44%\n",
      "Batch 46, Loss: 0.007503, Accuracy: 99.46%\n",
      "Batch 47, Loss: 0.003847, Accuracy: 99.47%\n",
      "Batch 48, Loss: 0.014924, Accuracy: 99.48%\n",
      "Batch 49, Loss: 0.005724, Accuracy: 99.49%\n",
      "Batch 50, Loss: 0.005694, Accuracy: 99.50%\n",
      "Batch 51, Loss: 0.023457, Accuracy: 99.48%\n",
      "Batch 52, Loss: 0.003847, Accuracy: 99.49%\n",
      "Batch 53, Loss: 0.008333, Accuracy: 99.50%\n",
      "Batch 54, Loss: 0.055779, Accuracy: 99.48%\n",
      "Batch 55, Loss: 0.010130, Accuracy: 99.49%\n",
      "Batch 56, Loss: 0.003951, Accuracy: 99.50%\n",
      "Batch 57, Loss: 0.005997, Accuracy: 99.51%\n",
      "Batch 58, Loss: 0.008050, Accuracy: 99.52%\n",
      "Batch 59, Loss: 0.011944, Accuracy: 99.52%\n",
      "Batch 60, Loss: 0.012409, Accuracy: 99.53%\n",
      "Batch 61, Loss: 0.005868, Accuracy: 99.54%\n",
      "Batch 62, Loss: 0.008380, Accuracy: 99.55%\n",
      "Batch 63, Loss: 0.028493, Accuracy: 99.53%\n",
      "Batch 64, Loss: 0.019372, Accuracy: 99.54%\n",
      "Batch 65, Loss: 0.003707, Accuracy: 99.54%\n",
      "Batch 66, Loss: 0.004707, Accuracy: 99.55%\n",
      "Batch 67, Loss: 0.004282, Accuracy: 99.56%\n",
      "Batch 68, Loss: 0.077200, Accuracy: 99.54%\n",
      "Batch 69, Loss: 0.012582, Accuracy: 99.55%\n",
      "Batch 70, Loss: 0.028386, Accuracy: 99.53%\n",
      "Batch 71, Loss: 0.009048, Accuracy: 99.54%\n",
      "Batch 72, Loss: 0.010288, Accuracy: 99.54%\n",
      "Batch 73, Loss: 0.020646, Accuracy: 99.55%\n",
      "Batch 74, Loss: 0.006917, Accuracy: 99.56%\n",
      "Batch 75, Loss: 0.021567, Accuracy: 99.56%\n",
      "Batch 76, Loss: 0.088005, Accuracy: 99.53%\n",
      "Batch 77, Loss: 0.010831, Accuracy: 99.53%\n",
      "Batch 78, Loss: 0.006744, Accuracy: 99.54%\n",
      "Batch 79, Loss: 0.004288, Accuracy: 99.55%\n",
      "Batch 80, Loss: 0.005563, Accuracy: 99.55%\n",
      "Batch 81, Loss: 0.004233, Accuracy: 99.56%\n",
      "Batch 82, Loss: 0.015030, Accuracy: 99.56%\n",
      "Batch 83, Loss: 0.064448, Accuracy: 99.55%\n",
      "Batch 84, Loss: 0.012386, Accuracy: 99.55%\n",
      "Batch 85, Loss: 0.004718, Accuracy: 99.56%\n",
      "Batch 86, Loss: 0.006948, Accuracy: 99.56%\n",
      "Batch 87, Loss: 0.076504, Accuracy: 99.55%\n",
      "Batch 88, Loss: 0.053591, Accuracy: 99.52%\n",
      "Batch 89, Loss: 0.138519, Accuracy: 99.47%\n",
      "Batch 90, Loss: 0.005304, Accuracy: 99.48%\n",
      "Batch 91, Loss: 0.011489, Accuracy: 99.48%\n",
      "Batch 92, Loss: 0.046450, Accuracy: 99.47%\n",
      "Batch 93, Loss: 0.006458, Accuracy: 99.48%\n",
      "Batch 94, Loss: 0.005724, Accuracy: 99.48%\n",
      "Batch 95, Loss: 0.005689, Accuracy: 99.49%\n",
      "Batch 96, Loss: 0.010591, Accuracy: 99.50%\n",
      "Batch 97, Loss: 0.005495, Accuracy: 99.50%\n",
      "Batch 98, Loss: 0.031889, Accuracy: 99.49%\n",
      "Batch 99, Loss: 0.011515, Accuracy: 99.49%\n",
      "Batch 100, Loss: 0.057349, Accuracy: 99.47%\n",
      "Batch 101, Loss: 0.156479, Accuracy: 99.43%\n",
      "Batch 102, Loss: 0.004830, Accuracy: 99.43%\n",
      "Batch 103, Loss: 0.016916, Accuracy: 99.44%\n",
      "Batch 104, Loss: 0.017418, Accuracy: 99.44%\n",
      "Batch 105, Loss: 0.024307, Accuracy: 99.45%\n",
      "Batch 106, Loss: 0.126909, Accuracy: 99.43%\n",
      "Batch 107, Loss: 0.082979, Accuracy: 99.40%\n",
      "Batch 108, Loss: 0.018074, Accuracy: 99.41%\n",
      "Batch 109, Loss: 0.005479, Accuracy: 99.41%\n",
      "Batch 110, Loss: 0.022535, Accuracy: 99.42%\n",
      "Batch 111, Loss: 0.004835, Accuracy: 99.42%\n",
      "Batch 112, Loss: 0.091514, Accuracy: 99.41%\n",
      "Batch 113, Loss: 0.024937, Accuracy: 99.41%\n",
      "Batch 114, Loss: 0.018156, Accuracy: 99.41%\n",
      "Batch 115, Loss: 0.197211, Accuracy: 99.38%\n",
      "Batch 116, Loss: 0.009320, Accuracy: 99.38%\n",
      "Batch 117, Loss: 0.016049, Accuracy: 99.39%\n",
      "Batch 118, Loss: 0.045294, Accuracy: 99.38%\n",
      "Batch 119, Loss: 0.072412, Accuracy: 99.37%\n",
      "Batch 120, Loss: 0.003553, Accuracy: 99.38%\n",
      "Batch 121, Loss: 0.026041, Accuracy: 99.38%\n",
      "Batch 122, Loss: 0.075452, Accuracy: 99.37%\n",
      "Batch 123, Loss: 0.110354, Accuracy: 99.36%\n",
      "Batch 124, Loss: 0.043533, Accuracy: 99.36%\n",
      "Batch 125, Loss: 0.040219, Accuracy: 99.35%\n",
      "Batch 126, Loss: 0.113990, Accuracy: 99.33%\n",
      "Batch 127, Loss: 0.066997, Accuracy: 99.32%\n",
      "Batch 128, Loss: 0.068796, Accuracy: 99.32%\n",
      "Batch 129, Loss: 0.054553, Accuracy: 99.31%\n",
      "Batch 130, Loss: 0.146308, Accuracy: 99.28%\n",
      "Batch 131, Loss: 0.114218, Accuracy: 99.25%\n",
      "Batch 132, Loss: 0.028341, Accuracy: 99.24%\n",
      "Batch 133, Loss: 0.113006, Accuracy: 99.24%\n",
      "Batch 134, Loss: 0.098976, Accuracy: 99.22%\n",
      "Batch 135, Loss: 0.010165, Accuracy: 99.22%\n",
      "Batch 136, Loss: 0.033692, Accuracy: 99.22%\n",
      "Batch 137, Loss: 0.030242, Accuracy: 99.21%\n",
      "Batch 138, Loss: 0.069203, Accuracy: 99.21%\n",
      "Batch 139, Loss: 0.103705, Accuracy: 99.19%\n",
      "Batch 140, Loss: 0.029236, Accuracy: 99.19%\n",
      "Batch 141, Loss: 0.064205, Accuracy: 99.18%\n",
      "Batch 142, Loss: 0.005700, Accuracy: 99.19%\n",
      "Batch 143, Loss: 0.017023, Accuracy: 99.19%\n",
      "Batch 144, Loss: 0.014567, Accuracy: 99.20%\n",
      "Batch 145, Loss: 0.007167, Accuracy: 99.20%\n",
      "Batch 146, Loss: 0.006906, Accuracy: 99.21%\n",
      "Batch 147, Loss: 0.014041, Accuracy: 99.21%\n",
      "Batch 148, Loss: 0.020443, Accuracy: 99.22%\n",
      "Batch 149, Loss: 0.053429, Accuracy: 99.21%\n",
      "Batch 150, Loss: 0.049501, Accuracy: 99.20%\n",
      "Batch 151, Loss: 0.048749, Accuracy: 99.18%\n",
      "Batch 152, Loss: 0.007264, Accuracy: 99.19%\n",
      "Batch 153, Loss: 0.018418, Accuracy: 99.18%\n",
      "Batch 154, Loss: 0.070433, Accuracy: 99.16%\n",
      "Batch 155, Loss: 0.004686, Accuracy: 99.16%\n",
      "Batch 156, Loss: 0.066835, Accuracy: 99.16%\n",
      "Batch 157, Loss: 0.111961, Accuracy: 99.14%\n",
      "Batch 158, Loss: 0.004739, Accuracy: 99.15%\n",
      "Batch 159, Loss: 0.033805, Accuracy: 99.15%\n",
      "Batch 160, Loss: 0.025541, Accuracy: 99.15%\n",
      "Batch 161, Loss: 0.056097, Accuracy: 99.15%\n",
      "Batch 162, Loss: 0.098420, Accuracy: 99.14%\n",
      "Batch 163, Loss: 0.038664, Accuracy: 99.14%\n",
      "Batch 164, Loss: 0.027849, Accuracy: 99.13%\n",
      "Batch 165, Loss: 0.128296, Accuracy: 99.11%\n",
      "Batch 166, Loss: 0.038901, Accuracy: 99.11%\n",
      "Batch 167, Loss: 0.023169, Accuracy: 99.10%\n",
      "Batch 168, Loss: 0.072620, Accuracy: 99.09%\n",
      "Batch 169, Loss: 0.051667, Accuracy: 99.08%\n",
      "Batch 170, Loss: 0.062377, Accuracy: 99.06%\n",
      "Batch 171, Loss: 0.015550, Accuracy: 99.07%\n",
      "Batch 172, Loss: 0.053760, Accuracy: 99.06%\n",
      "Batch 173, Loss: 0.114508, Accuracy: 99.04%\n",
      "Batch 174, Loss: 0.019254, Accuracy: 99.05%\n",
      "Batch 175, Loss: 0.139589, Accuracy: 99.03%\n",
      "Batch 176, Loss: 0.036947, Accuracy: 99.02%\n",
      "Batch 177, Loss: 0.030091, Accuracy: 99.02%\n",
      "Batch 178, Loss: 0.061714, Accuracy: 99.01%\n",
      "Batch 179, Loss: 0.117394, Accuracy: 99.00%\n",
      "Batch 180, Loss: 0.151032, Accuracy: 98.97%\n",
      "Batch 181, Loss: 0.147381, Accuracy: 98.95%\n",
      "Batch 182, Loss: 0.058172, Accuracy: 98.94%\n",
      "Batch 183, Loss: 0.052086, Accuracy: 98.93%\n",
      "Batch 184, Loss: 0.122969, Accuracy: 98.91%\n",
      "Batch 185, Loss: 0.038881, Accuracy: 98.91%\n",
      "Batch 186, Loss: 0.016897, Accuracy: 98.91%\n",
      "Batch 187, Loss: 0.094108, Accuracy: 98.90%\n",
      "Batch 188, Loss: 0.014791, Accuracy: 98.90%\n",
      "Batch 189, Loss: 0.041411, Accuracy: 98.90%\n",
      "Batch 190, Loss: 0.190119, Accuracy: 98.88%\n",
      "Batch 191, Loss: 0.086908, Accuracy: 98.87%\n",
      "Batch 192, Loss: 0.094262, Accuracy: 98.86%\n",
      "Batch 193, Loss: 0.102523, Accuracy: 98.85%\n",
      "Batch 194, Loss: 0.023795, Accuracy: 98.85%\n",
      "Batch 195, Loss: 0.209200, Accuracy: 98.82%\n",
      "Batch 196, Loss: 0.065449, Accuracy: 98.82%\n",
      "Batch 197, Loss: 0.117073, Accuracy: 98.82%\n",
      "Batch 198, Loss: 0.064810, Accuracy: 98.82%\n",
      "Batch 199, Loss: 0.056687, Accuracy: 98.81%\n",
      "Batch 200, Loss: 0.068837, Accuracy: 98.80%\n",
      "Batch 201, Loss: 0.089766, Accuracy: 98.80%\n",
      "Batch 202, Loss: 0.129428, Accuracy: 98.79%\n",
      "Batch 203, Loss: 0.010361, Accuracy: 98.79%\n",
      "Batch 204, Loss: 0.133975, Accuracy: 98.78%\n",
      "Batch 205, Loss: 0.014572, Accuracy: 98.79%\n",
      "Batch 206, Loss: 0.087101, Accuracy: 98.79%\n",
      "Batch 207, Loss: 0.125661, Accuracy: 98.77%\n",
      "Batch 208, Loss: 0.051908, Accuracy: 98.77%\n",
      "Batch 209, Loss: 0.027936, Accuracy: 98.77%\n",
      "Batch 210, Loss: 0.131048, Accuracy: 98.76%\n",
      "Batch 211, Loss: 0.097385, Accuracy: 98.76%\n",
      "Batch 212, Loss: 0.045105, Accuracy: 98.76%\n",
      "Batch 213, Loss: 0.158551, Accuracy: 98.75%\n",
      "Training - Epoch 15, Loss: 0.043344, Accuracy: 98.75%\n",
      "Validation Batch 1, Loss: 0.066014, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.081635, Accuracy: 96.09%\n",
      "Validation Batch 3, Loss: 0.029124, Accuracy: 97.40%\n",
      "Validation Batch 4, Loss: 0.024918, Accuracy: 97.66%\n",
      "Validation Batch 5, Loss: 0.046920, Accuracy: 97.81%\n",
      "Validation Batch 6, Loss: 0.058369, Accuracy: 97.92%\n",
      "Validation Batch 7, Loss: 0.007058, Accuracy: 98.21%\n",
      "Validation Batch 8, Loss: 0.071458, Accuracy: 98.24%\n",
      "Validation Batch 9, Loss: 0.126326, Accuracy: 97.92%\n",
      "Validation Batch 10, Loss: 0.072105, Accuracy: 97.97%\n",
      "Validation Batch 11, Loss: 0.091450, Accuracy: 97.87%\n",
      "Validation Batch 12, Loss: 0.090777, Accuracy: 97.92%\n",
      "Validation Batch 13, Loss: 0.091479, Accuracy: 97.72%\n",
      "Validation Batch 14, Loss: 0.103086, Accuracy: 97.54%\n",
      "Validation Batch 15, Loss: 0.048073, Accuracy: 97.60%\n",
      "Validation Batch 16, Loss: 0.123281, Accuracy: 97.56%\n",
      "Validation Batch 17, Loss: 0.057875, Accuracy: 97.61%\n",
      "Validation Batch 18, Loss: 0.055716, Accuracy: 97.66%\n",
      "Validation Batch 19, Loss: 0.104721, Accuracy: 97.62%\n",
      "Validation Batch 20, Loss: 0.017974, Accuracy: 97.73%\n",
      "Validation Batch 21, Loss: 0.166714, Accuracy: 97.47%\n",
      "Validation Batch 22, Loss: 0.099816, Accuracy: 97.23%\n",
      "Validation Batch 23, Loss: 0.039222, Accuracy: 97.28%\n",
      "Validation Batch 24, Loss: 0.133205, Accuracy: 97.27%\n",
      "Validation Batch 25, Loss: 0.027281, Accuracy: 97.31%\n",
      "Validation Batch 26, Loss: 0.031558, Accuracy: 97.42%\n",
      "Validation Batch 27, Loss: 0.142219, Accuracy: 97.42%\n",
      "Validation - Epoch 15, Loss: 0.074384, Accuracy: 97.42%\n",
      "Patience—1\n",
      "Epoch 16\n",
      "Batch 1, Loss: 0.015956, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.064766, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.114260, Accuracy: 98.44%\n",
      "Batch 4, Loss: 0.007306, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.073535, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.017539, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.024343, Accuracy: 98.66%\n",
      "Batch 8, Loss: 0.096028, Accuracy: 98.44%\n",
      "Batch 9, Loss: 0.044949, Accuracy: 98.44%\n",
      "Batch 10, Loss: 0.024264, Accuracy: 98.59%\n",
      "Batch 11, Loss: 0.017267, Accuracy: 98.72%\n",
      "Batch 12, Loss: 0.021911, Accuracy: 98.83%\n",
      "Batch 13, Loss: 0.039492, Accuracy: 98.80%\n",
      "Batch 14, Loss: 0.046479, Accuracy: 98.77%\n",
      "Batch 15, Loss: 0.074850, Accuracy: 98.65%\n",
      "Batch 16, Loss: 0.030728, Accuracy: 98.73%\n",
      "Batch 17, Loss: 0.011598, Accuracy: 98.81%\n",
      "Batch 18, Loss: 0.013730, Accuracy: 98.87%\n",
      "Batch 19, Loss: 0.009749, Accuracy: 98.93%\n",
      "Batch 20, Loss: 0.038268, Accuracy: 98.91%\n",
      "Batch 21, Loss: 0.010076, Accuracy: 98.96%\n",
      "Batch 22, Loss: 0.010223, Accuracy: 99.01%\n",
      "Batch 23, Loss: 0.038469, Accuracy: 98.98%\n",
      "Batch 24, Loss: 0.005309, Accuracy: 99.02%\n",
      "Batch 25, Loss: 0.006408, Accuracy: 99.06%\n",
      "Batch 26, Loss: 0.021659, Accuracy: 99.10%\n",
      "Batch 27, Loss: 0.010178, Accuracy: 99.13%\n",
      "Batch 28, Loss: 0.086498, Accuracy: 99.05%\n",
      "Batch 29, Loss: 0.015920, Accuracy: 99.08%\n",
      "Batch 30, Loss: 0.011609, Accuracy: 99.11%\n",
      "Batch 31, Loss: 0.080828, Accuracy: 99.04%\n",
      "Batch 32, Loss: 0.043323, Accuracy: 99.02%\n",
      "Batch 33, Loss: 0.006250, Accuracy: 99.05%\n",
      "Batch 34, Loss: 0.007450, Accuracy: 99.08%\n",
      "Batch 35, Loss: 0.012973, Accuracy: 99.11%\n",
      "Batch 36, Loss: 0.006013, Accuracy: 99.13%\n",
      "Batch 37, Loss: 0.037382, Accuracy: 99.11%\n",
      "Batch 38, Loss: 0.067264, Accuracy: 99.10%\n",
      "Batch 39, Loss: 0.050247, Accuracy: 99.08%\n",
      "Batch 40, Loss: 0.035778, Accuracy: 99.06%\n",
      "Batch 41, Loss: 0.056078, Accuracy: 99.05%\n",
      "Batch 42, Loss: 0.049886, Accuracy: 99.03%\n",
      "Batch 43, Loss: 0.004602, Accuracy: 99.06%\n",
      "Batch 44, Loss: 0.010111, Accuracy: 99.08%\n",
      "Batch 45, Loss: 0.055607, Accuracy: 99.03%\n",
      "Batch 46, Loss: 0.079891, Accuracy: 98.98%\n",
      "Batch 47, Loss: 0.041399, Accuracy: 98.94%\n",
      "Batch 48, Loss: 0.062209, Accuracy: 98.89%\n",
      "Batch 49, Loss: 0.041207, Accuracy: 98.88%\n",
      "Batch 50, Loss: 0.011702, Accuracy: 98.91%\n",
      "Batch 51, Loss: 0.009634, Accuracy: 98.93%\n",
      "Batch 52, Loss: 0.057185, Accuracy: 98.92%\n",
      "Batch 53, Loss: 0.008873, Accuracy: 98.94%\n",
      "Batch 54, Loss: 0.060558, Accuracy: 98.90%\n",
      "Batch 55, Loss: 0.033798, Accuracy: 98.89%\n",
      "Batch 56, Loss: 0.015016, Accuracy: 98.91%\n",
      "Batch 57, Loss: 0.008787, Accuracy: 98.93%\n",
      "Batch 58, Loss: 0.018174, Accuracy: 98.92%\n",
      "Batch 59, Loss: 0.016782, Accuracy: 98.94%\n",
      "Batch 60, Loss: 0.024951, Accuracy: 98.96%\n",
      "Batch 61, Loss: 0.058966, Accuracy: 98.95%\n",
      "Batch 62, Loss: 0.007618, Accuracy: 98.97%\n",
      "Batch 63, Loss: 0.114597, Accuracy: 98.96%\n",
      "Batch 64, Loss: 0.015443, Accuracy: 98.97%\n",
      "Batch 65, Loss: 0.011943, Accuracy: 98.99%\n",
      "Batch 66, Loss: 0.006183, Accuracy: 99.01%\n",
      "Batch 67, Loss: 0.054336, Accuracy: 99.00%\n",
      "Batch 68, Loss: 0.008032, Accuracy: 99.01%\n",
      "Batch 69, Loss: 0.019395, Accuracy: 99.03%\n",
      "Batch 70, Loss: 0.015719, Accuracy: 99.04%\n",
      "Batch 71, Loss: 0.025767, Accuracy: 99.03%\n",
      "Batch 72, Loss: 0.008512, Accuracy: 99.05%\n",
      "Batch 73, Loss: 0.030413, Accuracy: 99.04%\n",
      "Batch 74, Loss: 0.007414, Accuracy: 99.05%\n",
      "Batch 75, Loss: 0.016691, Accuracy: 99.06%\n",
      "Batch 76, Loss: 0.012028, Accuracy: 99.07%\n",
      "Batch 77, Loss: 0.008319, Accuracy: 99.09%\n",
      "Batch 78, Loss: 0.008636, Accuracy: 99.10%\n",
      "Batch 79, Loss: 0.004217, Accuracy: 99.11%\n",
      "Batch 80, Loss: 0.005793, Accuracy: 99.12%\n",
      "Batch 81, Loss: 0.008369, Accuracy: 99.13%\n",
      "Batch 82, Loss: 0.023429, Accuracy: 99.14%\n",
      "Batch 83, Loss: 0.008385, Accuracy: 99.15%\n",
      "Batch 84, Loss: 0.045139, Accuracy: 99.13%\n",
      "Batch 85, Loss: 0.004753, Accuracy: 99.14%\n",
      "Batch 86, Loss: 0.008317, Accuracy: 99.15%\n",
      "Batch 87, Loss: 0.032970, Accuracy: 99.14%\n",
      "Batch 88, Loss: 0.012011, Accuracy: 99.15%\n",
      "Batch 89, Loss: 0.016107, Accuracy: 99.16%\n",
      "Batch 90, Loss: 0.006737, Accuracy: 99.17%\n",
      "Batch 91, Loss: 0.025141, Accuracy: 99.18%\n",
      "Batch 92, Loss: 0.048182, Accuracy: 99.17%\n",
      "Batch 93, Loss: 0.009739, Accuracy: 99.18%\n",
      "Batch 94, Loss: 0.011451, Accuracy: 99.19%\n",
      "Batch 95, Loss: 0.018122, Accuracy: 99.19%\n",
      "Batch 96, Loss: 0.012913, Accuracy: 99.20%\n",
      "Batch 97, Loss: 0.009413, Accuracy: 99.21%\n",
      "Batch 98, Loss: 0.014589, Accuracy: 99.22%\n",
      "Batch 99, Loss: 0.005492, Accuracy: 99.23%\n",
      "Batch 100, Loss: 0.095365, Accuracy: 99.20%\n",
      "Batch 101, Loss: 0.014870, Accuracy: 99.21%\n",
      "Batch 102, Loss: 0.024074, Accuracy: 99.20%\n",
      "Batch 103, Loss: 0.012225, Accuracy: 99.21%\n",
      "Batch 104, Loss: 0.016884, Accuracy: 99.20%\n",
      "Batch 105, Loss: 0.004339, Accuracy: 99.21%\n",
      "Batch 106, Loss: 0.032710, Accuracy: 99.20%\n",
      "Batch 107, Loss: 0.030515, Accuracy: 99.21%\n",
      "Batch 108, Loss: 0.006156, Accuracy: 99.22%\n",
      "Batch 109, Loss: 0.018145, Accuracy: 99.21%\n",
      "Batch 110, Loss: 0.045432, Accuracy: 99.19%\n",
      "Batch 111, Loss: 0.006262, Accuracy: 99.20%\n",
      "Batch 112, Loss: 0.010744, Accuracy: 99.20%\n",
      "Batch 113, Loss: 0.003959, Accuracy: 99.21%\n",
      "Batch 114, Loss: 0.028487, Accuracy: 99.21%\n",
      "Batch 115, Loss: 0.003834, Accuracy: 99.21%\n",
      "Batch 116, Loss: 0.007287, Accuracy: 99.22%\n",
      "Batch 117, Loss: 0.012198, Accuracy: 99.23%\n",
      "Batch 118, Loss: 0.005242, Accuracy: 99.23%\n",
      "Batch 119, Loss: 0.006372, Accuracy: 99.24%\n",
      "Batch 120, Loss: 0.003525, Accuracy: 99.24%\n",
      "Batch 121, Loss: 0.007033, Accuracy: 99.25%\n",
      "Batch 122, Loss: 0.003882, Accuracy: 99.26%\n",
      "Batch 123, Loss: 0.018231, Accuracy: 99.26%\n",
      "Batch 124, Loss: 0.128633, Accuracy: 99.24%\n",
      "Batch 125, Loss: 0.009039, Accuracy: 99.25%\n",
      "Batch 126, Loss: 0.070900, Accuracy: 99.24%\n",
      "Batch 127, Loss: 0.008321, Accuracy: 99.25%\n",
      "Batch 128, Loss: 0.098243, Accuracy: 99.23%\n",
      "Batch 129, Loss: 0.013808, Accuracy: 99.24%\n",
      "Batch 130, Loss: 0.006904, Accuracy: 99.24%\n",
      "Batch 131, Loss: 0.009501, Accuracy: 99.25%\n",
      "Batch 132, Loss: 0.004812, Accuracy: 99.25%\n",
      "Batch 133, Loss: 0.003236, Accuracy: 99.26%\n",
      "Batch 134, Loss: 0.015635, Accuracy: 99.27%\n",
      "Batch 135, Loss: 0.005368, Accuracy: 99.27%\n",
      "Batch 136, Loss: 0.075618, Accuracy: 99.26%\n",
      "Batch 137, Loss: 0.004951, Accuracy: 99.27%\n",
      "Batch 138, Loss: 0.010612, Accuracy: 99.28%\n",
      "Batch 139, Loss: 0.005980, Accuracy: 99.28%\n",
      "Batch 140, Loss: 0.005909, Accuracy: 99.29%\n",
      "Batch 141, Loss: 0.009145, Accuracy: 99.29%\n",
      "Batch 142, Loss: 0.024795, Accuracy: 99.30%\n",
      "Batch 143, Loss: 0.021945, Accuracy: 99.29%\n",
      "Batch 144, Loss: 0.010613, Accuracy: 99.29%\n",
      "Batch 145, Loss: 0.003513, Accuracy: 99.30%\n",
      "Batch 146, Loss: 0.024224, Accuracy: 99.29%\n",
      "Batch 147, Loss: 0.009868, Accuracy: 99.30%\n",
      "Batch 148, Loss: 0.009583, Accuracy: 99.30%\n",
      "Batch 149, Loss: 0.085657, Accuracy: 99.30%\n",
      "Batch 150, Loss: 0.111364, Accuracy: 99.29%\n",
      "Batch 151, Loss: 0.024637, Accuracy: 99.30%\n",
      "Batch 152, Loss: 0.044417, Accuracy: 99.29%\n",
      "Batch 153, Loss: 0.005458, Accuracy: 99.30%\n",
      "Batch 154, Loss: 0.005550, Accuracy: 99.30%\n",
      "Batch 155, Loss: 0.027119, Accuracy: 99.29%\n",
      "Batch 156, Loss: 0.007308, Accuracy: 99.30%\n",
      "Batch 157, Loss: 0.004433, Accuracy: 99.30%\n",
      "Batch 158, Loss: 0.004158, Accuracy: 99.31%\n",
      "Batch 159, Loss: 0.003459, Accuracy: 99.31%\n",
      "Batch 160, Loss: 0.004849, Accuracy: 99.32%\n",
      "Batch 161, Loss: 0.025564, Accuracy: 99.31%\n",
      "Batch 162, Loss: 0.066268, Accuracy: 99.30%\n",
      "Batch 163, Loss: 0.003969, Accuracy: 99.30%\n",
      "Batch 164, Loss: 0.015576, Accuracy: 99.30%\n",
      "Batch 165, Loss: 0.006643, Accuracy: 99.31%\n",
      "Batch 166, Loss: 0.013606, Accuracy: 99.31%\n",
      "Batch 167, Loss: 0.003660, Accuracy: 99.32%\n",
      "Batch 168, Loss: 0.004992, Accuracy: 99.32%\n",
      "Batch 169, Loss: 0.010178, Accuracy: 99.33%\n",
      "Batch 170, Loss: 0.004545, Accuracy: 99.33%\n",
      "Batch 171, Loss: 0.004658, Accuracy: 99.33%\n",
      "Batch 172, Loss: 0.005092, Accuracy: 99.34%\n",
      "Batch 173, Loss: 0.153801, Accuracy: 99.31%\n",
      "Batch 174, Loss: 0.003761, Accuracy: 99.32%\n",
      "Batch 175, Loss: 0.005015, Accuracy: 99.32%\n",
      "Batch 176, Loss: 0.045992, Accuracy: 99.32%\n",
      "Batch 177, Loss: 0.004359, Accuracy: 99.32%\n",
      "Batch 178, Loss: 0.006154, Accuracy: 99.32%\n",
      "Batch 179, Loss: 0.012249, Accuracy: 99.33%\n",
      "Batch 180, Loss: 0.049066, Accuracy: 99.32%\n",
      "Batch 181, Loss: 0.004775, Accuracy: 99.33%\n",
      "Batch 182, Loss: 0.033038, Accuracy: 99.32%\n",
      "Batch 183, Loss: 0.012803, Accuracy: 99.33%\n",
      "Batch 184, Loss: 0.005278, Accuracy: 99.33%\n",
      "Batch 185, Loss: 0.020573, Accuracy: 99.32%\n",
      "Batch 186, Loss: 0.041710, Accuracy: 99.32%\n",
      "Batch 187, Loss: 0.044548, Accuracy: 99.31%\n",
      "Batch 188, Loss: 0.072969, Accuracy: 99.30%\n",
      "Batch 189, Loss: 0.038831, Accuracy: 99.30%\n",
      "Batch 190, Loss: 0.012688, Accuracy: 99.30%\n",
      "Batch 191, Loss: 0.005575, Accuracy: 99.30%\n",
      "Batch 192, Loss: 0.007599, Accuracy: 99.31%\n",
      "Batch 193, Loss: 0.007100, Accuracy: 99.31%\n",
      "Batch 194, Loss: 0.073686, Accuracy: 99.31%\n",
      "Batch 195, Loss: 0.004734, Accuracy: 99.31%\n",
      "Batch 196, Loss: 0.052061, Accuracy: 99.31%\n",
      "Batch 197, Loss: 0.130028, Accuracy: 99.29%\n",
      "Batch 198, Loss: 0.084564, Accuracy: 99.29%\n",
      "Batch 199, Loss: 0.056987, Accuracy: 99.28%\n",
      "Batch 200, Loss: 0.009218, Accuracy: 99.28%\n",
      "Batch 201, Loss: 0.009750, Accuracy: 99.28%\n",
      "Batch 202, Loss: 0.012359, Accuracy: 99.29%\n",
      "Batch 203, Loss: 0.054799, Accuracy: 99.28%\n",
      "Batch 204, Loss: 0.018796, Accuracy: 99.29%\n",
      "Batch 205, Loss: 0.033356, Accuracy: 99.29%\n",
      "Batch 206, Loss: 0.100223, Accuracy: 99.28%\n",
      "Batch 207, Loss: 0.014674, Accuracy: 99.28%\n",
      "Batch 208, Loss: 0.007146, Accuracy: 99.29%\n",
      "Batch 209, Loss: 0.040310, Accuracy: 99.28%\n",
      "Batch 210, Loss: 0.075896, Accuracy: 99.28%\n",
      "Batch 211, Loss: 0.014335, Accuracy: 99.28%\n",
      "Batch 212, Loss: 0.033680, Accuracy: 99.28%\n",
      "Batch 213, Loss: 0.024365, Accuracy: 99.27%\n",
      "Training - Epoch 16, Loss: 0.026852, Accuracy: 99.27%\n",
      "Validation Batch 1, Loss: 0.018834, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.011594, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.017855, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.017152, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.032056, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.012965, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.006399, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.039427, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.060297, Accuracy: 99.31%\n",
      "Validation Batch 10, Loss: 0.010657, Accuracy: 99.38%\n",
      "Validation Batch 11, Loss: 0.112744, Accuracy: 98.86%\n",
      "Validation Batch 12, Loss: 0.009846, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.015989, Accuracy: 99.04%\n",
      "Validation Batch 14, Loss: 0.055691, Accuracy: 99.00%\n",
      "Validation Batch 15, Loss: 0.021764, Accuracy: 98.96%\n",
      "Validation Batch 16, Loss: 0.007945, Accuracy: 99.02%\n",
      "Validation Batch 17, Loss: 0.068907, Accuracy: 98.99%\n",
      "Validation Batch 18, Loss: 0.033505, Accuracy: 98.96%\n",
      "Validation Batch 19, Loss: 0.010746, Accuracy: 99.01%\n",
      "Validation Batch 20, Loss: 0.017141, Accuracy: 98.98%\n",
      "Validation Batch 21, Loss: 0.013089, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.012400, Accuracy: 99.08%\n",
      "Validation Batch 23, Loss: 0.008225, Accuracy: 99.12%\n",
      "Validation Batch 24, Loss: 0.153279, Accuracy: 99.02%\n",
      "Validation Batch 25, Loss: 0.005778, Accuracy: 99.06%\n",
      "Validation Batch 26, Loss: 0.032063, Accuracy: 99.04%\n",
      "Validation Batch 27, Loss: 0.025157, Accuracy: 99.06%\n",
      "Validation - Epoch 16, Loss: 0.030796, Accuracy: 99.06%\n",
      "Patience—0\n",
      "Epoch 17\n",
      "Batch 1, Loss: 0.021002, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.054067, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.012918, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.005646, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.007727, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.010983, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.011020, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.034285, Accuracy: 99.41%\n",
      "Batch 9, Loss: 0.025064, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.032475, Accuracy: 99.22%\n",
      "Batch 11, Loss: 0.016969, Accuracy: 99.29%\n",
      "Batch 12, Loss: 0.005999, Accuracy: 99.35%\n",
      "Batch 13, Loss: 0.007161, Accuracy: 99.40%\n",
      "Batch 14, Loss: 0.031807, Accuracy: 99.33%\n",
      "Batch 15, Loss: 0.018621, Accuracy: 99.38%\n",
      "Batch 16, Loss: 0.031121, Accuracy: 99.22%\n",
      "Batch 17, Loss: 0.009771, Accuracy: 99.26%\n",
      "Batch 18, Loss: 0.006883, Accuracy: 99.31%\n",
      "Batch 19, Loss: 0.011345, Accuracy: 99.34%\n",
      "Batch 20, Loss: 0.004729, Accuracy: 99.38%\n",
      "Batch 21, Loss: 0.045304, Accuracy: 99.33%\n",
      "Batch 22, Loss: 0.045750, Accuracy: 99.29%\n",
      "Batch 23, Loss: 0.005655, Accuracy: 99.32%\n",
      "Batch 24, Loss: 0.013010, Accuracy: 99.35%\n",
      "Batch 25, Loss: 0.037556, Accuracy: 99.31%\n",
      "Batch 26, Loss: 0.021966, Accuracy: 99.28%\n",
      "Batch 27, Loss: 0.065196, Accuracy: 99.25%\n",
      "Batch 28, Loss: 0.006004, Accuracy: 99.27%\n",
      "Batch 29, Loss: 0.134897, Accuracy: 99.14%\n",
      "Batch 30, Loss: 0.087353, Accuracy: 99.06%\n",
      "Batch 31, Loss: 0.005361, Accuracy: 99.09%\n",
      "Batch 32, Loss: 0.081846, Accuracy: 99.02%\n",
      "Batch 33, Loss: 0.077310, Accuracy: 99.01%\n",
      "Batch 34, Loss: 0.072524, Accuracy: 98.99%\n",
      "Batch 35, Loss: 0.007852, Accuracy: 99.02%\n",
      "Batch 36, Loss: 0.005361, Accuracy: 99.05%\n",
      "Batch 37, Loss: 0.006545, Accuracy: 99.07%\n",
      "Batch 38, Loss: 0.098036, Accuracy: 99.05%\n",
      "Batch 39, Loss: 0.008982, Accuracy: 99.08%\n",
      "Batch 40, Loss: 0.003611, Accuracy: 99.10%\n",
      "Batch 41, Loss: 0.004649, Accuracy: 99.12%\n",
      "Batch 42, Loss: 0.022958, Accuracy: 99.11%\n",
      "Batch 43, Loss: 0.011057, Accuracy: 99.13%\n",
      "Batch 44, Loss: 0.065734, Accuracy: 99.04%\n",
      "Batch 45, Loss: 0.117513, Accuracy: 98.99%\n",
      "Batch 46, Loss: 0.034347, Accuracy: 98.98%\n",
      "Batch 47, Loss: 0.011168, Accuracy: 99.00%\n",
      "Batch 48, Loss: 0.008648, Accuracy: 99.02%\n",
      "Batch 49, Loss: 0.013357, Accuracy: 99.04%\n",
      "Batch 50, Loss: 0.089844, Accuracy: 99.00%\n",
      "Batch 51, Loss: 0.019735, Accuracy: 99.02%\n",
      "Batch 52, Loss: 0.050367, Accuracy: 99.01%\n",
      "Batch 53, Loss: 0.031567, Accuracy: 99.03%\n",
      "Batch 54, Loss: 0.012783, Accuracy: 99.05%\n",
      "Batch 55, Loss: 0.056236, Accuracy: 99.03%\n",
      "Batch 56, Loss: 0.076800, Accuracy: 99.02%\n",
      "Batch 57, Loss: 0.053282, Accuracy: 99.01%\n",
      "Batch 58, Loss: 0.014366, Accuracy: 99.03%\n",
      "Batch 59, Loss: 0.086806, Accuracy: 98.99%\n",
      "Batch 60, Loss: 0.066517, Accuracy: 98.98%\n",
      "Batch 61, Loss: 0.018626, Accuracy: 99.00%\n",
      "Batch 62, Loss: 0.005745, Accuracy: 99.02%\n",
      "Batch 63, Loss: 0.013934, Accuracy: 99.03%\n",
      "Batch 64, Loss: 0.029582, Accuracy: 99.05%\n",
      "Batch 65, Loss: 0.049350, Accuracy: 99.04%\n",
      "Batch 66, Loss: 0.067127, Accuracy: 99.01%\n",
      "Batch 67, Loss: 0.124627, Accuracy: 98.95%\n",
      "Batch 68, Loss: 0.006034, Accuracy: 98.97%\n",
      "Batch 69, Loss: 0.006676, Accuracy: 98.98%\n",
      "Batch 70, Loss: 0.018570, Accuracy: 99.00%\n",
      "Batch 71, Loss: 0.028077, Accuracy: 99.01%\n",
      "Batch 72, Loss: 0.112845, Accuracy: 98.98%\n",
      "Batch 73, Loss: 0.011471, Accuracy: 98.99%\n",
      "Batch 74, Loss: 0.012931, Accuracy: 99.01%\n",
      "Batch 75, Loss: 0.018602, Accuracy: 99.02%\n",
      "Batch 76, Loss: 0.155077, Accuracy: 98.97%\n",
      "Batch 77, Loss: 0.066645, Accuracy: 98.94%\n",
      "Batch 78, Loss: 0.062736, Accuracy: 98.94%\n",
      "Batch 79, Loss: 0.004927, Accuracy: 98.95%\n",
      "Batch 80, Loss: 0.023691, Accuracy: 98.95%\n",
      "Batch 81, Loss: 0.009786, Accuracy: 98.96%\n",
      "Batch 82, Loss: 0.017324, Accuracy: 98.97%\n",
      "Batch 83, Loss: 0.016225, Accuracy: 98.98%\n",
      "Batch 84, Loss: 0.025339, Accuracy: 99.00%\n",
      "Batch 85, Loss: 0.144308, Accuracy: 98.95%\n",
      "Batch 86, Loss: 0.031807, Accuracy: 98.95%\n",
      "Batch 87, Loss: 0.025032, Accuracy: 98.94%\n",
      "Batch 88, Loss: 0.008738, Accuracy: 98.95%\n",
      "Batch 89, Loss: 0.014561, Accuracy: 98.96%\n",
      "Batch 90, Loss: 0.008546, Accuracy: 98.98%\n",
      "Batch 91, Loss: 0.005746, Accuracy: 98.99%\n",
      "Batch 92, Loss: 0.037455, Accuracy: 98.98%\n",
      "Batch 93, Loss: 0.107417, Accuracy: 98.96%\n",
      "Batch 94, Loss: 0.016880, Accuracy: 98.97%\n",
      "Batch 95, Loss: 0.005123, Accuracy: 98.98%\n",
      "Batch 96, Loss: 0.006579, Accuracy: 98.99%\n",
      "Batch 97, Loss: 0.010574, Accuracy: 99.00%\n",
      "Batch 98, Loss: 0.045369, Accuracy: 99.00%\n",
      "Batch 99, Loss: 0.009264, Accuracy: 99.01%\n",
      "Batch 100, Loss: 0.018929, Accuracy: 99.02%\n",
      "Batch 101, Loss: 0.004720, Accuracy: 99.03%\n",
      "Batch 102, Loss: 0.003735, Accuracy: 99.03%\n",
      "Batch 103, Loss: 0.018797, Accuracy: 99.04%\n",
      "Batch 104, Loss: 0.024316, Accuracy: 99.04%\n",
      "Batch 105, Loss: 0.082118, Accuracy: 99.03%\n",
      "Batch 106, Loss: 0.259850, Accuracy: 98.98%\n",
      "Batch 107, Loss: 0.004191, Accuracy: 98.99%\n",
      "Batch 108, Loss: 0.004382, Accuracy: 99.00%\n",
      "Batch 109, Loss: 0.006660, Accuracy: 99.01%\n",
      "Batch 110, Loss: 0.022574, Accuracy: 99.01%\n",
      "Batch 111, Loss: 0.004532, Accuracy: 99.01%\n",
      "Batch 112, Loss: 0.011442, Accuracy: 99.02%\n",
      "Batch 113, Loss: 0.020667, Accuracy: 99.02%\n",
      "Batch 114, Loss: 0.187970, Accuracy: 98.97%\n",
      "Batch 115, Loss: 0.026763, Accuracy: 98.98%\n",
      "Batch 116, Loss: 0.050771, Accuracy: 98.98%\n",
      "Batch 117, Loss: 0.045147, Accuracy: 98.96%\n",
      "Batch 118, Loss: 0.067904, Accuracy: 98.94%\n",
      "Batch 119, Loss: 0.040595, Accuracy: 98.92%\n",
      "Batch 120, Loss: 0.022230, Accuracy: 98.92%\n",
      "Batch 121, Loss: 0.015918, Accuracy: 98.93%\n",
      "Batch 122, Loss: 0.019677, Accuracy: 98.94%\n",
      "Batch 123, Loss: 0.058279, Accuracy: 98.93%\n",
      "Batch 124, Loss: 0.008391, Accuracy: 98.94%\n",
      "Batch 125, Loss: 0.111297, Accuracy: 98.94%\n",
      "Batch 126, Loss: 0.253355, Accuracy: 98.88%\n",
      "Batch 127, Loss: 0.009637, Accuracy: 98.89%\n",
      "Batch 128, Loss: 0.012933, Accuracy: 98.90%\n",
      "Batch 129, Loss: 0.070184, Accuracy: 98.89%\n",
      "Batch 130, Loss: 0.011266, Accuracy: 98.89%\n",
      "Batch 131, Loss: 0.022217, Accuracy: 98.90%\n",
      "Batch 132, Loss: 0.041025, Accuracy: 98.90%\n",
      "Batch 133, Loss: 0.014848, Accuracy: 98.91%\n",
      "Batch 134, Loss: 0.015058, Accuracy: 98.92%\n",
      "Batch 135, Loss: 0.012710, Accuracy: 98.92%\n",
      "Batch 136, Loss: 0.049460, Accuracy: 98.91%\n",
      "Batch 137, Loss: 0.019302, Accuracy: 98.92%\n",
      "Batch 138, Loss: 0.021930, Accuracy: 98.92%\n",
      "Batch 139, Loss: 0.006795, Accuracy: 98.93%\n",
      "Batch 140, Loss: 0.150690, Accuracy: 98.91%\n",
      "Batch 141, Loss: 0.016092, Accuracy: 98.91%\n",
      "Batch 142, Loss: 0.005150, Accuracy: 98.92%\n",
      "Batch 143, Loss: 0.023378, Accuracy: 98.92%\n",
      "Batch 144, Loss: 0.033208, Accuracy: 98.91%\n",
      "Batch 145, Loss: 0.009143, Accuracy: 98.92%\n",
      "Batch 146, Loss: 0.006764, Accuracy: 98.93%\n",
      "Batch 147, Loss: 0.028650, Accuracy: 98.93%\n",
      "Batch 148, Loss: 0.090362, Accuracy: 98.92%\n",
      "Batch 149, Loss: 0.010305, Accuracy: 98.93%\n",
      "Batch 150, Loss: 0.006548, Accuracy: 98.94%\n",
      "Batch 151, Loss: 0.043576, Accuracy: 98.93%\n",
      "Batch 152, Loss: 0.018195, Accuracy: 98.94%\n",
      "Batch 153, Loss: 0.095263, Accuracy: 98.93%\n",
      "Batch 154, Loss: 0.003860, Accuracy: 98.93%\n",
      "Batch 155, Loss: 0.029785, Accuracy: 98.94%\n",
      "Batch 156, Loss: 0.029225, Accuracy: 98.94%\n",
      "Batch 157, Loss: 0.011154, Accuracy: 98.95%\n",
      "Batch 158, Loss: 0.046763, Accuracy: 98.94%\n",
      "Batch 159, Loss: 0.004830, Accuracy: 98.95%\n",
      "Batch 160, Loss: 0.012150, Accuracy: 98.96%\n",
      "Batch 161, Loss: 0.005533, Accuracy: 98.96%\n",
      "Batch 162, Loss: 0.010354, Accuracy: 98.97%\n",
      "Batch 163, Loss: 0.018419, Accuracy: 98.96%\n",
      "Batch 164, Loss: 0.006321, Accuracy: 98.97%\n",
      "Batch 165, Loss: 0.003615, Accuracy: 98.98%\n",
      "Batch 166, Loss: 0.074518, Accuracy: 98.96%\n",
      "Batch 167, Loss: 0.004435, Accuracy: 98.97%\n",
      "Batch 168, Loss: 0.013189, Accuracy: 98.98%\n",
      "Batch 169, Loss: 0.031864, Accuracy: 98.97%\n",
      "Batch 170, Loss: 0.035657, Accuracy: 98.97%\n",
      "Batch 171, Loss: 0.007317, Accuracy: 98.98%\n",
      "Batch 172, Loss: 0.056140, Accuracy: 98.96%\n",
      "Batch 173, Loss: 0.032757, Accuracy: 98.96%\n",
      "Batch 174, Loss: 0.015066, Accuracy: 98.97%\n",
      "Batch 175, Loss: 0.011528, Accuracy: 98.97%\n",
      "Batch 176, Loss: 0.035219, Accuracy: 98.97%\n",
      "Batch 177, Loss: 0.008921, Accuracy: 98.98%\n",
      "Batch 178, Loss: 0.015299, Accuracy: 98.98%\n",
      "Batch 179, Loss: 0.016019, Accuracy: 98.99%\n",
      "Batch 180, Loss: 0.010542, Accuracy: 98.99%\n",
      "Batch 181, Loss: 0.018098, Accuracy: 98.99%\n",
      "Batch 182, Loss: 0.116455, Accuracy: 98.98%\n",
      "Batch 183, Loss: 0.029490, Accuracy: 98.98%\n",
      "Batch 184, Loss: 0.067471, Accuracy: 98.97%\n",
      "Batch 185, Loss: 0.029604, Accuracy: 98.97%\n",
      "Batch 186, Loss: 0.023840, Accuracy: 98.97%\n",
      "Batch 187, Loss: 0.051536, Accuracy: 98.96%\n",
      "Batch 188, Loss: 0.005305, Accuracy: 98.96%\n",
      "Batch 189, Loss: 0.116252, Accuracy: 98.96%\n",
      "Batch 190, Loss: 0.059219, Accuracy: 98.96%\n",
      "Batch 191, Loss: 0.155691, Accuracy: 98.94%\n",
      "Batch 192, Loss: 0.068106, Accuracy: 98.94%\n",
      "Batch 193, Loss: 0.029110, Accuracy: 98.94%\n",
      "Batch 194, Loss: 0.018669, Accuracy: 98.94%\n",
      "Batch 195, Loss: 0.023236, Accuracy: 98.94%\n",
      "Batch 196, Loss: 0.133926, Accuracy: 98.92%\n",
      "Batch 197, Loss: 0.043778, Accuracy: 98.91%\n",
      "Batch 198, Loss: 0.107718, Accuracy: 98.90%\n",
      "Batch 199, Loss: 0.010831, Accuracy: 98.90%\n",
      "Batch 200, Loss: 0.023678, Accuracy: 98.90%\n",
      "Batch 201, Loss: 0.018073, Accuracy: 98.90%\n",
      "Batch 202, Loss: 0.103147, Accuracy: 98.90%\n",
      "Batch 203, Loss: 0.088551, Accuracy: 98.90%\n",
      "Batch 204, Loss: 0.010426, Accuracy: 98.90%\n",
      "Batch 205, Loss: 0.086558, Accuracy: 98.89%\n",
      "Batch 206, Loss: 0.033724, Accuracy: 98.89%\n",
      "Batch 207, Loss: 0.051922, Accuracy: 98.89%\n",
      "Batch 208, Loss: 0.073044, Accuracy: 98.89%\n",
      "Batch 209, Loss: 0.057287, Accuracy: 98.88%\n",
      "Batch 210, Loss: 0.089551, Accuracy: 98.88%\n",
      "Batch 211, Loss: 0.012363, Accuracy: 98.88%\n",
      "Batch 212, Loss: 0.061818, Accuracy: 98.88%\n",
      "Batch 213, Loss: 0.088182, Accuracy: 98.88%\n",
      "Training - Epoch 17, Loss: 0.038112, Accuracy: 98.88%\n",
      "Validation Batch 1, Loss: 0.127752, Accuracy: 93.75%\n",
      "Validation Batch 2, Loss: 0.197013, Accuracy: 92.19%\n",
      "Validation Batch 3, Loss: 0.152188, Accuracy: 93.75%\n",
      "Validation Batch 4, Loss: 0.085003, Accuracy: 94.53%\n",
      "Validation Batch 5, Loss: 0.094452, Accuracy: 95.00%\n",
      "Validation Batch 6, Loss: 0.071605, Accuracy: 95.05%\n",
      "Validation Batch 7, Loss: 0.010435, Accuracy: 95.76%\n",
      "Validation Batch 8, Loss: 0.056317, Accuracy: 96.09%\n",
      "Validation Batch 9, Loss: 0.245397, Accuracy: 95.83%\n",
      "Validation Batch 10, Loss: 0.089112, Accuracy: 95.78%\n",
      "Validation Batch 11, Loss: 0.161002, Accuracy: 95.60%\n",
      "Validation Batch 12, Loss: 0.161500, Accuracy: 95.57%\n",
      "Validation Batch 13, Loss: 0.103621, Accuracy: 95.55%\n",
      "Validation Batch 14, Loss: 0.381457, Accuracy: 95.09%\n",
      "Validation Batch 15, Loss: 0.182069, Accuracy: 95.10%\n",
      "Validation Batch 16, Loss: 0.047013, Accuracy: 95.31%\n",
      "Validation Batch 17, Loss: 0.085126, Accuracy: 95.40%\n",
      "Validation Batch 18, Loss: 0.124335, Accuracy: 95.40%\n",
      "Validation Batch 19, Loss: 0.023884, Accuracy: 95.56%\n",
      "Validation Batch 20, Loss: 0.168344, Accuracy: 95.47%\n",
      "Validation Batch 21, Loss: 0.076023, Accuracy: 95.54%\n",
      "Validation Batch 22, Loss: 0.115842, Accuracy: 95.53%\n",
      "Validation Batch 23, Loss: 0.047224, Accuracy: 95.65%\n",
      "Validation Batch 24, Loss: 0.184923, Accuracy: 95.70%\n",
      "Validation Batch 25, Loss: 0.052896, Accuracy: 95.75%\n",
      "Validation Batch 26, Loss: 0.227105, Accuracy: 95.73%\n",
      "Validation Batch 27, Loss: 0.030993, Accuracy: 95.77%\n",
      "Validation - Epoch 17, Loss: 0.122320, Accuracy: 95.77%\n",
      "Patience—1\n",
      "Epoch 18\n",
      "Batch 1, Loss: 0.057856, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.016495, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.011743, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.093776, Accuracy: 98.05%\n",
      "Batch 5, Loss: 0.008718, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.010522, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.015283, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.061218, Accuracy: 98.83%\n",
      "Batch 9, Loss: 0.004135, Accuracy: 98.96%\n",
      "Batch 10, Loss: 0.048734, Accuracy: 98.91%\n",
      "Batch 11, Loss: 0.005468, Accuracy: 99.01%\n",
      "Batch 12, Loss: 0.043164, Accuracy: 98.96%\n",
      "Batch 13, Loss: 0.006374, Accuracy: 99.04%\n",
      "Batch 14, Loss: 0.006765, Accuracy: 99.11%\n",
      "Batch 15, Loss: 0.123026, Accuracy: 98.96%\n",
      "Batch 16, Loss: 0.020595, Accuracy: 98.93%\n",
      "Batch 17, Loss: 0.013519, Accuracy: 98.99%\n",
      "Batch 18, Loss: 0.029311, Accuracy: 98.96%\n",
      "Batch 19, Loss: 0.006958, Accuracy: 99.01%\n",
      "Batch 20, Loss: 0.038656, Accuracy: 98.98%\n",
      "Batch 21, Loss: 0.027901, Accuracy: 98.96%\n",
      "Batch 22, Loss: 0.080185, Accuracy: 98.93%\n",
      "Batch 23, Loss: 0.008612, Accuracy: 98.98%\n",
      "Batch 24, Loss: 0.090708, Accuracy: 98.89%\n",
      "Batch 25, Loss: 0.011152, Accuracy: 98.94%\n",
      "Batch 26, Loss: 0.011278, Accuracy: 98.98%\n",
      "Batch 27, Loss: 0.009883, Accuracy: 99.02%\n",
      "Batch 28, Loss: 0.015021, Accuracy: 99.05%\n",
      "Batch 29, Loss: 0.040223, Accuracy: 99.03%\n",
      "Batch 30, Loss: 0.017516, Accuracy: 99.06%\n",
      "Batch 31, Loss: 0.008946, Accuracy: 99.09%\n",
      "Batch 32, Loss: 0.006042, Accuracy: 99.12%\n",
      "Batch 33, Loss: 0.010794, Accuracy: 99.15%\n",
      "Batch 34, Loss: 0.089890, Accuracy: 99.03%\n",
      "Batch 35, Loss: 0.013576, Accuracy: 99.06%\n",
      "Batch 36, Loss: 0.100886, Accuracy: 99.00%\n",
      "Batch 37, Loss: 0.004553, Accuracy: 99.03%\n",
      "Batch 38, Loss: 0.043416, Accuracy: 98.97%\n",
      "Batch 39, Loss: 0.079167, Accuracy: 98.96%\n",
      "Batch 40, Loss: 0.006552, Accuracy: 98.98%\n",
      "Batch 41, Loss: 0.028996, Accuracy: 98.97%\n",
      "Batch 42, Loss: 0.008983, Accuracy: 99.00%\n",
      "Batch 43, Loss: 0.078164, Accuracy: 98.91%\n",
      "Batch 44, Loss: 0.019717, Accuracy: 98.90%\n",
      "Batch 45, Loss: 0.007737, Accuracy: 98.92%\n",
      "Batch 46, Loss: 0.100667, Accuracy: 98.91%\n",
      "Batch 47, Loss: 0.083352, Accuracy: 98.90%\n",
      "Batch 48, Loss: 0.007834, Accuracy: 98.93%\n",
      "Batch 49, Loss: 0.051845, Accuracy: 98.88%\n",
      "Batch 50, Loss: 0.006313, Accuracy: 98.91%\n",
      "Batch 51, Loss: 0.006606, Accuracy: 98.93%\n",
      "Batch 52, Loss: 0.021418, Accuracy: 98.95%\n",
      "Batch 53, Loss: 0.022820, Accuracy: 98.94%\n",
      "Batch 54, Loss: 0.045562, Accuracy: 98.93%\n",
      "Batch 55, Loss: 0.052077, Accuracy: 98.92%\n",
      "Batch 56, Loss: 0.038903, Accuracy: 98.91%\n",
      "Batch 57, Loss: 0.010253, Accuracy: 98.93%\n",
      "Batch 58, Loss: 0.131770, Accuracy: 98.92%\n",
      "Batch 59, Loss: 0.034248, Accuracy: 98.91%\n",
      "Batch 60, Loss: 0.013069, Accuracy: 98.93%\n",
      "Batch 61, Loss: 0.054017, Accuracy: 98.92%\n",
      "Batch 62, Loss: 0.035182, Accuracy: 98.92%\n",
      "Batch 63, Loss: 0.020895, Accuracy: 98.91%\n",
      "Batch 64, Loss: 0.006829, Accuracy: 98.93%\n",
      "Batch 65, Loss: 0.013328, Accuracy: 98.94%\n",
      "Batch 66, Loss: 0.040163, Accuracy: 98.91%\n",
      "Batch 67, Loss: 0.031149, Accuracy: 98.90%\n",
      "Batch 68, Loss: 0.024506, Accuracy: 98.90%\n",
      "Batch 69, Loss: 0.105219, Accuracy: 98.87%\n",
      "Batch 70, Loss: 0.014751, Accuracy: 98.88%\n",
      "Batch 71, Loss: 0.007142, Accuracy: 98.90%\n",
      "Batch 72, Loss: 0.054394, Accuracy: 98.85%\n",
      "Batch 73, Loss: 0.006100, Accuracy: 98.87%\n",
      "Batch 74, Loss: 0.020262, Accuracy: 98.86%\n",
      "Batch 75, Loss: 0.016268, Accuracy: 98.85%\n",
      "Batch 76, Loss: 0.047659, Accuracy: 98.85%\n",
      "Batch 77, Loss: 0.066291, Accuracy: 98.84%\n",
      "Batch 78, Loss: 0.075736, Accuracy: 98.82%\n",
      "Batch 79, Loss: 0.094389, Accuracy: 98.79%\n",
      "Batch 80, Loss: 0.013772, Accuracy: 98.81%\n",
      "Batch 81, Loss: 0.010462, Accuracy: 98.82%\n",
      "Batch 82, Loss: 0.014160, Accuracy: 98.84%\n",
      "Batch 83, Loss: 0.005347, Accuracy: 98.85%\n",
      "Batch 84, Loss: 0.013866, Accuracy: 98.87%\n",
      "Batch 85, Loss: 0.155526, Accuracy: 98.82%\n",
      "Batch 86, Loss: 0.007491, Accuracy: 98.84%\n",
      "Batch 87, Loss: 0.099175, Accuracy: 98.81%\n",
      "Batch 88, Loss: 0.030787, Accuracy: 98.81%\n",
      "Batch 89, Loss: 0.027557, Accuracy: 98.81%\n",
      "Batch 90, Loss: 0.103770, Accuracy: 98.78%\n",
      "Batch 91, Loss: 0.006000, Accuracy: 98.80%\n",
      "Batch 92, Loss: 0.005560, Accuracy: 98.81%\n",
      "Batch 93, Loss: 0.012900, Accuracy: 98.82%\n",
      "Batch 94, Loss: 0.019749, Accuracy: 98.82%\n",
      "Batch 95, Loss: 0.020855, Accuracy: 98.83%\n",
      "Batch 96, Loss: 0.007499, Accuracy: 98.84%\n",
      "Batch 97, Loss: 0.026553, Accuracy: 98.86%\n",
      "Batch 98, Loss: 0.014956, Accuracy: 98.87%\n",
      "Batch 99, Loss: 0.013156, Accuracy: 98.88%\n",
      "Batch 100, Loss: 0.011195, Accuracy: 98.89%\n",
      "Batch 101, Loss: 0.013943, Accuracy: 98.90%\n",
      "Batch 102, Loss: 0.008477, Accuracy: 98.91%\n",
      "Batch 103, Loss: 0.039037, Accuracy: 98.91%\n",
      "Batch 104, Loss: 0.025666, Accuracy: 98.90%\n",
      "Batch 105, Loss: 0.080565, Accuracy: 98.88%\n",
      "Batch 106, Loss: 0.008051, Accuracy: 98.89%\n",
      "Batch 107, Loss: 0.009718, Accuracy: 98.90%\n",
      "Batch 108, Loss: 0.004095, Accuracy: 98.91%\n",
      "Batch 109, Loss: 0.012019, Accuracy: 98.92%\n",
      "Batch 110, Loss: 0.005286, Accuracy: 98.93%\n",
      "Batch 111, Loss: 0.017531, Accuracy: 98.94%\n",
      "Batch 112, Loss: 0.049012, Accuracy: 98.94%\n",
      "Batch 113, Loss: 0.009036, Accuracy: 98.95%\n",
      "Batch 114, Loss: 0.094330, Accuracy: 98.93%\n",
      "Batch 115, Loss: 0.010553, Accuracy: 98.94%\n",
      "Batch 116, Loss: 0.031709, Accuracy: 98.94%\n",
      "Batch 117, Loss: 0.010056, Accuracy: 98.94%\n",
      "Batch 118, Loss: 0.013559, Accuracy: 98.95%\n",
      "Batch 119, Loss: 0.011638, Accuracy: 98.96%\n",
      "Batch 120, Loss: 0.053731, Accuracy: 98.95%\n",
      "Batch 121, Loss: 0.007840, Accuracy: 98.95%\n",
      "Batch 122, Loss: 0.008604, Accuracy: 98.96%\n",
      "Batch 123, Loss: 0.014123, Accuracy: 98.97%\n",
      "Batch 124, Loss: 0.004589, Accuracy: 98.98%\n",
      "Batch 125, Loss: 0.030296, Accuracy: 98.97%\n",
      "Batch 126, Loss: 0.022592, Accuracy: 98.97%\n",
      "Batch 127, Loss: 0.005300, Accuracy: 98.98%\n",
      "Batch 128, Loss: 0.007658, Accuracy: 98.99%\n",
      "Batch 129, Loss: 0.197858, Accuracy: 98.95%\n",
      "Batch 130, Loss: 0.025601, Accuracy: 98.94%\n",
      "Batch 131, Loss: 0.006612, Accuracy: 98.95%\n",
      "Batch 132, Loss: 0.024583, Accuracy: 98.95%\n",
      "Batch 133, Loss: 0.009154, Accuracy: 98.95%\n",
      "Batch 134, Loss: 0.076835, Accuracy: 98.95%\n",
      "Batch 135, Loss: 0.011196, Accuracy: 98.96%\n",
      "Batch 136, Loss: 0.008855, Accuracy: 98.97%\n",
      "Batch 137, Loss: 0.125074, Accuracy: 98.95%\n",
      "Batch 138, Loss: 0.052483, Accuracy: 98.95%\n",
      "Batch 139, Loss: 0.007572, Accuracy: 98.95%\n",
      "Batch 140, Loss: 0.034368, Accuracy: 98.95%\n",
      "Batch 141, Loss: 0.018029, Accuracy: 98.96%\n",
      "Batch 142, Loss: 0.061355, Accuracy: 98.95%\n",
      "Batch 143, Loss: 0.059277, Accuracy: 98.95%\n",
      "Batch 144, Loss: 0.015573, Accuracy: 98.96%\n",
      "Batch 145, Loss: 0.014954, Accuracy: 98.97%\n",
      "Batch 146, Loss: 0.012576, Accuracy: 98.97%\n",
      "Batch 147, Loss: 0.004168, Accuracy: 98.98%\n",
      "Batch 148, Loss: 0.009032, Accuracy: 98.99%\n",
      "Batch 149, Loss: 0.088107, Accuracy: 98.96%\n",
      "Batch 150, Loss: 0.126902, Accuracy: 98.94%\n",
      "Batch 151, Loss: 0.015345, Accuracy: 98.94%\n",
      "Batch 152, Loss: 0.018218, Accuracy: 98.95%\n",
      "Batch 153, Loss: 0.012470, Accuracy: 98.96%\n",
      "Batch 154, Loss: 0.056741, Accuracy: 98.95%\n",
      "Batch 155, Loss: 0.069583, Accuracy: 98.95%\n",
      "Batch 156, Loss: 0.072519, Accuracy: 98.93%\n",
      "Batch 157, Loss: 0.107840, Accuracy: 98.92%\n",
      "Batch 158, Loss: 0.007477, Accuracy: 98.92%\n",
      "Batch 159, Loss: 0.067231, Accuracy: 98.91%\n",
      "Batch 160, Loss: 0.004073, Accuracy: 98.92%\n",
      "Batch 161, Loss: 0.049961, Accuracy: 98.91%\n",
      "Batch 162, Loss: 0.004385, Accuracy: 98.92%\n",
      "Batch 163, Loss: 0.068010, Accuracy: 98.91%\n",
      "Batch 164, Loss: 0.031669, Accuracy: 98.90%\n",
      "Batch 165, Loss: 0.123123, Accuracy: 98.89%\n",
      "Batch 166, Loss: 0.014680, Accuracy: 98.90%\n",
      "Batch 167, Loss: 0.007750, Accuracy: 98.91%\n",
      "Batch 168, Loss: 0.006897, Accuracy: 98.91%\n",
      "Batch 169, Loss: 0.013981, Accuracy: 98.92%\n",
      "Batch 170, Loss: 0.013461, Accuracy: 98.92%\n",
      "Batch 171, Loss: 0.007197, Accuracy: 98.93%\n",
      "Batch 172, Loss: 0.021341, Accuracy: 98.93%\n",
      "Batch 173, Loss: 0.008931, Accuracy: 98.93%\n",
      "Batch 174, Loss: 0.004440, Accuracy: 98.94%\n",
      "Batch 175, Loss: 0.070291, Accuracy: 98.93%\n",
      "Batch 176, Loss: 0.010884, Accuracy: 98.93%\n",
      "Batch 177, Loss: 0.020838, Accuracy: 98.93%\n",
      "Batch 178, Loss: 0.007217, Accuracy: 98.94%\n",
      "Batch 179, Loss: 0.009762, Accuracy: 98.94%\n",
      "Batch 180, Loss: 0.011630, Accuracy: 98.95%\n",
      "Batch 181, Loss: 0.079167, Accuracy: 98.94%\n",
      "Batch 182, Loss: 0.007049, Accuracy: 98.94%\n",
      "Batch 183, Loss: 0.042698, Accuracy: 98.94%\n",
      "Batch 184, Loss: 0.010336, Accuracy: 98.95%\n",
      "Batch 185, Loss: 0.103174, Accuracy: 98.93%\n",
      "Batch 186, Loss: 0.123998, Accuracy: 98.92%\n",
      "Batch 187, Loss: 0.005138, Accuracy: 98.92%\n",
      "Batch 188, Loss: 0.009544, Accuracy: 98.93%\n",
      "Batch 189, Loss: 0.095211, Accuracy: 98.92%\n",
      "Batch 190, Loss: 0.007007, Accuracy: 98.92%\n",
      "Batch 191, Loss: 0.020676, Accuracy: 98.93%\n",
      "Batch 192, Loss: 0.007384, Accuracy: 98.93%\n",
      "Batch 193, Loss: 0.050675, Accuracy: 98.92%\n",
      "Batch 194, Loss: 0.074589, Accuracy: 98.92%\n",
      "Batch 195, Loss: 0.026302, Accuracy: 98.93%\n",
      "Batch 196, Loss: 0.069950, Accuracy: 98.92%\n",
      "Batch 197, Loss: 0.007743, Accuracy: 98.93%\n",
      "Batch 198, Loss: 0.006232, Accuracy: 98.93%\n",
      "Batch 199, Loss: 0.026734, Accuracy: 98.93%\n",
      "Batch 200, Loss: 0.092885, Accuracy: 98.93%\n",
      "Batch 201, Loss: 0.138686, Accuracy: 98.90%\n",
      "Batch 202, Loss: 0.008795, Accuracy: 98.91%\n",
      "Batch 203, Loss: 0.119434, Accuracy: 98.91%\n",
      "Batch 204, Loss: 0.146263, Accuracy: 98.90%\n",
      "Batch 205, Loss: 0.061286, Accuracy: 98.89%\n",
      "Batch 206, Loss: 0.096717, Accuracy: 98.88%\n",
      "Batch 207, Loss: 0.018657, Accuracy: 98.88%\n",
      "Batch 208, Loss: 0.026940, Accuracy: 98.88%\n",
      "Batch 209, Loss: 0.042605, Accuracy: 98.88%\n",
      "Batch 210, Loss: 0.024291, Accuracy: 98.88%\n",
      "Batch 211, Loss: 0.016560, Accuracy: 98.88%\n",
      "Batch 212, Loss: 0.007073, Accuracy: 98.89%\n",
      "Batch 213, Loss: 0.004788, Accuracy: 98.89%\n",
      "Training - Epoch 18, Loss: 0.035396, Accuracy: 98.89%\n",
      "Validation Batch 1, Loss: 0.070415, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.035057, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.092695, Accuracy: 97.40%\n",
      "Validation Batch 4, Loss: 0.103505, Accuracy: 97.66%\n",
      "Validation Batch 5, Loss: 0.037757, Accuracy: 97.81%\n",
      "Validation Batch 6, Loss: 0.011362, Accuracy: 98.18%\n",
      "Validation Batch 7, Loss: 0.062169, Accuracy: 98.21%\n",
      "Validation Batch 8, Loss: 0.075924, Accuracy: 98.05%\n",
      "Validation Batch 9, Loss: 0.133880, Accuracy: 97.74%\n",
      "Validation Batch 10, Loss: 0.084064, Accuracy: 97.66%\n",
      "Validation Batch 11, Loss: 0.087345, Accuracy: 97.73%\n",
      "Validation Batch 12, Loss: 0.087691, Accuracy: 97.79%\n",
      "Validation Batch 13, Loss: 0.124912, Accuracy: 97.72%\n",
      "Validation Batch 14, Loss: 0.076197, Accuracy: 97.66%\n",
      "Validation Batch 15, Loss: 0.074146, Accuracy: 97.60%\n",
      "Validation Batch 16, Loss: 0.021563, Accuracy: 97.75%\n",
      "Validation Batch 17, Loss: 0.102372, Accuracy: 97.79%\n",
      "Validation Batch 18, Loss: 0.037974, Accuracy: 97.83%\n",
      "Validation Batch 19, Loss: 0.080315, Accuracy: 97.70%\n",
      "Validation Batch 20, Loss: 0.108155, Accuracy: 97.58%\n",
      "Validation Batch 21, Loss: 0.145012, Accuracy: 97.54%\n",
      "Validation Batch 22, Loss: 0.067238, Accuracy: 97.59%\n",
      "Validation Batch 23, Loss: 0.086349, Accuracy: 97.42%\n",
      "Validation Batch 24, Loss: 0.194922, Accuracy: 97.33%\n",
      "Validation Batch 25, Loss: 0.034812, Accuracy: 97.38%\n",
      "Validation Batch 26, Loss: 0.077061, Accuracy: 97.36%\n",
      "Validation Batch 27, Loss: 0.021903, Accuracy: 97.42%\n",
      "Validation - Epoch 18, Loss: 0.079067, Accuracy: 97.42%\n",
      "Patience—2\n",
      "Epoch 19\n",
      "Batch 1, Loss: 0.043043, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.011532, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.058538, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.047585, Accuracy: 98.83%\n",
      "Batch 5, Loss: 0.081299, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.044321, Accuracy: 98.44%\n",
      "Batch 7, Loss: 0.062165, Accuracy: 98.44%\n",
      "Batch 8, Loss: 0.003911, Accuracy: 98.63%\n",
      "Batch 9, Loss: 0.004225, Accuracy: 98.78%\n",
      "Batch 10, Loss: 0.008542, Accuracy: 98.91%\n",
      "Batch 11, Loss: 0.082273, Accuracy: 98.86%\n",
      "Batch 12, Loss: 0.089967, Accuracy: 98.57%\n",
      "Batch 13, Loss: 0.005662, Accuracy: 98.68%\n",
      "Batch 14, Loss: 0.025335, Accuracy: 98.66%\n",
      "Batch 15, Loss: 0.038985, Accuracy: 98.65%\n",
      "Batch 16, Loss: 0.033790, Accuracy: 98.63%\n",
      "Batch 17, Loss: 0.106793, Accuracy: 98.53%\n",
      "Batch 18, Loss: 0.008947, Accuracy: 98.61%\n",
      "Batch 19, Loss: 0.008410, Accuracy: 98.68%\n",
      "Batch 20, Loss: 0.020613, Accuracy: 98.67%\n",
      "Batch 21, Loss: 0.048014, Accuracy: 98.51%\n",
      "Batch 22, Loss: 0.006125, Accuracy: 98.58%\n",
      "Batch 23, Loss: 0.032853, Accuracy: 98.51%\n",
      "Batch 24, Loss: 0.069807, Accuracy: 98.50%\n",
      "Batch 25, Loss: 0.050272, Accuracy: 98.44%\n",
      "Batch 26, Loss: 0.011360, Accuracy: 98.50%\n",
      "Batch 27, Loss: 0.056951, Accuracy: 98.50%\n",
      "Batch 28, Loss: 0.012946, Accuracy: 98.55%\n",
      "Batch 29, Loss: 0.009556, Accuracy: 98.60%\n",
      "Batch 30, Loss: 0.004972, Accuracy: 98.65%\n",
      "Batch 31, Loss: 0.043388, Accuracy: 98.59%\n",
      "Batch 32, Loss: 0.024945, Accuracy: 98.63%\n",
      "Batch 33, Loss: 0.029996, Accuracy: 98.63%\n",
      "Batch 34, Loss: 0.030406, Accuracy: 98.62%\n",
      "Batch 35, Loss: 0.023230, Accuracy: 98.62%\n",
      "Batch 36, Loss: 0.030866, Accuracy: 98.61%\n",
      "Batch 37, Loss: 0.018148, Accuracy: 98.61%\n",
      "Batch 38, Loss: 0.100491, Accuracy: 98.60%\n",
      "Batch 39, Loss: 0.015057, Accuracy: 98.64%\n",
      "Batch 40, Loss: 0.020796, Accuracy: 98.63%\n",
      "Batch 41, Loss: 0.079629, Accuracy: 98.63%\n",
      "Batch 42, Loss: 0.013980, Accuracy: 98.66%\n",
      "Batch 43, Loss: 0.007481, Accuracy: 98.69%\n",
      "Batch 44, Loss: 0.004438, Accuracy: 98.72%\n",
      "Batch 45, Loss: 0.003988, Accuracy: 98.75%\n",
      "Batch 46, Loss: 0.009169, Accuracy: 98.78%\n",
      "Batch 47, Loss: 0.006682, Accuracy: 98.80%\n",
      "Batch 48, Loss: 0.004719, Accuracy: 98.83%\n",
      "Batch 49, Loss: 0.004427, Accuracy: 98.85%\n",
      "Batch 50, Loss: 0.017923, Accuracy: 98.88%\n",
      "Batch 51, Loss: 0.006093, Accuracy: 98.90%\n",
      "Batch 52, Loss: 0.019747, Accuracy: 98.89%\n",
      "Batch 53, Loss: 0.055126, Accuracy: 98.85%\n",
      "Batch 54, Loss: 0.110962, Accuracy: 98.84%\n",
      "Batch 55, Loss: 0.028775, Accuracy: 98.84%\n",
      "Batch 56, Loss: 0.007405, Accuracy: 98.86%\n",
      "Batch 57, Loss: 0.014775, Accuracy: 98.88%\n",
      "Batch 58, Loss: 0.059141, Accuracy: 98.87%\n",
      "Batch 59, Loss: 0.039920, Accuracy: 98.86%\n",
      "Batch 60, Loss: 0.023222, Accuracy: 98.88%\n",
      "Batch 61, Loss: 0.009601, Accuracy: 98.90%\n",
      "Batch 62, Loss: 0.019073, Accuracy: 98.89%\n",
      "Batch 63, Loss: 0.007004, Accuracy: 98.91%\n",
      "Batch 64, Loss: 0.030847, Accuracy: 98.90%\n",
      "Batch 65, Loss: 0.004987, Accuracy: 98.92%\n",
      "Batch 66, Loss: 0.021576, Accuracy: 98.93%\n",
      "Batch 67, Loss: 0.026649, Accuracy: 98.93%\n",
      "Batch 68, Loss: 0.003945, Accuracy: 98.94%\n",
      "Batch 69, Loss: 0.027541, Accuracy: 98.94%\n",
      "Batch 70, Loss: 0.028233, Accuracy: 98.93%\n",
      "Batch 71, Loss: 0.017881, Accuracy: 98.92%\n",
      "Batch 72, Loss: 0.051367, Accuracy: 98.91%\n",
      "Batch 73, Loss: 0.069930, Accuracy: 98.91%\n",
      "Batch 74, Loss: 0.007860, Accuracy: 98.92%\n",
      "Batch 75, Loss: 0.026385, Accuracy: 98.92%\n",
      "Batch 76, Loss: 0.005527, Accuracy: 98.93%\n",
      "Batch 77, Loss: 0.034756, Accuracy: 98.92%\n",
      "Batch 78, Loss: 0.007934, Accuracy: 98.94%\n",
      "Batch 79, Loss: 0.045300, Accuracy: 98.91%\n",
      "Batch 80, Loss: 0.028557, Accuracy: 98.91%\n",
      "Batch 81, Loss: 0.056797, Accuracy: 98.90%\n",
      "Batch 82, Loss: 0.004501, Accuracy: 98.91%\n",
      "Batch 83, Loss: 0.066296, Accuracy: 98.89%\n",
      "Batch 84, Loss: 0.010582, Accuracy: 98.90%\n",
      "Batch 85, Loss: 0.004160, Accuracy: 98.92%\n",
      "Batch 86, Loss: 0.003326, Accuracy: 98.93%\n",
      "Batch 87, Loss: 0.021590, Accuracy: 98.94%\n",
      "Batch 88, Loss: 0.041038, Accuracy: 98.93%\n",
      "Batch 89, Loss: 0.007488, Accuracy: 98.95%\n",
      "Batch 90, Loss: 0.007484, Accuracy: 98.96%\n",
      "Batch 91, Loss: 0.006401, Accuracy: 98.97%\n",
      "Batch 92, Loss: 0.013032, Accuracy: 98.98%\n",
      "Batch 93, Loss: 0.021148, Accuracy: 98.98%\n",
      "Batch 94, Loss: 0.003380, Accuracy: 98.99%\n",
      "Batch 95, Loss: 0.038265, Accuracy: 98.98%\n",
      "Batch 96, Loss: 0.005323, Accuracy: 98.99%\n",
      "Batch 97, Loss: 0.080901, Accuracy: 98.95%\n",
      "Batch 98, Loss: 0.008981, Accuracy: 98.96%\n",
      "Batch 99, Loss: 0.003435, Accuracy: 98.97%\n",
      "Batch 100, Loss: 0.006352, Accuracy: 98.98%\n",
      "Batch 101, Loss: 0.003522, Accuracy: 98.99%\n",
      "Batch 102, Loss: 0.022939, Accuracy: 98.99%\n",
      "Batch 103, Loss: 0.002416, Accuracy: 99.00%\n",
      "Batch 104, Loss: 0.015762, Accuracy: 98.99%\n",
      "Batch 105, Loss: 0.004493, Accuracy: 99.00%\n",
      "Batch 106, Loss: 0.009593, Accuracy: 99.01%\n",
      "Batch 107, Loss: 0.011667, Accuracy: 99.02%\n",
      "Batch 108, Loss: 0.004430, Accuracy: 99.03%\n",
      "Batch 109, Loss: 0.002869, Accuracy: 99.04%\n",
      "Batch 110, Loss: 0.008322, Accuracy: 99.05%\n",
      "Batch 111, Loss: 0.005033, Accuracy: 99.06%\n",
      "Batch 112, Loss: 0.006217, Accuracy: 99.07%\n",
      "Batch 113, Loss: 0.034294, Accuracy: 99.06%\n",
      "Batch 114, Loss: 0.003481, Accuracy: 99.07%\n",
      "Batch 115, Loss: 0.004856, Accuracy: 99.08%\n",
      "Batch 116, Loss: 0.018736, Accuracy: 99.08%\n",
      "Batch 117, Loss: 0.024256, Accuracy: 99.08%\n",
      "Batch 118, Loss: 0.031364, Accuracy: 99.07%\n",
      "Batch 119, Loss: 0.006266, Accuracy: 99.08%\n",
      "Batch 120, Loss: 0.005645, Accuracy: 99.09%\n",
      "Batch 121, Loss: 0.003629, Accuracy: 99.10%\n",
      "Batch 122, Loss: 0.006146, Accuracy: 99.10%\n",
      "Batch 123, Loss: 0.003978, Accuracy: 99.11%\n",
      "Batch 124, Loss: 0.005954, Accuracy: 99.12%\n",
      "Batch 125, Loss: 0.007525, Accuracy: 99.12%\n",
      "Batch 126, Loss: 0.012777, Accuracy: 99.13%\n",
      "Batch 127, Loss: 0.020320, Accuracy: 99.14%\n",
      "Batch 128, Loss: 0.004639, Accuracy: 99.15%\n",
      "Batch 129, Loss: 0.040168, Accuracy: 99.14%\n",
      "Batch 130, Loss: 0.009907, Accuracy: 99.15%\n",
      "Batch 131, Loss: 0.021415, Accuracy: 99.14%\n",
      "Batch 132, Loss: 0.005389, Accuracy: 99.15%\n",
      "Batch 133, Loss: 0.034480, Accuracy: 99.14%\n",
      "Batch 134, Loss: 0.012935, Accuracy: 99.15%\n",
      "Batch 135, Loss: 0.059242, Accuracy: 99.13%\n",
      "Batch 136, Loss: 0.002947, Accuracy: 99.14%\n",
      "Batch 137, Loss: 0.006159, Accuracy: 99.14%\n",
      "Batch 138, Loss: 0.068099, Accuracy: 99.14%\n",
      "Batch 139, Loss: 0.054289, Accuracy: 99.13%\n",
      "Batch 140, Loss: 0.013662, Accuracy: 99.14%\n",
      "Batch 141, Loss: 0.012179, Accuracy: 99.15%\n",
      "Batch 142, Loss: 0.008856, Accuracy: 99.15%\n",
      "Batch 143, Loss: 0.003147, Accuracy: 99.16%\n",
      "Batch 144, Loss: 0.004687, Accuracy: 99.16%\n",
      "Batch 145, Loss: 0.007120, Accuracy: 99.17%\n",
      "Batch 146, Loss: 0.003554, Accuracy: 99.18%\n",
      "Batch 147, Loss: 0.015676, Accuracy: 99.18%\n",
      "Batch 148, Loss: 0.007440, Accuracy: 99.19%\n",
      "Batch 149, Loss: 0.004696, Accuracy: 99.19%\n",
      "Batch 150, Loss: 0.004204, Accuracy: 99.20%\n",
      "Batch 151, Loss: 0.007782, Accuracy: 99.20%\n",
      "Batch 152, Loss: 0.002365, Accuracy: 99.21%\n",
      "Batch 153, Loss: 0.004112, Accuracy: 99.21%\n",
      "Batch 154, Loss: 0.032593, Accuracy: 99.21%\n",
      "Batch 155, Loss: 0.003919, Accuracy: 99.21%\n",
      "Batch 156, Loss: 0.006556, Accuracy: 99.22%\n",
      "Batch 157, Loss: 0.075644, Accuracy: 99.21%\n",
      "Batch 158, Loss: 0.028074, Accuracy: 99.21%\n",
      "Batch 159, Loss: 0.002782, Accuracy: 99.21%\n",
      "Batch 160, Loss: 0.101837, Accuracy: 99.20%\n",
      "Batch 161, Loss: 0.080467, Accuracy: 99.18%\n",
      "Batch 162, Loss: 0.048861, Accuracy: 99.18%\n",
      "Batch 163, Loss: 0.016789, Accuracy: 99.19%\n",
      "Batch 164, Loss: 0.002564, Accuracy: 99.19%\n",
      "Batch 165, Loss: 0.003105, Accuracy: 99.20%\n",
      "Batch 166, Loss: 0.007528, Accuracy: 99.20%\n",
      "Batch 167, Loss: 0.029489, Accuracy: 99.20%\n",
      "Batch 168, Loss: 0.004845, Accuracy: 99.20%\n",
      "Batch 169, Loss: 0.004642, Accuracy: 99.20%\n",
      "Batch 170, Loss: 0.052225, Accuracy: 99.18%\n",
      "Batch 171, Loss: 0.007563, Accuracy: 99.19%\n",
      "Batch 172, Loss: 0.033555, Accuracy: 99.18%\n",
      "Batch 173, Loss: 0.010012, Accuracy: 99.19%\n",
      "Batch 174, Loss: 0.011687, Accuracy: 99.19%\n",
      "Batch 175, Loss: 0.004564, Accuracy: 99.20%\n",
      "Batch 176, Loss: 0.005177, Accuracy: 99.20%\n",
      "Batch 177, Loss: 0.014288, Accuracy: 99.21%\n",
      "Batch 178, Loss: 0.029886, Accuracy: 99.20%\n",
      "Batch 179, Loss: 0.014294, Accuracy: 99.21%\n",
      "Batch 180, Loss: 0.021497, Accuracy: 99.20%\n",
      "Batch 181, Loss: 0.009842, Accuracy: 99.21%\n",
      "Batch 182, Loss: 0.062515, Accuracy: 99.20%\n",
      "Batch 183, Loss: 0.004688, Accuracy: 99.21%\n",
      "Batch 184, Loss: 0.063400, Accuracy: 99.20%\n",
      "Batch 185, Loss: 0.085634, Accuracy: 99.20%\n",
      "Batch 186, Loss: 0.073551, Accuracy: 99.19%\n",
      "Batch 187, Loss: 0.164920, Accuracy: 99.17%\n",
      "Batch 188, Loss: 0.056845, Accuracy: 99.16%\n",
      "Batch 189, Loss: 0.036166, Accuracy: 99.16%\n",
      "Batch 190, Loss: 0.026187, Accuracy: 99.15%\n",
      "Batch 191, Loss: 0.006689, Accuracy: 99.16%\n",
      "Batch 192, Loss: 0.187683, Accuracy: 99.15%\n",
      "Batch 193, Loss: 0.010392, Accuracy: 99.15%\n",
      "Batch 194, Loss: 0.231579, Accuracy: 99.12%\n",
      "Batch 195, Loss: 0.074059, Accuracy: 99.12%\n",
      "Batch 196, Loss: 0.015961, Accuracy: 99.12%\n",
      "Batch 197, Loss: 0.026429, Accuracy: 99.12%\n",
      "Batch 198, Loss: 0.045525, Accuracy: 99.11%\n",
      "Batch 199, Loss: 0.137244, Accuracy: 99.09%\n",
      "Batch 200, Loss: 0.068727, Accuracy: 99.09%\n",
      "Batch 201, Loss: 0.042595, Accuracy: 99.08%\n",
      "Batch 202, Loss: 0.106327, Accuracy: 99.08%\n",
      "Batch 203, Loss: 0.092585, Accuracy: 99.08%\n",
      "Batch 204, Loss: 0.114115, Accuracy: 99.06%\n",
      "Batch 205, Loss: 0.233020, Accuracy: 99.03%\n",
      "Batch 206, Loss: 0.097771, Accuracy: 99.02%\n",
      "Batch 207, Loss: 0.057355, Accuracy: 99.02%\n",
      "Batch 208, Loss: 0.012895, Accuracy: 99.02%\n",
      "Batch 209, Loss: 0.150744, Accuracy: 99.00%\n",
      "Batch 210, Loss: 0.057661, Accuracy: 99.00%\n",
      "Batch 211, Loss: 0.052373, Accuracy: 98.99%\n",
      "Batch 212, Loss: 0.045815, Accuracy: 98.99%\n",
      "Batch 213, Loss: 0.108036, Accuracy: 98.98%\n",
      "Training - Epoch 19, Loss: 0.031683, Accuracy: 98.98%\n",
      "Validation Batch 1, Loss: 0.063856, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.189554, Accuracy: 96.09%\n",
      "Validation Batch 3, Loss: 0.023209, Accuracy: 96.88%\n",
      "Validation Batch 4, Loss: 0.040244, Accuracy: 97.27%\n",
      "Validation Batch 5, Loss: 0.092189, Accuracy: 96.88%\n",
      "Validation Batch 6, Loss: 0.064992, Accuracy: 96.88%\n",
      "Validation Batch 7, Loss: 0.074717, Accuracy: 96.88%\n",
      "Validation Batch 8, Loss: 0.153795, Accuracy: 96.88%\n",
      "Validation Batch 9, Loss: 0.132451, Accuracy: 96.53%\n",
      "Validation Batch 10, Loss: 0.048712, Accuracy: 96.72%\n",
      "Validation Batch 11, Loss: 0.102831, Accuracy: 96.73%\n",
      "Validation Batch 12, Loss: 0.093365, Accuracy: 96.88%\n",
      "Validation Batch 13, Loss: 0.183434, Accuracy: 96.51%\n",
      "Validation Batch 14, Loss: 0.047062, Accuracy: 96.76%\n",
      "Validation Batch 15, Loss: 0.032587, Accuracy: 96.88%\n",
      "Validation Batch 16, Loss: 0.167993, Accuracy: 96.78%\n",
      "Validation Batch 17, Loss: 0.071933, Accuracy: 96.78%\n",
      "Validation Batch 18, Loss: 0.061017, Accuracy: 96.88%\n",
      "Validation Batch 19, Loss: 0.049766, Accuracy: 96.96%\n",
      "Validation Batch 20, Loss: 0.108875, Accuracy: 96.95%\n",
      "Validation Batch 21, Loss: 0.117630, Accuracy: 96.88%\n",
      "Validation Batch 22, Loss: 0.103672, Accuracy: 96.88%\n",
      "Validation Batch 23, Loss: 0.043553, Accuracy: 96.88%\n",
      "Validation Batch 24, Loss: 0.007846, Accuracy: 97.01%\n",
      "Validation Batch 25, Loss: 0.013774, Accuracy: 97.12%\n",
      "Validation Batch 26, Loss: 0.032259, Accuracy: 97.18%\n",
      "Validation Batch 27, Loss: 0.079559, Accuracy: 97.18%\n",
      "Validation - Epoch 19, Loss: 0.081514, Accuracy: 97.18%\n",
      "Patience—3\n",
      "Epoch 20\n",
      "Batch 1, Loss: 0.032038, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.029526, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.005322, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.120461, Accuracy: 98.44%\n",
      "Batch 5, Loss: 0.007537, Accuracy: 98.75%\n",
      "Batch 6, Loss: 0.009369, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.102645, Accuracy: 98.66%\n",
      "Batch 8, Loss: 0.078836, Accuracy: 98.44%\n",
      "Batch 9, Loss: 0.126796, Accuracy: 98.26%\n",
      "Batch 10, Loss: 0.073856, Accuracy: 98.12%\n",
      "Batch 11, Loss: 0.047882, Accuracy: 98.15%\n",
      "Batch 12, Loss: 0.063112, Accuracy: 98.18%\n",
      "Batch 13, Loss: 0.024373, Accuracy: 98.20%\n",
      "Batch 14, Loss: 0.062875, Accuracy: 98.10%\n",
      "Batch 15, Loss: 0.134614, Accuracy: 97.92%\n",
      "Batch 16, Loss: 0.033426, Accuracy: 97.95%\n",
      "Batch 17, Loss: 0.007793, Accuracy: 98.07%\n",
      "Batch 18, Loss: 0.048937, Accuracy: 98.09%\n",
      "Batch 19, Loss: 0.014492, Accuracy: 98.19%\n",
      "Batch 20, Loss: 0.031006, Accuracy: 98.28%\n",
      "Batch 21, Loss: 0.093706, Accuracy: 98.07%\n",
      "Batch 22, Loss: 0.074140, Accuracy: 98.01%\n",
      "Batch 23, Loss: 0.138797, Accuracy: 97.96%\n",
      "Batch 24, Loss: 0.053758, Accuracy: 97.92%\n",
      "Batch 25, Loss: 0.010480, Accuracy: 98.00%\n",
      "Batch 26, Loss: 0.058230, Accuracy: 98.02%\n",
      "Batch 27, Loss: 0.013170, Accuracy: 98.09%\n",
      "Batch 28, Loss: 0.011949, Accuracy: 98.16%\n",
      "Batch 29, Loss: 0.018422, Accuracy: 98.22%\n",
      "Batch 30, Loss: 0.033203, Accuracy: 98.23%\n",
      "Batch 31, Loss: 0.012725, Accuracy: 98.29%\n",
      "Batch 32, Loss: 0.015343, Accuracy: 98.34%\n",
      "Batch 33, Loss: 0.055872, Accuracy: 98.34%\n",
      "Batch 34, Loss: 0.028540, Accuracy: 98.35%\n",
      "Batch 35, Loss: 0.005628, Accuracy: 98.39%\n",
      "Batch 36, Loss: 0.013871, Accuracy: 98.44%\n",
      "Batch 37, Loss: 0.012320, Accuracy: 98.48%\n",
      "Batch 38, Loss: 0.025207, Accuracy: 98.52%\n",
      "Batch 39, Loss: 0.087361, Accuracy: 98.48%\n",
      "Batch 40, Loss: 0.040097, Accuracy: 98.48%\n",
      "Batch 41, Loss: 0.016578, Accuracy: 98.51%\n",
      "Batch 42, Loss: 0.095597, Accuracy: 98.51%\n",
      "Batch 43, Loss: 0.027344, Accuracy: 98.51%\n",
      "Batch 44, Loss: 0.035002, Accuracy: 98.51%\n",
      "Batch 45, Loss: 0.080529, Accuracy: 98.40%\n",
      "Batch 46, Loss: 0.012500, Accuracy: 98.44%\n",
      "Batch 47, Loss: 0.031979, Accuracy: 98.44%\n",
      "Batch 48, Loss: 0.010234, Accuracy: 98.47%\n",
      "Batch 49, Loss: 0.047926, Accuracy: 98.44%\n",
      "Batch 50, Loss: 0.014025, Accuracy: 98.47%\n",
      "Batch 51, Loss: 0.011031, Accuracy: 98.50%\n",
      "Batch 52, Loss: 0.069221, Accuracy: 98.50%\n",
      "Batch 53, Loss: 0.014886, Accuracy: 98.53%\n",
      "Batch 54, Loss: 0.135784, Accuracy: 98.50%\n",
      "Batch 55, Loss: 0.053765, Accuracy: 98.47%\n",
      "Batch 56, Loss: 0.003760, Accuracy: 98.49%\n",
      "Batch 57, Loss: 0.007660, Accuracy: 98.52%\n",
      "Batch 58, Loss: 0.010250, Accuracy: 98.55%\n",
      "Batch 59, Loss: 0.043336, Accuracy: 98.54%\n",
      "Batch 60, Loss: 0.024427, Accuracy: 98.54%\n",
      "Batch 61, Loss: 0.002532, Accuracy: 98.57%\n",
      "Batch 62, Loss: 0.004134, Accuracy: 98.59%\n",
      "Batch 63, Loss: 0.003687, Accuracy: 98.61%\n",
      "Batch 64, Loss: 0.009192, Accuracy: 98.63%\n",
      "Batch 65, Loss: 0.004765, Accuracy: 98.65%\n",
      "Batch 66, Loss: 0.010478, Accuracy: 98.67%\n",
      "Batch 67, Loss: 0.003581, Accuracy: 98.69%\n",
      "Batch 68, Loss: 0.016919, Accuracy: 98.71%\n",
      "Batch 69, Loss: 0.012990, Accuracy: 98.73%\n",
      "Batch 70, Loss: 0.009352, Accuracy: 98.75%\n",
      "Batch 71, Loss: 0.016282, Accuracy: 98.77%\n",
      "Batch 72, Loss: 0.081744, Accuracy: 98.74%\n",
      "Batch 73, Loss: 0.012515, Accuracy: 98.76%\n",
      "Batch 74, Loss: 0.004265, Accuracy: 98.78%\n",
      "Batch 75, Loss: 0.065777, Accuracy: 98.77%\n",
      "Batch 76, Loss: 0.029584, Accuracy: 98.75%\n",
      "Batch 77, Loss: 0.011948, Accuracy: 98.76%\n",
      "Batch 78, Loss: 0.071452, Accuracy: 98.74%\n",
      "Batch 79, Loss: 0.050091, Accuracy: 98.73%\n",
      "Batch 80, Loss: 0.006537, Accuracy: 98.75%\n",
      "Batch 81, Loss: 0.003703, Accuracy: 98.77%\n",
      "Batch 82, Loss: 0.013674, Accuracy: 98.78%\n",
      "Batch 83, Loss: 0.053341, Accuracy: 98.78%\n",
      "Batch 84, Loss: 0.004486, Accuracy: 98.79%\n",
      "Batch 85, Loss: 0.064062, Accuracy: 98.79%\n",
      "Batch 86, Loss: 0.062597, Accuracy: 98.78%\n",
      "Batch 87, Loss: 0.035968, Accuracy: 98.78%\n",
      "Batch 88, Loss: 0.010488, Accuracy: 98.79%\n",
      "Batch 89, Loss: 0.068320, Accuracy: 98.77%\n",
      "Batch 90, Loss: 0.008792, Accuracy: 98.78%\n",
      "Batch 91, Loss: 0.010205, Accuracy: 98.80%\n",
      "Batch 92, Loss: 0.003707, Accuracy: 98.81%\n",
      "Batch 93, Loss: 0.024965, Accuracy: 98.81%\n",
      "Batch 94, Loss: 0.091581, Accuracy: 98.79%\n",
      "Batch 95, Loss: 0.006543, Accuracy: 98.80%\n",
      "Batch 96, Loss: 0.025448, Accuracy: 98.80%\n",
      "Batch 97, Loss: 0.002995, Accuracy: 98.81%\n",
      "Batch 98, Loss: 0.051084, Accuracy: 98.79%\n",
      "Batch 99, Loss: 0.069581, Accuracy: 98.78%\n",
      "Batch 100, Loss: 0.045810, Accuracy: 98.78%\n",
      "Batch 101, Loss: 0.004582, Accuracy: 98.79%\n",
      "Batch 102, Loss: 0.009018, Accuracy: 98.81%\n",
      "Batch 103, Loss: 0.035421, Accuracy: 98.80%\n",
      "Batch 104, Loss: 0.024273, Accuracy: 98.80%\n",
      "Batch 105, Loss: 0.030228, Accuracy: 98.79%\n",
      "Batch 106, Loss: 0.006063, Accuracy: 98.81%\n",
      "Batch 107, Loss: 0.037637, Accuracy: 98.80%\n",
      "Batch 108, Loss: 0.022272, Accuracy: 98.80%\n",
      "Batch 109, Loss: 0.003677, Accuracy: 98.81%\n",
      "Batch 110, Loss: 0.005301, Accuracy: 98.82%\n",
      "Batch 111, Loss: 0.006330, Accuracy: 98.83%\n",
      "Batch 112, Loss: 0.004592, Accuracy: 98.84%\n",
      "Batch 113, Loss: 0.056015, Accuracy: 98.84%\n",
      "Batch 114, Loss: 0.074869, Accuracy: 98.82%\n",
      "Batch 115, Loss: 0.004540, Accuracy: 98.83%\n",
      "Batch 116, Loss: 0.011516, Accuracy: 98.84%\n",
      "Batch 117, Loss: 0.041394, Accuracy: 98.84%\n",
      "Batch 118, Loss: 0.048979, Accuracy: 98.82%\n",
      "Batch 119, Loss: 0.005537, Accuracy: 98.83%\n",
      "Batch 120, Loss: 0.021836, Accuracy: 98.84%\n",
      "Batch 121, Loss: 0.042954, Accuracy: 98.82%\n",
      "Batch 122, Loss: 0.016945, Accuracy: 98.83%\n",
      "Batch 123, Loss: 0.094058, Accuracy: 98.81%\n",
      "Batch 124, Loss: 0.030173, Accuracy: 98.80%\n",
      "Batch 125, Loss: 0.076869, Accuracy: 98.79%\n",
      "Batch 126, Loss: 0.017471, Accuracy: 98.80%\n",
      "Batch 127, Loss: 0.021443, Accuracy: 98.79%\n",
      "Batch 128, Loss: 0.098994, Accuracy: 98.78%\n",
      "Batch 129, Loss: 0.109429, Accuracy: 98.76%\n",
      "Batch 130, Loss: 0.102853, Accuracy: 98.75%\n",
      "Batch 131, Loss: 0.068763, Accuracy: 98.74%\n",
      "Batch 132, Loss: 0.050029, Accuracy: 98.73%\n",
      "Batch 133, Loss: 0.030845, Accuracy: 98.74%\n",
      "Batch 134, Loss: 0.004483, Accuracy: 98.75%\n",
      "Batch 135, Loss: 0.017526, Accuracy: 98.76%\n",
      "Batch 136, Loss: 0.037335, Accuracy: 98.76%\n",
      "Batch 137, Loss: 0.021007, Accuracy: 98.76%\n",
      "Batch 138, Loss: 0.117861, Accuracy: 98.74%\n",
      "Batch 139, Loss: 0.068667, Accuracy: 98.74%\n",
      "Batch 140, Loss: 0.026803, Accuracy: 98.74%\n",
      "Batch 141, Loss: 0.063395, Accuracy: 98.73%\n",
      "Batch 142, Loss: 0.107398, Accuracy: 98.71%\n",
      "Batch 143, Loss: 0.019191, Accuracy: 98.72%\n",
      "Batch 144, Loss: 0.019729, Accuracy: 98.72%\n",
      "Batch 145, Loss: 0.052026, Accuracy: 98.71%\n",
      "Batch 146, Loss: 0.066823, Accuracy: 98.69%\n",
      "Batch 147, Loss: 0.040680, Accuracy: 98.68%\n",
      "Batch 148, Loss: 0.006867, Accuracy: 98.69%\n",
      "Batch 149, Loss: 0.045344, Accuracy: 98.68%\n",
      "Batch 150, Loss: 0.015119, Accuracy: 98.69%\n",
      "Batch 151, Loss: 0.072207, Accuracy: 98.69%\n",
      "Batch 152, Loss: 0.006661, Accuracy: 98.69%\n",
      "Batch 153, Loss: 0.082656, Accuracy: 98.69%\n",
      "Batch 154, Loss: 0.070926, Accuracy: 98.68%\n",
      "Batch 155, Loss: 0.010944, Accuracy: 98.69%\n",
      "Batch 156, Loss: 0.005046, Accuracy: 98.70%\n",
      "Batch 157, Loss: 0.013559, Accuracy: 98.71%\n",
      "Batch 158, Loss: 0.012662, Accuracy: 98.71%\n",
      "Batch 159, Loss: 0.012991, Accuracy: 98.72%\n",
      "Batch 160, Loss: 0.043343, Accuracy: 98.72%\n",
      "Batch 161, Loss: 0.026690, Accuracy: 98.72%\n",
      "Batch 162, Loss: 0.011660, Accuracy: 98.73%\n",
      "Batch 163, Loss: 0.017372, Accuracy: 98.73%\n",
      "Batch 164, Loss: 0.006143, Accuracy: 98.74%\n",
      "Batch 165, Loss: 0.068006, Accuracy: 98.74%\n",
      "Batch 166, Loss: 0.014654, Accuracy: 98.75%\n",
      "Batch 167, Loss: 0.060442, Accuracy: 98.74%\n",
      "Batch 168, Loss: 0.005601, Accuracy: 98.74%\n",
      "Batch 169, Loss: 0.101874, Accuracy: 98.72%\n",
      "Batch 170, Loss: 0.005455, Accuracy: 98.73%\n",
      "Batch 171, Loss: 0.007292, Accuracy: 98.74%\n",
      "Batch 172, Loss: 0.006673, Accuracy: 98.75%\n",
      "Batch 173, Loss: 0.023108, Accuracy: 98.74%\n",
      "Batch 174, Loss: 0.035776, Accuracy: 98.74%\n",
      "Batch 175, Loss: 0.013980, Accuracy: 98.75%\n",
      "Batch 176, Loss: 0.017855, Accuracy: 98.76%\n",
      "Batch 177, Loss: 0.068462, Accuracy: 98.76%\n",
      "Batch 178, Loss: 0.049524, Accuracy: 98.75%\n",
      "Batch 179, Loss: 0.022720, Accuracy: 98.76%\n",
      "Batch 180, Loss: 0.006262, Accuracy: 98.77%\n",
      "Batch 181, Loss: 0.077434, Accuracy: 98.75%\n",
      "Batch 182, Loss: 0.058966, Accuracy: 98.75%\n",
      "Batch 183, Loss: 0.064929, Accuracy: 98.74%\n",
      "Batch 184, Loss: 0.035449, Accuracy: 98.73%\n",
      "Batch 185, Loss: 0.016055, Accuracy: 98.74%\n",
      "Batch 186, Loss: 0.002817, Accuracy: 98.75%\n",
      "Batch 187, Loss: 0.018158, Accuracy: 98.75%\n",
      "Batch 188, Loss: 0.004741, Accuracy: 98.75%\n",
      "Batch 189, Loss: 0.011948, Accuracy: 98.76%\n",
      "Batch 190, Loss: 0.063195, Accuracy: 98.76%\n",
      "Batch 191, Loss: 0.004230, Accuracy: 98.76%\n",
      "Batch 192, Loss: 0.046583, Accuracy: 98.76%\n",
      "Batch 193, Loss: 0.031807, Accuracy: 98.76%\n",
      "Batch 194, Loss: 0.036754, Accuracy: 98.76%\n",
      "Batch 195, Loss: 0.011015, Accuracy: 98.77%\n",
      "Batch 196, Loss: 0.051388, Accuracy: 98.76%\n",
      "Batch 197, Loss: 0.021428, Accuracy: 98.76%\n",
      "Batch 198, Loss: 0.005190, Accuracy: 98.77%\n",
      "Batch 199, Loss: 0.063778, Accuracy: 98.77%\n",
      "Batch 200, Loss: 0.021148, Accuracy: 98.77%\n",
      "Batch 201, Loss: 0.015623, Accuracy: 98.76%\n",
      "Batch 202, Loss: 0.032670, Accuracy: 98.76%\n",
      "Batch 203, Loss: 0.013355, Accuracy: 98.77%\n",
      "Batch 204, Loss: 0.011970, Accuracy: 98.77%\n",
      "Batch 205, Loss: 0.005311, Accuracy: 98.78%\n",
      "Batch 206, Loss: 0.177256, Accuracy: 98.75%\n",
      "Batch 207, Loss: 0.022270, Accuracy: 98.75%\n",
      "Batch 208, Loss: 0.072779, Accuracy: 98.74%\n",
      "Batch 209, Loss: 0.006146, Accuracy: 98.74%\n",
      "Batch 210, Loss: 0.053142, Accuracy: 98.74%\n",
      "Batch 211, Loss: 0.011152, Accuracy: 98.75%\n",
      "Batch 212, Loss: 0.056096, Accuracy: 98.74%\n",
      "Batch 213, Loss: 0.120676, Accuracy: 98.73%\n",
      "Training - Epoch 20, Loss: 0.036525, Accuracy: 98.73%\n",
      "Validation Batch 1, Loss: 0.139798, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.148473, Accuracy: 96.88%\n",
      "Validation Batch 3, Loss: 0.104144, Accuracy: 96.88%\n",
      "Validation Batch 4, Loss: 0.028861, Accuracy: 97.27%\n",
      "Validation Batch 5, Loss: 0.022624, Accuracy: 97.81%\n",
      "Validation Batch 6, Loss: 0.037808, Accuracy: 97.92%\n",
      "Validation Batch 7, Loss: 0.006959, Accuracy: 98.21%\n",
      "Validation Batch 8, Loss: 0.152052, Accuracy: 97.85%\n",
      "Validation Batch 9, Loss: 0.083673, Accuracy: 97.57%\n",
      "Validation Batch 10, Loss: 0.128159, Accuracy: 97.50%\n",
      "Validation Batch 11, Loss: 0.093886, Accuracy: 97.44%\n",
      "Validation Batch 12, Loss: 0.149902, Accuracy: 97.40%\n",
      "Validation Batch 13, Loss: 0.079605, Accuracy: 97.48%\n",
      "Validation Batch 14, Loss: 0.158518, Accuracy: 97.21%\n",
      "Validation Batch 15, Loss: 0.079955, Accuracy: 97.19%\n",
      "Validation Batch 16, Loss: 0.240050, Accuracy: 96.88%\n",
      "Validation Batch 17, Loss: 0.105267, Accuracy: 96.88%\n",
      "Validation Batch 18, Loss: 0.146941, Accuracy: 96.79%\n",
      "Validation Batch 19, Loss: 0.059036, Accuracy: 96.79%\n",
      "Validation Batch 20, Loss: 0.067073, Accuracy: 96.88%\n",
      "Validation Batch 21, Loss: 0.048576, Accuracy: 96.95%\n",
      "Validation Batch 22, Loss: 0.011661, Accuracy: 97.09%\n",
      "Validation Batch 23, Loss: 0.014024, Accuracy: 97.21%\n",
      "Validation Batch 24, Loss: 0.125047, Accuracy: 97.27%\n",
      "Validation Batch 25, Loss: 0.008228, Accuracy: 97.38%\n",
      "Validation Batch 26, Loss: 0.032327, Accuracy: 97.42%\n",
      "Validation Batch 27, Loss: 0.046988, Accuracy: 97.42%\n",
      "Validation - Epoch 20, Loss: 0.085912, Accuracy: 97.42%\n",
      "Patience—4\n",
      "Epoch 21\n",
      "Batch 1, Loss: 0.029150, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.063892, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.224226, Accuracy: 97.92%\n",
      "Batch 4, Loss: 0.049290, Accuracy: 98.05%\n",
      "Batch 5, Loss: 0.053633, Accuracy: 98.12%\n",
      "Batch 6, Loss: 0.006604, Accuracy: 98.44%\n",
      "Batch 7, Loss: 0.064776, Accuracy: 98.21%\n",
      "Batch 8, Loss: 0.009171, Accuracy: 98.44%\n",
      "Batch 9, Loss: 0.027479, Accuracy: 98.44%\n",
      "Batch 10, Loss: 0.029512, Accuracy: 98.59%\n",
      "Batch 11, Loss: 0.095915, Accuracy: 98.30%\n",
      "Batch 12, Loss: 0.123737, Accuracy: 98.18%\n",
      "Batch 13, Loss: 0.027540, Accuracy: 98.32%\n",
      "Batch 14, Loss: 0.024835, Accuracy: 98.44%\n",
      "Batch 15, Loss: 0.141222, Accuracy: 98.33%\n",
      "Batch 16, Loss: 0.103701, Accuracy: 98.24%\n",
      "Batch 17, Loss: 0.085152, Accuracy: 98.16%\n",
      "Batch 18, Loss: 0.008801, Accuracy: 98.26%\n",
      "Batch 19, Loss: 0.123081, Accuracy: 98.19%\n",
      "Batch 20, Loss: 0.005976, Accuracy: 98.28%\n",
      "Batch 21, Loss: 0.003111, Accuracy: 98.36%\n",
      "Batch 22, Loss: 0.113992, Accuracy: 98.22%\n",
      "Batch 23, Loss: 0.010200, Accuracy: 98.30%\n",
      "Batch 24, Loss: 0.047357, Accuracy: 98.31%\n",
      "Batch 25, Loss: 0.134661, Accuracy: 98.19%\n",
      "Batch 26, Loss: 0.023977, Accuracy: 98.26%\n",
      "Batch 27, Loss: 0.026506, Accuracy: 98.26%\n",
      "Batch 28, Loss: 0.046738, Accuracy: 98.27%\n",
      "Batch 29, Loss: 0.128985, Accuracy: 98.11%\n",
      "Batch 30, Loss: 0.032637, Accuracy: 98.12%\n",
      "Batch 31, Loss: 0.004797, Accuracy: 98.19%\n",
      "Batch 32, Loss: 0.018990, Accuracy: 98.24%\n",
      "Batch 33, Loss: 0.093936, Accuracy: 98.20%\n",
      "Batch 34, Loss: 0.113917, Accuracy: 98.16%\n",
      "Batch 35, Loss: 0.047727, Accuracy: 98.21%\n",
      "Batch 36, Loss: 0.086872, Accuracy: 98.22%\n",
      "Batch 37, Loss: 0.005909, Accuracy: 98.27%\n",
      "Batch 38, Loss: 0.032341, Accuracy: 98.27%\n",
      "Batch 39, Loss: 0.029607, Accuracy: 98.32%\n",
      "Batch 40, Loss: 0.005126, Accuracy: 98.36%\n",
      "Batch 41, Loss: 0.038461, Accuracy: 98.36%\n",
      "Batch 42, Loss: 0.034173, Accuracy: 98.36%\n",
      "Batch 43, Loss: 0.013181, Accuracy: 98.40%\n",
      "Batch 44, Loss: 0.011145, Accuracy: 98.44%\n",
      "Batch 45, Loss: 0.013181, Accuracy: 98.47%\n",
      "Batch 46, Loss: 0.042570, Accuracy: 98.47%\n",
      "Batch 47, Loss: 0.130329, Accuracy: 98.40%\n",
      "Batch 48, Loss: 0.009236, Accuracy: 98.44%\n",
      "Batch 49, Loss: 0.015027, Accuracy: 98.47%\n",
      "Batch 50, Loss: 0.043395, Accuracy: 98.47%\n",
      "Batch 51, Loss: 0.006600, Accuracy: 98.50%\n",
      "Batch 52, Loss: 0.064826, Accuracy: 98.47%\n",
      "Batch 53, Loss: 0.066379, Accuracy: 98.44%\n",
      "Batch 54, Loss: 0.014064, Accuracy: 98.47%\n",
      "Batch 55, Loss: 0.009282, Accuracy: 98.49%\n",
      "Batch 56, Loss: 0.004994, Accuracy: 98.52%\n",
      "Batch 57, Loss: 0.081183, Accuracy: 98.52%\n",
      "Batch 58, Loss: 0.020115, Accuracy: 98.55%\n",
      "Batch 59, Loss: 0.008625, Accuracy: 98.57%\n",
      "Batch 60, Loss: 0.006897, Accuracy: 98.59%\n",
      "Batch 61, Loss: 0.019320, Accuracy: 98.59%\n",
      "Batch 62, Loss: 0.021993, Accuracy: 98.61%\n",
      "Batch 63, Loss: 0.030390, Accuracy: 98.61%\n",
      "Batch 64, Loss: 0.046949, Accuracy: 98.61%\n",
      "Batch 65, Loss: 0.065470, Accuracy: 98.61%\n",
      "Batch 66, Loss: 0.012188, Accuracy: 98.63%\n",
      "Batch 67, Loss: 0.007458, Accuracy: 98.65%\n",
      "Batch 68, Loss: 0.005881, Accuracy: 98.67%\n",
      "Batch 69, Loss: 0.008990, Accuracy: 98.69%\n",
      "Batch 70, Loss: 0.005915, Accuracy: 98.71%\n",
      "Batch 71, Loss: 0.020518, Accuracy: 98.72%\n",
      "Batch 72, Loss: 0.004320, Accuracy: 98.74%\n",
      "Batch 73, Loss: 0.004992, Accuracy: 98.76%\n",
      "Batch 74, Loss: 0.008197, Accuracy: 98.78%\n",
      "Batch 75, Loss: 0.004823, Accuracy: 98.79%\n",
      "Batch 76, Loss: 0.022876, Accuracy: 98.79%\n",
      "Batch 77, Loss: 0.004127, Accuracy: 98.80%\n",
      "Batch 78, Loss: 0.007527, Accuracy: 98.82%\n",
      "Batch 79, Loss: 0.006086, Accuracy: 98.83%\n",
      "Batch 80, Loss: 0.008355, Accuracy: 98.85%\n",
      "Batch 81, Loss: 0.005861, Accuracy: 98.86%\n",
      "Batch 82, Loss: 0.005977, Accuracy: 98.88%\n",
      "Batch 83, Loss: 0.015783, Accuracy: 98.89%\n",
      "Batch 84, Loss: 0.023081, Accuracy: 98.88%\n",
      "Batch 85, Loss: 0.006795, Accuracy: 98.90%\n",
      "Batch 86, Loss: 0.008480, Accuracy: 98.91%\n",
      "Batch 87, Loss: 0.008068, Accuracy: 98.92%\n",
      "Batch 88, Loss: 0.028791, Accuracy: 98.92%\n",
      "Batch 89, Loss: 0.002884, Accuracy: 98.93%\n",
      "Batch 90, Loss: 0.004070, Accuracy: 98.94%\n",
      "Batch 91, Loss: 0.011176, Accuracy: 98.95%\n",
      "Batch 92, Loss: 0.004195, Accuracy: 98.96%\n",
      "Batch 93, Loss: 0.006067, Accuracy: 98.98%\n",
      "Batch 94, Loss: 0.002800, Accuracy: 98.99%\n",
      "Batch 95, Loss: 0.035974, Accuracy: 98.98%\n",
      "Batch 96, Loss: 0.011301, Accuracy: 98.99%\n",
      "Batch 97, Loss: 0.058324, Accuracy: 98.99%\n",
      "Batch 98, Loss: 0.010791, Accuracy: 99.00%\n",
      "Batch 99, Loss: 0.015700, Accuracy: 98.99%\n",
      "Batch 100, Loss: 0.009379, Accuracy: 99.00%\n",
      "Batch 101, Loss: 0.005706, Accuracy: 99.01%\n",
      "Batch 102, Loss: 0.014661, Accuracy: 99.02%\n",
      "Batch 103, Loss: 0.045227, Accuracy: 99.00%\n",
      "Batch 104, Loss: 0.011272, Accuracy: 99.01%\n",
      "Batch 105, Loss: 0.019925, Accuracy: 99.00%\n",
      "Batch 106, Loss: 0.035090, Accuracy: 99.00%\n",
      "Batch 107, Loss: 0.004120, Accuracy: 99.01%\n",
      "Batch 108, Loss: 0.017851, Accuracy: 99.00%\n",
      "Batch 109, Loss: 0.049901, Accuracy: 98.98%\n",
      "Batch 110, Loss: 0.004345, Accuracy: 98.99%\n",
      "Batch 111, Loss: 0.003707, Accuracy: 99.00%\n",
      "Batch 112, Loss: 0.008431, Accuracy: 99.01%\n",
      "Batch 113, Loss: 0.003993, Accuracy: 99.02%\n",
      "Batch 114, Loss: 0.006373, Accuracy: 99.03%\n",
      "Batch 115, Loss: 0.005642, Accuracy: 99.04%\n",
      "Batch 116, Loss: 0.012038, Accuracy: 99.04%\n",
      "Batch 117, Loss: 0.114144, Accuracy: 99.03%\n",
      "Batch 118, Loss: 0.007215, Accuracy: 99.03%\n",
      "Batch 119, Loss: 0.007878, Accuracy: 99.04%\n",
      "Batch 120, Loss: 0.012735, Accuracy: 99.05%\n",
      "Batch 121, Loss: 0.019821, Accuracy: 99.04%\n",
      "Batch 122, Loss: 0.003290, Accuracy: 99.05%\n",
      "Batch 123, Loss: 0.080028, Accuracy: 99.03%\n",
      "Batch 124, Loss: 0.058694, Accuracy: 99.03%\n",
      "Batch 125, Loss: 0.020293, Accuracy: 99.04%\n",
      "Batch 126, Loss: 0.011397, Accuracy: 99.05%\n",
      "Batch 127, Loss: 0.005426, Accuracy: 99.05%\n",
      "Batch 128, Loss: 0.003322, Accuracy: 99.06%\n",
      "Batch 129, Loss: 0.022050, Accuracy: 99.07%\n",
      "Batch 130, Loss: 0.004292, Accuracy: 99.07%\n",
      "Batch 131, Loss: 0.250455, Accuracy: 99.05%\n",
      "Batch 132, Loss: 0.038686, Accuracy: 99.04%\n",
      "Batch 133, Loss: 0.009780, Accuracy: 99.05%\n",
      "Batch 134, Loss: 0.008620, Accuracy: 99.06%\n",
      "Batch 135, Loss: 0.004222, Accuracy: 99.06%\n",
      "Batch 136, Loss: 0.018950, Accuracy: 99.06%\n",
      "Batch 137, Loss: 0.081507, Accuracy: 99.04%\n",
      "Batch 138, Loss: 0.008321, Accuracy: 99.05%\n",
      "Batch 139, Loss: 0.003157, Accuracy: 99.06%\n",
      "Batch 140, Loss: 0.032370, Accuracy: 99.05%\n",
      "Batch 141, Loss: 0.009452, Accuracy: 99.06%\n",
      "Batch 142, Loss: 0.043640, Accuracy: 99.05%\n",
      "Batch 143, Loss: 0.047288, Accuracy: 99.05%\n",
      "Batch 144, Loss: 0.003355, Accuracy: 99.06%\n",
      "Batch 145, Loss: 0.026295, Accuracy: 99.06%\n",
      "Batch 146, Loss: 0.041430, Accuracy: 99.06%\n",
      "Batch 147, Loss: 0.012861, Accuracy: 99.06%\n",
      "Batch 148, Loss: 0.039361, Accuracy: 99.06%\n",
      "Batch 149, Loss: 0.003816, Accuracy: 99.07%\n",
      "Batch 150, Loss: 0.013424, Accuracy: 99.07%\n",
      "Batch 151, Loss: 0.002850, Accuracy: 99.08%\n",
      "Batch 152, Loss: 0.011874, Accuracy: 99.09%\n",
      "Batch 153, Loss: 0.003223, Accuracy: 99.09%\n",
      "Batch 154, Loss: 0.061729, Accuracy: 99.09%\n",
      "Batch 155, Loss: 0.006152, Accuracy: 99.09%\n",
      "Batch 156, Loss: 0.004028, Accuracy: 99.10%\n",
      "Batch 157, Loss: 0.004107, Accuracy: 99.10%\n",
      "Batch 158, Loss: 0.002845, Accuracy: 99.11%\n",
      "Batch 159, Loss: 0.034438, Accuracy: 99.11%\n",
      "Batch 160, Loss: 0.045736, Accuracy: 99.10%\n",
      "Batch 161, Loss: 0.005332, Accuracy: 99.11%\n",
      "Batch 162, Loss: 0.047129, Accuracy: 99.10%\n",
      "Batch 163, Loss: 0.006730, Accuracy: 99.11%\n",
      "Batch 164, Loss: 0.006047, Accuracy: 99.11%\n",
      "Batch 165, Loss: 0.026307, Accuracy: 99.11%\n",
      "Batch 166, Loss: 0.003027, Accuracy: 99.12%\n",
      "Batch 167, Loss: 0.006839, Accuracy: 99.12%\n",
      "Batch 168, Loss: 0.019440, Accuracy: 99.13%\n",
      "Batch 169, Loss: 0.034951, Accuracy: 99.11%\n",
      "Batch 170, Loss: 0.056403, Accuracy: 99.11%\n",
      "Batch 171, Loss: 0.004867, Accuracy: 99.11%\n",
      "Batch 172, Loss: 0.078049, Accuracy: 99.11%\n",
      "Batch 173, Loss: 0.038667, Accuracy: 99.11%\n",
      "Batch 174, Loss: 0.027572, Accuracy: 99.10%\n",
      "Batch 175, Loss: 0.037299, Accuracy: 99.10%\n",
      "Batch 176, Loss: 0.026616, Accuracy: 99.09%\n",
      "Batch 177, Loss: 0.057291, Accuracy: 99.09%\n",
      "Batch 178, Loss: 0.120080, Accuracy: 99.07%\n",
      "Batch 179, Loss: 0.009285, Accuracy: 99.07%\n",
      "Batch 180, Loss: 0.008765, Accuracy: 99.08%\n",
      "Batch 181, Loss: 0.003193, Accuracy: 99.08%\n",
      "Batch 182, Loss: 0.094201, Accuracy: 99.08%\n",
      "Batch 183, Loss: 0.007375, Accuracy: 99.09%\n",
      "Batch 184, Loss: 0.005343, Accuracy: 99.09%\n",
      "Batch 185, Loss: 0.040860, Accuracy: 99.09%\n",
      "Batch 186, Loss: 0.003652, Accuracy: 99.09%\n",
      "Batch 187, Loss: 0.007007, Accuracy: 99.10%\n",
      "Batch 188, Loss: 0.029988, Accuracy: 99.09%\n",
      "Batch 189, Loss: 0.020444, Accuracy: 99.09%\n",
      "Batch 190, Loss: 0.097115, Accuracy: 99.09%\n",
      "Batch 191, Loss: 0.012363, Accuracy: 99.09%\n",
      "Batch 192, Loss: 0.013515, Accuracy: 99.10%\n",
      "Batch 193, Loss: 0.073742, Accuracy: 99.09%\n",
      "Batch 194, Loss: 0.039814, Accuracy: 99.08%\n",
      "Batch 195, Loss: 0.003453, Accuracy: 99.09%\n",
      "Batch 196, Loss: 0.012852, Accuracy: 99.09%\n",
      "Batch 197, Loss: 0.017410, Accuracy: 99.10%\n",
      "Batch 198, Loss: 0.005531, Accuracy: 99.10%\n",
      "Batch 199, Loss: 0.021848, Accuracy: 99.10%\n",
      "Batch 200, Loss: 0.002617, Accuracy: 99.10%\n",
      "Batch 201, Loss: 0.009766, Accuracy: 99.11%\n",
      "Batch 202, Loss: 0.061100, Accuracy: 99.10%\n",
      "Batch 203, Loss: 0.002980, Accuracy: 99.11%\n",
      "Batch 204, Loss: 0.144974, Accuracy: 99.10%\n",
      "Batch 205, Loss: 0.009630, Accuracy: 99.10%\n",
      "Batch 206, Loss: 0.007113, Accuracy: 99.10%\n",
      "Batch 207, Loss: 0.003101, Accuracy: 99.11%\n",
      "Batch 208, Loss: 0.005371, Accuracy: 99.11%\n",
      "Batch 209, Loss: 0.003376, Accuracy: 99.12%\n",
      "Batch 210, Loss: 0.049376, Accuracy: 99.11%\n",
      "Batch 211, Loss: 0.005462, Accuracy: 99.12%\n",
      "Batch 212, Loss: 0.048111, Accuracy: 99.12%\n",
      "Batch 213, Loss: 0.004358, Accuracy: 99.12%\n",
      "Training - Epoch 21, Loss: 0.030569, Accuracy: 99.12%\n",
      "Validation Batch 1, Loss: 0.020830, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.034261, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.018067, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.025860, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.015250, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.006912, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.003067, Accuracy: 99.11%\n",
      "Validation Batch 8, Loss: 0.010473, Accuracy: 99.22%\n",
      "Validation Batch 9, Loss: 0.039724, Accuracy: 99.13%\n",
      "Validation Batch 10, Loss: 0.003802, Accuracy: 99.22%\n",
      "Validation Batch 11, Loss: 0.022319, Accuracy: 99.15%\n",
      "Validation Batch 12, Loss: 0.045041, Accuracy: 99.09%\n",
      "Validation Batch 13, Loss: 0.061795, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.270668, Accuracy: 98.55%\n",
      "Validation Batch 15, Loss: 0.020750, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.006693, Accuracy: 98.73%\n",
      "Validation Batch 17, Loss: 0.004896, Accuracy: 98.81%\n",
      "Validation Batch 18, Loss: 0.101341, Accuracy: 98.70%\n",
      "Validation Batch 19, Loss: 0.019400, Accuracy: 98.77%\n",
      "Validation Batch 20, Loss: 0.028641, Accuracy: 98.75%\n",
      "Validation Batch 21, Loss: 0.051414, Accuracy: 98.74%\n",
      "Validation Batch 22, Loss: 0.026204, Accuracy: 98.72%\n",
      "Validation Batch 23, Loss: 0.003914, Accuracy: 98.78%\n",
      "Validation Batch 24, Loss: 0.146535, Accuracy: 98.70%\n",
      "Validation Batch 25, Loss: 0.060180, Accuracy: 98.69%\n",
      "Validation Batch 26, Loss: 0.010061, Accuracy: 98.74%\n",
      "Validation Batch 27, Loss: 0.010193, Accuracy: 98.77%\n",
      "Validation - Epoch 21, Loss: 0.039566, Accuracy: 98.77%\n",
      "Patience—5\n",
      "Epoch 22\n",
      "Batch 1, Loss: 0.003121, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.008012, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.038600, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.010217, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.003523, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.012064, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.003726, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.013046, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.014224, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.005131, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.004810, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.010726, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.003596, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.002388, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.002385, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.006789, Accuracy: 99.90%\n",
      "Batch 17, Loss: 0.006925, Accuracy: 99.91%\n",
      "Batch 18, Loss: 0.002641, Accuracy: 99.91%\n",
      "Batch 19, Loss: 0.003723, Accuracy: 99.92%\n",
      "Batch 20, Loss: 0.005676, Accuracy: 99.92%\n",
      "Batch 21, Loss: 0.003273, Accuracy: 99.93%\n",
      "Batch 22, Loss: 0.004674, Accuracy: 99.93%\n",
      "Batch 23, Loss: 0.004386, Accuracy: 99.93%\n",
      "Batch 24, Loss: 0.003077, Accuracy: 99.93%\n",
      "Batch 25, Loss: 0.015771, Accuracy: 99.94%\n",
      "Batch 26, Loss: 0.005612, Accuracy: 99.94%\n",
      "Batch 27, Loss: 0.009598, Accuracy: 99.94%\n",
      "Batch 28, Loss: 0.004420, Accuracy: 99.94%\n",
      "Batch 29, Loss: 0.002418, Accuracy: 99.95%\n",
      "Batch 30, Loss: 0.002543, Accuracy: 99.95%\n",
      "Batch 31, Loss: 0.001783, Accuracy: 99.95%\n",
      "Batch 32, Loss: 0.003071, Accuracy: 99.95%\n",
      "Batch 33, Loss: 0.021490, Accuracy: 99.91%\n",
      "Batch 34, Loss: 0.002599, Accuracy: 99.91%\n",
      "Batch 35, Loss: 0.006329, Accuracy: 99.91%\n",
      "Batch 36, Loss: 0.004270, Accuracy: 99.91%\n",
      "Batch 37, Loss: 0.003247, Accuracy: 99.92%\n",
      "Batch 38, Loss: 0.008296, Accuracy: 99.92%\n",
      "Batch 39, Loss: 0.002689, Accuracy: 99.92%\n",
      "Batch 40, Loss: 0.002292, Accuracy: 99.92%\n",
      "Batch 41, Loss: 0.007465, Accuracy: 99.92%\n",
      "Batch 42, Loss: 0.002301, Accuracy: 99.93%\n",
      "Batch 43, Loss: 0.007064, Accuracy: 99.93%\n",
      "Batch 44, Loss: 0.003967, Accuracy: 99.93%\n",
      "Batch 45, Loss: 0.006440, Accuracy: 99.93%\n",
      "Batch 46, Loss: 0.002532, Accuracy: 99.93%\n",
      "Batch 47, Loss: 0.003570, Accuracy: 99.93%\n",
      "Batch 48, Loss: 0.003892, Accuracy: 99.93%\n",
      "Batch 49, Loss: 0.002730, Accuracy: 99.94%\n",
      "Batch 50, Loss: 0.030396, Accuracy: 99.91%\n",
      "Batch 51, Loss: 0.002166, Accuracy: 99.91%\n",
      "Batch 52, Loss: 0.002090, Accuracy: 99.91%\n",
      "Batch 53, Loss: 0.001962, Accuracy: 99.91%\n",
      "Batch 54, Loss: 0.001720, Accuracy: 99.91%\n",
      "Batch 55, Loss: 0.001973, Accuracy: 99.91%\n",
      "Batch 56, Loss: 0.001989, Accuracy: 99.92%\n",
      "Batch 57, Loss: 0.002005, Accuracy: 99.92%\n",
      "Batch 58, Loss: 0.001784, Accuracy: 99.92%\n",
      "Batch 59, Loss: 0.004180, Accuracy: 99.92%\n",
      "Batch 60, Loss: 0.001821, Accuracy: 99.92%\n",
      "Batch 61, Loss: 0.003302, Accuracy: 99.92%\n",
      "Batch 62, Loss: 0.001849, Accuracy: 99.92%\n",
      "Batch 63, Loss: 0.003080, Accuracy: 99.93%\n",
      "Batch 64, Loss: 0.001800, Accuracy: 99.93%\n",
      "Batch 65, Loss: 0.002272, Accuracy: 99.93%\n",
      "Batch 66, Loss: 0.003888, Accuracy: 99.93%\n",
      "Batch 67, Loss: 0.005678, Accuracy: 99.93%\n",
      "Batch 68, Loss: 0.004816, Accuracy: 99.93%\n",
      "Batch 69, Loss: 0.002103, Accuracy: 99.93%\n",
      "Batch 70, Loss: 0.004581, Accuracy: 99.93%\n",
      "Batch 71, Loss: 0.001767, Accuracy: 99.93%\n",
      "Batch 72, Loss: 0.001849, Accuracy: 99.93%\n",
      "Batch 73, Loss: 0.002776, Accuracy: 99.94%\n",
      "Batch 74, Loss: 0.002240, Accuracy: 99.94%\n",
      "Batch 75, Loss: 0.002454, Accuracy: 99.94%\n",
      "Batch 76, Loss: 0.013328, Accuracy: 99.92%\n",
      "Batch 77, Loss: 0.003855, Accuracy: 99.92%\n",
      "Batch 78, Loss: 0.003932, Accuracy: 99.92%\n",
      "Batch 79, Loss: 0.004818, Accuracy: 99.92%\n",
      "Batch 80, Loss: 0.002079, Accuracy: 99.92%\n",
      "Batch 81, Loss: 0.001626, Accuracy: 99.92%\n",
      "Batch 82, Loss: 0.004475, Accuracy: 99.92%\n",
      "Batch 83, Loss: 0.004606, Accuracy: 99.92%\n",
      "Batch 84, Loss: 0.002379, Accuracy: 99.93%\n",
      "Batch 85, Loss: 0.063984, Accuracy: 99.91%\n",
      "Batch 86, Loss: 0.003260, Accuracy: 99.91%\n",
      "Batch 87, Loss: 0.001534, Accuracy: 99.91%\n",
      "Batch 88, Loss: 0.004228, Accuracy: 99.91%\n",
      "Batch 89, Loss: 0.001888, Accuracy: 99.91%\n",
      "Batch 90, Loss: 0.002310, Accuracy: 99.91%\n",
      "Batch 91, Loss: 0.002973, Accuracy: 99.91%\n",
      "Batch 92, Loss: 0.001620, Accuracy: 99.92%\n",
      "Batch 93, Loss: 0.002272, Accuracy: 99.92%\n",
      "Batch 94, Loss: 0.013374, Accuracy: 99.92%\n",
      "Batch 95, Loss: 0.004697, Accuracy: 99.92%\n",
      "Batch 96, Loss: 0.008106, Accuracy: 99.92%\n",
      "Batch 97, Loss: 0.002632, Accuracy: 99.92%\n",
      "Batch 98, Loss: 0.001816, Accuracy: 99.92%\n",
      "Batch 99, Loss: 0.002453, Accuracy: 99.92%\n",
      "Batch 100, Loss: 0.007826, Accuracy: 99.92%\n",
      "Batch 101, Loss: 0.003857, Accuracy: 99.92%\n",
      "Batch 102, Loss: 0.002387, Accuracy: 99.92%\n",
      "Batch 103, Loss: 0.002118, Accuracy: 99.92%\n",
      "Batch 104, Loss: 0.002329, Accuracy: 99.92%\n",
      "Batch 105, Loss: 0.001934, Accuracy: 99.93%\n",
      "Batch 106, Loss: 0.001814, Accuracy: 99.93%\n",
      "Batch 107, Loss: 0.002182, Accuracy: 99.93%\n",
      "Batch 108, Loss: 0.002731, Accuracy: 99.93%\n",
      "Batch 109, Loss: 0.001857, Accuracy: 99.93%\n",
      "Batch 110, Loss: 0.002160, Accuracy: 99.93%\n",
      "Batch 111, Loss: 0.001854, Accuracy: 99.93%\n",
      "Batch 112, Loss: 0.001707, Accuracy: 99.93%\n",
      "Batch 113, Loss: 0.002635, Accuracy: 99.93%\n",
      "Batch 114, Loss: 0.002274, Accuracy: 99.93%\n",
      "Batch 115, Loss: 0.001580, Accuracy: 99.93%\n",
      "Batch 116, Loss: 0.002552, Accuracy: 99.93%\n",
      "Batch 117, Loss: 0.002090, Accuracy: 99.93%\n",
      "Batch 118, Loss: 0.001877, Accuracy: 99.93%\n",
      "Batch 119, Loss: 0.001768, Accuracy: 99.93%\n",
      "Batch 120, Loss: 0.002785, Accuracy: 99.93%\n",
      "Batch 121, Loss: 0.002878, Accuracy: 99.94%\n",
      "Batch 122, Loss: 0.004701, Accuracy: 99.94%\n",
      "Batch 123, Loss: 0.001825, Accuracy: 99.94%\n",
      "Batch 124, Loss: 0.004474, Accuracy: 99.94%\n",
      "Batch 125, Loss: 0.001580, Accuracy: 99.94%\n",
      "Batch 126, Loss: 0.001523, Accuracy: 99.94%\n",
      "Batch 127, Loss: 0.007114, Accuracy: 99.94%\n",
      "Batch 128, Loss: 0.001447, Accuracy: 99.94%\n",
      "Batch 129, Loss: 0.003476, Accuracy: 99.94%\n",
      "Batch 130, Loss: 0.001386, Accuracy: 99.94%\n",
      "Batch 131, Loss: 0.003098, Accuracy: 99.94%\n",
      "Batch 132, Loss: 0.001425, Accuracy: 99.94%\n",
      "Batch 133, Loss: 0.011032, Accuracy: 99.94%\n",
      "Batch 134, Loss: 0.002618, Accuracy: 99.94%\n",
      "Batch 135, Loss: 0.001774, Accuracy: 99.94%\n",
      "Batch 136, Loss: 0.001843, Accuracy: 99.94%\n",
      "Batch 137, Loss: 0.001711, Accuracy: 99.94%\n",
      "Batch 138, Loss: 0.001593, Accuracy: 99.94%\n",
      "Batch 139, Loss: 0.002015, Accuracy: 99.94%\n",
      "Batch 140, Loss: 0.001790, Accuracy: 99.94%\n",
      "Batch 141, Loss: 0.003040, Accuracy: 99.94%\n",
      "Batch 142, Loss: 0.001481, Accuracy: 99.94%\n",
      "Batch 143, Loss: 0.002034, Accuracy: 99.95%\n",
      "Batch 144, Loss: 0.001758, Accuracy: 99.95%\n",
      "Batch 145, Loss: 0.001698, Accuracy: 99.95%\n",
      "Batch 146, Loss: 0.002034, Accuracy: 99.95%\n",
      "Batch 147, Loss: 0.002105, Accuracy: 99.95%\n",
      "Batch 148, Loss: 0.001448, Accuracy: 99.95%\n",
      "Batch 149, Loss: 0.001711, Accuracy: 99.95%\n",
      "Batch 150, Loss: 0.002019, Accuracy: 99.95%\n",
      "Batch 151, Loss: 0.004311, Accuracy: 99.95%\n",
      "Batch 152, Loss: 0.001496, Accuracy: 99.95%\n",
      "Batch 153, Loss: 0.002111, Accuracy: 99.95%\n",
      "Batch 154, Loss: 0.001825, Accuracy: 99.95%\n",
      "Batch 155, Loss: 0.001762, Accuracy: 99.95%\n",
      "Batch 156, Loss: 0.002276, Accuracy: 99.95%\n",
      "Batch 157, Loss: 0.001546, Accuracy: 99.95%\n",
      "Batch 158, Loss: 0.001359, Accuracy: 99.95%\n",
      "Batch 159, Loss: 0.002734, Accuracy: 99.95%\n",
      "Batch 160, Loss: 0.002617, Accuracy: 99.95%\n",
      "Batch 161, Loss: 0.001794, Accuracy: 99.95%\n",
      "Batch 162, Loss: 0.001494, Accuracy: 99.95%\n",
      "Batch 163, Loss: 0.001544, Accuracy: 99.95%\n",
      "Batch 164, Loss: 0.001848, Accuracy: 99.95%\n",
      "Batch 165, Loss: 0.001700, Accuracy: 99.95%\n",
      "Batch 166, Loss: 0.001605, Accuracy: 99.95%\n",
      "Batch 167, Loss: 0.001844, Accuracy: 99.95%\n",
      "Batch 168, Loss: 0.001537, Accuracy: 99.95%\n",
      "Batch 169, Loss: 0.002404, Accuracy: 99.95%\n",
      "Batch 170, Loss: 0.001371, Accuracy: 99.95%\n",
      "Batch 171, Loss: 0.001793, Accuracy: 99.95%\n",
      "Batch 172, Loss: 0.001546, Accuracy: 99.95%\n",
      "Batch 173, Loss: 0.001541, Accuracy: 99.95%\n",
      "Batch 174, Loss: 0.002254, Accuracy: 99.96%\n",
      "Batch 175, Loss: 0.002649, Accuracy: 99.96%\n",
      "Batch 176, Loss: 0.002912, Accuracy: 99.96%\n",
      "Batch 177, Loss: 0.002239, Accuracy: 99.96%\n",
      "Batch 178, Loss: 0.001815, Accuracy: 99.96%\n",
      "Batch 179, Loss: 0.006119, Accuracy: 99.96%\n",
      "Batch 180, Loss: 0.002537, Accuracy: 99.96%\n",
      "Batch 181, Loss: 0.001433, Accuracy: 99.96%\n",
      "Batch 182, Loss: 0.001670, Accuracy: 99.96%\n",
      "Batch 183, Loss: 0.002038, Accuracy: 99.96%\n",
      "Batch 184, Loss: 0.001574, Accuracy: 99.96%\n",
      "Batch 185, Loss: 0.001459, Accuracy: 99.96%\n",
      "Batch 186, Loss: 0.001212, Accuracy: 99.96%\n",
      "Batch 187, Loss: 0.002787, Accuracy: 99.96%\n",
      "Batch 188, Loss: 0.001489, Accuracy: 99.96%\n",
      "Batch 189, Loss: 0.033991, Accuracy: 99.95%\n",
      "Batch 190, Loss: 0.001526, Accuracy: 99.95%\n",
      "Batch 191, Loss: 0.001582, Accuracy: 99.95%\n",
      "Batch 192, Loss: 0.001348, Accuracy: 99.95%\n",
      "Batch 193, Loss: 0.001907, Accuracy: 99.95%\n",
      "Batch 194, Loss: 0.003559, Accuracy: 99.95%\n",
      "Batch 195, Loss: 0.001845, Accuracy: 99.95%\n",
      "Batch 196, Loss: 0.010026, Accuracy: 99.95%\n",
      "Batch 197, Loss: 0.001485, Accuracy: 99.95%\n",
      "Batch 198, Loss: 0.003505, Accuracy: 99.95%\n",
      "Batch 199, Loss: 0.002341, Accuracy: 99.95%\n",
      "Batch 200, Loss: 0.005521, Accuracy: 99.95%\n",
      "Batch 201, Loss: 0.069974, Accuracy: 99.95%\n",
      "Batch 202, Loss: 0.001619, Accuracy: 99.95%\n",
      "Batch 203, Loss: 0.001771, Accuracy: 99.95%\n",
      "Batch 204, Loss: 0.002115, Accuracy: 99.95%\n",
      "Batch 205, Loss: 0.007610, Accuracy: 99.95%\n",
      "Batch 206, Loss: 0.002976, Accuracy: 99.95%\n",
      "Batch 207, Loss: 0.004320, Accuracy: 99.95%\n",
      "Batch 208, Loss: 0.001534, Accuracy: 99.95%\n",
      "Batch 209, Loss: 0.003792, Accuracy: 99.95%\n",
      "Batch 210, Loss: 0.002166, Accuracy: 99.95%\n",
      "Batch 211, Loss: 0.170939, Accuracy: 99.93%\n",
      "Batch 212, Loss: 0.008915, Accuracy: 99.93%\n",
      "Batch 213, Loss: 0.004864, Accuracy: 99.93%\n",
      "Training - Epoch 22, Loss: 0.005297, Accuracy: 99.93%\n",
      "Validation Batch 1, Loss: 0.011994, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.003842, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.003810, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.001775, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.003080, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.002223, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.001944, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.006590, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.008153, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.001553, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.005546, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.038292, Accuracy: 99.87%\n",
      "Validation Batch 13, Loss: 0.140817, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.006125, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.004488, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.046671, Accuracy: 99.61%\n",
      "Validation Batch 17, Loss: 0.004182, Accuracy: 99.63%\n",
      "Validation Batch 18, Loss: 0.002033, Accuracy: 99.65%\n",
      "Validation Batch 19, Loss: 0.017067, Accuracy: 99.59%\n",
      "Validation Batch 20, Loss: 0.001993, Accuracy: 99.61%\n",
      "Validation Batch 21, Loss: 0.002197, Accuracy: 99.63%\n",
      "Validation Batch 22, Loss: 0.004308, Accuracy: 99.64%\n",
      "Validation Batch 23, Loss: 0.013908, Accuracy: 99.59%\n",
      "Validation Batch 24, Loss: 0.011201, Accuracy: 99.61%\n",
      "Validation Batch 25, Loss: 0.001829, Accuracy: 99.62%\n",
      "Validation Batch 26, Loss: 0.003645, Accuracy: 99.64%\n",
      "Validation Batch 27, Loss: 0.002725, Accuracy: 99.65%\n",
      "Validation - Epoch 22, Loss: 0.013037, Accuracy: 99.65%\n",
      "Patience—0\n",
      "Epoch 23\n",
      "Batch 1, Loss: 0.004624, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.002194, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.004590, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.018555, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.003473, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.001508, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.001804, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.002048, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.002501, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.002275, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.003167, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.019821, Accuracy: 99.74%\n",
      "Batch 13, Loss: 0.012797, Accuracy: 99.76%\n",
      "Batch 14, Loss: 0.004658, Accuracy: 99.78%\n",
      "Batch 15, Loss: 0.002950, Accuracy: 99.79%\n",
      "Batch 16, Loss: 0.004725, Accuracy: 99.80%\n",
      "Batch 17, Loss: 0.002804, Accuracy: 99.82%\n",
      "Batch 18, Loss: 0.005158, Accuracy: 99.83%\n",
      "Batch 19, Loss: 0.006866, Accuracy: 99.84%\n",
      "Batch 20, Loss: 0.006887, Accuracy: 99.84%\n",
      "Batch 21, Loss: 0.003763, Accuracy: 99.85%\n",
      "Batch 22, Loss: 0.062156, Accuracy: 99.79%\n",
      "Batch 23, Loss: 0.003122, Accuracy: 99.80%\n",
      "Batch 24, Loss: 0.007478, Accuracy: 99.80%\n",
      "Batch 25, Loss: 0.002871, Accuracy: 99.81%\n",
      "Batch 26, Loss: 0.002358, Accuracy: 99.82%\n",
      "Batch 27, Loss: 0.004762, Accuracy: 99.83%\n",
      "Batch 28, Loss: 0.002682, Accuracy: 99.83%\n",
      "Batch 29, Loss: 0.022146, Accuracy: 99.78%\n",
      "Batch 30, Loss: 0.002041, Accuracy: 99.79%\n",
      "Batch 31, Loss: 0.014838, Accuracy: 99.75%\n",
      "Batch 32, Loss: 0.024093, Accuracy: 99.71%\n",
      "Batch 33, Loss: 0.001967, Accuracy: 99.72%\n",
      "Batch 34, Loss: 0.002825, Accuracy: 99.72%\n",
      "Batch 35, Loss: 0.015983, Accuracy: 99.69%\n",
      "Batch 36, Loss: 0.003678, Accuracy: 99.70%\n",
      "Batch 37, Loss: 0.002690, Accuracy: 99.70%\n",
      "Batch 38, Loss: 0.015913, Accuracy: 99.71%\n",
      "Batch 39, Loss: 0.001996, Accuracy: 99.72%\n",
      "Batch 40, Loss: 0.005856, Accuracy: 99.73%\n",
      "Batch 41, Loss: 0.001602, Accuracy: 99.73%\n",
      "Batch 42, Loss: 0.002632, Accuracy: 99.74%\n",
      "Batch 43, Loss: 0.002511, Accuracy: 99.75%\n",
      "Batch 44, Loss: 0.003315, Accuracy: 99.75%\n",
      "Batch 45, Loss: 0.001499, Accuracy: 99.76%\n",
      "Batch 46, Loss: 0.013049, Accuracy: 99.76%\n",
      "Batch 47, Loss: 0.010060, Accuracy: 99.77%\n",
      "Batch 48, Loss: 0.002220, Accuracy: 99.77%\n",
      "Batch 49, Loss: 0.001638, Accuracy: 99.78%\n",
      "Batch 50, Loss: 0.001469, Accuracy: 99.78%\n",
      "Batch 51, Loss: 0.011967, Accuracy: 99.79%\n",
      "Batch 52, Loss: 0.063886, Accuracy: 99.73%\n",
      "Batch 53, Loss: 0.007138, Accuracy: 99.73%\n",
      "Batch 54, Loss: 0.002039, Accuracy: 99.74%\n",
      "Batch 55, Loss: 0.002737, Accuracy: 99.74%\n",
      "Batch 56, Loss: 0.001651, Accuracy: 99.75%\n",
      "Batch 57, Loss: 0.002648, Accuracy: 99.75%\n",
      "Batch 58, Loss: 0.014620, Accuracy: 99.76%\n",
      "Batch 59, Loss: 0.021380, Accuracy: 99.74%\n",
      "Batch 60, Loss: 0.009275, Accuracy: 99.74%\n",
      "Batch 61, Loss: 0.002783, Accuracy: 99.74%\n",
      "Batch 62, Loss: 0.002022, Accuracy: 99.75%\n",
      "Batch 63, Loss: 0.073281, Accuracy: 99.73%\n",
      "Batch 64, Loss: 0.033266, Accuracy: 99.71%\n",
      "Batch 65, Loss: 0.060594, Accuracy: 99.69%\n",
      "Batch 66, Loss: 0.003018, Accuracy: 99.69%\n",
      "Batch 67, Loss: 0.003146, Accuracy: 99.70%\n",
      "Batch 68, Loss: 0.004974, Accuracy: 99.70%\n",
      "Batch 69, Loss: 0.003784, Accuracy: 99.71%\n",
      "Batch 70, Loss: 0.001671, Accuracy: 99.71%\n",
      "Batch 71, Loss: 0.120693, Accuracy: 99.67%\n",
      "Batch 72, Loss: 0.004987, Accuracy: 99.67%\n",
      "Batch 73, Loss: 0.093602, Accuracy: 99.64%\n",
      "Batch 74, Loss: 0.003839, Accuracy: 99.64%\n",
      "Batch 75, Loss: 0.001602, Accuracy: 99.65%\n",
      "Batch 76, Loss: 0.002358, Accuracy: 99.65%\n",
      "Batch 77, Loss: 0.003589, Accuracy: 99.66%\n",
      "Batch 78, Loss: 0.075970, Accuracy: 99.64%\n",
      "Batch 79, Loss: 0.002619, Accuracy: 99.64%\n",
      "Batch 80, Loss: 0.112577, Accuracy: 99.61%\n",
      "Batch 81, Loss: 0.002464, Accuracy: 99.61%\n",
      "Batch 82, Loss: 0.004673, Accuracy: 99.62%\n",
      "Batch 83, Loss: 0.003041, Accuracy: 99.62%\n",
      "Batch 84, Loss: 0.004246, Accuracy: 99.63%\n",
      "Batch 85, Loss: 0.026309, Accuracy: 99.61%\n",
      "Batch 86, Loss: 0.002121, Accuracy: 99.62%\n",
      "Batch 87, Loss: 0.001482, Accuracy: 99.62%\n",
      "Batch 88, Loss: 0.056196, Accuracy: 99.59%\n",
      "Batch 89, Loss: 0.002006, Accuracy: 99.60%\n",
      "Batch 90, Loss: 0.002505, Accuracy: 99.60%\n",
      "Batch 91, Loss: 0.004305, Accuracy: 99.61%\n",
      "Batch 92, Loss: 0.002130, Accuracy: 99.61%\n",
      "Batch 93, Loss: 0.002307, Accuracy: 99.61%\n",
      "Batch 94, Loss: 0.014182, Accuracy: 99.60%\n",
      "Batch 95, Loss: 0.047409, Accuracy: 99.59%\n",
      "Batch 96, Loss: 0.055739, Accuracy: 99.58%\n",
      "Batch 97, Loss: 0.002981, Accuracy: 99.58%\n",
      "Batch 98, Loss: 0.033042, Accuracy: 99.57%\n",
      "Batch 99, Loss: 0.046286, Accuracy: 99.56%\n",
      "Batch 100, Loss: 0.008644, Accuracy: 99.56%\n",
      "Batch 101, Loss: 0.036911, Accuracy: 99.54%\n",
      "Batch 102, Loss: 0.108178, Accuracy: 99.51%\n",
      "Batch 103, Loss: 0.048555, Accuracy: 99.50%\n",
      "Batch 104, Loss: 0.016543, Accuracy: 99.49%\n",
      "Batch 105, Loss: 0.004121, Accuracy: 99.49%\n",
      "Batch 106, Loss: 0.004728, Accuracy: 99.50%\n",
      "Batch 107, Loss: 0.004103, Accuracy: 99.50%\n",
      "Batch 108, Loss: 0.038066, Accuracy: 99.49%\n",
      "Batch 109, Loss: 0.006182, Accuracy: 99.50%\n",
      "Batch 110, Loss: 0.007768, Accuracy: 99.50%\n",
      "Batch 111, Loss: 0.030486, Accuracy: 99.49%\n",
      "Batch 112, Loss: 0.001951, Accuracy: 99.50%\n",
      "Batch 113, Loss: 0.038914, Accuracy: 99.49%\n",
      "Batch 114, Loss: 0.012603, Accuracy: 99.49%\n",
      "Batch 115, Loss: 0.005231, Accuracy: 99.50%\n",
      "Batch 116, Loss: 0.012635, Accuracy: 99.50%\n",
      "Batch 117, Loss: 0.065634, Accuracy: 99.49%\n",
      "Batch 118, Loss: 0.007645, Accuracy: 99.50%\n",
      "Batch 119, Loss: 0.020764, Accuracy: 99.49%\n",
      "Batch 120, Loss: 0.037075, Accuracy: 99.48%\n",
      "Batch 121, Loss: 0.002845, Accuracy: 99.48%\n",
      "Batch 122, Loss: 0.014387, Accuracy: 99.49%\n",
      "Batch 123, Loss: 0.188036, Accuracy: 99.45%\n",
      "Batch 124, Loss: 0.069927, Accuracy: 99.43%\n",
      "Batch 125, Loss: 0.016749, Accuracy: 99.42%\n",
      "Batch 126, Loss: 0.042818, Accuracy: 99.42%\n",
      "Batch 127, Loss: 0.159375, Accuracy: 99.38%\n",
      "Batch 128, Loss: 0.058057, Accuracy: 99.38%\n",
      "Batch 129, Loss: 0.203636, Accuracy: 99.35%\n",
      "Batch 130, Loss: 0.057237, Accuracy: 99.33%\n",
      "Batch 131, Loss: 0.019051, Accuracy: 99.33%\n",
      "Batch 132, Loss: 0.060636, Accuracy: 99.33%\n",
      "Batch 133, Loss: 0.073674, Accuracy: 99.32%\n",
      "Batch 134, Loss: 0.004665, Accuracy: 99.32%\n",
      "Batch 135, Loss: 0.081791, Accuracy: 99.31%\n",
      "Batch 136, Loss: 0.059783, Accuracy: 99.30%\n",
      "Batch 137, Loss: 0.052378, Accuracy: 99.29%\n",
      "Batch 138, Loss: 0.052421, Accuracy: 99.29%\n",
      "Batch 139, Loss: 0.059881, Accuracy: 99.28%\n",
      "Batch 140, Loss: 0.015106, Accuracy: 99.27%\n",
      "Batch 141, Loss: 0.003281, Accuracy: 99.28%\n",
      "Batch 142, Loss: 0.042934, Accuracy: 99.27%\n",
      "Batch 143, Loss: 0.098833, Accuracy: 99.26%\n",
      "Batch 144, Loss: 0.005364, Accuracy: 99.26%\n",
      "Batch 145, Loss: 0.041812, Accuracy: 99.26%\n",
      "Batch 146, Loss: 0.024250, Accuracy: 99.25%\n",
      "Batch 147, Loss: 0.039683, Accuracy: 99.25%\n",
      "Batch 148, Loss: 0.023506, Accuracy: 99.24%\n",
      "Batch 149, Loss: 0.016762, Accuracy: 99.24%\n",
      "Batch 150, Loss: 0.008750, Accuracy: 99.25%\n",
      "Batch 151, Loss: 0.100527, Accuracy: 99.24%\n",
      "Batch 152, Loss: 0.007588, Accuracy: 99.25%\n",
      "Batch 153, Loss: 0.040478, Accuracy: 99.24%\n",
      "Batch 154, Loss: 0.041889, Accuracy: 99.23%\n",
      "Batch 155, Loss: 0.018254, Accuracy: 99.23%\n",
      "Batch 156, Loss: 0.039216, Accuracy: 99.23%\n",
      "Batch 157, Loss: 0.003295, Accuracy: 99.23%\n",
      "Batch 158, Loss: 0.014710, Accuracy: 99.24%\n",
      "Batch 159, Loss: 0.021396, Accuracy: 99.23%\n",
      "Batch 160, Loss: 0.003921, Accuracy: 99.24%\n",
      "Batch 161, Loss: 0.005537, Accuracy: 99.24%\n",
      "Batch 162, Loss: 0.018872, Accuracy: 99.25%\n",
      "Batch 163, Loss: 0.010864, Accuracy: 99.25%\n",
      "Batch 164, Loss: 0.108363, Accuracy: 99.22%\n",
      "Batch 165, Loss: 0.069600, Accuracy: 99.21%\n",
      "Batch 166, Loss: 0.010279, Accuracy: 99.22%\n",
      "Batch 167, Loss: 0.008889, Accuracy: 99.22%\n",
      "Batch 168, Loss: 0.010515, Accuracy: 99.23%\n",
      "Batch 169, Loss: 0.098495, Accuracy: 99.21%\n",
      "Batch 170, Loss: 0.163717, Accuracy: 99.19%\n",
      "Batch 171, Loss: 0.059391, Accuracy: 99.18%\n",
      "Batch 172, Loss: 0.013001, Accuracy: 99.18%\n",
      "Batch 173, Loss: 0.017894, Accuracy: 99.18%\n",
      "Batch 174, Loss: 0.036382, Accuracy: 99.17%\n",
      "Batch 175, Loss: 0.179778, Accuracy: 99.16%\n",
      "Batch 176, Loss: 0.056690, Accuracy: 99.16%\n",
      "Batch 177, Loss: 0.126260, Accuracy: 99.15%\n",
      "Batch 178, Loss: 0.103827, Accuracy: 99.15%\n",
      "Batch 179, Loss: 0.105914, Accuracy: 99.14%\n",
      "Batch 180, Loss: 0.210280, Accuracy: 99.12%\n",
      "Batch 181, Loss: 0.070265, Accuracy: 99.12%\n",
      "Batch 182, Loss: 0.164167, Accuracy: 99.09%\n",
      "Batch 183, Loss: 0.008375, Accuracy: 99.09%\n",
      "Batch 184, Loss: 0.061407, Accuracy: 99.09%\n",
      "Batch 185, Loss: 0.011055, Accuracy: 99.10%\n",
      "Batch 186, Loss: 0.074893, Accuracy: 99.08%\n",
      "Batch 187, Loss: 0.069539, Accuracy: 99.08%\n",
      "Batch 188, Loss: 0.196035, Accuracy: 99.05%\n",
      "Batch 189, Loss: 0.009411, Accuracy: 99.06%\n",
      "Batch 190, Loss: 0.150119, Accuracy: 99.05%\n",
      "Batch 191, Loss: 0.028716, Accuracy: 99.04%\n",
      "Batch 192, Loss: 0.092016, Accuracy: 99.02%\n",
      "Batch 193, Loss: 0.045368, Accuracy: 99.02%\n",
      "Batch 194, Loss: 0.052175, Accuracy: 99.01%\n",
      "Batch 195, Loss: 0.119701, Accuracy: 98.99%\n",
      "Batch 196, Loss: 0.034249, Accuracy: 98.99%\n",
      "Batch 197, Loss: 0.115957, Accuracy: 98.96%\n",
      "Batch 198, Loss: 0.051670, Accuracy: 98.96%\n",
      "Batch 199, Loss: 0.004829, Accuracy: 98.96%\n",
      "Batch 200, Loss: 0.050567, Accuracy: 98.96%\n",
      "Batch 201, Loss: 0.156798, Accuracy: 98.95%\n",
      "Batch 202, Loss: 0.062533, Accuracy: 98.94%\n",
      "Batch 203, Loss: 0.471200, Accuracy: 98.88%\n",
      "Batch 204, Loss: 0.197537, Accuracy: 98.86%\n",
      "Batch 205, Loss: 0.030971, Accuracy: 98.86%\n",
      "Batch 206, Loss: 0.063729, Accuracy: 98.85%\n",
      "Batch 207, Loss: 0.053425, Accuracy: 98.85%\n",
      "Batch 208, Loss: 0.048216, Accuracy: 98.84%\n",
      "Batch 209, Loss: 0.015151, Accuracy: 98.85%\n",
      "Batch 210, Loss: 0.024016, Accuracy: 98.85%\n",
      "Batch 211, Loss: 0.012553, Accuracy: 98.85%\n",
      "Batch 212, Loss: 0.112714, Accuracy: 98.84%\n",
      "Batch 213, Loss: 0.066676, Accuracy: 98.82%\n",
      "Training - Epoch 23, Loss: 0.037390, Accuracy: 98.82%\n",
      "Validation Batch 1, Loss: 0.145865, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.024925, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.123020, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.012204, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.067292, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.006790, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.155140, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.104281, Accuracy: 98.05%\n",
      "Validation Batch 9, Loss: 0.146405, Accuracy: 97.92%\n",
      "Validation Batch 10, Loss: 0.063127, Accuracy: 97.81%\n",
      "Validation Batch 11, Loss: 0.078388, Accuracy: 97.73%\n",
      "Validation Batch 12, Loss: 0.088123, Accuracy: 97.79%\n",
      "Validation Batch 13, Loss: 0.017318, Accuracy: 97.96%\n",
      "Validation Batch 14, Loss: 0.161394, Accuracy: 97.66%\n",
      "Validation Batch 15, Loss: 0.045418, Accuracy: 97.71%\n",
      "Validation Batch 16, Loss: 0.070080, Accuracy: 97.66%\n",
      "Validation Batch 17, Loss: 0.049960, Accuracy: 97.70%\n",
      "Validation Batch 18, Loss: 0.055595, Accuracy: 97.66%\n",
      "Validation Batch 19, Loss: 0.045242, Accuracy: 97.70%\n",
      "Validation Batch 20, Loss: 0.044270, Accuracy: 97.73%\n",
      "Validation Batch 21, Loss: 0.021084, Accuracy: 97.84%\n",
      "Validation Batch 22, Loss: 0.074905, Accuracy: 97.80%\n",
      "Validation Batch 23, Loss: 0.050609, Accuracy: 97.83%\n",
      "Validation Batch 24, Loss: 0.238257, Accuracy: 97.53%\n",
      "Validation Batch 25, Loss: 0.008748, Accuracy: 97.62%\n",
      "Validation Batch 26, Loss: 0.041865, Accuracy: 97.66%\n",
      "Validation Batch 27, Loss: 0.010477, Accuracy: 97.71%\n",
      "Validation - Epoch 23, Loss: 0.072251, Accuracy: 97.71%\n",
      "Patience—1\n",
      "Epoch 24\n",
      "Batch 1, Loss: 0.077694, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.009788, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.023440, Accuracy: 98.44%\n",
      "Batch 4, Loss: 0.121588, Accuracy: 98.05%\n",
      "Batch 5, Loss: 0.007337, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.015621, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.031555, Accuracy: 98.66%\n",
      "Batch 8, Loss: 0.034197, Accuracy: 98.63%\n",
      "Batch 9, Loss: 0.055799, Accuracy: 98.44%\n",
      "Batch 10, Loss: 0.083802, Accuracy: 98.28%\n",
      "Batch 11, Loss: 0.010762, Accuracy: 98.44%\n",
      "Batch 12, Loss: 0.014673, Accuracy: 98.57%\n",
      "Batch 13, Loss: 0.007051, Accuracy: 98.68%\n",
      "Batch 14, Loss: 0.073328, Accuracy: 98.66%\n",
      "Batch 15, Loss: 0.017163, Accuracy: 98.75%\n",
      "Batch 16, Loss: 0.033536, Accuracy: 98.83%\n",
      "Batch 17, Loss: 0.011459, Accuracy: 98.90%\n",
      "Batch 18, Loss: 0.014894, Accuracy: 98.96%\n",
      "Batch 19, Loss: 0.018028, Accuracy: 99.01%\n",
      "Batch 20, Loss: 0.013197, Accuracy: 99.06%\n",
      "Batch 21, Loss: 0.022691, Accuracy: 99.11%\n",
      "Batch 22, Loss: 0.004490, Accuracy: 99.15%\n",
      "Batch 23, Loss: 0.007515, Accuracy: 99.18%\n",
      "Batch 24, Loss: 0.008658, Accuracy: 99.22%\n",
      "Batch 25, Loss: 0.007373, Accuracy: 99.25%\n",
      "Batch 26, Loss: 0.006384, Accuracy: 99.28%\n",
      "Batch 27, Loss: 0.006185, Accuracy: 99.31%\n",
      "Batch 28, Loss: 0.011249, Accuracy: 99.33%\n",
      "Batch 29, Loss: 0.050801, Accuracy: 99.30%\n",
      "Batch 30, Loss: 0.006456, Accuracy: 99.32%\n",
      "Batch 31, Loss: 0.036249, Accuracy: 99.29%\n",
      "Batch 32, Loss: 0.018502, Accuracy: 99.27%\n",
      "Batch 33, Loss: 0.035078, Accuracy: 99.24%\n",
      "Batch 34, Loss: 0.004114, Accuracy: 99.26%\n",
      "Batch 35, Loss: 0.018257, Accuracy: 99.29%\n",
      "Batch 36, Loss: 0.003269, Accuracy: 99.31%\n",
      "Batch 37, Loss: 0.004146, Accuracy: 99.32%\n",
      "Batch 38, Loss: 0.019057, Accuracy: 99.30%\n",
      "Batch 39, Loss: 0.002883, Accuracy: 99.32%\n",
      "Batch 40, Loss: 0.002604, Accuracy: 99.34%\n",
      "Batch 41, Loss: 0.002607, Accuracy: 99.35%\n",
      "Batch 42, Loss: 0.005478, Accuracy: 99.37%\n",
      "Batch 43, Loss: 0.029749, Accuracy: 99.35%\n",
      "Batch 44, Loss: 0.003626, Accuracy: 99.36%\n",
      "Batch 45, Loss: 0.005926, Accuracy: 99.38%\n",
      "Batch 46, Loss: 0.004172, Accuracy: 99.39%\n",
      "Batch 47, Loss: 0.015156, Accuracy: 99.40%\n",
      "Batch 48, Loss: 0.045071, Accuracy: 99.35%\n",
      "Batch 49, Loss: 0.006882, Accuracy: 99.36%\n",
      "Batch 50, Loss: 0.005228, Accuracy: 99.38%\n",
      "Batch 51, Loss: 0.022027, Accuracy: 99.36%\n",
      "Batch 52, Loss: 0.004072, Accuracy: 99.37%\n",
      "Batch 53, Loss: 0.003603, Accuracy: 99.38%\n",
      "Batch 54, Loss: 0.005278, Accuracy: 99.39%\n",
      "Batch 55, Loss: 0.003522, Accuracy: 99.40%\n",
      "Batch 56, Loss: 0.006109, Accuracy: 99.41%\n",
      "Batch 57, Loss: 0.003555, Accuracy: 99.42%\n",
      "Batch 58, Loss: 0.012451, Accuracy: 99.43%\n",
      "Batch 59, Loss: 0.027442, Accuracy: 99.42%\n",
      "Batch 60, Loss: 0.070131, Accuracy: 99.40%\n",
      "Batch 61, Loss: 0.006980, Accuracy: 99.41%\n",
      "Batch 62, Loss: 0.025603, Accuracy: 99.40%\n",
      "Batch 63, Loss: 0.110739, Accuracy: 99.36%\n",
      "Batch 64, Loss: 0.003227, Accuracy: 99.37%\n",
      "Batch 65, Loss: 0.008344, Accuracy: 99.38%\n",
      "Batch 66, Loss: 0.007981, Accuracy: 99.38%\n",
      "Batch 67, Loss: 0.015887, Accuracy: 99.39%\n",
      "Batch 68, Loss: 0.002634, Accuracy: 99.40%\n",
      "Batch 69, Loss: 0.008099, Accuracy: 99.41%\n",
      "Batch 70, Loss: 0.016109, Accuracy: 99.40%\n",
      "Batch 71, Loss: 0.004757, Accuracy: 99.41%\n",
      "Batch 72, Loss: 0.007747, Accuracy: 99.41%\n",
      "Batch 73, Loss: 0.003890, Accuracy: 99.42%\n",
      "Batch 74, Loss: 0.018841, Accuracy: 99.43%\n",
      "Batch 75, Loss: 0.006302, Accuracy: 99.44%\n",
      "Batch 76, Loss: 0.005598, Accuracy: 99.44%\n",
      "Batch 77, Loss: 0.002121, Accuracy: 99.45%\n",
      "Batch 78, Loss: 0.005015, Accuracy: 99.46%\n",
      "Batch 79, Loss: 0.002712, Accuracy: 99.47%\n",
      "Batch 80, Loss: 0.002511, Accuracy: 99.47%\n",
      "Batch 81, Loss: 0.003742, Accuracy: 99.48%\n",
      "Batch 82, Loss: 0.013152, Accuracy: 99.49%\n",
      "Batch 83, Loss: 0.026678, Accuracy: 99.47%\n",
      "Batch 84, Loss: 0.002696, Accuracy: 99.48%\n",
      "Batch 85, Loss: 0.002130, Accuracy: 99.49%\n",
      "Batch 86, Loss: 0.009972, Accuracy: 99.49%\n",
      "Batch 87, Loss: 0.025803, Accuracy: 99.46%\n",
      "Batch 88, Loss: 0.008163, Accuracy: 99.47%\n",
      "Batch 89, Loss: 0.014030, Accuracy: 99.47%\n",
      "Batch 90, Loss: 0.003551, Accuracy: 99.48%\n",
      "Batch 91, Loss: 0.003822, Accuracy: 99.48%\n",
      "Batch 92, Loss: 0.003137, Accuracy: 99.49%\n",
      "Batch 93, Loss: 0.081154, Accuracy: 99.48%\n",
      "Batch 94, Loss: 0.029292, Accuracy: 99.47%\n",
      "Batch 95, Loss: 0.003320, Accuracy: 99.47%\n",
      "Batch 96, Loss: 0.003731, Accuracy: 99.48%\n",
      "Batch 97, Loss: 0.004257, Accuracy: 99.48%\n",
      "Batch 98, Loss: 0.004048, Accuracy: 99.49%\n",
      "Batch 99, Loss: 0.002259, Accuracy: 99.49%\n",
      "Batch 100, Loss: 0.013975, Accuracy: 99.48%\n",
      "Batch 101, Loss: 0.007039, Accuracy: 99.49%\n",
      "Batch 102, Loss: 0.003431, Accuracy: 99.49%\n",
      "Batch 103, Loss: 0.003881, Accuracy: 99.50%\n",
      "Batch 104, Loss: 0.002385, Accuracy: 99.50%\n",
      "Batch 105, Loss: 0.001650, Accuracy: 99.51%\n",
      "Batch 106, Loss: 0.003077, Accuracy: 99.51%\n",
      "Batch 107, Loss: 0.001740, Accuracy: 99.52%\n",
      "Batch 108, Loss: 0.024061, Accuracy: 99.51%\n",
      "Batch 109, Loss: 0.003184, Accuracy: 99.51%\n",
      "Batch 110, Loss: 0.002841, Accuracy: 99.52%\n",
      "Batch 111, Loss: 0.015036, Accuracy: 99.52%\n",
      "Batch 112, Loss: 0.005506, Accuracy: 99.53%\n",
      "Batch 113, Loss: 0.012828, Accuracy: 99.53%\n",
      "Batch 114, Loss: 0.054791, Accuracy: 99.52%\n",
      "Batch 115, Loss: 0.005389, Accuracy: 99.52%\n",
      "Batch 116, Loss: 0.002522, Accuracy: 99.53%\n",
      "Batch 117, Loss: 0.001986, Accuracy: 99.53%\n",
      "Batch 118, Loss: 0.004158, Accuracy: 99.54%\n",
      "Batch 119, Loss: 0.014863, Accuracy: 99.54%\n",
      "Batch 120, Loss: 0.002675, Accuracy: 99.54%\n",
      "Batch 121, Loss: 0.002450, Accuracy: 99.55%\n",
      "Batch 122, Loss: 0.002596, Accuracy: 99.55%\n",
      "Batch 123, Loss: 0.001575, Accuracy: 99.56%\n",
      "Batch 124, Loss: 0.014997, Accuracy: 99.56%\n",
      "Batch 125, Loss: 0.001953, Accuracy: 99.56%\n",
      "Batch 126, Loss: 0.002418, Accuracy: 99.57%\n",
      "Batch 127, Loss: 0.004673, Accuracy: 99.57%\n",
      "Batch 128, Loss: 0.001795, Accuracy: 99.57%\n",
      "Batch 129, Loss: 0.003316, Accuracy: 99.58%\n",
      "Batch 130, Loss: 0.003413, Accuracy: 99.58%\n",
      "Batch 131, Loss: 0.002972, Accuracy: 99.58%\n",
      "Batch 132, Loss: 0.002105, Accuracy: 99.59%\n",
      "Batch 133, Loss: 0.032831, Accuracy: 99.58%\n",
      "Batch 134, Loss: 0.029482, Accuracy: 99.57%\n",
      "Batch 135, Loss: 0.004660, Accuracy: 99.57%\n",
      "Batch 136, Loss: 0.026916, Accuracy: 99.56%\n",
      "Batch 137, Loss: 0.002299, Accuracy: 99.57%\n",
      "Batch 138, Loss: 0.002340, Accuracy: 99.57%\n",
      "Batch 139, Loss: 0.002303, Accuracy: 99.57%\n",
      "Batch 140, Loss: 0.002977, Accuracy: 99.58%\n",
      "Batch 141, Loss: 0.014284, Accuracy: 99.57%\n",
      "Batch 142, Loss: 0.005393, Accuracy: 99.57%\n",
      "Batch 143, Loss: 0.005439, Accuracy: 99.57%\n",
      "Batch 144, Loss: 0.001584, Accuracy: 99.58%\n",
      "Batch 145, Loss: 0.003096, Accuracy: 99.58%\n",
      "Batch 146, Loss: 0.008812, Accuracy: 99.58%\n",
      "Batch 147, Loss: 0.001964, Accuracy: 99.59%\n",
      "Batch 148, Loss: 0.015711, Accuracy: 99.59%\n",
      "Batch 149, Loss: 0.030582, Accuracy: 99.58%\n",
      "Batch 150, Loss: 0.002305, Accuracy: 99.58%\n",
      "Batch 151, Loss: 0.004768, Accuracy: 99.59%\n",
      "Batch 152, Loss: 0.001692, Accuracy: 99.59%\n",
      "Batch 153, Loss: 0.003190, Accuracy: 99.59%\n",
      "Batch 154, Loss: 0.001440, Accuracy: 99.59%\n",
      "Batch 155, Loss: 0.002914, Accuracy: 99.60%\n",
      "Batch 156, Loss: 0.003133, Accuracy: 99.60%\n",
      "Batch 157, Loss: 0.015473, Accuracy: 99.59%\n",
      "Batch 158, Loss: 0.011622, Accuracy: 99.59%\n",
      "Batch 159, Loss: 0.002364, Accuracy: 99.60%\n",
      "Batch 160, Loss: 0.001947, Accuracy: 99.60%\n",
      "Batch 161, Loss: 0.004016, Accuracy: 99.60%\n",
      "Batch 162, Loss: 0.003751, Accuracy: 99.60%\n",
      "Batch 163, Loss: 0.002252, Accuracy: 99.61%\n",
      "Batch 164, Loss: 0.003002, Accuracy: 99.61%\n",
      "Batch 165, Loss: 0.009477, Accuracy: 99.61%\n",
      "Batch 166, Loss: 0.002375, Accuracy: 99.61%\n",
      "Batch 167, Loss: 0.003713, Accuracy: 99.62%\n",
      "Batch 168, Loss: 0.001587, Accuracy: 99.62%\n",
      "Batch 169, Loss: 0.004229, Accuracy: 99.62%\n",
      "Batch 170, Loss: 0.003173, Accuracy: 99.62%\n",
      "Batch 171, Loss: 0.002763, Accuracy: 99.63%\n",
      "Batch 172, Loss: 0.001514, Accuracy: 99.63%\n",
      "Batch 173, Loss: 0.020354, Accuracy: 99.62%\n",
      "Batch 174, Loss: 0.001749, Accuracy: 99.62%\n",
      "Batch 175, Loss: 0.002001, Accuracy: 99.62%\n",
      "Batch 176, Loss: 0.001437, Accuracy: 99.63%\n",
      "Batch 177, Loss: 0.002445, Accuracy: 99.63%\n",
      "Batch 178, Loss: 0.001650, Accuracy: 99.63%\n",
      "Batch 179, Loss: 0.002665, Accuracy: 99.63%\n",
      "Batch 180, Loss: 0.001833, Accuracy: 99.64%\n",
      "Batch 181, Loss: 0.001742, Accuracy: 99.64%\n",
      "Batch 182, Loss: 0.002468, Accuracy: 99.64%\n",
      "Batch 183, Loss: 0.003047, Accuracy: 99.64%\n",
      "Batch 184, Loss: 0.001681, Accuracy: 99.64%\n",
      "Batch 185, Loss: 0.001910, Accuracy: 99.65%\n",
      "Batch 186, Loss: 0.011569, Accuracy: 99.65%\n",
      "Batch 187, Loss: 0.009304, Accuracy: 99.65%\n",
      "Batch 188, Loss: 0.002214, Accuracy: 99.65%\n",
      "Batch 189, Loss: 0.002721, Accuracy: 99.65%\n",
      "Batch 190, Loss: 0.028890, Accuracy: 99.65%\n",
      "Batch 191, Loss: 0.002906, Accuracy: 99.65%\n",
      "Batch 192, Loss: 0.001649, Accuracy: 99.65%\n",
      "Batch 193, Loss: 0.004752, Accuracy: 99.65%\n",
      "Batch 194, Loss: 0.002265, Accuracy: 99.65%\n",
      "Batch 195, Loss: 0.001929, Accuracy: 99.66%\n",
      "Batch 196, Loss: 0.002284, Accuracy: 99.66%\n",
      "Batch 197, Loss: 0.002578, Accuracy: 99.66%\n",
      "Batch 198, Loss: 0.001876, Accuracy: 99.66%\n",
      "Batch 199, Loss: 0.001555, Accuracy: 99.66%\n",
      "Batch 200, Loss: 0.001849, Accuracy: 99.66%\n",
      "Batch 201, Loss: 0.001691, Accuracy: 99.67%\n",
      "Batch 202, Loss: 0.002488, Accuracy: 99.67%\n",
      "Batch 203, Loss: 0.056234, Accuracy: 99.66%\n",
      "Batch 204, Loss: 0.021180, Accuracy: 99.66%\n",
      "Batch 205, Loss: 0.001653, Accuracy: 99.66%\n",
      "Batch 206, Loss: 0.001676, Accuracy: 99.66%\n",
      "Batch 207, Loss: 0.001717, Accuracy: 99.66%\n",
      "Batch 208, Loss: 0.001722, Accuracy: 99.66%\n",
      "Batch 209, Loss: 0.081469, Accuracy: 99.66%\n",
      "Batch 210, Loss: 0.006509, Accuracy: 99.66%\n",
      "Batch 211, Loss: 0.039168, Accuracy: 99.65%\n",
      "Batch 212, Loss: 0.047426, Accuracy: 99.65%\n",
      "Batch 213, Loss: 0.001610, Accuracy: 99.65%\n",
      "Training - Epoch 24, Loss: 0.012420, Accuracy: 99.65%\n",
      "Validation Batch 1, Loss: 0.008734, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.002086, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.006392, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.032720, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.003645, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.001437, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.001388, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.005398, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.047711, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.001889, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.016234, Accuracy: 99.72%\n",
      "Validation Batch 12, Loss: 0.079564, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.158168, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.008009, Accuracy: 99.44%\n",
      "Validation Batch 15, Loss: 0.008087, Accuracy: 99.48%\n",
      "Validation Batch 16, Loss: 0.001960, Accuracy: 99.51%\n",
      "Validation Batch 17, Loss: 0.005033, Accuracy: 99.54%\n",
      "Validation Batch 18, Loss: 0.004246, Accuracy: 99.57%\n",
      "Validation Batch 19, Loss: 0.006434, Accuracy: 99.59%\n",
      "Validation Batch 20, Loss: 0.002779, Accuracy: 99.61%\n",
      "Validation Batch 21, Loss: 0.007221, Accuracy: 99.63%\n",
      "Validation Batch 22, Loss: 0.002290, Accuracy: 99.64%\n",
      "Validation Batch 23, Loss: 0.011990, Accuracy: 99.66%\n",
      "Validation Batch 24, Loss: 0.046418, Accuracy: 99.61%\n",
      "Validation Batch 25, Loss: 0.001355, Accuracy: 99.62%\n",
      "Validation Batch 26, Loss: 0.002011, Accuracy: 99.64%\n",
      "Validation Batch 27, Loss: 0.002206, Accuracy: 99.65%\n",
      "Validation - Epoch 24, Loss: 0.017608, Accuracy: 99.65%\n",
      "Patience—2\n",
      "Epoch 25\n",
      "Batch 1, Loss: 0.003028, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001894, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.002006, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.004919, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.002907, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.039859, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.002178, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.002972, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.002089, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.005993, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.002125, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.014997, Accuracy: 99.74%\n",
      "Batch 13, Loss: 0.002495, Accuracy: 99.76%\n",
      "Batch 14, Loss: 0.095949, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.029058, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.002493, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.124441, Accuracy: 99.45%\n",
      "Batch 18, Loss: 0.002483, Accuracy: 99.48%\n",
      "Batch 19, Loss: 0.024270, Accuracy: 99.42%\n",
      "Batch 20, Loss: 0.023171, Accuracy: 99.45%\n",
      "Batch 21, Loss: 0.111532, Accuracy: 99.40%\n",
      "Batch 22, Loss: 0.003025, Accuracy: 99.43%\n",
      "Batch 23, Loss: 0.013788, Accuracy: 99.46%\n",
      "Batch 24, Loss: 0.001807, Accuracy: 99.48%\n",
      "Batch 25, Loss: 0.007975, Accuracy: 99.50%\n",
      "Batch 26, Loss: 0.018995, Accuracy: 99.46%\n",
      "Batch 27, Loss: 0.083959, Accuracy: 99.42%\n",
      "Batch 28, Loss: 0.004865, Accuracy: 99.44%\n",
      "Batch 29, Loss: 0.002125, Accuracy: 99.46%\n",
      "Batch 30, Loss: 0.006916, Accuracy: 99.48%\n",
      "Batch 31, Loss: 0.016144, Accuracy: 99.45%\n",
      "Batch 32, Loss: 0.037416, Accuracy: 99.41%\n",
      "Batch 33, Loss: 0.005069, Accuracy: 99.43%\n",
      "Batch 34, Loss: 0.001743, Accuracy: 99.45%\n",
      "Batch 35, Loss: 0.005366, Accuracy: 99.46%\n",
      "Batch 36, Loss: 0.009065, Accuracy: 99.48%\n",
      "Batch 37, Loss: 0.013062, Accuracy: 99.49%\n",
      "Batch 38, Loss: 0.005789, Accuracy: 99.51%\n",
      "Batch 39, Loss: 0.173005, Accuracy: 99.40%\n",
      "Batch 40, Loss: 0.001704, Accuracy: 99.41%\n",
      "Batch 41, Loss: 0.011005, Accuracy: 99.43%\n",
      "Batch 42, Loss: 0.012852, Accuracy: 99.44%\n",
      "Batch 43, Loss: 0.002534, Accuracy: 99.45%\n",
      "Batch 44, Loss: 0.004718, Accuracy: 99.47%\n",
      "Batch 45, Loss: 0.005131, Accuracy: 99.48%\n",
      "Batch 46, Loss: 0.126157, Accuracy: 99.39%\n",
      "Batch 47, Loss: 0.017927, Accuracy: 99.40%\n",
      "Batch 48, Loss: 0.005549, Accuracy: 99.41%\n",
      "Batch 49, Loss: 0.010568, Accuracy: 99.43%\n",
      "Batch 50, Loss: 0.002245, Accuracy: 99.44%\n",
      "Batch 51, Loss: 0.002634, Accuracy: 99.45%\n",
      "Batch 52, Loss: 0.003591, Accuracy: 99.46%\n",
      "Batch 53, Loss: 0.024215, Accuracy: 99.47%\n",
      "Batch 54, Loss: 0.030719, Accuracy: 99.45%\n",
      "Batch 55, Loss: 0.064406, Accuracy: 99.43%\n",
      "Batch 56, Loss: 0.003107, Accuracy: 99.44%\n",
      "Batch 57, Loss: 0.020618, Accuracy: 99.42%\n",
      "Batch 58, Loss: 0.029666, Accuracy: 99.43%\n",
      "Batch 59, Loss: 0.006689, Accuracy: 99.44%\n",
      "Batch 60, Loss: 0.004351, Accuracy: 99.45%\n",
      "Batch 61, Loss: 0.012608, Accuracy: 99.46%\n",
      "Batch 62, Loss: 0.007685, Accuracy: 99.47%\n",
      "Batch 63, Loss: 0.003992, Accuracy: 99.48%\n",
      "Batch 64, Loss: 0.158515, Accuracy: 99.41%\n",
      "Batch 65, Loss: 0.015793, Accuracy: 99.40%\n",
      "Batch 66, Loss: 0.002823, Accuracy: 99.41%\n",
      "Batch 67, Loss: 0.019875, Accuracy: 99.39%\n",
      "Batch 68, Loss: 0.058217, Accuracy: 99.36%\n",
      "Batch 69, Loss: 0.188562, Accuracy: 99.30%\n",
      "Batch 70, Loss: 0.015638, Accuracy: 99.31%\n",
      "Batch 71, Loss: 0.038278, Accuracy: 99.30%\n",
      "Batch 72, Loss: 0.030782, Accuracy: 99.28%\n",
      "Batch 73, Loss: 0.076778, Accuracy: 99.27%\n",
      "Batch 74, Loss: 0.083070, Accuracy: 99.24%\n",
      "Batch 75, Loss: 0.444839, Accuracy: 99.06%\n",
      "Batch 76, Loss: 0.049179, Accuracy: 99.05%\n",
      "Batch 77, Loss: 0.005630, Accuracy: 99.07%\n",
      "Batch 78, Loss: 0.104225, Accuracy: 99.02%\n",
      "Batch 79, Loss: 0.069411, Accuracy: 98.97%\n",
      "Batch 80, Loss: 0.194066, Accuracy: 98.93%\n",
      "Batch 81, Loss: 0.255866, Accuracy: 98.88%\n",
      "Batch 82, Loss: 0.193456, Accuracy: 98.82%\n",
      "Batch 83, Loss: 0.038537, Accuracy: 98.81%\n",
      "Batch 84, Loss: 0.127213, Accuracy: 98.79%\n",
      "Batch 85, Loss: 0.025041, Accuracy: 98.79%\n",
      "Batch 86, Loss: 0.268450, Accuracy: 98.71%\n",
      "Batch 87, Loss: 0.043638, Accuracy: 98.69%\n",
      "Batch 88, Loss: 0.130690, Accuracy: 98.65%\n",
      "Batch 89, Loss: 0.059523, Accuracy: 98.65%\n",
      "Batch 90, Loss: 0.066162, Accuracy: 98.61%\n",
      "Batch 91, Loss: 0.025976, Accuracy: 98.63%\n",
      "Batch 92, Loss: 0.047856, Accuracy: 98.62%\n",
      "Batch 93, Loss: 0.013148, Accuracy: 98.64%\n",
      "Batch 94, Loss: 0.039816, Accuracy: 98.64%\n",
      "Batch 95, Loss: 0.012668, Accuracy: 98.65%\n",
      "Batch 96, Loss: 0.007037, Accuracy: 98.67%\n",
      "Batch 97, Loss: 0.120547, Accuracy: 98.63%\n",
      "Batch 98, Loss: 0.219596, Accuracy: 98.60%\n",
      "Batch 99, Loss: 0.187414, Accuracy: 98.56%\n",
      "Batch 100, Loss: 0.013729, Accuracy: 98.58%\n",
      "Batch 101, Loss: 0.104567, Accuracy: 98.55%\n",
      "Batch 102, Loss: 0.024852, Accuracy: 98.56%\n",
      "Batch 103, Loss: 0.014315, Accuracy: 98.57%\n",
      "Batch 104, Loss: 0.029119, Accuracy: 98.57%\n",
      "Batch 105, Loss: 0.017581, Accuracy: 98.59%\n",
      "Batch 106, Loss: 0.016767, Accuracy: 98.60%\n",
      "Batch 107, Loss: 0.082711, Accuracy: 98.58%\n",
      "Batch 108, Loss: 0.008958, Accuracy: 98.60%\n",
      "Batch 109, Loss: 0.013820, Accuracy: 98.61%\n",
      "Batch 110, Loss: 0.076799, Accuracy: 98.59%\n",
      "Batch 111, Loss: 0.024253, Accuracy: 98.59%\n",
      "Batch 112, Loss: 0.018738, Accuracy: 98.60%\n",
      "Batch 113, Loss: 0.028742, Accuracy: 98.62%\n",
      "Batch 114, Loss: 0.016264, Accuracy: 98.63%\n",
      "Batch 115, Loss: 0.022512, Accuracy: 98.63%\n",
      "Batch 116, Loss: 0.090426, Accuracy: 98.60%\n",
      "Batch 117, Loss: 0.014801, Accuracy: 98.61%\n",
      "Batch 118, Loss: 0.157114, Accuracy: 98.58%\n",
      "Batch 119, Loss: 0.006394, Accuracy: 98.60%\n",
      "Batch 120, Loss: 0.006531, Accuracy: 98.61%\n",
      "Batch 121, Loss: 0.048098, Accuracy: 98.61%\n",
      "Batch 122, Loss: 0.012699, Accuracy: 98.62%\n",
      "Batch 123, Loss: 0.057271, Accuracy: 98.60%\n",
      "Batch 124, Loss: 0.007710, Accuracy: 98.61%\n",
      "Batch 125, Loss: 0.006785, Accuracy: 98.62%\n",
      "Batch 126, Loss: 0.045847, Accuracy: 98.62%\n",
      "Batch 127, Loss: 0.006373, Accuracy: 98.63%\n",
      "Batch 128, Loss: 0.051934, Accuracy: 98.62%\n",
      "Batch 129, Loss: 0.093658, Accuracy: 98.62%\n",
      "Batch 130, Loss: 0.032166, Accuracy: 98.62%\n",
      "Batch 131, Loss: 0.011953, Accuracy: 98.63%\n",
      "Batch 132, Loss: 0.023543, Accuracy: 98.63%\n",
      "Batch 133, Loss: 0.011311, Accuracy: 98.64%\n",
      "Batch 134, Loss: 0.012972, Accuracy: 98.65%\n",
      "Batch 135, Loss: 0.049109, Accuracy: 98.63%\n",
      "Batch 136, Loss: 0.003257, Accuracy: 98.64%\n",
      "Batch 137, Loss: 0.016404, Accuracy: 98.65%\n",
      "Batch 138, Loss: 0.016740, Accuracy: 98.65%\n",
      "Batch 139, Loss: 0.049996, Accuracy: 98.65%\n",
      "Batch 140, Loss: 0.005088, Accuracy: 98.66%\n",
      "Batch 141, Loss: 0.011529, Accuracy: 98.67%\n",
      "Batch 142, Loss: 0.022534, Accuracy: 98.67%\n",
      "Batch 143, Loss: 0.044737, Accuracy: 98.66%\n",
      "Batch 144, Loss: 0.033915, Accuracy: 98.65%\n",
      "Batch 145, Loss: 0.035202, Accuracy: 98.65%\n",
      "Batch 146, Loss: 0.015896, Accuracy: 98.66%\n",
      "Batch 147, Loss: 0.020043, Accuracy: 98.66%\n",
      "Batch 148, Loss: 0.004085, Accuracy: 98.67%\n",
      "Batch 149, Loss: 0.030099, Accuracy: 98.67%\n",
      "Batch 150, Loss: 0.053923, Accuracy: 98.67%\n",
      "Batch 151, Loss: 0.009144, Accuracy: 98.68%\n",
      "Batch 152, Loss: 0.004133, Accuracy: 98.68%\n",
      "Batch 153, Loss: 0.020542, Accuracy: 98.69%\n",
      "Batch 154, Loss: 0.012741, Accuracy: 98.70%\n",
      "Batch 155, Loss: 0.077560, Accuracy: 98.69%\n",
      "Batch 156, Loss: 0.004649, Accuracy: 98.70%\n",
      "Batch 157, Loss: 0.040383, Accuracy: 98.69%\n",
      "Batch 158, Loss: 0.003364, Accuracy: 98.69%\n",
      "Batch 159, Loss: 0.014382, Accuracy: 98.70%\n",
      "Batch 160, Loss: 0.003377, Accuracy: 98.71%\n",
      "Batch 161, Loss: 0.002950, Accuracy: 98.72%\n",
      "Batch 162, Loss: 0.014180, Accuracy: 98.73%\n",
      "Batch 163, Loss: 0.008264, Accuracy: 98.73%\n",
      "Batch 164, Loss: 0.015033, Accuracy: 98.73%\n",
      "Batch 165, Loss: 0.002522, Accuracy: 98.74%\n",
      "Batch 166, Loss: 0.007700, Accuracy: 98.75%\n",
      "Batch 167, Loss: 0.010244, Accuracy: 98.76%\n",
      "Batch 168, Loss: 0.005246, Accuracy: 98.76%\n",
      "Batch 169, Loss: 0.003025, Accuracy: 98.77%\n",
      "Batch 170, Loss: 0.018831, Accuracy: 98.77%\n",
      "Batch 171, Loss: 0.004664, Accuracy: 98.78%\n",
      "Batch 172, Loss: 0.002097, Accuracy: 98.78%\n",
      "Batch 173, Loss: 0.003236, Accuracy: 98.79%\n",
      "Batch 174, Loss: 0.004401, Accuracy: 98.80%\n",
      "Batch 175, Loss: 0.044333, Accuracy: 98.79%\n",
      "Batch 176, Loss: 0.001693, Accuracy: 98.80%\n",
      "Batch 177, Loss: 0.036406, Accuracy: 98.80%\n",
      "Batch 178, Loss: 0.004239, Accuracy: 98.81%\n",
      "Batch 179, Loss: 0.003392, Accuracy: 98.81%\n",
      "Batch 180, Loss: 0.002855, Accuracy: 98.82%\n",
      "Batch 181, Loss: 0.003817, Accuracy: 98.83%\n",
      "Batch 182, Loss: 0.003228, Accuracy: 98.83%\n",
      "Batch 183, Loss: 0.018266, Accuracy: 98.83%\n",
      "Batch 184, Loss: 0.031505, Accuracy: 98.83%\n",
      "Batch 185, Loss: 0.002265, Accuracy: 98.83%\n",
      "Batch 186, Loss: 0.004986, Accuracy: 98.84%\n",
      "Batch 187, Loss: 0.002673, Accuracy: 98.85%\n",
      "Batch 188, Loss: 0.003897, Accuracy: 98.85%\n",
      "Batch 189, Loss: 0.006164, Accuracy: 98.86%\n",
      "Batch 190, Loss: 0.017198, Accuracy: 98.86%\n",
      "Batch 191, Loss: 0.013057, Accuracy: 98.86%\n",
      "Batch 192, Loss: 0.003507, Accuracy: 98.87%\n",
      "Batch 193, Loss: 0.025697, Accuracy: 98.87%\n",
      "Batch 194, Loss: 0.028224, Accuracy: 98.86%\n",
      "Batch 195, Loss: 0.014331, Accuracy: 98.86%\n",
      "Batch 196, Loss: 0.004141, Accuracy: 98.87%\n",
      "Batch 197, Loss: 0.003498, Accuracy: 98.87%\n",
      "Batch 198, Loss: 0.008496, Accuracy: 98.88%\n",
      "Batch 199, Loss: 0.005270, Accuracy: 98.89%\n",
      "Batch 200, Loss: 0.005234, Accuracy: 98.89%\n",
      "Batch 201, Loss: 0.011768, Accuracy: 98.90%\n",
      "Batch 202, Loss: 0.005060, Accuracy: 98.90%\n",
      "Batch 203, Loss: 0.018021, Accuracy: 98.90%\n",
      "Batch 204, Loss: 0.003639, Accuracy: 98.90%\n",
      "Batch 205, Loss: 0.002905, Accuracy: 98.91%\n",
      "Batch 206, Loss: 0.001917, Accuracy: 98.92%\n",
      "Batch 207, Loss: 0.057876, Accuracy: 98.91%\n",
      "Batch 208, Loss: 0.001823, Accuracy: 98.91%\n",
      "Batch 209, Loss: 0.009453, Accuracy: 98.92%\n",
      "Batch 210, Loss: 0.069342, Accuracy: 98.91%\n",
      "Batch 211, Loss: 0.006931, Accuracy: 98.92%\n",
      "Batch 212, Loss: 0.003484, Accuracy: 98.92%\n",
      "Batch 213, Loss: 0.038963, Accuracy: 98.92%\n",
      "Training - Epoch 25, Loss: 0.033850, Accuracy: 98.92%\n",
      "Validation Batch 1, Loss: 0.075863, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.071017, Accuracy: 96.88%\n",
      "Validation Batch 3, Loss: 0.023377, Accuracy: 97.40%\n",
      "Validation Batch 4, Loss: 0.007622, Accuracy: 98.05%\n",
      "Validation Batch 5, Loss: 0.003987, Accuracy: 98.44%\n",
      "Validation Batch 6, Loss: 0.012558, Accuracy: 98.70%\n",
      "Validation Batch 7, Loss: 0.040136, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.011542, Accuracy: 98.83%\n",
      "Validation Batch 9, Loss: 0.133468, Accuracy: 98.44%\n",
      "Validation Batch 10, Loss: 0.012973, Accuracy: 98.59%\n",
      "Validation Batch 11, Loss: 0.036313, Accuracy: 98.58%\n",
      "Validation Batch 12, Loss: 0.103764, Accuracy: 98.57%\n",
      "Validation Batch 13, Loss: 0.023937, Accuracy: 98.56%\n",
      "Validation Batch 14, Loss: 0.143321, Accuracy: 98.33%\n",
      "Validation Batch 15, Loss: 0.055459, Accuracy: 98.23%\n",
      "Validation Batch 16, Loss: 0.011777, Accuracy: 98.34%\n",
      "Validation Batch 17, Loss: 0.097174, Accuracy: 98.35%\n",
      "Validation Batch 18, Loss: 0.009934, Accuracy: 98.44%\n",
      "Validation Batch 19, Loss: 0.120066, Accuracy: 98.36%\n",
      "Validation Batch 20, Loss: 0.010833, Accuracy: 98.44%\n",
      "Validation Batch 21, Loss: 0.008161, Accuracy: 98.51%\n",
      "Validation Batch 22, Loss: 0.052545, Accuracy: 98.51%\n",
      "Validation Batch 23, Loss: 0.023231, Accuracy: 98.51%\n",
      "Validation Batch 24, Loss: 0.133535, Accuracy: 98.50%\n",
      "Validation Batch 25, Loss: 0.010820, Accuracy: 98.56%\n",
      "Validation Batch 26, Loss: 0.013200, Accuracy: 98.62%\n",
      "Validation Batch 27, Loss: 0.004415, Accuracy: 98.65%\n",
      "Validation - Epoch 25, Loss: 0.046334, Accuracy: 98.65%\n",
      "Patience—3\n",
      "Epoch 26\n",
      "Batch 1, Loss: 0.002308, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.008874, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.002702, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.019892, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.004972, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.023660, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.041873, Accuracy: 99.33%\n",
      "Batch 8, Loss: 0.015191, Accuracy: 99.41%\n",
      "Batch 9, Loss: 0.055119, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.001607, Accuracy: 99.38%\n",
      "Batch 11, Loss: 0.003594, Accuracy: 99.43%\n",
      "Batch 12, Loss: 0.001409, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.002926, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.002168, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.039426, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.008552, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.048184, Accuracy: 99.36%\n",
      "Batch 18, Loss: 0.006600, Accuracy: 99.39%\n",
      "Batch 19, Loss: 0.012316, Accuracy: 99.42%\n",
      "Batch 20, Loss: 0.004208, Accuracy: 99.45%\n",
      "Batch 21, Loss: 0.001960, Accuracy: 99.48%\n",
      "Batch 22, Loss: 0.008123, Accuracy: 99.50%\n",
      "Batch 23, Loss: 0.080129, Accuracy: 99.39%\n",
      "Batch 24, Loss: 0.004105, Accuracy: 99.41%\n",
      "Batch 25, Loss: 0.002730, Accuracy: 99.44%\n",
      "Batch 26, Loss: 0.004846, Accuracy: 99.46%\n",
      "Batch 27, Loss: 0.010355, Accuracy: 99.48%\n",
      "Batch 28, Loss: 0.008245, Accuracy: 99.50%\n",
      "Batch 29, Loss: 0.010295, Accuracy: 99.52%\n",
      "Batch 30, Loss: 0.005712, Accuracy: 99.53%\n",
      "Batch 31, Loss: 0.002057, Accuracy: 99.55%\n",
      "Batch 32, Loss: 0.006750, Accuracy: 99.56%\n",
      "Batch 33, Loss: 0.011752, Accuracy: 99.57%\n",
      "Batch 34, Loss: 0.003284, Accuracy: 99.59%\n",
      "Batch 35, Loss: 0.003958, Accuracy: 99.60%\n",
      "Batch 36, Loss: 0.005579, Accuracy: 99.61%\n",
      "Batch 37, Loss: 0.005873, Accuracy: 99.62%\n",
      "Batch 38, Loss: 0.008274, Accuracy: 99.63%\n",
      "Batch 39, Loss: 0.005885, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.005923, Accuracy: 99.65%\n",
      "Batch 41, Loss: 0.006209, Accuracy: 99.66%\n",
      "Batch 42, Loss: 0.051320, Accuracy: 99.63%\n",
      "Batch 43, Loss: 0.003451, Accuracy: 99.64%\n",
      "Batch 44, Loss: 0.005942, Accuracy: 99.64%\n",
      "Batch 45, Loss: 0.002383, Accuracy: 99.65%\n",
      "Batch 46, Loss: 0.002546, Accuracy: 99.66%\n",
      "Batch 47, Loss: 0.013042, Accuracy: 99.67%\n",
      "Batch 48, Loss: 0.004023, Accuracy: 99.67%\n",
      "Batch 49, Loss: 0.004400, Accuracy: 99.68%\n",
      "Batch 50, Loss: 0.001480, Accuracy: 99.69%\n",
      "Batch 51, Loss: 0.077797, Accuracy: 99.66%\n",
      "Batch 52, Loss: 0.009034, Accuracy: 99.67%\n",
      "Batch 53, Loss: 0.097438, Accuracy: 99.59%\n",
      "Batch 54, Loss: 0.001965, Accuracy: 99.59%\n",
      "Batch 55, Loss: 0.002831, Accuracy: 99.60%\n",
      "Batch 56, Loss: 0.004144, Accuracy: 99.61%\n",
      "Batch 57, Loss: 0.003714, Accuracy: 99.62%\n",
      "Batch 58, Loss: 0.105424, Accuracy: 99.57%\n",
      "Batch 59, Loss: 0.005456, Accuracy: 99.58%\n",
      "Batch 60, Loss: 0.047897, Accuracy: 99.53%\n",
      "Batch 61, Loss: 0.041252, Accuracy: 99.49%\n",
      "Batch 62, Loss: 0.007437, Accuracy: 99.50%\n",
      "Batch 63, Loss: 0.067451, Accuracy: 99.45%\n",
      "Batch 64, Loss: 0.095616, Accuracy: 99.41%\n",
      "Batch 65, Loss: 0.008905, Accuracy: 99.42%\n",
      "Batch 66, Loss: 0.005673, Accuracy: 99.43%\n",
      "Batch 67, Loss: 0.023162, Accuracy: 99.42%\n",
      "Batch 68, Loss: 0.004079, Accuracy: 99.43%\n",
      "Batch 69, Loss: 0.077461, Accuracy: 99.39%\n",
      "Batch 70, Loss: 0.006025, Accuracy: 99.40%\n",
      "Batch 71, Loss: 0.009048, Accuracy: 99.41%\n",
      "Batch 72, Loss: 0.015279, Accuracy: 99.41%\n",
      "Batch 73, Loss: 0.030831, Accuracy: 99.40%\n",
      "Batch 74, Loss: 0.028658, Accuracy: 99.39%\n",
      "Batch 75, Loss: 0.045531, Accuracy: 99.38%\n",
      "Batch 76, Loss: 0.030300, Accuracy: 99.36%\n",
      "Batch 77, Loss: 0.005091, Accuracy: 99.37%\n",
      "Batch 78, Loss: 0.008040, Accuracy: 99.38%\n",
      "Batch 79, Loss: 0.080073, Accuracy: 99.35%\n",
      "Batch 80, Loss: 0.014039, Accuracy: 99.36%\n",
      "Batch 81, Loss: 0.004947, Accuracy: 99.36%\n",
      "Batch 82, Loss: 0.061903, Accuracy: 99.35%\n",
      "Batch 83, Loss: 0.003628, Accuracy: 99.36%\n",
      "Batch 84, Loss: 0.004029, Accuracy: 99.37%\n",
      "Batch 85, Loss: 0.076729, Accuracy: 99.36%\n",
      "Batch 86, Loss: 0.009284, Accuracy: 99.36%\n",
      "Batch 87, Loss: 0.063201, Accuracy: 99.34%\n",
      "Batch 88, Loss: 0.002281, Accuracy: 99.34%\n",
      "Batch 89, Loss: 0.007888, Accuracy: 99.35%\n",
      "Batch 90, Loss: 0.005569, Accuracy: 99.36%\n",
      "Batch 91, Loss: 0.025846, Accuracy: 99.35%\n",
      "Batch 92, Loss: 0.007580, Accuracy: 99.35%\n",
      "Batch 93, Loss: 0.004284, Accuracy: 99.36%\n",
      "Batch 94, Loss: 0.020044, Accuracy: 99.35%\n",
      "Batch 95, Loss: 0.004620, Accuracy: 99.36%\n",
      "Batch 96, Loss: 0.018793, Accuracy: 99.35%\n",
      "Batch 97, Loss: 0.002441, Accuracy: 99.36%\n",
      "Batch 98, Loss: 0.002667, Accuracy: 99.36%\n",
      "Batch 99, Loss: 0.026856, Accuracy: 99.35%\n",
      "Batch 100, Loss: 0.004212, Accuracy: 99.36%\n",
      "Batch 101, Loss: 0.024545, Accuracy: 99.35%\n",
      "Batch 102, Loss: 0.031501, Accuracy: 99.34%\n",
      "Batch 103, Loss: 0.020889, Accuracy: 99.33%\n",
      "Batch 104, Loss: 0.006845, Accuracy: 99.34%\n",
      "Batch 105, Loss: 0.025873, Accuracy: 99.33%\n",
      "Batch 106, Loss: 0.039860, Accuracy: 99.32%\n",
      "Batch 107, Loss: 0.008900, Accuracy: 99.33%\n",
      "Batch 108, Loss: 0.006917, Accuracy: 99.33%\n",
      "Batch 109, Loss: 0.004933, Accuracy: 99.34%\n",
      "Batch 110, Loss: 0.005993, Accuracy: 99.35%\n",
      "Batch 111, Loss: 0.002860, Accuracy: 99.35%\n",
      "Batch 112, Loss: 0.006578, Accuracy: 99.36%\n",
      "Batch 113, Loss: 0.012075, Accuracy: 99.36%\n",
      "Batch 114, Loss: 0.004893, Accuracy: 99.37%\n",
      "Batch 115, Loss: 0.003629, Accuracy: 99.38%\n",
      "Batch 116, Loss: 0.028308, Accuracy: 99.37%\n",
      "Batch 117, Loss: 0.005628, Accuracy: 99.37%\n",
      "Batch 118, Loss: 0.061407, Accuracy: 99.35%\n",
      "Batch 119, Loss: 0.002347, Accuracy: 99.36%\n",
      "Batch 120, Loss: 0.002647, Accuracy: 99.36%\n",
      "Batch 121, Loss: 0.107010, Accuracy: 99.34%\n",
      "Batch 122, Loss: 0.025288, Accuracy: 99.33%\n",
      "Batch 123, Loss: 0.004084, Accuracy: 99.34%\n",
      "Batch 124, Loss: 0.062561, Accuracy: 99.32%\n",
      "Batch 125, Loss: 0.032161, Accuracy: 99.31%\n",
      "Batch 126, Loss: 0.010458, Accuracy: 99.32%\n",
      "Batch 127, Loss: 0.022589, Accuracy: 99.31%\n",
      "Batch 128, Loss: 0.006364, Accuracy: 99.32%\n",
      "Batch 129, Loss: 0.099295, Accuracy: 99.31%\n",
      "Batch 130, Loss: 0.019005, Accuracy: 99.30%\n",
      "Batch 131, Loss: 0.006931, Accuracy: 99.31%\n",
      "Batch 132, Loss: 0.003619, Accuracy: 99.31%\n",
      "Batch 133, Loss: 0.070532, Accuracy: 99.31%\n",
      "Batch 134, Loss: 0.002626, Accuracy: 99.31%\n",
      "Batch 135, Loss: 0.002041, Accuracy: 99.32%\n",
      "Batch 136, Loss: 0.105619, Accuracy: 99.30%\n",
      "Batch 137, Loss: 0.006193, Accuracy: 99.30%\n",
      "Batch 138, Loss: 0.003963, Accuracy: 99.31%\n",
      "Batch 139, Loss: 0.050868, Accuracy: 99.30%\n",
      "Batch 140, Loss: 0.004455, Accuracy: 99.31%\n",
      "Batch 141, Loss: 0.007978, Accuracy: 99.31%\n",
      "Batch 142, Loss: 0.005670, Accuracy: 99.32%\n",
      "Batch 143, Loss: 0.003694, Accuracy: 99.32%\n",
      "Batch 144, Loss: 0.028257, Accuracy: 99.32%\n",
      "Batch 145, Loss: 0.056389, Accuracy: 99.31%\n",
      "Batch 146, Loss: 0.032313, Accuracy: 99.30%\n",
      "Batch 147, Loss: 0.002059, Accuracy: 99.31%\n",
      "Batch 148, Loss: 0.003230, Accuracy: 99.31%\n",
      "Batch 149, Loss: 0.001820, Accuracy: 99.32%\n",
      "Batch 150, Loss: 0.008622, Accuracy: 99.32%\n",
      "Batch 151, Loss: 0.068445, Accuracy: 99.32%\n",
      "Batch 152, Loss: 0.018082, Accuracy: 99.31%\n",
      "Batch 153, Loss: 0.004699, Accuracy: 99.32%\n",
      "Batch 154, Loss: 0.026780, Accuracy: 99.31%\n",
      "Batch 155, Loss: 0.008331, Accuracy: 99.31%\n",
      "Batch 156, Loss: 0.013235, Accuracy: 99.32%\n",
      "Batch 157, Loss: 0.022895, Accuracy: 99.32%\n",
      "Batch 158, Loss: 0.012224, Accuracy: 99.33%\n",
      "Batch 159, Loss: 0.062583, Accuracy: 99.31%\n",
      "Batch 160, Loss: 0.002900, Accuracy: 99.32%\n",
      "Batch 161, Loss: 0.014453, Accuracy: 99.32%\n",
      "Batch 162, Loss: 0.029871, Accuracy: 99.32%\n",
      "Batch 163, Loss: 0.008467, Accuracy: 99.32%\n",
      "Batch 164, Loss: 0.052357, Accuracy: 99.31%\n",
      "Batch 165, Loss: 0.003222, Accuracy: 99.32%\n",
      "Batch 166, Loss: 0.034134, Accuracy: 99.31%\n",
      "Batch 167, Loss: 0.031012, Accuracy: 99.31%\n",
      "Batch 168, Loss: 0.056835, Accuracy: 99.30%\n",
      "Batch 169, Loss: 0.002317, Accuracy: 99.31%\n",
      "Batch 170, Loss: 0.004122, Accuracy: 99.31%\n",
      "Batch 171, Loss: 0.035860, Accuracy: 99.31%\n",
      "Batch 172, Loss: 0.024725, Accuracy: 99.31%\n",
      "Batch 173, Loss: 0.011383, Accuracy: 99.31%\n",
      "Batch 174, Loss: 0.043958, Accuracy: 99.31%\n",
      "Batch 175, Loss: 0.085918, Accuracy: 99.29%\n",
      "Batch 176, Loss: 0.005921, Accuracy: 99.30%\n",
      "Batch 177, Loss: 0.004863, Accuracy: 99.30%\n",
      "Batch 178, Loss: 0.002546, Accuracy: 99.31%\n",
      "Batch 179, Loss: 0.007243, Accuracy: 99.31%\n",
      "Batch 180, Loss: 0.009918, Accuracy: 99.31%\n",
      "Batch 181, Loss: 0.004186, Accuracy: 99.32%\n",
      "Batch 182, Loss: 0.167631, Accuracy: 99.29%\n",
      "Batch 183, Loss: 0.145975, Accuracy: 99.25%\n",
      "Batch 184, Loss: 0.001776, Accuracy: 99.25%\n",
      "Batch 185, Loss: 0.003086, Accuracy: 99.26%\n",
      "Batch 186, Loss: 0.006101, Accuracy: 99.26%\n",
      "Batch 187, Loss: 0.016594, Accuracy: 99.26%\n",
      "Batch 188, Loss: 0.020655, Accuracy: 99.27%\n",
      "Batch 189, Loss: 0.093699, Accuracy: 99.25%\n",
      "Batch 190, Loss: 0.031707, Accuracy: 99.24%\n",
      "Batch 191, Loss: 0.122977, Accuracy: 99.21%\n",
      "Batch 192, Loss: 0.021298, Accuracy: 99.21%\n",
      "Batch 193, Loss: 0.009612, Accuracy: 99.21%\n",
      "Batch 194, Loss: 0.005865, Accuracy: 99.22%\n",
      "Batch 195, Loss: 0.056240, Accuracy: 99.21%\n",
      "Batch 196, Loss: 0.030256, Accuracy: 99.21%\n",
      "Batch 197, Loss: 0.004323, Accuracy: 99.21%\n",
      "Batch 198, Loss: 0.003877, Accuracy: 99.22%\n",
      "Batch 199, Loss: 0.056531, Accuracy: 99.21%\n",
      "Batch 200, Loss: 0.083355, Accuracy: 99.20%\n",
      "Batch 201, Loss: 0.025139, Accuracy: 99.20%\n",
      "Batch 202, Loss: 0.020598, Accuracy: 99.20%\n",
      "Batch 203, Loss: 0.017735, Accuracy: 99.20%\n",
      "Batch 204, Loss: 0.005692, Accuracy: 99.20%\n",
      "Batch 205, Loss: 0.027481, Accuracy: 99.21%\n",
      "Batch 206, Loss: 0.004904, Accuracy: 99.21%\n",
      "Batch 207, Loss: 0.006028, Accuracy: 99.21%\n",
      "Batch 208, Loss: 0.047056, Accuracy: 99.20%\n",
      "Batch 209, Loss: 0.010307, Accuracy: 99.21%\n",
      "Batch 210, Loss: 0.015126, Accuracy: 99.20%\n",
      "Batch 211, Loss: 0.010486, Accuracy: 99.21%\n",
      "Batch 212, Loss: 0.080134, Accuracy: 99.20%\n",
      "Batch 213, Loss: 0.038722, Accuracy: 99.20%\n",
      "Training - Epoch 26, Loss: 0.023096, Accuracy: 99.20%\n",
      "Validation Batch 1, Loss: 0.061569, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.022972, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.007293, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.025247, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.019111, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.011489, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.003262, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.171239, Accuracy: 99.02%\n",
      "Validation Batch 9, Loss: 0.092257, Accuracy: 98.78%\n",
      "Validation Batch 10, Loss: 0.006401, Accuracy: 98.91%\n",
      "Validation Batch 11, Loss: 0.135351, Accuracy: 98.72%\n",
      "Validation Batch 12, Loss: 0.113674, Accuracy: 98.70%\n",
      "Validation Batch 13, Loss: 0.058253, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.009555, Accuracy: 98.77%\n",
      "Validation Batch 15, Loss: 0.016324, Accuracy: 98.85%\n",
      "Validation Batch 16, Loss: 0.032708, Accuracy: 98.83%\n",
      "Validation Batch 17, Loss: 0.032514, Accuracy: 98.81%\n",
      "Validation Batch 18, Loss: 0.007579, Accuracy: 98.87%\n",
      "Validation Batch 19, Loss: 0.007954, Accuracy: 98.93%\n",
      "Validation Batch 20, Loss: 0.005967, Accuracy: 98.98%\n",
      "Validation Batch 21, Loss: 0.014307, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.035399, Accuracy: 99.01%\n",
      "Validation Batch 23, Loss: 0.008318, Accuracy: 99.05%\n",
      "Validation Batch 24, Loss: 0.111387, Accuracy: 99.02%\n",
      "Validation Batch 25, Loss: 0.065137, Accuracy: 99.00%\n",
      "Validation Batch 26, Loss: 0.014756, Accuracy: 99.04%\n",
      "Validation Batch 27, Loss: 0.007919, Accuracy: 99.06%\n",
      "Validation - Epoch 26, Loss: 0.040664, Accuracy: 99.06%\n",
      "Patience—4\n",
      "Epoch 27\n",
      "Batch 1, Loss: 0.007109, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.002869, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.006911, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.020944, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.005575, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.008666, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.020998, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.043703, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.003174, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.013570, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.002437, Accuracy: 99.72%\n",
      "Batch 12, Loss: 0.092958, Accuracy: 99.35%\n",
      "Batch 13, Loss: 0.002395, Accuracy: 99.40%\n",
      "Batch 14, Loss: 0.002328, Accuracy: 99.44%\n",
      "Batch 15, Loss: 0.017765, Accuracy: 99.48%\n",
      "Batch 16, Loss: 0.068367, Accuracy: 99.41%\n",
      "Batch 17, Loss: 0.002535, Accuracy: 99.45%\n",
      "Batch 18, Loss: 0.005971, Accuracy: 99.48%\n",
      "Batch 19, Loss: 0.014209, Accuracy: 99.42%\n",
      "Batch 20, Loss: 0.002791, Accuracy: 99.45%\n",
      "Batch 21, Loss: 0.007206, Accuracy: 99.48%\n",
      "Batch 22, Loss: 0.002298, Accuracy: 99.50%\n",
      "Batch 23, Loss: 0.026699, Accuracy: 99.52%\n",
      "Batch 24, Loss: 0.093478, Accuracy: 99.41%\n",
      "Batch 25, Loss: 0.003838, Accuracy: 99.44%\n",
      "Batch 26, Loss: 0.006950, Accuracy: 99.46%\n",
      "Batch 27, Loss: 0.002938, Accuracy: 99.48%\n",
      "Batch 28, Loss: 0.005100, Accuracy: 99.50%\n",
      "Batch 29, Loss: 0.005318, Accuracy: 99.52%\n",
      "Batch 30, Loss: 0.003784, Accuracy: 99.53%\n",
      "Batch 31, Loss: 0.001890, Accuracy: 99.55%\n",
      "Batch 32, Loss: 0.005274, Accuracy: 99.56%\n",
      "Batch 33, Loss: 0.002039, Accuracy: 99.57%\n",
      "Batch 34, Loss: 0.003858, Accuracy: 99.59%\n",
      "Batch 35, Loss: 0.002055, Accuracy: 99.60%\n",
      "Batch 36, Loss: 0.004985, Accuracy: 99.61%\n",
      "Batch 37, Loss: 0.003320, Accuracy: 99.62%\n",
      "Batch 38, Loss: 0.024536, Accuracy: 99.63%\n",
      "Batch 39, Loss: 0.005774, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.006004, Accuracy: 99.65%\n",
      "Batch 41, Loss: 0.007217, Accuracy: 99.66%\n",
      "Batch 42, Loss: 0.002435, Accuracy: 99.67%\n",
      "Batch 43, Loss: 0.004852, Accuracy: 99.67%\n",
      "Batch 44, Loss: 0.003862, Accuracy: 99.68%\n",
      "Batch 45, Loss: 0.002324, Accuracy: 99.69%\n",
      "Batch 46, Loss: 0.009806, Accuracy: 99.69%\n",
      "Batch 47, Loss: 0.002652, Accuracy: 99.70%\n",
      "Batch 48, Loss: 0.002548, Accuracy: 99.71%\n",
      "Batch 49, Loss: 0.001890, Accuracy: 99.71%\n",
      "Batch 50, Loss: 0.003659, Accuracy: 99.72%\n",
      "Batch 51, Loss: 0.003805, Accuracy: 99.72%\n",
      "Batch 52, Loss: 0.002516, Accuracy: 99.73%\n",
      "Batch 53, Loss: 0.002509, Accuracy: 99.73%\n",
      "Batch 54, Loss: 0.002634, Accuracy: 99.74%\n",
      "Batch 55, Loss: 0.001867, Accuracy: 99.74%\n",
      "Batch 56, Loss: 0.002697, Accuracy: 99.75%\n",
      "Batch 57, Loss: 0.001795, Accuracy: 99.75%\n",
      "Batch 58, Loss: 0.002419, Accuracy: 99.76%\n",
      "Batch 59, Loss: 0.001342, Accuracy: 99.76%\n",
      "Batch 60, Loss: 0.001791, Accuracy: 99.77%\n",
      "Batch 61, Loss: 0.002568, Accuracy: 99.77%\n",
      "Batch 62, Loss: 0.003404, Accuracy: 99.77%\n",
      "Batch 63, Loss: 0.003116, Accuracy: 99.78%\n",
      "Batch 64, Loss: 0.001219, Accuracy: 99.78%\n",
      "Batch 65, Loss: 0.002438, Accuracy: 99.78%\n",
      "Batch 66, Loss: 0.001849, Accuracy: 99.79%\n",
      "Batch 67, Loss: 0.004100, Accuracy: 99.79%\n",
      "Batch 68, Loss: 0.001834, Accuracy: 99.79%\n",
      "Batch 69, Loss: 0.001897, Accuracy: 99.80%\n",
      "Batch 70, Loss: 0.002959, Accuracy: 99.80%\n",
      "Batch 71, Loss: 0.001849, Accuracy: 99.80%\n",
      "Batch 72, Loss: 0.001738, Accuracy: 99.80%\n",
      "Batch 73, Loss: 0.001379, Accuracy: 99.81%\n",
      "Batch 74, Loss: 0.004308, Accuracy: 99.81%\n",
      "Batch 75, Loss: 0.001241, Accuracy: 99.81%\n",
      "Batch 76, Loss: 0.006276, Accuracy: 99.81%\n",
      "Batch 77, Loss: 0.001595, Accuracy: 99.82%\n",
      "Batch 78, Loss: 0.001633, Accuracy: 99.82%\n",
      "Batch 79, Loss: 0.002841, Accuracy: 99.82%\n",
      "Batch 80, Loss: 0.001464, Accuracy: 99.82%\n",
      "Batch 81, Loss: 0.001313, Accuracy: 99.83%\n",
      "Batch 82, Loss: 0.006884, Accuracy: 99.83%\n",
      "Batch 83, Loss: 0.001668, Accuracy: 99.83%\n",
      "Batch 84, Loss: 0.002067, Accuracy: 99.83%\n",
      "Batch 85, Loss: 0.001199, Accuracy: 99.83%\n",
      "Batch 86, Loss: 0.002017, Accuracy: 99.84%\n",
      "Batch 87, Loss: 0.001215, Accuracy: 99.84%\n",
      "Batch 88, Loss: 0.002033, Accuracy: 99.84%\n",
      "Batch 89, Loss: 0.001454, Accuracy: 99.84%\n",
      "Batch 90, Loss: 0.001606, Accuracy: 99.84%\n",
      "Batch 91, Loss: 0.001967, Accuracy: 99.85%\n",
      "Batch 92, Loss: 0.001348, Accuracy: 99.85%\n",
      "Batch 93, Loss: 0.002426, Accuracy: 99.85%\n",
      "Batch 94, Loss: 0.001769, Accuracy: 99.85%\n",
      "Batch 95, Loss: 0.001785, Accuracy: 99.85%\n",
      "Batch 96, Loss: 0.001525, Accuracy: 99.85%\n",
      "Batch 97, Loss: 0.011115, Accuracy: 99.86%\n",
      "Batch 98, Loss: 0.003331, Accuracy: 99.86%\n",
      "Batch 99, Loss: 0.001623, Accuracy: 99.86%\n",
      "Batch 100, Loss: 0.001868, Accuracy: 99.86%\n",
      "Batch 101, Loss: 0.001332, Accuracy: 99.86%\n",
      "Batch 102, Loss: 0.001346, Accuracy: 99.86%\n",
      "Batch 103, Loss: 0.001651, Accuracy: 99.86%\n",
      "Batch 104, Loss: 0.002716, Accuracy: 99.86%\n",
      "Batch 105, Loss: 0.001969, Accuracy: 99.87%\n",
      "Batch 106, Loss: 0.001360, Accuracy: 99.87%\n",
      "Batch 107, Loss: 0.019757, Accuracy: 99.85%\n",
      "Batch 108, Loss: 0.001184, Accuracy: 99.86%\n",
      "Batch 109, Loss: 0.001407, Accuracy: 99.86%\n",
      "Batch 110, Loss: 0.005472, Accuracy: 99.86%\n",
      "Batch 111, Loss: 0.001129, Accuracy: 99.86%\n",
      "Batch 112, Loss: 0.001452, Accuracy: 99.86%\n",
      "Batch 113, Loss: 0.003400, Accuracy: 99.86%\n",
      "Batch 114, Loss: 0.002052, Accuracy: 99.86%\n",
      "Batch 115, Loss: 0.003325, Accuracy: 99.86%\n",
      "Batch 116, Loss: 0.002617, Accuracy: 99.87%\n",
      "Batch 117, Loss: 0.001945, Accuracy: 99.87%\n",
      "Batch 118, Loss: 0.001507, Accuracy: 99.87%\n",
      "Batch 119, Loss: 0.003992, Accuracy: 99.87%\n",
      "Batch 120, Loss: 0.001265, Accuracy: 99.87%\n",
      "Batch 121, Loss: 0.002489, Accuracy: 99.87%\n",
      "Batch 122, Loss: 0.001227, Accuracy: 99.87%\n",
      "Batch 123, Loss: 0.058925, Accuracy: 99.86%\n",
      "Batch 124, Loss: 0.001948, Accuracy: 99.86%\n",
      "Batch 125, Loss: 0.001632, Accuracy: 99.86%\n",
      "Batch 126, Loss: 0.001137, Accuracy: 99.86%\n",
      "Batch 127, Loss: 0.002329, Accuracy: 99.86%\n",
      "Batch 128, Loss: 0.002466, Accuracy: 99.87%\n",
      "Batch 129, Loss: 0.001589, Accuracy: 99.87%\n",
      "Batch 130, Loss: 0.001333, Accuracy: 99.87%\n",
      "Batch 131, Loss: 0.001501, Accuracy: 99.87%\n",
      "Batch 132, Loss: 0.001319, Accuracy: 99.87%\n",
      "Batch 133, Loss: 0.001080, Accuracy: 99.87%\n",
      "Batch 134, Loss: 0.001652, Accuracy: 99.87%\n",
      "Batch 135, Loss: 0.001581, Accuracy: 99.87%\n",
      "Batch 136, Loss: 0.001364, Accuracy: 99.87%\n",
      "Batch 137, Loss: 0.003657, Accuracy: 99.87%\n",
      "Batch 138, Loss: 0.002764, Accuracy: 99.88%\n",
      "Batch 139, Loss: 0.021114, Accuracy: 99.87%\n",
      "Batch 140, Loss: 0.010100, Accuracy: 99.87%\n",
      "Batch 141, Loss: 0.001801, Accuracy: 99.87%\n",
      "Batch 142, Loss: 0.001373, Accuracy: 99.87%\n",
      "Batch 143, Loss: 0.002598, Accuracy: 99.87%\n",
      "Batch 144, Loss: 0.016065, Accuracy: 99.86%\n",
      "Batch 145, Loss: 0.002014, Accuracy: 99.86%\n",
      "Batch 146, Loss: 0.001273, Accuracy: 99.86%\n",
      "Batch 147, Loss: 0.001823, Accuracy: 99.86%\n",
      "Batch 148, Loss: 0.003363, Accuracy: 99.86%\n",
      "Batch 149, Loss: 0.001672, Accuracy: 99.86%\n",
      "Batch 150, Loss: 0.010303, Accuracy: 99.86%\n",
      "Batch 151, Loss: 0.001253, Accuracy: 99.87%\n",
      "Batch 152, Loss: 0.001344, Accuracy: 99.87%\n",
      "Batch 153, Loss: 0.002462, Accuracy: 99.87%\n",
      "Batch 154, Loss: 0.004944, Accuracy: 99.87%\n",
      "Batch 155, Loss: 0.002259, Accuracy: 99.87%\n",
      "Batch 156, Loss: 0.002596, Accuracy: 99.87%\n",
      "Batch 157, Loss: 0.003822, Accuracy: 99.87%\n",
      "Batch 158, Loss: 0.001432, Accuracy: 99.87%\n",
      "Batch 159, Loss: 0.013161, Accuracy: 99.87%\n",
      "Batch 160, Loss: 0.002285, Accuracy: 99.87%\n",
      "Batch 161, Loss: 0.000999, Accuracy: 99.87%\n",
      "Batch 162, Loss: 0.001069, Accuracy: 99.87%\n",
      "Batch 163, Loss: 0.006096, Accuracy: 99.88%\n",
      "Batch 164, Loss: 0.004019, Accuracy: 99.88%\n",
      "Batch 165, Loss: 0.003538, Accuracy: 99.88%\n",
      "Batch 166, Loss: 0.003037, Accuracy: 99.88%\n",
      "Batch 167, Loss: 0.001551, Accuracy: 99.88%\n",
      "Batch 168, Loss: 0.002679, Accuracy: 99.88%\n",
      "Batch 169, Loss: 0.001124, Accuracy: 99.88%\n",
      "Batch 170, Loss: 0.001599, Accuracy: 99.88%\n",
      "Batch 171, Loss: 0.001772, Accuracy: 99.88%\n",
      "Batch 172, Loss: 0.001470, Accuracy: 99.88%\n",
      "Batch 173, Loss: 0.001945, Accuracy: 99.88%\n",
      "Batch 174, Loss: 0.001504, Accuracy: 99.88%\n",
      "Batch 175, Loss: 0.002276, Accuracy: 99.88%\n",
      "Batch 176, Loss: 0.002553, Accuracy: 99.88%\n",
      "Batch 177, Loss: 0.001830, Accuracy: 99.89%\n",
      "Batch 178, Loss: 0.003179, Accuracy: 99.89%\n",
      "Batch 179, Loss: 0.001784, Accuracy: 99.89%\n",
      "Batch 180, Loss: 0.001317, Accuracy: 99.89%\n",
      "Batch 181, Loss: 0.001401, Accuracy: 99.89%\n",
      "Batch 182, Loss: 0.004379, Accuracy: 99.89%\n",
      "Batch 183, Loss: 0.001259, Accuracy: 99.89%\n",
      "Batch 184, Loss: 0.001277, Accuracy: 99.89%\n",
      "Batch 185, Loss: 0.004806, Accuracy: 99.89%\n",
      "Batch 186, Loss: 0.003024, Accuracy: 99.89%\n",
      "Batch 187, Loss: 0.000949, Accuracy: 99.89%\n",
      "Batch 188, Loss: 0.001373, Accuracy: 99.89%\n",
      "Batch 189, Loss: 0.000930, Accuracy: 99.89%\n",
      "Batch 190, Loss: 0.001388, Accuracy: 99.89%\n",
      "Batch 191, Loss: 0.001188, Accuracy: 99.89%\n",
      "Batch 192, Loss: 0.001517, Accuracy: 99.89%\n",
      "Batch 193, Loss: 0.001883, Accuracy: 99.89%\n",
      "Batch 194, Loss: 0.001262, Accuracy: 99.90%\n",
      "Batch 195, Loss: 0.001064, Accuracy: 99.90%\n",
      "Batch 196, Loss: 0.001878, Accuracy: 99.90%\n",
      "Batch 197, Loss: 0.001136, Accuracy: 99.90%\n",
      "Batch 198, Loss: 0.009203, Accuracy: 99.90%\n",
      "Batch 199, Loss: 0.001104, Accuracy: 99.90%\n",
      "Batch 200, Loss: 0.001258, Accuracy: 99.90%\n",
      "Batch 201, Loss: 0.002164, Accuracy: 99.90%\n",
      "Batch 202, Loss: 0.000986, Accuracy: 99.90%\n",
      "Batch 203, Loss: 0.003738, Accuracy: 99.90%\n",
      "Batch 204, Loss: 0.001007, Accuracy: 99.90%\n",
      "Batch 205, Loss: 0.002351, Accuracy: 99.90%\n",
      "Batch 206, Loss: 0.001206, Accuracy: 99.90%\n",
      "Batch 207, Loss: 0.001648, Accuracy: 99.90%\n",
      "Batch 208, Loss: 0.002000, Accuracy: 99.90%\n",
      "Batch 209, Loss: 0.001060, Accuracy: 99.90%\n",
      "Batch 210, Loss: 0.002918, Accuracy: 99.90%\n",
      "Batch 211, Loss: 0.011227, Accuracy: 99.90%\n",
      "Batch 212, Loss: 0.001322, Accuracy: 99.90%\n",
      "Batch 213, Loss: 0.001005, Accuracy: 99.90%\n",
      "Training - Epoch 27, Loss: 0.005199, Accuracy: 99.90%\n",
      "Validation Batch 1, Loss: 0.001278, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.002143, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.002395, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.001151, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.001838, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000932, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.001697, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.001433, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.063740, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.001031, Accuracy: 99.84%\n",
      "Validation Batch 11, Loss: 0.006015, Accuracy: 99.86%\n",
      "Validation Batch 12, Loss: 0.030798, Accuracy: 99.74%\n",
      "Validation Batch 13, Loss: 0.002770, Accuracy: 99.76%\n",
      "Validation Batch 14, Loss: 0.005672, Accuracy: 99.78%\n",
      "Validation Batch 15, Loss: 0.001119, Accuracy: 99.79%\n",
      "Validation Batch 16, Loss: 0.030003, Accuracy: 99.71%\n",
      "Validation Batch 17, Loss: 0.001661, Accuracy: 99.72%\n",
      "Validation Batch 18, Loss: 0.001238, Accuracy: 99.74%\n",
      "Validation Batch 19, Loss: 0.001160, Accuracy: 99.75%\n",
      "Validation Batch 20, Loss: 0.001075, Accuracy: 99.77%\n",
      "Validation Batch 21, Loss: 0.002715, Accuracy: 99.78%\n",
      "Validation Batch 22, Loss: 0.001184, Accuracy: 99.79%\n",
      "Validation Batch 23, Loss: 0.001553, Accuracy: 99.80%\n",
      "Validation Batch 24, Loss: 0.128368, Accuracy: 99.74%\n",
      "Validation Batch 25, Loss: 0.001137, Accuracy: 99.75%\n",
      "Validation Batch 26, Loss: 0.001624, Accuracy: 99.76%\n",
      "Validation Batch 27, Loss: 0.000979, Accuracy: 99.77%\n",
      "Validation - Epoch 27, Loss: 0.010989, Accuracy: 99.77%\n",
      "Patience—0\n",
      "Epoch 28\n",
      "Batch 1, Loss: 0.001057, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001135, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000903, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000935, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001014, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.001254, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.001519, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.001408, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.001057, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.008674, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.001238, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.001110, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000994, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.003056, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.001055, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.001094, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000891, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.001205, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000872, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000884, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.014736, Accuracy: 99.93%\n",
      "Batch 22, Loss: 0.001239, Accuracy: 99.93%\n",
      "Batch 23, Loss: 0.001363, Accuracy: 99.93%\n",
      "Batch 24, Loss: 0.001487, Accuracy: 99.93%\n",
      "Batch 25, Loss: 0.003388, Accuracy: 99.94%\n",
      "Batch 26, Loss: 0.002340, Accuracy: 99.94%\n",
      "Batch 27, Loss: 0.001459, Accuracy: 99.94%\n",
      "Batch 28, Loss: 0.002019, Accuracy: 99.94%\n",
      "Batch 29, Loss: 0.002577, Accuracy: 99.95%\n",
      "Batch 30, Loss: 0.001846, Accuracy: 99.95%\n",
      "Batch 31, Loss: 0.002183, Accuracy: 99.95%\n",
      "Batch 32, Loss: 0.001222, Accuracy: 99.95%\n",
      "Batch 33, Loss: 0.001407, Accuracy: 99.95%\n",
      "Batch 34, Loss: 0.002029, Accuracy: 99.95%\n",
      "Batch 35, Loss: 0.002780, Accuracy: 99.96%\n",
      "Batch 36, Loss: 0.005361, Accuracy: 99.96%\n",
      "Batch 37, Loss: 0.001682, Accuracy: 99.96%\n",
      "Batch 38, Loss: 0.003612, Accuracy: 99.96%\n",
      "Batch 39, Loss: 0.001457, Accuracy: 99.96%\n",
      "Batch 40, Loss: 0.001151, Accuracy: 99.96%\n",
      "Batch 41, Loss: 0.001188, Accuracy: 99.96%\n",
      "Batch 42, Loss: 0.001196, Accuracy: 99.96%\n",
      "Batch 43, Loss: 0.000968, Accuracy: 99.96%\n",
      "Batch 44, Loss: 0.000950, Accuracy: 99.96%\n",
      "Batch 45, Loss: 0.000874, Accuracy: 99.97%\n",
      "Batch 46, Loss: 0.001138, Accuracy: 99.97%\n",
      "Batch 47, Loss: 0.001321, Accuracy: 99.97%\n",
      "Batch 48, Loss: 0.001289, Accuracy: 99.97%\n",
      "Batch 49, Loss: 0.029030, Accuracy: 99.94%\n",
      "Batch 50, Loss: 0.001515, Accuracy: 99.94%\n",
      "Batch 51, Loss: 0.001122, Accuracy: 99.94%\n",
      "Batch 52, Loss: 0.000821, Accuracy: 99.94%\n",
      "Batch 53, Loss: 0.000961, Accuracy: 99.94%\n",
      "Batch 54, Loss: 0.002261, Accuracy: 99.94%\n",
      "Batch 55, Loss: 0.001453, Accuracy: 99.94%\n",
      "Batch 56, Loss: 0.012311, Accuracy: 99.94%\n",
      "Batch 57, Loss: 0.000933, Accuracy: 99.95%\n",
      "Batch 58, Loss: 0.002149, Accuracy: 99.95%\n",
      "Batch 59, Loss: 0.012627, Accuracy: 99.95%\n",
      "Batch 60, Loss: 0.000963, Accuracy: 99.95%\n",
      "Batch 61, Loss: 0.043461, Accuracy: 99.92%\n",
      "Batch 62, Loss: 0.090408, Accuracy: 99.90%\n",
      "Batch 63, Loss: 0.001329, Accuracy: 99.90%\n",
      "Batch 64, Loss: 0.002908, Accuracy: 99.90%\n",
      "Batch 65, Loss: 0.001360, Accuracy: 99.90%\n",
      "Batch 66, Loss: 0.005642, Accuracy: 99.91%\n",
      "Batch 67, Loss: 0.023845, Accuracy: 99.88%\n",
      "Batch 68, Loss: 0.002320, Accuracy: 99.89%\n",
      "Batch 69, Loss: 0.001659, Accuracy: 99.89%\n",
      "Batch 70, Loss: 0.006452, Accuracy: 99.89%\n",
      "Batch 71, Loss: 0.169195, Accuracy: 99.85%\n",
      "Batch 72, Loss: 0.086558, Accuracy: 99.83%\n",
      "Batch 73, Loss: 0.023986, Accuracy: 99.81%\n",
      "Batch 74, Loss: 0.030389, Accuracy: 99.79%\n",
      "Batch 75, Loss: 0.001583, Accuracy: 99.79%\n",
      "Batch 76, Loss: 0.001328, Accuracy: 99.79%\n",
      "Batch 77, Loss: 0.073823, Accuracy: 99.78%\n",
      "Batch 78, Loss: 0.001484, Accuracy: 99.78%\n",
      "Batch 79, Loss: 0.001802, Accuracy: 99.78%\n",
      "Batch 80, Loss: 0.001962, Accuracy: 99.79%\n",
      "Batch 81, Loss: 0.005792, Accuracy: 99.79%\n",
      "Batch 82, Loss: 0.002244, Accuracy: 99.79%\n",
      "Batch 83, Loss: 0.007508, Accuracy: 99.79%\n",
      "Batch 84, Loss: 0.003709, Accuracy: 99.80%\n",
      "Batch 85, Loss: 0.023272, Accuracy: 99.78%\n",
      "Batch 86, Loss: 0.015321, Accuracy: 99.76%\n",
      "Batch 87, Loss: 0.003178, Accuracy: 99.77%\n",
      "Batch 88, Loss: 0.004251, Accuracy: 99.77%\n",
      "Batch 89, Loss: 0.008345, Accuracy: 99.77%\n",
      "Batch 90, Loss: 0.018607, Accuracy: 99.76%\n",
      "Batch 91, Loss: 0.027101, Accuracy: 99.74%\n",
      "Batch 92, Loss: 0.081938, Accuracy: 99.69%\n",
      "Batch 93, Loss: 0.013215, Accuracy: 99.70%\n",
      "Batch 94, Loss: 0.004774, Accuracy: 99.70%\n",
      "Batch 95, Loss: 0.079082, Accuracy: 99.69%\n",
      "Batch 96, Loss: 0.004545, Accuracy: 99.69%\n",
      "Batch 97, Loss: 0.054845, Accuracy: 99.66%\n",
      "Batch 98, Loss: 0.092680, Accuracy: 99.65%\n",
      "Batch 99, Loss: 0.041983, Accuracy: 99.62%\n",
      "Batch 100, Loss: 0.117447, Accuracy: 99.59%\n",
      "Batch 101, Loss: 0.012544, Accuracy: 99.60%\n",
      "Batch 102, Loss: 0.056468, Accuracy: 99.59%\n",
      "Batch 103, Loss: 0.047024, Accuracy: 99.56%\n",
      "Batch 104, Loss: 0.027322, Accuracy: 99.55%\n",
      "Batch 105, Loss: 0.063855, Accuracy: 99.54%\n",
      "Batch 106, Loss: 0.034160, Accuracy: 99.53%\n",
      "Batch 107, Loss: 0.026056, Accuracy: 99.52%\n",
      "Batch 108, Loss: 0.101803, Accuracy: 99.48%\n",
      "Batch 109, Loss: 0.005563, Accuracy: 99.48%\n",
      "Batch 110, Loss: 0.019897, Accuracy: 99.49%\n",
      "Batch 111, Loss: 0.022813, Accuracy: 99.48%\n",
      "Batch 112, Loss: 0.011739, Accuracy: 99.48%\n",
      "Batch 113, Loss: 0.085049, Accuracy: 99.47%\n",
      "Batch 114, Loss: 0.096585, Accuracy: 99.45%\n",
      "Batch 115, Loss: 0.037066, Accuracy: 99.44%\n",
      "Batch 116, Loss: 0.055093, Accuracy: 99.43%\n",
      "Batch 117, Loss: 0.003061, Accuracy: 99.44%\n",
      "Batch 118, Loss: 0.110351, Accuracy: 99.42%\n",
      "Batch 119, Loss: 0.035122, Accuracy: 99.40%\n",
      "Batch 120, Loss: 0.036128, Accuracy: 99.39%\n",
      "Batch 121, Loss: 0.014750, Accuracy: 99.39%\n",
      "Batch 122, Loss: 0.017315, Accuracy: 99.39%\n",
      "Batch 123, Loss: 0.032050, Accuracy: 99.38%\n",
      "Batch 124, Loss: 0.032856, Accuracy: 99.37%\n",
      "Batch 125, Loss: 0.030897, Accuracy: 99.36%\n",
      "Batch 126, Loss: 0.017461, Accuracy: 99.37%\n",
      "Batch 127, Loss: 0.006475, Accuracy: 99.37%\n",
      "Batch 128, Loss: 0.051386, Accuracy: 99.35%\n",
      "Batch 129, Loss: 0.081560, Accuracy: 99.35%\n",
      "Batch 130, Loss: 0.077502, Accuracy: 99.31%\n",
      "Batch 131, Loss: 0.052512, Accuracy: 99.31%\n",
      "Batch 132, Loss: 0.025025, Accuracy: 99.30%\n",
      "Batch 133, Loss: 0.020008, Accuracy: 99.30%\n",
      "Batch 134, Loss: 0.014927, Accuracy: 99.30%\n",
      "Batch 135, Loss: 0.122204, Accuracy: 99.28%\n",
      "Batch 136, Loss: 0.168685, Accuracy: 99.25%\n",
      "Batch 137, Loss: 0.046560, Accuracy: 99.25%\n",
      "Batch 138, Loss: 0.165788, Accuracy: 99.23%\n",
      "Batch 139, Loss: 0.059530, Accuracy: 99.22%\n",
      "Batch 140, Loss: 0.044189, Accuracy: 99.22%\n",
      "Batch 141, Loss: 0.019742, Accuracy: 99.21%\n",
      "Batch 142, Loss: 0.076460, Accuracy: 99.20%\n",
      "Batch 143, Loss: 0.107493, Accuracy: 99.18%\n",
      "Batch 144, Loss: 0.072265, Accuracy: 99.18%\n",
      "Batch 145, Loss: 0.072025, Accuracy: 99.16%\n",
      "Batch 146, Loss: 0.006777, Accuracy: 99.17%\n",
      "Batch 147, Loss: 0.088559, Accuracy: 99.15%\n",
      "Batch 148, Loss: 0.060458, Accuracy: 99.14%\n",
      "Batch 149, Loss: 0.071323, Accuracy: 99.12%\n",
      "Batch 150, Loss: 0.079146, Accuracy: 99.09%\n",
      "Batch 151, Loss: 0.061467, Accuracy: 99.09%\n",
      "Batch 152, Loss: 0.127179, Accuracy: 99.07%\n",
      "Batch 153, Loss: 0.008223, Accuracy: 99.08%\n",
      "Batch 154, Loss: 0.014877, Accuracy: 99.09%\n",
      "Batch 155, Loss: 0.003909, Accuracy: 99.09%\n",
      "Batch 156, Loss: 0.017524, Accuracy: 99.10%\n",
      "Batch 157, Loss: 0.021599, Accuracy: 99.09%\n",
      "Batch 158, Loss: 0.016368, Accuracy: 99.09%\n",
      "Batch 159, Loss: 0.035091, Accuracy: 99.09%\n",
      "Batch 160, Loss: 0.097821, Accuracy: 99.08%\n",
      "Batch 161, Loss: 0.013666, Accuracy: 99.09%\n",
      "Batch 162, Loss: 0.050340, Accuracy: 99.08%\n",
      "Batch 163, Loss: 0.123372, Accuracy: 99.07%\n",
      "Batch 164, Loss: 0.003290, Accuracy: 99.08%\n",
      "Batch 165, Loss: 0.006434, Accuracy: 99.08%\n",
      "Batch 166, Loss: 0.166335, Accuracy: 99.05%\n",
      "Batch 167, Loss: 0.101654, Accuracy: 99.03%\n",
      "Batch 168, Loss: 0.024609, Accuracy: 99.03%\n",
      "Batch 169, Loss: 0.005246, Accuracy: 99.04%\n",
      "Batch 170, Loss: 0.031211, Accuracy: 99.03%\n",
      "Batch 171, Loss: 0.034988, Accuracy: 99.03%\n",
      "Batch 172, Loss: 0.098874, Accuracy: 99.03%\n",
      "Batch 173, Loss: 0.044825, Accuracy: 99.02%\n",
      "Batch 174, Loss: 0.003191, Accuracy: 99.03%\n",
      "Batch 175, Loss: 0.060243, Accuracy: 99.03%\n",
      "Batch 176, Loss: 0.169509, Accuracy: 99.01%\n",
      "Batch 177, Loss: 0.062543, Accuracy: 98.99%\n",
      "Batch 178, Loss: 0.011363, Accuracy: 99.00%\n",
      "Batch 179, Loss: 0.003966, Accuracy: 99.00%\n",
      "Batch 180, Loss: 0.055058, Accuracy: 98.99%\n",
      "Batch 181, Loss: 0.024119, Accuracy: 98.99%\n",
      "Batch 182, Loss: 0.176684, Accuracy: 98.96%\n",
      "Batch 183, Loss: 0.005848, Accuracy: 98.97%\n",
      "Batch 184, Loss: 0.008132, Accuracy: 98.97%\n",
      "Batch 185, Loss: 0.026464, Accuracy: 98.97%\n",
      "Batch 186, Loss: 0.012490, Accuracy: 98.98%\n",
      "Batch 187, Loss: 0.009134, Accuracy: 98.98%\n",
      "Batch 188, Loss: 0.009234, Accuracy: 98.99%\n",
      "Batch 189, Loss: 0.012943, Accuracy: 98.99%\n",
      "Batch 190, Loss: 0.032042, Accuracy: 98.99%\n",
      "Batch 191, Loss: 0.018174, Accuracy: 98.99%\n",
      "Batch 192, Loss: 0.074000, Accuracy: 98.97%\n",
      "Batch 193, Loss: 0.028058, Accuracy: 98.97%\n",
      "Batch 194, Loss: 0.007021, Accuracy: 98.98%\n",
      "Batch 195, Loss: 0.003387, Accuracy: 98.98%\n",
      "Batch 196, Loss: 0.007268, Accuracy: 98.99%\n",
      "Batch 197, Loss: 0.005089, Accuracy: 98.99%\n",
      "Batch 198, Loss: 0.002607, Accuracy: 99.00%\n",
      "Batch 199, Loss: 0.026115, Accuracy: 98.99%\n",
      "Batch 200, Loss: 0.013436, Accuracy: 99.00%\n",
      "Batch 201, Loss: 0.020190, Accuracy: 99.00%\n",
      "Batch 202, Loss: 0.105898, Accuracy: 98.99%\n",
      "Batch 203, Loss: 0.004679, Accuracy: 98.99%\n",
      "Batch 204, Loss: 0.002285, Accuracy: 99.00%\n",
      "Batch 205, Loss: 0.094599, Accuracy: 98.99%\n",
      "Batch 206, Loss: 0.037931, Accuracy: 98.98%\n",
      "Batch 207, Loss: 0.008123, Accuracy: 98.99%\n",
      "Batch 208, Loss: 0.011908, Accuracy: 98.99%\n",
      "Batch 209, Loss: 0.077347, Accuracy: 98.99%\n",
      "Batch 210, Loss: 0.019487, Accuracy: 99.00%\n",
      "Batch 211, Loss: 0.003333, Accuracy: 99.00%\n",
      "Batch 212, Loss: 0.002060, Accuracy: 99.01%\n",
      "Batch 213, Loss: 0.002654, Accuracy: 99.01%\n",
      "Training - Epoch 28, Loss: 0.029738, Accuracy: 99.01%\n",
      "Validation Batch 1, Loss: 0.026918, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.061743, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.001901, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.041105, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.102612, Accuracy: 98.12%\n",
      "Validation Batch 6, Loss: 0.002240, Accuracy: 98.44%\n",
      "Validation Batch 7, Loss: 0.002702, Accuracy: 98.66%\n",
      "Validation Batch 8, Loss: 0.202299, Accuracy: 98.24%\n",
      "Validation Batch 9, Loss: 0.082837, Accuracy: 98.26%\n",
      "Validation Batch 10, Loss: 0.001508, Accuracy: 98.44%\n",
      "Validation Batch 11, Loss: 0.038547, Accuracy: 98.44%\n",
      "Validation Batch 12, Loss: 0.004401, Accuracy: 98.57%\n",
      "Validation Batch 13, Loss: 0.008918, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.023544, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.136369, Accuracy: 98.44%\n",
      "Validation Batch 16, Loss: 0.103260, Accuracy: 98.44%\n",
      "Validation Batch 17, Loss: 0.062021, Accuracy: 98.35%\n",
      "Validation Batch 18, Loss: 0.064118, Accuracy: 98.35%\n",
      "Validation Batch 19, Loss: 0.004957, Accuracy: 98.44%\n",
      "Validation Batch 20, Loss: 0.073708, Accuracy: 98.36%\n",
      "Validation Batch 21, Loss: 0.024497, Accuracy: 98.36%\n",
      "Validation Batch 22, Loss: 0.010010, Accuracy: 98.44%\n",
      "Validation Batch 23, Loss: 0.019900, Accuracy: 98.44%\n",
      "Validation Batch 24, Loss: 0.135766, Accuracy: 98.37%\n",
      "Validation Batch 25, Loss: 0.003203, Accuracy: 98.44%\n",
      "Validation Batch 26, Loss: 0.048225, Accuracy: 98.44%\n",
      "Validation Batch 27, Loss: 0.067999, Accuracy: 98.41%\n",
      "Validation - Epoch 28, Loss: 0.050197, Accuracy: 98.41%\n",
      "Patience—1\n",
      "Epoch 29\n",
      "Batch 1, Loss: 0.003454, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001527, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.004046, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.002527, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.012589, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.033850, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.031318, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.004749, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.004286, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.002627, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.017749, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.003556, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.006410, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.006893, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.010515, Accuracy: 99.69%\n",
      "Batch 16, Loss: 0.002241, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.055821, Accuracy: 99.63%\n",
      "Batch 18, Loss: 0.004434, Accuracy: 99.65%\n",
      "Batch 19, Loss: 0.003256, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.108627, Accuracy: 99.61%\n",
      "Batch 21, Loss: 0.005671, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.002813, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.002402, Accuracy: 99.66%\n",
      "Batch 24, Loss: 0.003714, Accuracy: 99.67%\n",
      "Batch 25, Loss: 0.010244, Accuracy: 99.69%\n",
      "Batch 26, Loss: 0.003398, Accuracy: 99.70%\n",
      "Batch 27, Loss: 0.007061, Accuracy: 99.71%\n",
      "Batch 28, Loss: 0.004712, Accuracy: 99.72%\n",
      "Batch 29, Loss: 0.002104, Accuracy: 99.73%\n",
      "Batch 30, Loss: 0.001654, Accuracy: 99.74%\n",
      "Batch 31, Loss: 0.014914, Accuracy: 99.75%\n",
      "Batch 32, Loss: 0.028096, Accuracy: 99.71%\n",
      "Batch 33, Loss: 0.003992, Accuracy: 99.72%\n",
      "Batch 34, Loss: 0.006045, Accuracy: 99.72%\n",
      "Batch 35, Loss: 0.034834, Accuracy: 99.69%\n",
      "Batch 36, Loss: 0.004822, Accuracy: 99.70%\n",
      "Batch 37, Loss: 0.011234, Accuracy: 99.70%\n",
      "Batch 38, Loss: 0.003170, Accuracy: 99.71%\n",
      "Batch 39, Loss: 0.050896, Accuracy: 99.68%\n",
      "Batch 40, Loss: 0.003433, Accuracy: 99.69%\n",
      "Batch 41, Loss: 0.011009, Accuracy: 99.70%\n",
      "Batch 42, Loss: 0.021806, Accuracy: 99.67%\n",
      "Batch 43, Loss: 0.010954, Accuracy: 99.67%\n",
      "Batch 44, Loss: 0.008239, Accuracy: 99.68%\n",
      "Batch 45, Loss: 0.006452, Accuracy: 99.69%\n",
      "Batch 46, Loss: 0.012497, Accuracy: 99.69%\n",
      "Batch 47, Loss: 0.003033, Accuracy: 99.70%\n",
      "Batch 48, Loss: 0.025312, Accuracy: 99.67%\n",
      "Batch 49, Loss: 0.007225, Accuracy: 99.68%\n",
      "Batch 50, Loss: 0.001770, Accuracy: 99.69%\n",
      "Batch 51, Loss: 0.001749, Accuracy: 99.69%\n",
      "Batch 52, Loss: 0.002860, Accuracy: 99.70%\n",
      "Batch 53, Loss: 0.052790, Accuracy: 99.65%\n",
      "Batch 54, Loss: 0.032514, Accuracy: 99.62%\n",
      "Batch 55, Loss: 0.083942, Accuracy: 99.57%\n",
      "Batch 56, Loss: 0.004532, Accuracy: 99.58%\n",
      "Batch 57, Loss: 0.008415, Accuracy: 99.59%\n",
      "Batch 58, Loss: 0.005179, Accuracy: 99.60%\n",
      "Batch 59, Loss: 0.024148, Accuracy: 99.58%\n",
      "Batch 60, Loss: 0.006300, Accuracy: 99.58%\n",
      "Batch 61, Loss: 0.078141, Accuracy: 99.56%\n",
      "Batch 62, Loss: 0.001814, Accuracy: 99.57%\n",
      "Batch 63, Loss: 0.036814, Accuracy: 99.55%\n",
      "Batch 64, Loss: 0.002864, Accuracy: 99.56%\n",
      "Batch 65, Loss: 0.002341, Accuracy: 99.57%\n",
      "Batch 66, Loss: 0.006116, Accuracy: 99.57%\n",
      "Batch 67, Loss: 0.039704, Accuracy: 99.56%\n",
      "Batch 68, Loss: 0.014994, Accuracy: 99.56%\n",
      "Batch 69, Loss: 0.015948, Accuracy: 99.57%\n",
      "Batch 70, Loss: 0.008517, Accuracy: 99.58%\n",
      "Batch 71, Loss: 0.002975, Accuracy: 99.58%\n",
      "Batch 72, Loss: 0.003348, Accuracy: 99.59%\n",
      "Batch 73, Loss: 0.001954, Accuracy: 99.59%\n",
      "Batch 74, Loss: 0.056263, Accuracy: 99.58%\n",
      "Batch 75, Loss: 0.004629, Accuracy: 99.58%\n",
      "Batch 76, Loss: 0.008142, Accuracy: 99.59%\n",
      "Batch 77, Loss: 0.001780, Accuracy: 99.59%\n",
      "Batch 78, Loss: 0.002550, Accuracy: 99.60%\n",
      "Batch 79, Loss: 0.022467, Accuracy: 99.58%\n",
      "Batch 80, Loss: 0.001560, Accuracy: 99.59%\n",
      "Batch 81, Loss: 0.002678, Accuracy: 99.59%\n",
      "Batch 82, Loss: 0.002579, Accuracy: 99.60%\n",
      "Batch 83, Loss: 0.002212, Accuracy: 99.60%\n",
      "Batch 84, Loss: 0.004919, Accuracy: 99.61%\n",
      "Batch 85, Loss: 0.002868, Accuracy: 99.61%\n",
      "Batch 86, Loss: 0.003363, Accuracy: 99.62%\n",
      "Batch 87, Loss: 0.044908, Accuracy: 99.60%\n",
      "Batch 88, Loss: 0.063497, Accuracy: 99.57%\n",
      "Batch 89, Loss: 0.004994, Accuracy: 99.58%\n",
      "Batch 90, Loss: 0.001128, Accuracy: 99.58%\n",
      "Batch 91, Loss: 0.103481, Accuracy: 99.55%\n",
      "Batch 92, Loss: 0.046522, Accuracy: 99.52%\n",
      "Batch 93, Loss: 0.015520, Accuracy: 99.51%\n",
      "Batch 94, Loss: 0.002149, Accuracy: 99.52%\n",
      "Batch 95, Loss: 0.008604, Accuracy: 99.52%\n",
      "Batch 96, Loss: 0.006172, Accuracy: 99.53%\n",
      "Batch 97, Loss: 0.009329, Accuracy: 99.53%\n",
      "Batch 98, Loss: 0.057880, Accuracy: 99.51%\n",
      "Batch 99, Loss: 0.180256, Accuracy: 99.48%\n",
      "Batch 100, Loss: 0.047937, Accuracy: 99.45%\n",
      "Batch 101, Loss: 0.001540, Accuracy: 99.46%\n",
      "Batch 102, Loss: 0.020000, Accuracy: 99.46%\n",
      "Batch 103, Loss: 0.029558, Accuracy: 99.44%\n",
      "Batch 104, Loss: 0.045877, Accuracy: 99.41%\n",
      "Batch 105, Loss: 0.022588, Accuracy: 99.40%\n",
      "Batch 106, Loss: 0.002406, Accuracy: 99.41%\n",
      "Batch 107, Loss: 0.004836, Accuracy: 99.42%\n",
      "Batch 108, Loss: 0.045563, Accuracy: 99.41%\n",
      "Batch 109, Loss: 0.039793, Accuracy: 99.38%\n",
      "Batch 110, Loss: 0.004466, Accuracy: 99.39%\n",
      "Batch 111, Loss: 0.077855, Accuracy: 99.35%\n",
      "Batch 112, Loss: 0.008236, Accuracy: 99.36%\n",
      "Batch 113, Loss: 0.048673, Accuracy: 99.34%\n",
      "Batch 114, Loss: 0.019800, Accuracy: 99.33%\n",
      "Batch 115, Loss: 0.005594, Accuracy: 99.33%\n",
      "Batch 116, Loss: 0.021770, Accuracy: 99.34%\n",
      "Batch 117, Loss: 0.156636, Accuracy: 99.31%\n",
      "Batch 118, Loss: 0.012481, Accuracy: 99.31%\n",
      "Batch 119, Loss: 0.004029, Accuracy: 99.32%\n",
      "Batch 120, Loss: 0.026565, Accuracy: 99.31%\n",
      "Batch 121, Loss: 0.026887, Accuracy: 99.30%\n",
      "Batch 122, Loss: 0.004599, Accuracy: 99.31%\n",
      "Batch 123, Loss: 0.009232, Accuracy: 99.31%\n",
      "Batch 124, Loss: 0.029938, Accuracy: 99.31%\n",
      "Batch 125, Loss: 0.041244, Accuracy: 99.30%\n",
      "Batch 126, Loss: 0.003044, Accuracy: 99.31%\n",
      "Batch 127, Loss: 0.042679, Accuracy: 99.30%\n",
      "Batch 128, Loss: 0.182645, Accuracy: 99.27%\n",
      "Batch 129, Loss: 0.031402, Accuracy: 99.26%\n",
      "Batch 130, Loss: 0.110895, Accuracy: 99.23%\n",
      "Batch 131, Loss: 0.005865, Accuracy: 99.24%\n",
      "Batch 132, Loss: 0.052890, Accuracy: 99.22%\n",
      "Batch 133, Loss: 0.017421, Accuracy: 99.22%\n",
      "Batch 134, Loss: 0.082336, Accuracy: 99.21%\n",
      "Batch 135, Loss: 0.028121, Accuracy: 99.20%\n",
      "Batch 136, Loss: 0.003352, Accuracy: 99.21%\n",
      "Batch 137, Loss: 0.009481, Accuracy: 99.21%\n",
      "Batch 138, Loss: 0.003541, Accuracy: 99.22%\n",
      "Batch 139, Loss: 0.018205, Accuracy: 99.21%\n",
      "Batch 140, Loss: 0.005325, Accuracy: 99.22%\n",
      "Batch 141, Loss: 0.013326, Accuracy: 99.22%\n",
      "Batch 142, Loss: 0.162991, Accuracy: 99.21%\n",
      "Batch 143, Loss: 0.102082, Accuracy: 99.19%\n",
      "Batch 144, Loss: 0.019930, Accuracy: 99.19%\n",
      "Batch 145, Loss: 0.011612, Accuracy: 99.19%\n",
      "Batch 146, Loss: 0.007638, Accuracy: 99.20%\n",
      "Batch 147, Loss: 0.009771, Accuracy: 99.20%\n",
      "Batch 148, Loss: 0.005477, Accuracy: 99.21%\n",
      "Batch 149, Loss: 0.043703, Accuracy: 99.20%\n",
      "Batch 150, Loss: 0.042056, Accuracy: 99.19%\n",
      "Batch 151, Loss: 0.098648, Accuracy: 99.18%\n",
      "Batch 152, Loss: 0.020959, Accuracy: 99.19%\n",
      "Batch 153, Loss: 0.008165, Accuracy: 99.19%\n",
      "Batch 154, Loss: 0.004084, Accuracy: 99.20%\n",
      "Batch 155, Loss: 0.005873, Accuracy: 99.20%\n",
      "Batch 156, Loss: 0.005996, Accuracy: 99.21%\n",
      "Batch 157, Loss: 0.015711, Accuracy: 99.20%\n",
      "Batch 158, Loss: 0.006942, Accuracy: 99.21%\n",
      "Batch 159, Loss: 0.021795, Accuracy: 99.20%\n",
      "Batch 160, Loss: 0.001839, Accuracy: 99.21%\n",
      "Batch 161, Loss: 0.003751, Accuracy: 99.21%\n",
      "Batch 162, Loss: 0.003829, Accuracy: 99.22%\n",
      "Batch 163, Loss: 0.060565, Accuracy: 99.21%\n",
      "Batch 164, Loss: 0.008184, Accuracy: 99.22%\n",
      "Batch 165, Loss: 0.003764, Accuracy: 99.22%\n",
      "Batch 166, Loss: 0.004849, Accuracy: 99.23%\n",
      "Batch 167, Loss: 0.008109, Accuracy: 99.23%\n",
      "Batch 168, Loss: 0.007980, Accuracy: 99.24%\n",
      "Batch 169, Loss: 0.003202, Accuracy: 99.24%\n",
      "Batch 170, Loss: 0.024591, Accuracy: 99.25%\n",
      "Batch 171, Loss: 0.010480, Accuracy: 99.25%\n",
      "Batch 172, Loss: 0.008431, Accuracy: 99.26%\n",
      "Batch 173, Loss: 0.013512, Accuracy: 99.26%\n",
      "Batch 174, Loss: 0.003008, Accuracy: 99.26%\n",
      "Batch 175, Loss: 0.012934, Accuracy: 99.27%\n",
      "Batch 176, Loss: 0.003544, Accuracy: 99.27%\n",
      "Batch 177, Loss: 0.013153, Accuracy: 99.28%\n",
      "Batch 178, Loss: 0.039563, Accuracy: 99.26%\n",
      "Batch 179, Loss: 0.005364, Accuracy: 99.27%\n",
      "Batch 180, Loss: 0.004345, Accuracy: 99.27%\n",
      "Batch 181, Loss: 0.053702, Accuracy: 99.27%\n",
      "Batch 182, Loss: 0.005656, Accuracy: 99.27%\n",
      "Batch 183, Loss: 0.004774, Accuracy: 99.27%\n",
      "Batch 184, Loss: 0.001279, Accuracy: 99.28%\n",
      "Batch 185, Loss: 0.003223, Accuracy: 99.28%\n",
      "Batch 186, Loss: 0.010760, Accuracy: 99.29%\n",
      "Batch 187, Loss: 0.008908, Accuracy: 99.29%\n",
      "Batch 188, Loss: 0.009597, Accuracy: 99.29%\n",
      "Batch 189, Loss: 0.003941, Accuracy: 99.30%\n",
      "Batch 190, Loss: 0.002307, Accuracy: 99.30%\n",
      "Batch 191, Loss: 0.005681, Accuracy: 99.30%\n",
      "Batch 192, Loss: 0.001953, Accuracy: 99.31%\n",
      "Batch 193, Loss: 0.010909, Accuracy: 99.31%\n",
      "Batch 194, Loss: 0.028625, Accuracy: 99.31%\n",
      "Batch 195, Loss: 0.006296, Accuracy: 99.31%\n",
      "Batch 196, Loss: 0.001958, Accuracy: 99.31%\n",
      "Batch 197, Loss: 0.003070, Accuracy: 99.32%\n",
      "Batch 198, Loss: 0.011837, Accuracy: 99.32%\n",
      "Batch 199, Loss: 0.003667, Accuracy: 99.32%\n",
      "Batch 200, Loss: 0.001908, Accuracy: 99.33%\n",
      "Batch 201, Loss: 0.006492, Accuracy: 99.33%\n",
      "Batch 202, Loss: 0.002728, Accuracy: 99.33%\n",
      "Batch 203, Loss: 0.002127, Accuracy: 99.34%\n",
      "Batch 204, Loss: 0.058570, Accuracy: 99.33%\n",
      "Batch 205, Loss: 0.050205, Accuracy: 99.33%\n",
      "Batch 206, Loss: 0.006767, Accuracy: 99.33%\n",
      "Batch 207, Loss: 0.002733, Accuracy: 99.34%\n",
      "Batch 208, Loss: 0.001632, Accuracy: 99.34%\n",
      "Batch 209, Loss: 0.033253, Accuracy: 99.33%\n",
      "Batch 210, Loss: 0.084005, Accuracy: 99.32%\n",
      "Batch 211, Loss: 0.057211, Accuracy: 99.32%\n",
      "Batch 212, Loss: 0.003157, Accuracy: 99.32%\n",
      "Batch 213, Loss: 0.035912, Accuracy: 99.32%\n",
      "Training - Epoch 29, Loss: 0.020959, Accuracy: 99.32%\n",
      "Validation Batch 1, Loss: 0.011304, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.005307, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.002018, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.002896, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.003551, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.003727, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.004546, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.009437, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.069119, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.039334, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.075979, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.060723, Accuracy: 99.35%\n",
      "Validation Batch 13, Loss: 0.006252, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.063727, Accuracy: 99.33%\n",
      "Validation Batch 15, Loss: 0.077766, Accuracy: 99.17%\n",
      "Validation Batch 16, Loss: 0.005854, Accuracy: 99.22%\n",
      "Validation Batch 17, Loss: 0.003469, Accuracy: 99.26%\n",
      "Validation Batch 18, Loss: 0.006338, Accuracy: 99.31%\n",
      "Validation Batch 19, Loss: 0.003777, Accuracy: 99.34%\n",
      "Validation Batch 20, Loss: 0.002057, Accuracy: 99.38%\n",
      "Validation Batch 21, Loss: 0.001737, Accuracy: 99.40%\n",
      "Validation Batch 22, Loss: 0.004836, Accuracy: 99.43%\n",
      "Validation Batch 23, Loss: 0.002817, Accuracy: 99.46%\n",
      "Validation Batch 24, Loss: 0.122451, Accuracy: 99.41%\n",
      "Validation Batch 25, Loss: 0.001184, Accuracy: 99.44%\n",
      "Validation Batch 26, Loss: 0.010523, Accuracy: 99.46%\n",
      "Validation Batch 27, Loss: 0.001451, Accuracy: 99.47%\n",
      "Validation - Epoch 29, Loss: 0.022303, Accuracy: 99.47%\n",
      "Patience—2\n",
      "Epoch 30\n",
      "Batch 1, Loss: 0.005241, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.003046, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.004702, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.007273, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.006528, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.001370, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.019594, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.003802, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.030199, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.044414, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.058497, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.001440, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.020143, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.010081, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.008217, Accuracy: 99.58%\n",
      "Batch 16, Loss: 0.078415, Accuracy: 99.51%\n",
      "Batch 17, Loss: 0.077296, Accuracy: 99.45%\n",
      "Batch 18, Loss: 0.035284, Accuracy: 99.39%\n",
      "Batch 19, Loss: 0.036817, Accuracy: 99.34%\n",
      "Batch 20, Loss: 0.005901, Accuracy: 99.38%\n",
      "Batch 21, Loss: 0.041571, Accuracy: 99.33%\n",
      "Batch 22, Loss: 0.006189, Accuracy: 99.36%\n",
      "Batch 23, Loss: 0.057099, Accuracy: 99.32%\n",
      "Batch 24, Loss: 0.012623, Accuracy: 99.35%\n",
      "Batch 25, Loss: 0.108564, Accuracy: 99.31%\n",
      "Batch 26, Loss: 0.031372, Accuracy: 99.28%\n",
      "Batch 27, Loss: 0.043083, Accuracy: 99.25%\n",
      "Batch 28, Loss: 0.018412, Accuracy: 99.27%\n",
      "Batch 29, Loss: 0.056255, Accuracy: 99.25%\n",
      "Batch 30, Loss: 0.002510, Accuracy: 99.27%\n",
      "Batch 31, Loss: 0.005780, Accuracy: 99.29%\n",
      "Batch 32, Loss: 0.003917, Accuracy: 99.32%\n",
      "Batch 33, Loss: 0.024899, Accuracy: 99.29%\n",
      "Batch 34, Loss: 0.064368, Accuracy: 99.26%\n",
      "Batch 35, Loss: 0.030835, Accuracy: 99.24%\n",
      "Batch 36, Loss: 0.021403, Accuracy: 99.26%\n",
      "Batch 37, Loss: 0.035447, Accuracy: 99.24%\n",
      "Batch 38, Loss: 0.013925, Accuracy: 99.26%\n",
      "Batch 39, Loss: 0.007770, Accuracy: 99.28%\n",
      "Batch 40, Loss: 0.005820, Accuracy: 99.30%\n",
      "Batch 41, Loss: 0.008799, Accuracy: 99.31%\n",
      "Batch 42, Loss: 0.005440, Accuracy: 99.33%\n",
      "Batch 43, Loss: 0.004323, Accuracy: 99.35%\n",
      "Batch 44, Loss: 0.027052, Accuracy: 99.33%\n",
      "Batch 45, Loss: 0.009067, Accuracy: 99.34%\n",
      "Batch 46, Loss: 0.038112, Accuracy: 99.29%\n",
      "Batch 47, Loss: 0.003576, Accuracy: 99.30%\n",
      "Batch 48, Loss: 0.111509, Accuracy: 99.28%\n",
      "Batch 49, Loss: 0.006303, Accuracy: 99.30%\n",
      "Batch 50, Loss: 0.064301, Accuracy: 99.25%\n",
      "Batch 51, Loss: 0.003004, Accuracy: 99.26%\n",
      "Batch 52, Loss: 0.004411, Accuracy: 99.28%\n",
      "Batch 53, Loss: 0.002521, Accuracy: 99.29%\n",
      "Batch 54, Loss: 0.010309, Accuracy: 99.31%\n",
      "Batch 55, Loss: 0.049258, Accuracy: 99.29%\n",
      "Batch 56, Loss: 0.026310, Accuracy: 99.27%\n",
      "Batch 57, Loss: 0.047843, Accuracy: 99.26%\n",
      "Batch 58, Loss: 0.066558, Accuracy: 99.22%\n",
      "Batch 59, Loss: 0.023228, Accuracy: 99.21%\n",
      "Batch 60, Loss: 0.001952, Accuracy: 99.22%\n",
      "Batch 61, Loss: 0.018528, Accuracy: 99.21%\n",
      "Batch 62, Loss: 0.012492, Accuracy: 99.22%\n",
      "Batch 63, Loss: 0.029036, Accuracy: 99.18%\n",
      "Batch 64, Loss: 0.011971, Accuracy: 99.19%\n",
      "Batch 65, Loss: 0.002520, Accuracy: 99.21%\n",
      "Batch 66, Loss: 0.017640, Accuracy: 99.20%\n",
      "Batch 67, Loss: 0.009578, Accuracy: 99.21%\n",
      "Batch 68, Loss: 0.002978, Accuracy: 99.22%\n",
      "Batch 69, Loss: 0.037088, Accuracy: 99.21%\n",
      "Batch 70, Loss: 0.019984, Accuracy: 99.20%\n",
      "Batch 71, Loss: 0.012379, Accuracy: 99.21%\n",
      "Batch 72, Loss: 0.003938, Accuracy: 99.22%\n",
      "Batch 73, Loss: 0.079010, Accuracy: 99.21%\n",
      "Batch 74, Loss: 0.023799, Accuracy: 99.20%\n",
      "Batch 75, Loss: 0.006224, Accuracy: 99.21%\n",
      "Batch 76, Loss: 0.027769, Accuracy: 99.20%\n",
      "Batch 77, Loss: 0.004383, Accuracy: 99.21%\n",
      "Batch 78, Loss: 0.008320, Accuracy: 99.22%\n",
      "Batch 79, Loss: 0.019631, Accuracy: 99.23%\n",
      "Batch 80, Loss: 0.039802, Accuracy: 99.22%\n",
      "Batch 81, Loss: 0.027251, Accuracy: 99.21%\n",
      "Batch 82, Loss: 0.001855, Accuracy: 99.22%\n",
      "Batch 83, Loss: 0.007441, Accuracy: 99.23%\n",
      "Batch 84, Loss: 0.002702, Accuracy: 99.24%\n",
      "Batch 85, Loss: 0.002567, Accuracy: 99.25%\n",
      "Batch 86, Loss: 0.001426, Accuracy: 99.26%\n",
      "Batch 87, Loss: 0.004455, Accuracy: 99.26%\n",
      "Batch 88, Loss: 0.003520, Accuracy: 99.27%\n",
      "Batch 89, Loss: 0.008019, Accuracy: 99.28%\n",
      "Batch 90, Loss: 0.001338, Accuracy: 99.29%\n",
      "Batch 91, Loss: 0.006456, Accuracy: 99.30%\n",
      "Batch 92, Loss: 0.003411, Accuracy: 99.30%\n",
      "Batch 93, Loss: 0.009487, Accuracy: 99.31%\n",
      "Batch 94, Loss: 0.002292, Accuracy: 99.32%\n",
      "Batch 95, Loss: 0.002580, Accuracy: 99.33%\n",
      "Batch 96, Loss: 0.010691, Accuracy: 99.33%\n",
      "Batch 97, Loss: 0.013852, Accuracy: 99.34%\n",
      "Batch 98, Loss: 0.002665, Accuracy: 99.35%\n",
      "Batch 99, Loss: 0.002316, Accuracy: 99.35%\n",
      "Batch 100, Loss: 0.004783, Accuracy: 99.36%\n",
      "Batch 101, Loss: 0.002269, Accuracy: 99.37%\n",
      "Batch 102, Loss: 0.002071, Accuracy: 99.37%\n",
      "Batch 103, Loss: 0.002920, Accuracy: 99.38%\n",
      "Batch 104, Loss: 0.001978, Accuracy: 99.38%\n",
      "Batch 105, Loss: 0.003124, Accuracy: 99.39%\n",
      "Batch 106, Loss: 0.013855, Accuracy: 99.40%\n",
      "Batch 107, Loss: 0.004490, Accuracy: 99.40%\n",
      "Batch 108, Loss: 0.001923, Accuracy: 99.41%\n",
      "Batch 109, Loss: 0.094195, Accuracy: 99.40%\n",
      "Batch 110, Loss: 0.002567, Accuracy: 99.40%\n",
      "Batch 111, Loss: 0.045806, Accuracy: 99.39%\n",
      "Batch 112, Loss: 0.002965, Accuracy: 99.40%\n",
      "Batch 113, Loss: 0.006954, Accuracy: 99.41%\n",
      "Batch 114, Loss: 0.001405, Accuracy: 99.41%\n",
      "Batch 115, Loss: 0.007501, Accuracy: 99.42%\n",
      "Batch 116, Loss: 0.061021, Accuracy: 99.41%\n",
      "Batch 117, Loss: 0.038119, Accuracy: 99.40%\n",
      "Batch 118, Loss: 0.001200, Accuracy: 99.40%\n",
      "Batch 119, Loss: 0.007980, Accuracy: 99.41%\n",
      "Batch 120, Loss: 0.002125, Accuracy: 99.41%\n",
      "Batch 121, Loss: 0.001283, Accuracy: 99.42%\n",
      "Batch 122, Loss: 0.001777, Accuracy: 99.42%\n",
      "Batch 123, Loss: 0.014903, Accuracy: 99.43%\n",
      "Batch 124, Loss: 0.005278, Accuracy: 99.43%\n",
      "Batch 125, Loss: 0.002378, Accuracy: 99.44%\n",
      "Batch 126, Loss: 0.007003, Accuracy: 99.44%\n",
      "Batch 127, Loss: 0.002666, Accuracy: 99.45%\n",
      "Batch 128, Loss: 0.009620, Accuracy: 99.45%\n",
      "Batch 129, Loss: 0.005294, Accuracy: 99.45%\n",
      "Batch 130, Loss: 0.009473, Accuracy: 99.46%\n",
      "Batch 131, Loss: 0.011167, Accuracy: 99.46%\n",
      "Batch 132, Loss: 0.003389, Accuracy: 99.47%\n",
      "Batch 133, Loss: 0.012952, Accuracy: 99.46%\n",
      "Batch 134, Loss: 0.029114, Accuracy: 99.45%\n",
      "Batch 135, Loss: 0.001386, Accuracy: 99.46%\n",
      "Batch 136, Loss: 0.001880, Accuracy: 99.46%\n",
      "Batch 137, Loss: 0.042266, Accuracy: 99.45%\n",
      "Batch 138, Loss: 0.034562, Accuracy: 99.45%\n",
      "Batch 139, Loss: 0.006169, Accuracy: 99.45%\n",
      "Batch 140, Loss: 0.001705, Accuracy: 99.45%\n",
      "Batch 141, Loss: 0.003338, Accuracy: 99.46%\n",
      "Batch 142, Loss: 0.001264, Accuracy: 99.46%\n",
      "Batch 143, Loss: 0.002327, Accuracy: 99.46%\n",
      "Batch 144, Loss: 0.017589, Accuracy: 99.46%\n",
      "Batch 145, Loss: 0.017192, Accuracy: 99.45%\n",
      "Batch 146, Loss: 0.003869, Accuracy: 99.45%\n",
      "Batch 147, Loss: 0.003263, Accuracy: 99.46%\n",
      "Batch 148, Loss: 0.002183, Accuracy: 99.46%\n",
      "Batch 149, Loss: 0.003126, Accuracy: 99.47%\n",
      "Batch 150, Loss: 0.001816, Accuracy: 99.47%\n",
      "Batch 151, Loss: 0.002119, Accuracy: 99.47%\n",
      "Batch 152, Loss: 0.057204, Accuracy: 99.47%\n",
      "Batch 153, Loss: 0.009971, Accuracy: 99.47%\n",
      "Batch 154, Loss: 0.007160, Accuracy: 99.47%\n",
      "Batch 155, Loss: 0.001931, Accuracy: 99.48%\n",
      "Batch 156, Loss: 0.001250, Accuracy: 99.48%\n",
      "Batch 157, Loss: 0.023023, Accuracy: 99.47%\n",
      "Batch 158, Loss: 0.002658, Accuracy: 99.48%\n",
      "Batch 159, Loss: 0.001176, Accuracy: 99.48%\n",
      "Batch 160, Loss: 0.116923, Accuracy: 99.46%\n",
      "Batch 161, Loss: 0.031439, Accuracy: 99.46%\n",
      "Batch 162, Loss: 0.002867, Accuracy: 99.46%\n",
      "Batch 163, Loss: 0.027161, Accuracy: 99.45%\n",
      "Batch 164, Loss: 0.001779, Accuracy: 99.46%\n",
      "Batch 165, Loss: 0.002692, Accuracy: 99.46%\n",
      "Batch 166, Loss: 0.002958, Accuracy: 99.46%\n",
      "Batch 167, Loss: 0.002235, Accuracy: 99.47%\n",
      "Batch 168, Loss: 0.010445, Accuracy: 99.47%\n",
      "Batch 169, Loss: 0.005313, Accuracy: 99.47%\n",
      "Batch 170, Loss: 0.002269, Accuracy: 99.48%\n",
      "Batch 171, Loss: 0.003046, Accuracy: 99.48%\n",
      "Batch 172, Loss: 0.001740, Accuracy: 99.48%\n",
      "Batch 173, Loss: 0.080381, Accuracy: 99.48%\n",
      "Batch 174, Loss: 0.029913, Accuracy: 99.47%\n",
      "Batch 175, Loss: 0.001229, Accuracy: 99.47%\n",
      "Batch 176, Loss: 0.002362, Accuracy: 99.48%\n",
      "Batch 177, Loss: 0.013453, Accuracy: 99.47%\n",
      "Batch 178, Loss: 0.026944, Accuracy: 99.46%\n",
      "Batch 179, Loss: 0.003292, Accuracy: 99.47%\n",
      "Batch 180, Loss: 0.031720, Accuracy: 99.46%\n",
      "Batch 181, Loss: 0.011111, Accuracy: 99.46%\n",
      "Batch 182, Loss: 0.011800, Accuracy: 99.47%\n",
      "Batch 183, Loss: 0.004180, Accuracy: 99.47%\n",
      "Batch 184, Loss: 0.033886, Accuracy: 99.47%\n",
      "Batch 185, Loss: 0.013848, Accuracy: 99.46%\n",
      "Batch 186, Loss: 0.003706, Accuracy: 99.46%\n",
      "Batch 187, Loss: 0.020674, Accuracy: 99.46%\n",
      "Batch 188, Loss: 0.006151, Accuracy: 99.46%\n",
      "Batch 189, Loss: 0.014049, Accuracy: 99.46%\n",
      "Batch 190, Loss: 0.005127, Accuracy: 99.47%\n",
      "Batch 191, Loss: 0.084759, Accuracy: 99.45%\n",
      "Batch 192, Loss: 0.021186, Accuracy: 99.45%\n",
      "Batch 193, Loss: 0.003367, Accuracy: 99.45%\n",
      "Batch 194, Loss: 0.003817, Accuracy: 99.45%\n",
      "Batch 195, Loss: 0.003867, Accuracy: 99.46%\n",
      "Batch 196, Loss: 0.067288, Accuracy: 99.45%\n",
      "Batch 197, Loss: 0.003876, Accuracy: 99.45%\n",
      "Batch 198, Loss: 0.020057, Accuracy: 99.45%\n",
      "Batch 199, Loss: 0.005110, Accuracy: 99.45%\n",
      "Batch 200, Loss: 0.013771, Accuracy: 99.45%\n",
      "Batch 201, Loss: 0.004404, Accuracy: 99.45%\n",
      "Batch 202, Loss: 0.017838, Accuracy: 99.44%\n",
      "Batch 203, Loss: 0.010603, Accuracy: 99.45%\n",
      "Batch 204, Loss: 0.022005, Accuracy: 99.44%\n",
      "Batch 205, Loss: 0.010210, Accuracy: 99.44%\n",
      "Batch 206, Loss: 0.001706, Accuracy: 99.45%\n",
      "Batch 207, Loss: 0.006615, Accuracy: 99.45%\n",
      "Batch 208, Loss: 0.004393, Accuracy: 99.45%\n",
      "Batch 209, Loss: 0.012937, Accuracy: 99.45%\n",
      "Batch 210, Loss: 0.113222, Accuracy: 99.43%\n",
      "Batch 211, Loss: 0.006227, Accuracy: 99.44%\n",
      "Batch 212, Loss: 0.001703, Accuracy: 99.44%\n",
      "Batch 213, Loss: 0.001628, Accuracy: 99.44%\n",
      "Training - Epoch 30, Loss: 0.017402, Accuracy: 99.44%\n",
      "Validation Batch 1, Loss: 0.020500, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.055546, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.003385, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.003181, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.001840, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.001732, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.000974, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.004759, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.032756, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.010097, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.023728, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.007163, Accuracy: 99.48%\n",
      "Validation Batch 13, Loss: 0.049691, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.011442, Accuracy: 99.44%\n",
      "Validation Batch 15, Loss: 0.046951, Accuracy: 99.27%\n",
      "Validation Batch 16, Loss: 0.033502, Accuracy: 99.22%\n",
      "Validation Batch 17, Loss: 0.007233, Accuracy: 99.26%\n",
      "Validation Batch 18, Loss: 0.003581, Accuracy: 99.31%\n",
      "Validation Batch 19, Loss: 0.005041, Accuracy: 99.34%\n",
      "Validation Batch 20, Loss: 0.031050, Accuracy: 99.22%\n",
      "Validation Batch 21, Loss: 0.001252, Accuracy: 99.26%\n",
      "Validation Batch 22, Loss: 0.008679, Accuracy: 99.29%\n",
      "Validation Batch 23, Loss: 0.004499, Accuracy: 99.32%\n",
      "Validation Batch 24, Loss: 0.121813, Accuracy: 99.28%\n",
      "Validation Batch 25, Loss: 0.001496, Accuracy: 99.31%\n",
      "Validation Batch 26, Loss: 0.006253, Accuracy: 99.34%\n",
      "Validation Batch 27, Loss: 0.001498, Accuracy: 99.35%\n",
      "Validation - Epoch 30, Loss: 0.018505, Accuracy: 99.35%\n",
      "Patience—3\n",
      "Epoch 31\n",
      "Batch 1, Loss: 0.001785, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.014866, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.007276, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.011019, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.034438, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.079655, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.022645, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.004299, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.007775, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.002946, Accuracy: 99.38%\n",
      "Batch 11, Loss: 0.003708, Accuracy: 99.43%\n",
      "Batch 12, Loss: 0.001804, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.003672, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.001687, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.003551, Accuracy: 99.58%\n",
      "Batch 16, Loss: 0.002814, Accuracy: 99.61%\n",
      "Batch 17, Loss: 0.006955, Accuracy: 99.63%\n",
      "Batch 18, Loss: 0.003594, Accuracy: 99.65%\n",
      "Batch 19, Loss: 0.002596, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.016142, Accuracy: 99.61%\n",
      "Batch 21, Loss: 0.001806, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.001474, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.025935, Accuracy: 99.59%\n",
      "Batch 24, Loss: 0.002309, Accuracy: 99.61%\n",
      "Batch 25, Loss: 0.003170, Accuracy: 99.62%\n",
      "Batch 26, Loss: 0.011699, Accuracy: 99.64%\n",
      "Batch 27, Loss: 0.002340, Accuracy: 99.65%\n",
      "Batch 28, Loss: 0.008023, Accuracy: 99.67%\n",
      "Batch 29, Loss: 0.001573, Accuracy: 99.68%\n",
      "Batch 30, Loss: 0.007763, Accuracy: 99.69%\n",
      "Batch 31, Loss: 0.001440, Accuracy: 99.70%\n",
      "Batch 32, Loss: 0.001974, Accuracy: 99.71%\n",
      "Batch 33, Loss: 0.001839, Accuracy: 99.72%\n",
      "Batch 34, Loss: 0.006749, Accuracy: 99.72%\n",
      "Batch 35, Loss: 0.001478, Accuracy: 99.73%\n",
      "Batch 36, Loss: 0.004628, Accuracy: 99.74%\n",
      "Batch 37, Loss: 0.002220, Accuracy: 99.75%\n",
      "Batch 38, Loss: 0.001178, Accuracy: 99.75%\n",
      "Batch 39, Loss: 0.001321, Accuracy: 99.76%\n",
      "Batch 40, Loss: 0.001377, Accuracy: 99.77%\n",
      "Batch 41, Loss: 0.001274, Accuracy: 99.77%\n",
      "Batch 42, Loss: 0.001101, Accuracy: 99.78%\n",
      "Batch 43, Loss: 0.001277, Accuracy: 99.78%\n",
      "Batch 44, Loss: 0.007467, Accuracy: 99.79%\n",
      "Batch 45, Loss: 0.001156, Accuracy: 99.79%\n",
      "Batch 46, Loss: 0.001391, Accuracy: 99.80%\n",
      "Batch 47, Loss: 0.001271, Accuracy: 99.80%\n",
      "Batch 48, Loss: 0.001441, Accuracy: 99.80%\n",
      "Batch 49, Loss: 0.001128, Accuracy: 99.81%\n",
      "Batch 50, Loss: 0.001642, Accuracy: 99.81%\n",
      "Batch 51, Loss: 0.001082, Accuracy: 99.82%\n",
      "Batch 52, Loss: 0.000826, Accuracy: 99.82%\n",
      "Batch 53, Loss: 0.001354, Accuracy: 99.82%\n",
      "Batch 54, Loss: 0.001386, Accuracy: 99.83%\n",
      "Batch 55, Loss: 0.004197, Accuracy: 99.83%\n",
      "Batch 56, Loss: 0.001024, Accuracy: 99.83%\n",
      "Batch 57, Loss: 0.002702, Accuracy: 99.84%\n",
      "Batch 58, Loss: 0.001597, Accuracy: 99.84%\n",
      "Batch 59, Loss: 0.003273, Accuracy: 99.84%\n",
      "Batch 60, Loss: 0.001001, Accuracy: 99.84%\n",
      "Batch 61, Loss: 0.001263, Accuracy: 99.85%\n",
      "Batch 62, Loss: 0.020518, Accuracy: 99.82%\n",
      "Batch 63, Loss: 0.002845, Accuracy: 99.83%\n",
      "Batch 64, Loss: 0.001889, Accuracy: 99.83%\n",
      "Batch 65, Loss: 0.002746, Accuracy: 99.83%\n",
      "Batch 66, Loss: 0.005389, Accuracy: 99.83%\n",
      "Batch 67, Loss: 0.002730, Accuracy: 99.84%\n",
      "Batch 68, Loss: 0.000834, Accuracy: 99.84%\n",
      "Batch 69, Loss: 0.116542, Accuracy: 99.82%\n",
      "Batch 70, Loss: 0.037725, Accuracy: 99.78%\n",
      "Batch 71, Loss: 0.016786, Accuracy: 99.76%\n",
      "Batch 72, Loss: 0.003230, Accuracy: 99.76%\n",
      "Batch 73, Loss: 0.002033, Accuracy: 99.76%\n",
      "Batch 74, Loss: 0.001928, Accuracy: 99.77%\n",
      "Batch 75, Loss: 0.001192, Accuracy: 99.77%\n",
      "Batch 76, Loss: 0.064843, Accuracy: 99.75%\n",
      "Batch 77, Loss: 0.069702, Accuracy: 99.70%\n",
      "Batch 78, Loss: 0.056923, Accuracy: 99.68%\n",
      "Batch 79, Loss: 0.002263, Accuracy: 99.68%\n",
      "Batch 80, Loss: 0.002100, Accuracy: 99.69%\n",
      "Batch 81, Loss: 0.075849, Accuracy: 99.67%\n",
      "Batch 82, Loss: 0.001577, Accuracy: 99.68%\n",
      "Batch 83, Loss: 0.023233, Accuracy: 99.66%\n",
      "Batch 84, Loss: 0.001094, Accuracy: 99.67%\n",
      "Batch 85, Loss: 0.128451, Accuracy: 99.63%\n",
      "Batch 86, Loss: 0.118371, Accuracy: 99.62%\n",
      "Batch 87, Loss: 0.001863, Accuracy: 99.62%\n",
      "Batch 88, Loss: 0.026206, Accuracy: 99.61%\n",
      "Batch 89, Loss: 0.039553, Accuracy: 99.60%\n",
      "Batch 90, Loss: 0.004531, Accuracy: 99.60%\n",
      "Batch 91, Loss: 0.041722, Accuracy: 99.59%\n",
      "Batch 92, Loss: 0.001637, Accuracy: 99.59%\n",
      "Batch 93, Loss: 0.027013, Accuracy: 99.58%\n",
      "Batch 94, Loss: 0.014845, Accuracy: 99.58%\n",
      "Batch 95, Loss: 0.032924, Accuracy: 99.57%\n",
      "Batch 96, Loss: 0.040592, Accuracy: 99.54%\n",
      "Batch 97, Loss: 0.004872, Accuracy: 99.55%\n",
      "Batch 98, Loss: 0.105428, Accuracy: 99.52%\n",
      "Batch 99, Loss: 0.006089, Accuracy: 99.53%\n",
      "Batch 100, Loss: 0.065926, Accuracy: 99.52%\n",
      "Batch 101, Loss: 0.018966, Accuracy: 99.50%\n",
      "Batch 102, Loss: 0.099832, Accuracy: 99.48%\n",
      "Batch 103, Loss: 0.022365, Accuracy: 99.47%\n",
      "Batch 104, Loss: 0.015893, Accuracy: 99.46%\n",
      "Batch 105, Loss: 0.001728, Accuracy: 99.46%\n",
      "Batch 106, Loss: 0.020812, Accuracy: 99.45%\n",
      "Batch 107, Loss: 0.015906, Accuracy: 99.45%\n",
      "Batch 108, Loss: 0.008908, Accuracy: 99.45%\n",
      "Batch 109, Loss: 0.005715, Accuracy: 99.46%\n",
      "Batch 110, Loss: 0.113530, Accuracy: 99.45%\n",
      "Batch 111, Loss: 0.051769, Accuracy: 99.44%\n",
      "Batch 112, Loss: 0.104258, Accuracy: 99.40%\n",
      "Batch 113, Loss: 0.002301, Accuracy: 99.41%\n",
      "Batch 114, Loss: 0.002445, Accuracy: 99.41%\n",
      "Batch 115, Loss: 0.005566, Accuracy: 99.42%\n",
      "Batch 116, Loss: 0.007903, Accuracy: 99.42%\n",
      "Batch 117, Loss: 0.060684, Accuracy: 99.39%\n",
      "Batch 118, Loss: 0.013616, Accuracy: 99.38%\n",
      "Batch 119, Loss: 0.007732, Accuracy: 99.38%\n",
      "Batch 120, Loss: 0.047928, Accuracy: 99.36%\n",
      "Batch 121, Loss: 0.008166, Accuracy: 99.37%\n",
      "Batch 122, Loss: 0.094887, Accuracy: 99.35%\n",
      "Batch 123, Loss: 0.085276, Accuracy: 99.33%\n",
      "Batch 124, Loss: 0.004960, Accuracy: 99.33%\n",
      "Batch 125, Loss: 0.002684, Accuracy: 99.34%\n",
      "Batch 126, Loss: 0.007714, Accuracy: 99.34%\n",
      "Batch 127, Loss: 0.112460, Accuracy: 99.32%\n",
      "Batch 128, Loss: 0.016759, Accuracy: 99.33%\n",
      "Batch 129, Loss: 0.072261, Accuracy: 99.32%\n",
      "Batch 130, Loss: 0.011311, Accuracy: 99.33%\n",
      "Batch 131, Loss: 0.078061, Accuracy: 99.31%\n",
      "Batch 132, Loss: 0.004629, Accuracy: 99.31%\n",
      "Batch 133, Loss: 0.041804, Accuracy: 99.30%\n",
      "Batch 134, Loss: 0.014936, Accuracy: 99.30%\n",
      "Batch 135, Loss: 0.094510, Accuracy: 99.29%\n",
      "Batch 136, Loss: 0.001701, Accuracy: 99.30%\n",
      "Batch 137, Loss: 0.014909, Accuracy: 99.30%\n",
      "Batch 138, Loss: 0.022441, Accuracy: 99.30%\n",
      "Batch 139, Loss: 0.057959, Accuracy: 99.28%\n",
      "Batch 140, Loss: 0.002295, Accuracy: 99.29%\n",
      "Batch 141, Loss: 0.002630, Accuracy: 99.29%\n",
      "Batch 142, Loss: 0.004208, Accuracy: 99.30%\n",
      "Batch 143, Loss: 0.008277, Accuracy: 99.30%\n",
      "Batch 144, Loss: 0.021768, Accuracy: 99.29%\n",
      "Batch 145, Loss: 0.001996, Accuracy: 99.30%\n",
      "Batch 146, Loss: 0.003351, Accuracy: 99.30%\n",
      "Batch 147, Loss: 0.007068, Accuracy: 99.31%\n",
      "Batch 148, Loss: 0.032586, Accuracy: 99.30%\n",
      "Batch 149, Loss: 0.004508, Accuracy: 99.31%\n",
      "Batch 150, Loss: 0.022408, Accuracy: 99.30%\n",
      "Batch 151, Loss: 0.057961, Accuracy: 99.30%\n",
      "Batch 152, Loss: 0.069927, Accuracy: 99.29%\n",
      "Batch 153, Loss: 0.014851, Accuracy: 99.30%\n",
      "Batch 154, Loss: 0.002705, Accuracy: 99.30%\n",
      "Batch 155, Loss: 0.003292, Accuracy: 99.30%\n",
      "Batch 156, Loss: 0.004422, Accuracy: 99.31%\n",
      "Batch 157, Loss: 0.083921, Accuracy: 99.29%\n",
      "Batch 158, Loss: 0.004777, Accuracy: 99.30%\n",
      "Batch 159, Loss: 0.028820, Accuracy: 99.29%\n",
      "Batch 160, Loss: 0.014049, Accuracy: 99.30%\n",
      "Batch 161, Loss: 0.020584, Accuracy: 99.29%\n",
      "Batch 162, Loss: 0.004887, Accuracy: 99.30%\n",
      "Batch 163, Loss: 0.024362, Accuracy: 99.29%\n",
      "Batch 164, Loss: 0.013842, Accuracy: 99.29%\n",
      "Batch 165, Loss: 0.003947, Accuracy: 99.30%\n",
      "Batch 166, Loss: 0.003963, Accuracy: 99.30%\n",
      "Batch 167, Loss: 0.085793, Accuracy: 99.30%\n",
      "Batch 168, Loss: 0.002980, Accuracy: 99.30%\n",
      "Batch 169, Loss: 0.005109, Accuracy: 99.31%\n",
      "Batch 170, Loss: 0.026775, Accuracy: 99.30%\n",
      "Batch 171, Loss: 0.001813, Accuracy: 99.31%\n",
      "Batch 172, Loss: 0.004747, Accuracy: 99.31%\n",
      "Batch 173, Loss: 0.014539, Accuracy: 99.31%\n",
      "Batch 174, Loss: 0.012298, Accuracy: 99.32%\n",
      "Batch 175, Loss: 0.004868, Accuracy: 99.32%\n",
      "Batch 176, Loss: 0.002228, Accuracy: 99.33%\n",
      "Batch 177, Loss: 0.005616, Accuracy: 99.33%\n",
      "Batch 178, Loss: 0.010820, Accuracy: 99.33%\n",
      "Batch 179, Loss: 0.015439, Accuracy: 99.33%\n",
      "Batch 180, Loss: 0.049587, Accuracy: 99.32%\n",
      "Batch 181, Loss: 0.011487, Accuracy: 99.33%\n",
      "Batch 182, Loss: 0.046207, Accuracy: 99.32%\n",
      "Batch 183, Loss: 0.003076, Accuracy: 99.33%\n",
      "Batch 184, Loss: 0.001380, Accuracy: 99.33%\n",
      "Batch 185, Loss: 0.002600, Accuracy: 99.33%\n",
      "Batch 186, Loss: 0.003304, Accuracy: 99.34%\n",
      "Batch 187, Loss: 0.060995, Accuracy: 99.33%\n",
      "Batch 188, Loss: 0.004674, Accuracy: 99.34%\n",
      "Batch 189, Loss: 0.082723, Accuracy: 99.32%\n",
      "Batch 190, Loss: 0.053229, Accuracy: 99.32%\n",
      "Batch 191, Loss: 0.005041, Accuracy: 99.32%\n",
      "Batch 192, Loss: 0.004476, Accuracy: 99.32%\n",
      "Batch 193, Loss: 0.001521, Accuracy: 99.33%\n",
      "Batch 194, Loss: 0.018036, Accuracy: 99.32%\n",
      "Batch 195, Loss: 0.001910, Accuracy: 99.33%\n",
      "Batch 196, Loss: 0.008825, Accuracy: 99.33%\n",
      "Batch 197, Loss: 0.001372, Accuracy: 99.33%\n",
      "Batch 198, Loss: 0.004913, Accuracy: 99.34%\n",
      "Batch 199, Loss: 0.001738, Accuracy: 99.34%\n",
      "Batch 200, Loss: 0.002720, Accuracy: 99.34%\n",
      "Batch 201, Loss: 0.005000, Accuracy: 99.35%\n",
      "Batch 202, Loss: 0.005194, Accuracy: 99.35%\n",
      "Batch 203, Loss: 0.002508, Accuracy: 99.35%\n",
      "Batch 204, Loss: 0.002270, Accuracy: 99.36%\n",
      "Batch 205, Loss: 0.016669, Accuracy: 99.35%\n",
      "Batch 206, Loss: 0.001905, Accuracy: 99.36%\n",
      "Batch 207, Loss: 0.002199, Accuracy: 99.36%\n",
      "Batch 208, Loss: 0.004177, Accuracy: 99.36%\n",
      "Batch 209, Loss: 0.001801, Accuracy: 99.36%\n",
      "Batch 210, Loss: 0.009593, Accuracy: 99.37%\n",
      "Batch 211, Loss: 0.029193, Accuracy: 99.36%\n",
      "Batch 212, Loss: 0.001339, Accuracy: 99.37%\n",
      "Batch 213, Loss: 0.003320, Accuracy: 99.37%\n",
      "Training - Epoch 31, Loss: 0.018906, Accuracy: 99.37%\n",
      "Validation Batch 1, Loss: 0.002280, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.003795, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.006404, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.001582, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.058053, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.001801, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.005188, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.004531, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.016824, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.003329, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.006188, Accuracy: 99.57%\n",
      "Validation Batch 12, Loss: 0.041991, Accuracy: 99.48%\n",
      "Validation Batch 13, Loss: 0.017461, Accuracy: 99.52%\n",
      "Validation Batch 14, Loss: 0.009270, Accuracy: 99.55%\n",
      "Validation Batch 15, Loss: 0.006300, Accuracy: 99.58%\n",
      "Validation Batch 16, Loss: 0.097937, Accuracy: 99.41%\n",
      "Validation Batch 17, Loss: 0.003094, Accuracy: 99.45%\n",
      "Validation Batch 18, Loss: 0.003747, Accuracy: 99.48%\n",
      "Validation Batch 19, Loss: 0.008204, Accuracy: 99.51%\n",
      "Validation Batch 20, Loss: 0.002763, Accuracy: 99.53%\n",
      "Validation Batch 21, Loss: 0.002112, Accuracy: 99.55%\n",
      "Validation Batch 22, Loss: 0.003708, Accuracy: 99.57%\n",
      "Validation Batch 23, Loss: 0.072378, Accuracy: 99.46%\n",
      "Validation Batch 24, Loss: 0.139630, Accuracy: 99.41%\n",
      "Validation Batch 25, Loss: 0.001904, Accuracy: 99.44%\n",
      "Validation Batch 26, Loss: 0.001718, Accuracy: 99.46%\n",
      "Validation Batch 27, Loss: 0.001576, Accuracy: 99.47%\n",
      "Validation - Epoch 31, Loss: 0.019399, Accuracy: 99.47%\n",
      "Patience—4\n",
      "Epoch 32\n",
      "Batch 1, Loss: 0.003365, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.001616, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.005245, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.002134, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.006417, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.035264, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.001431, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.001145, Accuracy: 99.80%\n",
      "Batch 9, Loss: 0.001205, Accuracy: 99.83%\n",
      "Batch 10, Loss: 0.002455, Accuracy: 99.84%\n",
      "Batch 11, Loss: 0.002391, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.001720, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.003609, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.001223, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.001312, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.002290, Accuracy: 99.90%\n",
      "Batch 17, Loss: 0.001639, Accuracy: 99.91%\n",
      "Batch 18, Loss: 0.001369, Accuracy: 99.91%\n",
      "Batch 19, Loss: 0.001394, Accuracy: 99.92%\n",
      "Batch 20, Loss: 0.001758, Accuracy: 99.92%\n",
      "Batch 21, Loss: 0.001378, Accuracy: 99.93%\n",
      "Batch 22, Loss: 0.004355, Accuracy: 99.93%\n",
      "Batch 23, Loss: 0.010558, Accuracy: 99.93%\n",
      "Batch 24, Loss: 0.003476, Accuracy: 99.93%\n",
      "Batch 25, Loss: 0.006428, Accuracy: 99.94%\n",
      "Batch 26, Loss: 0.001958, Accuracy: 99.94%\n",
      "Batch 27, Loss: 0.007000, Accuracy: 99.94%\n",
      "Batch 28, Loss: 0.004111, Accuracy: 99.94%\n",
      "Batch 29, Loss: 0.001686, Accuracy: 99.95%\n",
      "Batch 30, Loss: 0.029394, Accuracy: 99.90%\n",
      "Batch 31, Loss: 0.001158, Accuracy: 99.90%\n",
      "Batch 32, Loss: 0.004300, Accuracy: 99.90%\n",
      "Batch 33, Loss: 0.001236, Accuracy: 99.91%\n",
      "Batch 34, Loss: 0.002749, Accuracy: 99.91%\n",
      "Batch 35, Loss: 0.001726, Accuracy: 99.91%\n",
      "Batch 36, Loss: 0.002890, Accuracy: 99.91%\n",
      "Batch 37, Loss: 0.002960, Accuracy: 99.92%\n",
      "Batch 38, Loss: 0.086973, Accuracy: 99.88%\n",
      "Batch 39, Loss: 0.003052, Accuracy: 99.88%\n",
      "Batch 40, Loss: 0.002854, Accuracy: 99.88%\n",
      "Batch 41, Loss: 0.002200, Accuracy: 99.89%\n",
      "Batch 42, Loss: 0.003405, Accuracy: 99.89%\n",
      "Batch 43, Loss: 0.011766, Accuracy: 99.89%\n",
      "Batch 44, Loss: 0.001502, Accuracy: 99.89%\n",
      "Batch 45, Loss: 0.001070, Accuracy: 99.90%\n",
      "Batch 46, Loss: 0.001651, Accuracy: 99.90%\n",
      "Batch 47, Loss: 0.001205, Accuracy: 99.90%\n",
      "Batch 48, Loss: 0.002043, Accuracy: 99.90%\n",
      "Batch 49, Loss: 0.001528, Accuracy: 99.90%\n",
      "Batch 50, Loss: 0.004477, Accuracy: 99.91%\n",
      "Batch 51, Loss: 0.001261, Accuracy: 99.91%\n",
      "Batch 52, Loss: 0.001620, Accuracy: 99.91%\n",
      "Batch 53, Loss: 0.001184, Accuracy: 99.91%\n",
      "Batch 54, Loss: 0.001439, Accuracy: 99.91%\n",
      "Batch 55, Loss: 0.000986, Accuracy: 99.91%\n",
      "Batch 56, Loss: 0.003024, Accuracy: 99.92%\n",
      "Batch 57, Loss: 0.088554, Accuracy: 99.89%\n",
      "Batch 58, Loss: 0.002047, Accuracy: 99.89%\n",
      "Batch 59, Loss: 0.001962, Accuracy: 99.89%\n",
      "Batch 60, Loss: 0.024719, Accuracy: 99.87%\n",
      "Batch 61, Loss: 0.001872, Accuracy: 99.87%\n",
      "Batch 62, Loss: 0.002030, Accuracy: 99.87%\n",
      "Batch 63, Loss: 0.000994, Accuracy: 99.88%\n",
      "Batch 64, Loss: 0.001147, Accuracy: 99.88%\n",
      "Batch 65, Loss: 0.001695, Accuracy: 99.88%\n",
      "Batch 66, Loss: 0.003111, Accuracy: 99.88%\n",
      "Batch 67, Loss: 0.017341, Accuracy: 99.86%\n",
      "Batch 68, Loss: 0.001027, Accuracy: 99.86%\n",
      "Batch 69, Loss: 0.001432, Accuracy: 99.86%\n",
      "Batch 70, Loss: 0.008497, Accuracy: 99.87%\n",
      "Batch 71, Loss: 0.001041, Accuracy: 99.87%\n",
      "Batch 72, Loss: 0.002148, Accuracy: 99.87%\n",
      "Batch 73, Loss: 0.000982, Accuracy: 99.87%\n",
      "Batch 74, Loss: 0.002457, Accuracy: 99.87%\n",
      "Batch 75, Loss: 0.002129, Accuracy: 99.88%\n",
      "Batch 76, Loss: 0.001208, Accuracy: 99.88%\n",
      "Batch 77, Loss: 0.012092, Accuracy: 99.88%\n",
      "Batch 78, Loss: 0.000971, Accuracy: 99.88%\n",
      "Batch 79, Loss: 0.001259, Accuracy: 99.88%\n",
      "Batch 80, Loss: 0.002556, Accuracy: 99.88%\n",
      "Batch 81, Loss: 0.007555, Accuracy: 99.88%\n",
      "Batch 82, Loss: 0.001368, Accuracy: 99.89%\n",
      "Batch 83, Loss: 0.001181, Accuracy: 99.89%\n",
      "Batch 84, Loss: 0.002022, Accuracy: 99.89%\n",
      "Batch 85, Loss: 0.000913, Accuracy: 99.89%\n",
      "Batch 86, Loss: 0.001036, Accuracy: 99.89%\n",
      "Batch 87, Loss: 0.002708, Accuracy: 99.89%\n",
      "Batch 88, Loss: 0.001001, Accuracy: 99.89%\n",
      "Batch 89, Loss: 0.002502, Accuracy: 99.89%\n",
      "Batch 90, Loss: 0.001785, Accuracy: 99.90%\n",
      "Batch 91, Loss: 0.001951, Accuracy: 99.90%\n",
      "Batch 92, Loss: 0.014163, Accuracy: 99.88%\n",
      "Batch 93, Loss: 0.002598, Accuracy: 99.88%\n",
      "Batch 94, Loss: 0.001384, Accuracy: 99.88%\n",
      "Batch 95, Loss: 0.000895, Accuracy: 99.88%\n",
      "Batch 96, Loss: 0.001156, Accuracy: 99.89%\n",
      "Batch 97, Loss: 0.002226, Accuracy: 99.89%\n",
      "Batch 98, Loss: 0.001330, Accuracy: 99.89%\n",
      "Batch 99, Loss: 0.000939, Accuracy: 99.89%\n",
      "Batch 100, Loss: 0.002819, Accuracy: 99.89%\n",
      "Batch 101, Loss: 0.000787, Accuracy: 99.89%\n",
      "Batch 102, Loss: 0.001495, Accuracy: 99.89%\n",
      "Batch 103, Loss: 0.000970, Accuracy: 99.89%\n",
      "Batch 104, Loss: 0.001255, Accuracy: 99.89%\n",
      "Batch 105, Loss: 0.000863, Accuracy: 99.90%\n",
      "Batch 106, Loss: 0.001029, Accuracy: 99.90%\n",
      "Batch 107, Loss: 0.005019, Accuracy: 99.90%\n",
      "Batch 108, Loss: 0.037600, Accuracy: 99.88%\n",
      "Batch 109, Loss: 0.000957, Accuracy: 99.89%\n",
      "Batch 110, Loss: 0.001025, Accuracy: 99.89%\n",
      "Batch 111, Loss: 0.001174, Accuracy: 99.89%\n",
      "Batch 112, Loss: 0.001525, Accuracy: 99.89%\n",
      "Batch 113, Loss: 0.001198, Accuracy: 99.89%\n",
      "Batch 114, Loss: 0.000922, Accuracy: 99.89%\n",
      "Batch 115, Loss: 0.006781, Accuracy: 99.89%\n",
      "Batch 116, Loss: 0.002241, Accuracy: 99.89%\n",
      "Batch 117, Loss: 0.001092, Accuracy: 99.89%\n",
      "Batch 118, Loss: 0.012258, Accuracy: 99.89%\n",
      "Batch 119, Loss: 0.001425, Accuracy: 99.89%\n",
      "Batch 120, Loss: 0.001030, Accuracy: 99.90%\n",
      "Batch 121, Loss: 0.002862, Accuracy: 99.90%\n",
      "Batch 122, Loss: 0.001278, Accuracy: 99.90%\n",
      "Batch 123, Loss: 0.001762, Accuracy: 99.90%\n",
      "Batch 124, Loss: 0.001961, Accuracy: 99.90%\n",
      "Batch 125, Loss: 0.001344, Accuracy: 99.90%\n",
      "Batch 126, Loss: 0.001098, Accuracy: 99.90%\n",
      "Batch 127, Loss: 0.001136, Accuracy: 99.90%\n",
      "Batch 128, Loss: 0.001400, Accuracy: 99.90%\n",
      "Batch 129, Loss: 0.003436, Accuracy: 99.90%\n",
      "Batch 130, Loss: 0.002276, Accuracy: 99.90%\n",
      "Batch 131, Loss: 0.026622, Accuracy: 99.89%\n",
      "Batch 132, Loss: 0.003123, Accuracy: 99.89%\n",
      "Batch 133, Loss: 0.001282, Accuracy: 99.89%\n",
      "Batch 134, Loss: 0.014838, Accuracy: 99.88%\n",
      "Batch 135, Loss: 0.009778, Accuracy: 99.88%\n",
      "Batch 136, Loss: 0.002485, Accuracy: 99.89%\n",
      "Batch 137, Loss: 0.001375, Accuracy: 99.89%\n",
      "Batch 138, Loss: 0.001268, Accuracy: 99.89%\n",
      "Batch 139, Loss: 0.004194, Accuracy: 99.89%\n",
      "Batch 140, Loss: 0.002348, Accuracy: 99.89%\n",
      "Batch 141, Loss: 0.006704, Accuracy: 99.89%\n",
      "Batch 142, Loss: 0.007093, Accuracy: 99.89%\n",
      "Batch 143, Loss: 0.001712, Accuracy: 99.89%\n",
      "Batch 144, Loss: 0.001024, Accuracy: 99.89%\n",
      "Batch 145, Loss: 0.001611, Accuracy: 99.89%\n",
      "Batch 146, Loss: 0.003271, Accuracy: 99.89%\n",
      "Batch 147, Loss: 0.001059, Accuracy: 99.89%\n",
      "Batch 148, Loss: 0.004701, Accuracy: 99.89%\n",
      "Batch 149, Loss: 0.002571, Accuracy: 99.90%\n",
      "Batch 150, Loss: 0.046479, Accuracy: 99.89%\n",
      "Batch 151, Loss: 0.015861, Accuracy: 99.89%\n",
      "Batch 152, Loss: 0.001582, Accuracy: 99.89%\n",
      "Batch 153, Loss: 0.000954, Accuracy: 99.89%\n",
      "Batch 154, Loss: 0.003191, Accuracy: 99.89%\n",
      "Batch 155, Loss: 0.002553, Accuracy: 99.89%\n",
      "Batch 156, Loss: 0.001717, Accuracy: 99.89%\n",
      "Batch 157, Loss: 0.002502, Accuracy: 99.89%\n",
      "Batch 158, Loss: 0.000996, Accuracy: 99.89%\n",
      "Batch 159, Loss: 0.034383, Accuracy: 99.88%\n",
      "Batch 160, Loss: 0.000919, Accuracy: 99.88%\n",
      "Batch 161, Loss: 0.001335, Accuracy: 99.88%\n",
      "Batch 162, Loss: 0.003178, Accuracy: 99.88%\n",
      "Batch 163, Loss: 0.001262, Accuracy: 99.88%\n",
      "Batch 164, Loss: 0.001995, Accuracy: 99.89%\n",
      "Batch 165, Loss: 0.010903, Accuracy: 99.89%\n",
      "Batch 166, Loss: 0.004720, Accuracy: 99.89%\n",
      "Batch 167, Loss: 0.003618, Accuracy: 99.89%\n",
      "Batch 168, Loss: 0.062037, Accuracy: 99.87%\n",
      "Batch 169, Loss: 0.000960, Accuracy: 99.87%\n",
      "Batch 170, Loss: 0.007216, Accuracy: 99.87%\n",
      "Batch 171, Loss: 0.000819, Accuracy: 99.87%\n",
      "Batch 172, Loss: 0.004508, Accuracy: 99.87%\n",
      "Batch 173, Loss: 0.096745, Accuracy: 99.86%\n",
      "Batch 174, Loss: 0.001279, Accuracy: 99.86%\n",
      "Batch 175, Loss: 0.002689, Accuracy: 99.86%\n",
      "Batch 176, Loss: 0.000998, Accuracy: 99.86%\n",
      "Batch 177, Loss: 0.053726, Accuracy: 99.85%\n",
      "Batch 178, Loss: 0.000977, Accuracy: 99.85%\n",
      "Batch 179, Loss: 0.007828, Accuracy: 99.85%\n",
      "Batch 180, Loss: 0.001333, Accuracy: 99.85%\n",
      "Batch 181, Loss: 0.004357, Accuracy: 99.85%\n",
      "Batch 182, Loss: 0.006883, Accuracy: 99.85%\n",
      "Batch 183, Loss: 0.002946, Accuracy: 99.85%\n",
      "Batch 184, Loss: 0.020878, Accuracy: 99.85%\n",
      "Batch 185, Loss: 0.010040, Accuracy: 99.85%\n",
      "Batch 186, Loss: 0.046560, Accuracy: 99.84%\n",
      "Batch 187, Loss: 0.003589, Accuracy: 99.84%\n",
      "Batch 188, Loss: 0.037277, Accuracy: 99.83%\n",
      "Batch 189, Loss: 0.066388, Accuracy: 99.82%\n",
      "Batch 190, Loss: 0.003140, Accuracy: 99.82%\n",
      "Batch 191, Loss: 0.004714, Accuracy: 99.82%\n",
      "Batch 192, Loss: 0.004482, Accuracy: 99.82%\n",
      "Batch 193, Loss: 0.048980, Accuracy: 99.81%\n",
      "Batch 194, Loss: 0.007314, Accuracy: 99.81%\n",
      "Batch 195, Loss: 0.004905, Accuracy: 99.81%\n",
      "Batch 196, Loss: 0.003068, Accuracy: 99.81%\n",
      "Batch 197, Loss: 0.002152, Accuracy: 99.81%\n",
      "Batch 198, Loss: 0.002656, Accuracy: 99.81%\n",
      "Batch 199, Loss: 0.004472, Accuracy: 99.81%\n",
      "Batch 200, Loss: 0.007391, Accuracy: 99.81%\n",
      "Batch 201, Loss: 0.047465, Accuracy: 99.81%\n",
      "Batch 202, Loss: 0.003067, Accuracy: 99.81%\n",
      "Batch 203, Loss: 0.010742, Accuracy: 99.81%\n",
      "Batch 204, Loss: 0.003431, Accuracy: 99.81%\n",
      "Batch 205, Loss: 0.002954, Accuracy: 99.81%\n",
      "Batch 206, Loss: 0.004243, Accuracy: 99.81%\n",
      "Batch 207, Loss: 0.002802, Accuracy: 99.81%\n",
      "Batch 208, Loss: 0.003271, Accuracy: 99.81%\n",
      "Batch 209, Loss: 0.003688, Accuracy: 99.81%\n",
      "Batch 210, Loss: 0.002177, Accuracy: 99.81%\n",
      "Batch 211, Loss: 0.110773, Accuracy: 99.80%\n",
      "Batch 212, Loss: 0.007630, Accuracy: 99.80%\n",
      "Batch 213, Loss: 0.001256, Accuracy: 99.80%\n",
      "Training - Epoch 32, Loss: 0.007538, Accuracy: 99.80%\n",
      "Validation Batch 1, Loss: 0.002025, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.010854, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.116567, Accuracy: 98.96%\n",
      "Validation Batch 4, Loss: 0.001562, Accuracy: 99.22%\n",
      "Validation Batch 5, Loss: 0.004310, Accuracy: 99.38%\n",
      "Validation Batch 6, Loss: 0.021980, Accuracy: 99.22%\n",
      "Validation Batch 7, Loss: 0.002057, Accuracy: 99.33%\n",
      "Validation Batch 8, Loss: 0.001707, Accuracy: 99.41%\n",
      "Validation Batch 9, Loss: 0.008481, Accuracy: 99.48%\n",
      "Validation Batch 10, Loss: 0.011772, Accuracy: 99.53%\n",
      "Validation Batch 11, Loss: 0.025218, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.031386, Accuracy: 99.35%\n",
      "Validation Batch 13, Loss: 0.016371, Accuracy: 99.40%\n",
      "Validation Batch 14, Loss: 0.024697, Accuracy: 99.33%\n",
      "Validation Batch 15, Loss: 0.013018, Accuracy: 99.38%\n",
      "Validation Batch 16, Loss: 0.001597, Accuracy: 99.41%\n",
      "Validation Batch 17, Loss: 0.009693, Accuracy: 99.45%\n",
      "Validation Batch 18, Loss: 0.002672, Accuracy: 99.48%\n",
      "Validation Batch 19, Loss: 0.011049, Accuracy: 99.51%\n",
      "Validation Batch 20, Loss: 0.005133, Accuracy: 99.53%\n",
      "Validation Batch 21, Loss: 0.010134, Accuracy: 99.55%\n",
      "Validation Batch 22, Loss: 0.002524, Accuracy: 99.57%\n",
      "Validation Batch 23, Loss: 0.009808, Accuracy: 99.59%\n",
      "Validation Batch 24, Loss: 0.123380, Accuracy: 99.54%\n",
      "Validation Batch 25, Loss: 0.002579, Accuracy: 99.56%\n",
      "Validation Batch 26, Loss: 0.009091, Accuracy: 99.58%\n",
      "Validation Batch 27, Loss: 0.008763, Accuracy: 99.59%\n",
      "Validation - Epoch 32, Loss: 0.018090, Accuracy: 99.59%\n",
      "Patience—5\n",
      "Epoch 33\n",
      "Batch 1, Loss: 0.030750, Accuracy: 96.88%\n",
      "Batch 2, Loss: 0.001437, Accuracy: 98.44%\n",
      "Batch 3, Loss: 0.002013, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.008529, Accuracy: 99.22%\n",
      "Batch 5, Loss: 0.001011, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.003008, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.001027, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.001831, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.010180, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.002812, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.001151, Accuracy: 99.72%\n",
      "Batch 12, Loss: 0.026722, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.005674, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.001712, Accuracy: 99.67%\n",
      "Batch 15, Loss: 0.001302, Accuracy: 99.69%\n",
      "Batch 16, Loss: 0.004074, Accuracy: 99.71%\n",
      "Batch 17, Loss: 0.002017, Accuracy: 99.72%\n",
      "Batch 18, Loss: 0.001712, Accuracy: 99.74%\n",
      "Batch 19, Loss: 0.002825, Accuracy: 99.75%\n",
      "Batch 20, Loss: 0.008089, Accuracy: 99.77%\n",
      "Batch 21, Loss: 0.001970, Accuracy: 99.78%\n",
      "Batch 22, Loss: 0.008400, Accuracy: 99.79%\n",
      "Batch 23, Loss: 0.001918, Accuracy: 99.80%\n",
      "Batch 24, Loss: 0.013093, Accuracy: 99.74%\n",
      "Batch 25, Loss: 0.002683, Accuracy: 99.75%\n",
      "Batch 26, Loss: 0.016703, Accuracy: 99.70%\n",
      "Batch 27, Loss: 0.000948, Accuracy: 99.71%\n",
      "Batch 28, Loss: 0.001216, Accuracy: 99.72%\n",
      "Batch 29, Loss: 0.001051, Accuracy: 99.73%\n",
      "Batch 30, Loss: 0.001170, Accuracy: 99.74%\n",
      "Batch 31, Loss: 0.003553, Accuracy: 99.75%\n",
      "Batch 32, Loss: 0.120909, Accuracy: 99.66%\n",
      "Batch 33, Loss: 0.005866, Accuracy: 99.67%\n",
      "Batch 34, Loss: 0.001892, Accuracy: 99.68%\n",
      "Batch 35, Loss: 0.001664, Accuracy: 99.69%\n",
      "Batch 36, Loss: 0.006141, Accuracy: 99.70%\n",
      "Batch 37, Loss: 0.021836, Accuracy: 99.66%\n",
      "Batch 38, Loss: 0.006305, Accuracy: 99.67%\n",
      "Batch 39, Loss: 0.057790, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.001068, Accuracy: 99.65%\n",
      "Batch 41, Loss: 0.109463, Accuracy: 99.62%\n",
      "Batch 42, Loss: 0.002564, Accuracy: 99.63%\n",
      "Batch 43, Loss: 0.001452, Accuracy: 99.64%\n",
      "Batch 44, Loss: 0.003400, Accuracy: 99.64%\n",
      "Batch 45, Loss: 0.005519, Accuracy: 99.65%\n",
      "Batch 46, Loss: 0.001555, Accuracy: 99.66%\n",
      "Batch 47, Loss: 0.083932, Accuracy: 99.60%\n",
      "Batch 48, Loss: 0.017638, Accuracy: 99.58%\n",
      "Batch 49, Loss: 0.006772, Accuracy: 99.59%\n",
      "Batch 50, Loss: 0.008332, Accuracy: 99.59%\n",
      "Batch 51, Loss: 0.012852, Accuracy: 99.60%\n",
      "Batch 52, Loss: 0.094711, Accuracy: 99.55%\n",
      "Batch 53, Loss: 0.002968, Accuracy: 99.56%\n",
      "Batch 54, Loss: 0.054365, Accuracy: 99.54%\n",
      "Batch 55, Loss: 0.011567, Accuracy: 99.55%\n",
      "Batch 56, Loss: 0.002007, Accuracy: 99.55%\n",
      "Batch 57, Loss: 0.006694, Accuracy: 99.56%\n",
      "Batch 58, Loss: 0.103295, Accuracy: 99.46%\n",
      "Batch 59, Loss: 0.047660, Accuracy: 99.44%\n",
      "Batch 60, Loss: 0.002769, Accuracy: 99.45%\n",
      "Batch 61, Loss: 0.003052, Accuracy: 99.46%\n",
      "Batch 62, Loss: 0.023575, Accuracy: 99.45%\n",
      "Batch 63, Loss: 0.016760, Accuracy: 99.43%\n",
      "Batch 64, Loss: 0.007047, Accuracy: 99.44%\n",
      "Batch 65, Loss: 0.032135, Accuracy: 99.45%\n",
      "Batch 66, Loss: 0.070613, Accuracy: 99.38%\n",
      "Batch 67, Loss: 0.011040, Accuracy: 99.39%\n",
      "Batch 68, Loss: 0.005256, Accuracy: 99.40%\n",
      "Batch 69, Loss: 0.004262, Accuracy: 99.41%\n",
      "Batch 70, Loss: 0.057881, Accuracy: 99.40%\n",
      "Batch 71, Loss: 0.032187, Accuracy: 99.38%\n",
      "Batch 72, Loss: 0.006390, Accuracy: 99.39%\n",
      "Batch 73, Loss: 0.002342, Accuracy: 99.40%\n",
      "Batch 74, Loss: 0.097782, Accuracy: 99.37%\n",
      "Batch 75, Loss: 0.002578, Accuracy: 99.38%\n",
      "Batch 76, Loss: 0.073389, Accuracy: 99.36%\n",
      "Batch 77, Loss: 0.041054, Accuracy: 99.33%\n",
      "Batch 78, Loss: 0.001427, Accuracy: 99.34%\n",
      "Batch 79, Loss: 0.074392, Accuracy: 99.31%\n",
      "Batch 80, Loss: 0.295918, Accuracy: 99.22%\n",
      "Batch 81, Loss: 0.012352, Accuracy: 99.23%\n",
      "Batch 82, Loss: 0.009980, Accuracy: 99.24%\n",
      "Batch 83, Loss: 0.025151, Accuracy: 99.23%\n",
      "Batch 84, Loss: 0.067454, Accuracy: 99.22%\n",
      "Batch 85, Loss: 0.009218, Accuracy: 99.23%\n",
      "Batch 86, Loss: 0.003560, Accuracy: 99.24%\n",
      "Batch 87, Loss: 0.003592, Accuracy: 99.25%\n",
      "Batch 88, Loss: 0.025102, Accuracy: 99.25%\n",
      "Batch 89, Loss: 0.216779, Accuracy: 99.21%\n",
      "Batch 90, Loss: 0.003883, Accuracy: 99.22%\n",
      "Batch 91, Loss: 0.118707, Accuracy: 99.18%\n",
      "Batch 92, Loss: 0.053997, Accuracy: 99.17%\n",
      "Batch 93, Loss: 0.003275, Accuracy: 99.18%\n",
      "Batch 94, Loss: 0.035670, Accuracy: 99.17%\n",
      "Batch 95, Loss: 0.042207, Accuracy: 99.14%\n",
      "Batch 96, Loss: 0.017614, Accuracy: 99.15%\n",
      "Batch 97, Loss: 0.040527, Accuracy: 99.16%\n",
      "Batch 98, Loss: 0.025303, Accuracy: 99.17%\n",
      "Batch 99, Loss: 0.037731, Accuracy: 99.16%\n",
      "Batch 100, Loss: 0.005004, Accuracy: 99.17%\n",
      "Batch 101, Loss: 0.050099, Accuracy: 99.16%\n",
      "Batch 102, Loss: 0.159900, Accuracy: 99.14%\n",
      "Batch 103, Loss: 0.002213, Accuracy: 99.15%\n",
      "Batch 104, Loss: 0.003945, Accuracy: 99.16%\n",
      "Batch 105, Loss: 0.025380, Accuracy: 99.15%\n",
      "Batch 106, Loss: 0.023721, Accuracy: 99.16%\n",
      "Batch 107, Loss: 0.038142, Accuracy: 99.15%\n",
      "Batch 108, Loss: 0.011032, Accuracy: 99.16%\n",
      "Batch 109, Loss: 0.012545, Accuracy: 99.17%\n",
      "Batch 110, Loss: 0.007355, Accuracy: 99.18%\n",
      "Batch 111, Loss: 0.007137, Accuracy: 99.18%\n",
      "Batch 112, Loss: 0.007031, Accuracy: 99.19%\n",
      "Batch 113, Loss: 0.005583, Accuracy: 99.20%\n",
      "Batch 114, Loss: 0.035730, Accuracy: 99.19%\n",
      "Batch 115, Loss: 0.004200, Accuracy: 99.20%\n",
      "Batch 116, Loss: 0.005700, Accuracy: 99.21%\n",
      "Batch 117, Loss: 0.028913, Accuracy: 99.21%\n",
      "Batch 118, Loss: 0.006529, Accuracy: 99.22%\n",
      "Batch 119, Loss: 0.081807, Accuracy: 99.19%\n",
      "Batch 120, Loss: 0.014078, Accuracy: 99.19%\n",
      "Batch 121, Loss: 0.084973, Accuracy: 99.17%\n",
      "Batch 122, Loss: 0.002733, Accuracy: 99.18%\n",
      "Batch 123, Loss: 0.055556, Accuracy: 99.17%\n",
      "Batch 124, Loss: 0.004488, Accuracy: 99.18%\n",
      "Batch 125, Loss: 0.023157, Accuracy: 99.17%\n",
      "Batch 126, Loss: 0.050858, Accuracy: 99.17%\n",
      "Batch 127, Loss: 0.114702, Accuracy: 99.16%\n",
      "Batch 128, Loss: 0.029250, Accuracy: 99.16%\n",
      "Batch 129, Loss: 0.149572, Accuracy: 99.14%\n",
      "Batch 130, Loss: 0.280830, Accuracy: 99.11%\n",
      "Batch 131, Loss: 0.074179, Accuracy: 99.11%\n",
      "Batch 132, Loss: 0.015447, Accuracy: 99.10%\n",
      "Batch 133, Loss: 0.002643, Accuracy: 99.11%\n",
      "Batch 134, Loss: 0.033690, Accuracy: 99.10%\n",
      "Batch 135, Loss: 0.006037, Accuracy: 99.11%\n",
      "Batch 136, Loss: 0.018477, Accuracy: 99.10%\n",
      "Batch 137, Loss: 0.132903, Accuracy: 99.06%\n",
      "Batch 138, Loss: 0.003095, Accuracy: 99.07%\n",
      "Batch 139, Loss: 0.003948, Accuracy: 99.08%\n",
      "Batch 140, Loss: 0.023311, Accuracy: 99.07%\n",
      "Batch 141, Loss: 0.003832, Accuracy: 99.08%\n",
      "Batch 142, Loss: 0.069270, Accuracy: 99.08%\n",
      "Batch 143, Loss: 0.025882, Accuracy: 99.07%\n",
      "Batch 144, Loss: 0.022215, Accuracy: 99.08%\n",
      "Batch 145, Loss: 0.015908, Accuracy: 99.08%\n",
      "Batch 146, Loss: 0.006229, Accuracy: 99.09%\n",
      "Batch 147, Loss: 0.167459, Accuracy: 99.06%\n",
      "Batch 148, Loss: 0.039026, Accuracy: 99.06%\n",
      "Batch 149, Loss: 0.003169, Accuracy: 99.07%\n",
      "Batch 150, Loss: 0.019683, Accuracy: 99.07%\n",
      "Batch 151, Loss: 0.002407, Accuracy: 99.08%\n",
      "Batch 152, Loss: 0.005250, Accuracy: 99.09%\n",
      "Batch 153, Loss: 0.003412, Accuracy: 99.09%\n",
      "Batch 154, Loss: 0.020287, Accuracy: 99.09%\n",
      "Batch 155, Loss: 0.019690, Accuracy: 99.09%\n",
      "Batch 156, Loss: 0.003917, Accuracy: 99.10%\n",
      "Batch 157, Loss: 0.045709, Accuracy: 99.09%\n",
      "Batch 158, Loss: 0.072392, Accuracy: 99.09%\n",
      "Batch 159, Loss: 0.004516, Accuracy: 99.10%\n",
      "Batch 160, Loss: 0.004165, Accuracy: 99.10%\n",
      "Batch 161, Loss: 0.004002, Accuracy: 99.11%\n",
      "Batch 162, Loss: 0.023968, Accuracy: 99.10%\n",
      "Batch 163, Loss: 0.013243, Accuracy: 99.11%\n",
      "Batch 164, Loss: 0.064307, Accuracy: 99.10%\n",
      "Batch 165, Loss: 0.002576, Accuracy: 99.11%\n",
      "Batch 166, Loss: 0.008108, Accuracy: 99.12%\n",
      "Batch 167, Loss: 0.015845, Accuracy: 99.12%\n",
      "Batch 168, Loss: 0.013228, Accuracy: 99.13%\n",
      "Batch 169, Loss: 0.003705, Accuracy: 99.13%\n",
      "Batch 170, Loss: 0.004331, Accuracy: 99.14%\n",
      "Batch 171, Loss: 0.015188, Accuracy: 99.13%\n",
      "Batch 172, Loss: 0.006042, Accuracy: 99.14%\n",
      "Batch 173, Loss: 0.010895, Accuracy: 99.14%\n",
      "Batch 174, Loss: 0.003584, Accuracy: 99.15%\n",
      "Batch 175, Loss: 0.003940, Accuracy: 99.15%\n",
      "Batch 176, Loss: 0.011505, Accuracy: 99.16%\n",
      "Batch 177, Loss: 0.001537, Accuracy: 99.16%\n",
      "Batch 178, Loss: 0.001697, Accuracy: 99.17%\n",
      "Batch 179, Loss: 0.002860, Accuracy: 99.17%\n",
      "Batch 180, Loss: 0.082976, Accuracy: 99.16%\n",
      "Batch 181, Loss: 0.011170, Accuracy: 99.16%\n",
      "Batch 182, Loss: 0.002329, Accuracy: 99.17%\n",
      "Batch 183, Loss: 0.001748, Accuracy: 99.17%\n",
      "Batch 184, Loss: 0.002234, Accuracy: 99.18%\n",
      "Batch 185, Loss: 0.005989, Accuracy: 99.18%\n",
      "Batch 186, Loss: 0.002289, Accuracy: 99.19%\n",
      "Batch 187, Loss: 0.022335, Accuracy: 99.19%\n",
      "Batch 188, Loss: 0.012467, Accuracy: 99.19%\n",
      "Batch 189, Loss: 0.004059, Accuracy: 99.20%\n",
      "Batch 190, Loss: 0.001306, Accuracy: 99.20%\n",
      "Batch 191, Loss: 0.161739, Accuracy: 99.19%\n",
      "Batch 192, Loss: 0.002613, Accuracy: 99.19%\n",
      "Batch 193, Loss: 0.003300, Accuracy: 99.20%\n",
      "Batch 194, Loss: 0.037491, Accuracy: 99.19%\n",
      "Batch 195, Loss: 0.002211, Accuracy: 99.20%\n",
      "Batch 196, Loss: 0.003575, Accuracy: 99.20%\n",
      "Batch 197, Loss: 0.083929, Accuracy: 99.20%\n",
      "Batch 198, Loss: 0.006948, Accuracy: 99.20%\n",
      "Batch 199, Loss: 0.003005, Accuracy: 99.21%\n",
      "Batch 200, Loss: 0.010945, Accuracy: 99.21%\n",
      "Batch 201, Loss: 0.001387, Accuracy: 99.21%\n",
      "Batch 202, Loss: 0.119950, Accuracy: 99.21%\n",
      "Batch 203, Loss: 0.008552, Accuracy: 99.21%\n",
      "Batch 204, Loss: 0.005725, Accuracy: 99.22%\n",
      "Batch 205, Loss: 0.003062, Accuracy: 99.22%\n",
      "Batch 206, Loss: 0.002289, Accuracy: 99.23%\n",
      "Batch 207, Loss: 0.003653, Accuracy: 99.23%\n",
      "Batch 208, Loss: 0.003109, Accuracy: 99.23%\n",
      "Batch 209, Loss: 0.055971, Accuracy: 99.23%\n",
      "Batch 210, Loss: 0.028362, Accuracy: 99.23%\n",
      "Batch 211, Loss: 0.002753, Accuracy: 99.23%\n",
      "Batch 212, Loss: 0.005360, Accuracy: 99.23%\n",
      "Batch 213, Loss: 0.003792, Accuracy: 99.24%\n",
      "Training - Epoch 33, Loss: 0.026780, Accuracy: 99.24%\n",
      "Validation Batch 1, Loss: 0.006221, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.034493, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.007644, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.106540, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.006253, Accuracy: 99.06%\n",
      "Validation Batch 6, Loss: 0.038768, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.015211, Accuracy: 98.88%\n",
      "Validation Batch 8, Loss: 0.005978, Accuracy: 99.02%\n",
      "Validation Batch 9, Loss: 0.009322, Accuracy: 99.13%\n",
      "Validation Batch 10, Loss: 0.029368, Accuracy: 99.06%\n",
      "Validation Batch 11, Loss: 0.024025, Accuracy: 99.01%\n",
      "Validation Batch 12, Loss: 0.050653, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.087612, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.049760, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.011896, Accuracy: 98.75%\n",
      "Validation Batch 16, Loss: 0.111711, Accuracy: 98.73%\n",
      "Validation Batch 17, Loss: 0.048103, Accuracy: 98.62%\n",
      "Validation Batch 18, Loss: 0.002365, Accuracy: 98.70%\n",
      "Validation Batch 19, Loss: 0.106416, Accuracy: 98.68%\n",
      "Validation Batch 20, Loss: 0.027149, Accuracy: 98.67%\n",
      "Validation Batch 21, Loss: 0.053121, Accuracy: 98.59%\n",
      "Validation Batch 22, Loss: 0.038555, Accuracy: 98.51%\n",
      "Validation Batch 23, Loss: 0.019246, Accuracy: 98.57%\n",
      "Validation Batch 24, Loss: 0.170764, Accuracy: 98.50%\n",
      "Validation Batch 25, Loss: 0.002516, Accuracy: 98.56%\n",
      "Validation Batch 26, Loss: 0.021693, Accuracy: 98.56%\n",
      "Validation Batch 27, Loss: 0.047346, Accuracy: 98.53%\n",
      "Validation - Epoch 33, Loss: 0.041953, Accuracy: 98.53%\n",
      "Patience—6\n",
      "Epoch 34\n",
      "Batch 1, Loss: 0.002863, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.022262, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.013433, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.015029, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.104069, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.007264, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.052765, Accuracy: 98.66%\n",
      "Batch 8, Loss: 0.008679, Accuracy: 98.83%\n",
      "Batch 9, Loss: 0.003969, Accuracy: 98.96%\n",
      "Batch 10, Loss: 0.005113, Accuracy: 99.06%\n",
      "Batch 11, Loss: 0.003056, Accuracy: 99.15%\n",
      "Batch 12, Loss: 0.003138, Accuracy: 99.22%\n",
      "Batch 13, Loss: 0.017255, Accuracy: 99.28%\n",
      "Batch 14, Loss: 0.004377, Accuracy: 99.33%\n",
      "Batch 15, Loss: 0.055788, Accuracy: 99.17%\n",
      "Batch 16, Loss: 0.041756, Accuracy: 99.12%\n",
      "Batch 17, Loss: 0.029529, Accuracy: 99.08%\n",
      "Batch 18, Loss: 0.003627, Accuracy: 99.13%\n",
      "Batch 19, Loss: 0.090461, Accuracy: 99.10%\n",
      "Batch 20, Loss: 0.003597, Accuracy: 99.14%\n",
      "Batch 21, Loss: 0.003430, Accuracy: 99.18%\n",
      "Batch 22, Loss: 0.008221, Accuracy: 99.22%\n",
      "Batch 23, Loss: 0.012376, Accuracy: 99.25%\n",
      "Batch 24, Loss: 0.014058, Accuracy: 99.22%\n",
      "Batch 25, Loss: 0.143042, Accuracy: 99.12%\n",
      "Batch 26, Loss: 0.009776, Accuracy: 99.16%\n",
      "Batch 27, Loss: 0.014460, Accuracy: 99.19%\n",
      "Batch 28, Loss: 0.023699, Accuracy: 99.22%\n",
      "Batch 29, Loss: 0.001792, Accuracy: 99.25%\n",
      "Batch 30, Loss: 0.013505, Accuracy: 99.27%\n",
      "Batch 31, Loss: 0.002779, Accuracy: 99.29%\n",
      "Batch 32, Loss: 0.024976, Accuracy: 99.27%\n",
      "Batch 33, Loss: 0.019075, Accuracy: 99.24%\n",
      "Batch 34, Loss: 0.007812, Accuracy: 99.26%\n",
      "Batch 35, Loss: 0.005840, Accuracy: 99.29%\n",
      "Batch 36, Loss: 0.063671, Accuracy: 99.18%\n",
      "Batch 37, Loss: 0.065073, Accuracy: 99.16%\n",
      "Batch 38, Loss: 0.013706, Accuracy: 99.14%\n",
      "Batch 39, Loss: 0.049180, Accuracy: 99.12%\n",
      "Batch 40, Loss: 0.031349, Accuracy: 99.10%\n",
      "Batch 41, Loss: 0.053290, Accuracy: 99.09%\n",
      "Batch 42, Loss: 0.001327, Accuracy: 99.11%\n",
      "Batch 43, Loss: 0.038907, Accuracy: 99.09%\n",
      "Batch 44, Loss: 0.001688, Accuracy: 99.11%\n",
      "Batch 45, Loss: 0.016531, Accuracy: 99.10%\n",
      "Batch 46, Loss: 0.044141, Accuracy: 99.08%\n",
      "Batch 47, Loss: 0.008280, Accuracy: 99.10%\n",
      "Batch 48, Loss: 0.035682, Accuracy: 99.09%\n",
      "Batch 49, Loss: 0.007434, Accuracy: 99.11%\n",
      "Batch 50, Loss: 0.003536, Accuracy: 99.12%\n",
      "Batch 51, Loss: 0.001968, Accuracy: 99.14%\n",
      "Batch 52, Loss: 0.008832, Accuracy: 99.16%\n",
      "Batch 53, Loss: 0.001432, Accuracy: 99.17%\n",
      "Batch 54, Loss: 0.012260, Accuracy: 99.19%\n",
      "Batch 55, Loss: 0.033069, Accuracy: 99.18%\n",
      "Batch 56, Loss: 0.007200, Accuracy: 99.19%\n",
      "Batch 57, Loss: 0.004001, Accuracy: 99.21%\n",
      "Batch 58, Loss: 0.007066, Accuracy: 99.22%\n",
      "Batch 59, Loss: 0.001775, Accuracy: 99.23%\n",
      "Batch 60, Loss: 0.040529, Accuracy: 99.22%\n",
      "Batch 61, Loss: 0.003132, Accuracy: 99.23%\n",
      "Batch 62, Loss: 0.038930, Accuracy: 99.22%\n",
      "Batch 63, Loss: 0.010653, Accuracy: 99.23%\n",
      "Batch 64, Loss: 0.009795, Accuracy: 99.24%\n",
      "Batch 65, Loss: 0.020163, Accuracy: 99.23%\n",
      "Batch 66, Loss: 0.120161, Accuracy: 99.20%\n",
      "Batch 67, Loss: 0.005746, Accuracy: 99.21%\n",
      "Batch 68, Loss: 0.002509, Accuracy: 99.22%\n",
      "Batch 69, Loss: 0.002299, Accuracy: 99.23%\n",
      "Batch 70, Loss: 0.016187, Accuracy: 99.22%\n",
      "Batch 71, Loss: 0.005508, Accuracy: 99.23%\n",
      "Batch 72, Loss: 0.001772, Accuracy: 99.24%\n",
      "Batch 73, Loss: 0.003401, Accuracy: 99.25%\n",
      "Batch 74, Loss: 0.016371, Accuracy: 99.26%\n",
      "Batch 75, Loss: 0.004053, Accuracy: 99.27%\n",
      "Batch 76, Loss: 0.036951, Accuracy: 99.26%\n",
      "Batch 77, Loss: 0.001399, Accuracy: 99.27%\n",
      "Batch 78, Loss: 0.113957, Accuracy: 99.26%\n",
      "Batch 79, Loss: 0.016646, Accuracy: 99.27%\n",
      "Batch 80, Loss: 0.045347, Accuracy: 99.26%\n",
      "Batch 81, Loss: 0.029907, Accuracy: 99.25%\n",
      "Batch 82, Loss: 0.008296, Accuracy: 99.26%\n",
      "Batch 83, Loss: 0.003612, Accuracy: 99.27%\n",
      "Batch 84, Loss: 0.002183, Accuracy: 99.27%\n",
      "Batch 85, Loss: 0.004652, Accuracy: 99.28%\n",
      "Batch 86, Loss: 0.003500, Accuracy: 99.29%\n",
      "Batch 87, Loss: 0.014016, Accuracy: 99.30%\n",
      "Batch 88, Loss: 0.003127, Accuracy: 99.31%\n",
      "Batch 89, Loss: 0.002790, Accuracy: 99.32%\n",
      "Batch 90, Loss: 0.004005, Accuracy: 99.32%\n",
      "Batch 91, Loss: 0.018380, Accuracy: 99.31%\n",
      "Batch 92, Loss: 0.050169, Accuracy: 99.30%\n",
      "Batch 93, Loss: 0.003678, Accuracy: 99.31%\n",
      "Batch 94, Loss: 0.020765, Accuracy: 99.30%\n",
      "Batch 95, Loss: 0.030368, Accuracy: 99.29%\n",
      "Batch 96, Loss: 0.022237, Accuracy: 99.28%\n",
      "Batch 97, Loss: 0.058469, Accuracy: 99.28%\n",
      "Batch 98, Loss: 0.001511, Accuracy: 99.28%\n",
      "Batch 99, Loss: 0.002455, Accuracy: 99.29%\n",
      "Batch 100, Loss: 0.016907, Accuracy: 99.28%\n",
      "Batch 101, Loss: 0.001476, Accuracy: 99.29%\n",
      "Batch 102, Loss: 0.006114, Accuracy: 99.30%\n",
      "Batch 103, Loss: 0.003832, Accuracy: 99.30%\n",
      "Batch 104, Loss: 0.001020, Accuracy: 99.31%\n",
      "Batch 105, Loss: 0.008148, Accuracy: 99.32%\n",
      "Batch 106, Loss: 0.001106, Accuracy: 99.32%\n",
      "Batch 107, Loss: 0.012209, Accuracy: 99.33%\n",
      "Batch 108, Loss: 0.003023, Accuracy: 99.33%\n",
      "Batch 109, Loss: 0.077938, Accuracy: 99.33%\n",
      "Batch 110, Loss: 0.002689, Accuracy: 99.33%\n",
      "Batch 111, Loss: 0.001189, Accuracy: 99.34%\n",
      "Batch 112, Loss: 0.002979, Accuracy: 99.34%\n",
      "Batch 113, Loss: 0.019930, Accuracy: 99.34%\n",
      "Batch 114, Loss: 0.006494, Accuracy: 99.34%\n",
      "Batch 115, Loss: 0.007229, Accuracy: 99.35%\n",
      "Batch 116, Loss: 0.009433, Accuracy: 99.35%\n",
      "Batch 117, Loss: 0.016290, Accuracy: 99.36%\n",
      "Batch 118, Loss: 0.006684, Accuracy: 99.36%\n",
      "Batch 119, Loss: 0.005226, Accuracy: 99.37%\n",
      "Batch 120, Loss: 0.001262, Accuracy: 99.38%\n",
      "Batch 121, Loss: 0.002162, Accuracy: 99.38%\n",
      "Batch 122, Loss: 0.001277, Accuracy: 99.39%\n",
      "Batch 123, Loss: 0.006868, Accuracy: 99.39%\n",
      "Batch 124, Loss: 0.007192, Accuracy: 99.40%\n",
      "Batch 125, Loss: 0.013045, Accuracy: 99.40%\n",
      "Batch 126, Loss: 0.001251, Accuracy: 99.40%\n",
      "Batch 127, Loss: 0.001406, Accuracy: 99.41%\n",
      "Batch 128, Loss: 0.112620, Accuracy: 99.38%\n",
      "Batch 129, Loss: 0.016063, Accuracy: 99.38%\n",
      "Batch 130, Loss: 0.004890, Accuracy: 99.39%\n",
      "Batch 131, Loss: 0.001530, Accuracy: 99.39%\n",
      "Batch 132, Loss: 0.023254, Accuracy: 99.38%\n",
      "Batch 133, Loss: 0.015806, Accuracy: 99.39%\n",
      "Batch 134, Loss: 0.064302, Accuracy: 99.38%\n",
      "Batch 135, Loss: 0.003368, Accuracy: 99.39%\n",
      "Batch 136, Loss: 0.007397, Accuracy: 99.39%\n",
      "Batch 137, Loss: 0.081128, Accuracy: 99.38%\n",
      "Batch 138, Loss: 0.003684, Accuracy: 99.39%\n",
      "Batch 139, Loss: 0.064151, Accuracy: 99.38%\n",
      "Batch 140, Loss: 0.000959, Accuracy: 99.39%\n",
      "Batch 141, Loss: 0.001668, Accuracy: 99.39%\n",
      "Batch 142, Loss: 0.011675, Accuracy: 99.39%\n",
      "Batch 143, Loss: 0.001193, Accuracy: 99.40%\n",
      "Batch 144, Loss: 0.007479, Accuracy: 99.40%\n",
      "Batch 145, Loss: 0.001940, Accuracy: 99.41%\n",
      "Batch 146, Loss: 0.003971, Accuracy: 99.41%\n",
      "Batch 147, Loss: 0.024753, Accuracy: 99.40%\n",
      "Batch 148, Loss: 0.027593, Accuracy: 99.40%\n",
      "Batch 149, Loss: 0.045309, Accuracy: 99.39%\n",
      "Batch 150, Loss: 0.002330, Accuracy: 99.40%\n",
      "Batch 151, Loss: 0.008777, Accuracy: 99.40%\n",
      "Batch 152, Loss: 0.002701, Accuracy: 99.40%\n",
      "Batch 153, Loss: 0.034441, Accuracy: 99.40%\n",
      "Batch 154, Loss: 0.014775, Accuracy: 99.40%\n",
      "Batch 155, Loss: 0.001139, Accuracy: 99.41%\n",
      "Batch 156, Loss: 0.020904, Accuracy: 99.40%\n",
      "Batch 157, Loss: 0.002375, Accuracy: 99.40%\n",
      "Batch 158, Loss: 0.003312, Accuracy: 99.41%\n",
      "Batch 159, Loss: 0.001311, Accuracy: 99.41%\n",
      "Batch 160, Loss: 0.004857, Accuracy: 99.41%\n",
      "Batch 161, Loss: 0.002774, Accuracy: 99.42%\n",
      "Batch 162, Loss: 0.002258, Accuracy: 99.42%\n",
      "Batch 163, Loss: 0.024080, Accuracy: 99.42%\n",
      "Batch 164, Loss: 0.001513, Accuracy: 99.42%\n",
      "Batch 165, Loss: 0.001219, Accuracy: 99.42%\n",
      "Batch 166, Loss: 0.019532, Accuracy: 99.42%\n",
      "Batch 167, Loss: 0.002726, Accuracy: 99.42%\n",
      "Batch 168, Loss: 0.004094, Accuracy: 99.42%\n",
      "Batch 169, Loss: 0.023613, Accuracy: 99.43%\n",
      "Batch 170, Loss: 0.009464, Accuracy: 99.43%\n",
      "Batch 171, Loss: 0.016744, Accuracy: 99.42%\n",
      "Batch 172, Loss: 0.004301, Accuracy: 99.43%\n",
      "Batch 173, Loss: 0.103985, Accuracy: 99.42%\n",
      "Batch 174, Loss: 0.002134, Accuracy: 99.43%\n",
      "Batch 175, Loss: 0.013101, Accuracy: 99.43%\n",
      "Batch 176, Loss: 0.001458, Accuracy: 99.43%\n",
      "Batch 177, Loss: 0.074482, Accuracy: 99.43%\n",
      "Batch 178, Loss: 0.065196, Accuracy: 99.42%\n",
      "Batch 179, Loss: 0.001859, Accuracy: 99.42%\n",
      "Batch 180, Loss: 0.030589, Accuracy: 99.42%\n",
      "Batch 181, Loss: 0.004168, Accuracy: 99.42%\n",
      "Batch 182, Loss: 0.004874, Accuracy: 99.42%\n",
      "Batch 183, Loss: 0.034780, Accuracy: 99.42%\n",
      "Batch 184, Loss: 0.069825, Accuracy: 99.41%\n",
      "Batch 185, Loss: 0.009050, Accuracy: 99.42%\n",
      "Batch 186, Loss: 0.003481, Accuracy: 99.42%\n",
      "Batch 187, Loss: 0.037138, Accuracy: 99.42%\n",
      "Batch 188, Loss: 0.037461, Accuracy: 99.41%\n",
      "Batch 189, Loss: 0.025097, Accuracy: 99.40%\n",
      "Batch 190, Loss: 0.004295, Accuracy: 99.41%\n",
      "Batch 191, Loss: 0.003852, Accuracy: 99.41%\n",
      "Batch 192, Loss: 0.003479, Accuracy: 99.41%\n",
      "Batch 193, Loss: 0.039514, Accuracy: 99.41%\n",
      "Batch 194, Loss: 0.003387, Accuracy: 99.41%\n",
      "Batch 195, Loss: 0.063158, Accuracy: 99.41%\n",
      "Batch 196, Loss: 0.129755, Accuracy: 99.39%\n",
      "Batch 197, Loss: 0.002179, Accuracy: 99.40%\n",
      "Batch 198, Loss: 0.011091, Accuracy: 99.40%\n",
      "Batch 199, Loss: 0.007934, Accuracy: 99.40%\n",
      "Batch 200, Loss: 0.008935, Accuracy: 99.41%\n",
      "Batch 201, Loss: 0.002378, Accuracy: 99.41%\n",
      "Batch 202, Loss: 0.006081, Accuracy: 99.41%\n",
      "Batch 203, Loss: 0.001695, Accuracy: 99.42%\n",
      "Batch 204, Loss: 0.012272, Accuracy: 99.42%\n",
      "Batch 205, Loss: 0.034619, Accuracy: 99.41%\n",
      "Batch 206, Loss: 0.002724, Accuracy: 99.42%\n",
      "Batch 207, Loss: 0.001624, Accuracy: 99.42%\n",
      "Batch 208, Loss: 0.015584, Accuracy: 99.42%\n",
      "Batch 209, Loss: 0.007238, Accuracy: 99.42%\n",
      "Batch 210, Loss: 0.043063, Accuracy: 99.42%\n",
      "Batch 211, Loss: 0.043200, Accuracy: 99.41%\n",
      "Batch 212, Loss: 0.042587, Accuracy: 99.41%\n",
      "Batch 213, Loss: 0.003337, Accuracy: 99.41%\n",
      "Training - Epoch 34, Loss: 0.019225, Accuracy: 99.41%\n",
      "Validation Batch 1, Loss: 0.001934, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.015352, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.021470, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.078355, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.021958, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.002560, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.005951, Accuracy: 99.11%\n",
      "Validation Batch 8, Loss: 0.021581, Accuracy: 99.02%\n",
      "Validation Batch 9, Loss: 0.011168, Accuracy: 99.13%\n",
      "Validation Batch 10, Loss: 0.001441, Accuracy: 99.22%\n",
      "Validation Batch 11, Loss: 0.009911, Accuracy: 99.29%\n",
      "Validation Batch 12, Loss: 0.013132, Accuracy: 99.35%\n",
      "Validation Batch 13, Loss: 0.053879, Accuracy: 99.28%\n",
      "Validation Batch 14, Loss: 0.128205, Accuracy: 99.22%\n",
      "Validation Batch 15, Loss: 0.034459, Accuracy: 99.17%\n",
      "Validation Batch 16, Loss: 0.124620, Accuracy: 99.12%\n",
      "Validation Batch 17, Loss: 0.067016, Accuracy: 99.08%\n",
      "Validation Batch 18, Loss: 0.018468, Accuracy: 99.05%\n",
      "Validation Batch 19, Loss: 0.016731, Accuracy: 99.10%\n",
      "Validation Batch 20, Loss: 0.012368, Accuracy: 99.14%\n",
      "Validation Batch 21, Loss: 0.018876, Accuracy: 99.11%\n",
      "Validation Batch 22, Loss: 0.013591, Accuracy: 99.15%\n",
      "Validation Batch 23, Loss: 0.003100, Accuracy: 99.18%\n",
      "Validation Batch 24, Loss: 0.058752, Accuracy: 99.15%\n",
      "Validation Batch 25, Loss: 0.003207, Accuracy: 99.19%\n",
      "Validation Batch 26, Loss: 0.032002, Accuracy: 99.16%\n",
      "Validation Batch 27, Loss: 0.002740, Accuracy: 99.18%\n",
      "Validation - Epoch 34, Loss: 0.029364, Accuracy: 99.18%\n",
      "Patience—7\n",
      "Epoch 35\n",
      "Batch 1, Loss: 0.021571, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.003809, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.005476, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.042641, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.090518, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.093148, Accuracy: 98.96%\n",
      "Batch 7, Loss: 0.002412, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.001554, Accuracy: 99.22%\n",
      "Batch 9, Loss: 0.005376, Accuracy: 99.31%\n",
      "Batch 10, Loss: 0.002454, Accuracy: 99.38%\n",
      "Batch 11, Loss: 0.002249, Accuracy: 99.43%\n",
      "Batch 12, Loss: 0.020262, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.032359, Accuracy: 99.40%\n",
      "Batch 14, Loss: 0.012218, Accuracy: 99.44%\n",
      "Batch 15, Loss: 0.029661, Accuracy: 99.38%\n",
      "Batch 16, Loss: 0.008087, Accuracy: 99.41%\n",
      "Batch 17, Loss: 0.042087, Accuracy: 99.36%\n",
      "Batch 18, Loss: 0.001788, Accuracy: 99.39%\n",
      "Batch 19, Loss: 0.030648, Accuracy: 99.34%\n",
      "Batch 20, Loss: 0.014994, Accuracy: 99.38%\n",
      "Batch 21, Loss: 0.009754, Accuracy: 99.40%\n",
      "Batch 22, Loss: 0.041444, Accuracy: 99.36%\n",
      "Batch 23, Loss: 0.114378, Accuracy: 99.12%\n",
      "Batch 24, Loss: 0.006618, Accuracy: 99.15%\n",
      "Batch 25, Loss: 0.010092, Accuracy: 99.19%\n",
      "Batch 26, Loss: 0.007091, Accuracy: 99.22%\n",
      "Batch 27, Loss: 0.009283, Accuracy: 99.25%\n",
      "Batch 28, Loss: 0.052628, Accuracy: 99.16%\n",
      "Batch 29, Loss: 0.005549, Accuracy: 99.19%\n",
      "Batch 30, Loss: 0.041321, Accuracy: 99.17%\n",
      "Batch 31, Loss: 0.052518, Accuracy: 99.14%\n",
      "Batch 32, Loss: 0.001941, Accuracy: 99.17%\n",
      "Batch 33, Loss: 0.007926, Accuracy: 99.20%\n",
      "Batch 34, Loss: 0.002882, Accuracy: 99.22%\n",
      "Batch 35, Loss: 0.004565, Accuracy: 99.24%\n",
      "Batch 36, Loss: 0.009035, Accuracy: 99.26%\n",
      "Batch 37, Loss: 0.001494, Accuracy: 99.28%\n",
      "Batch 38, Loss: 0.004305, Accuracy: 99.30%\n",
      "Batch 39, Loss: 0.140838, Accuracy: 99.16%\n",
      "Batch 40, Loss: 0.003186, Accuracy: 99.18%\n",
      "Batch 41, Loss: 0.001461, Accuracy: 99.20%\n",
      "Batch 42, Loss: 0.005492, Accuracy: 99.22%\n",
      "Batch 43, Loss: 0.037089, Accuracy: 99.20%\n",
      "Batch 44, Loss: 0.060394, Accuracy: 99.18%\n",
      "Batch 45, Loss: 0.050058, Accuracy: 99.17%\n",
      "Batch 46, Loss: 0.038595, Accuracy: 99.15%\n",
      "Batch 47, Loss: 0.010454, Accuracy: 99.17%\n",
      "Batch 48, Loss: 0.009128, Accuracy: 99.19%\n",
      "Batch 49, Loss: 0.017440, Accuracy: 99.20%\n",
      "Batch 50, Loss: 0.014836, Accuracy: 99.22%\n",
      "Batch 51, Loss: 0.012416, Accuracy: 99.23%\n",
      "Batch 52, Loss: 0.002272, Accuracy: 99.25%\n",
      "Batch 53, Loss: 0.002891, Accuracy: 99.26%\n",
      "Batch 54, Loss: 0.006674, Accuracy: 99.28%\n",
      "Batch 55, Loss: 0.030404, Accuracy: 99.26%\n",
      "Batch 56, Loss: 0.001293, Accuracy: 99.27%\n",
      "Batch 57, Loss: 0.009259, Accuracy: 99.29%\n",
      "Batch 58, Loss: 0.014458, Accuracy: 99.30%\n",
      "Batch 59, Loss: 0.026166, Accuracy: 99.28%\n",
      "Batch 60, Loss: 0.006361, Accuracy: 99.30%\n",
      "Batch 61, Loss: 0.001936, Accuracy: 99.31%\n",
      "Batch 62, Loss: 0.001052, Accuracy: 99.32%\n",
      "Batch 63, Loss: 0.022326, Accuracy: 99.31%\n",
      "Batch 64, Loss: 0.001704, Accuracy: 99.32%\n",
      "Batch 65, Loss: 0.004492, Accuracy: 99.33%\n",
      "Batch 66, Loss: 0.020234, Accuracy: 99.31%\n",
      "Batch 67, Loss: 0.002887, Accuracy: 99.32%\n",
      "Batch 68, Loss: 0.015132, Accuracy: 99.31%\n",
      "Batch 69, Loss: 0.060804, Accuracy: 99.30%\n",
      "Batch 70, Loss: 0.001764, Accuracy: 99.31%\n",
      "Batch 71, Loss: 0.004043, Accuracy: 99.32%\n",
      "Batch 72, Loss: 0.006616, Accuracy: 99.33%\n",
      "Batch 73, Loss: 0.009447, Accuracy: 99.34%\n",
      "Batch 74, Loss: 0.004685, Accuracy: 99.35%\n",
      "Batch 75, Loss: 0.001067, Accuracy: 99.35%\n",
      "Batch 76, Loss: 0.019640, Accuracy: 99.34%\n",
      "Batch 77, Loss: 0.000885, Accuracy: 99.35%\n",
      "Batch 78, Loss: 0.001424, Accuracy: 99.36%\n",
      "Batch 79, Loss: 0.004831, Accuracy: 99.37%\n",
      "Batch 80, Loss: 0.002456, Accuracy: 99.38%\n",
      "Batch 81, Loss: 0.006789, Accuracy: 99.38%\n",
      "Batch 82, Loss: 0.004296, Accuracy: 99.39%\n",
      "Batch 83, Loss: 0.006464, Accuracy: 99.40%\n",
      "Batch 84, Loss: 0.002740, Accuracy: 99.40%\n",
      "Batch 85, Loss: 0.030668, Accuracy: 99.39%\n",
      "Batch 86, Loss: 0.002299, Accuracy: 99.40%\n",
      "Batch 87, Loss: 0.001825, Accuracy: 99.41%\n",
      "Batch 88, Loss: 0.001854, Accuracy: 99.41%\n",
      "Batch 89, Loss: 0.011555, Accuracy: 99.42%\n",
      "Batch 90, Loss: 0.091494, Accuracy: 99.41%\n",
      "Batch 91, Loss: 0.004537, Accuracy: 99.42%\n",
      "Batch 92, Loss: 0.003154, Accuracy: 99.42%\n",
      "Batch 93, Loss: 0.071381, Accuracy: 99.40%\n",
      "Batch 94, Loss: 0.010364, Accuracy: 99.40%\n",
      "Batch 95, Loss: 0.017991, Accuracy: 99.39%\n",
      "Batch 96, Loss: 0.003030, Accuracy: 99.40%\n",
      "Batch 97, Loss: 0.001720, Accuracy: 99.40%\n",
      "Batch 98, Loss: 0.002223, Accuracy: 99.41%\n",
      "Batch 99, Loss: 0.011971, Accuracy: 99.42%\n",
      "Batch 100, Loss: 0.046624, Accuracy: 99.39%\n",
      "Batch 101, Loss: 0.002541, Accuracy: 99.40%\n",
      "Batch 102, Loss: 0.003340, Accuracy: 99.40%\n",
      "Batch 103, Loss: 0.007170, Accuracy: 99.41%\n",
      "Batch 104, Loss: 0.016396, Accuracy: 99.41%\n",
      "Batch 105, Loss: 0.047927, Accuracy: 99.39%\n",
      "Batch 106, Loss: 0.001949, Accuracy: 99.40%\n",
      "Batch 107, Loss: 0.001528, Accuracy: 99.40%\n",
      "Batch 108, Loss: 0.060838, Accuracy: 99.39%\n",
      "Batch 109, Loss: 0.001593, Accuracy: 99.40%\n",
      "Batch 110, Loss: 0.004575, Accuracy: 99.40%\n",
      "Batch 111, Loss: 0.001166, Accuracy: 99.41%\n",
      "Batch 112, Loss: 0.000851, Accuracy: 99.41%\n",
      "Batch 113, Loss: 0.001003, Accuracy: 99.42%\n",
      "Batch 114, Loss: 0.001767, Accuracy: 99.42%\n",
      "Batch 115, Loss: 0.000920, Accuracy: 99.43%\n",
      "Batch 116, Loss: 0.001303, Accuracy: 99.43%\n",
      "Batch 117, Loss: 0.001342, Accuracy: 99.44%\n",
      "Batch 118, Loss: 0.020054, Accuracy: 99.44%\n",
      "Batch 119, Loss: 0.010141, Accuracy: 99.45%\n",
      "Batch 120, Loss: 0.003909, Accuracy: 99.45%\n",
      "Batch 121, Loss: 0.000779, Accuracy: 99.46%\n",
      "Batch 122, Loss: 0.035500, Accuracy: 99.45%\n",
      "Batch 123, Loss: 0.000775, Accuracy: 99.45%\n",
      "Batch 124, Loss: 0.006880, Accuracy: 99.46%\n",
      "Batch 125, Loss: 0.001639, Accuracy: 99.46%\n",
      "Batch 126, Loss: 0.003982, Accuracy: 99.47%\n",
      "Batch 127, Loss: 0.006711, Accuracy: 99.47%\n",
      "Batch 128, Loss: 0.000703, Accuracy: 99.48%\n",
      "Batch 129, Loss: 0.000996, Accuracy: 99.48%\n",
      "Batch 130, Loss: 0.014639, Accuracy: 99.47%\n",
      "Batch 131, Loss: 0.009042, Accuracy: 99.48%\n",
      "Batch 132, Loss: 0.008344, Accuracy: 99.48%\n",
      "Batch 133, Loss: 0.003001, Accuracy: 99.48%\n",
      "Batch 134, Loss: 0.001603, Accuracy: 99.49%\n",
      "Batch 135, Loss: 0.000889, Accuracy: 99.49%\n",
      "Batch 136, Loss: 0.001595, Accuracy: 99.49%\n",
      "Batch 137, Loss: 0.000841, Accuracy: 99.50%\n",
      "Batch 138, Loss: 0.002965, Accuracy: 99.50%\n",
      "Batch 139, Loss: 0.000744, Accuracy: 99.51%\n",
      "Batch 140, Loss: 0.002396, Accuracy: 99.51%\n",
      "Batch 141, Loss: 0.001510, Accuracy: 99.51%\n",
      "Batch 142, Loss: 0.027917, Accuracy: 99.50%\n",
      "Batch 143, Loss: 0.001619, Accuracy: 99.51%\n",
      "Batch 144, Loss: 0.001683, Accuracy: 99.51%\n",
      "Batch 145, Loss: 0.001216, Accuracy: 99.52%\n",
      "Batch 146, Loss: 0.003603, Accuracy: 99.52%\n",
      "Batch 147, Loss: 0.001083, Accuracy: 99.52%\n",
      "Batch 148, Loss: 0.000755, Accuracy: 99.52%\n",
      "Batch 149, Loss: 0.000944, Accuracy: 99.53%\n",
      "Batch 150, Loss: 0.003329, Accuracy: 99.53%\n",
      "Batch 151, Loss: 0.001001, Accuracy: 99.53%\n",
      "Batch 152, Loss: 0.013081, Accuracy: 99.53%\n",
      "Batch 153, Loss: 0.001428, Accuracy: 99.53%\n",
      "Batch 154, Loss: 0.002946, Accuracy: 99.53%\n",
      "Batch 155, Loss: 0.001986, Accuracy: 99.54%\n",
      "Batch 156, Loss: 0.000877, Accuracy: 99.54%\n",
      "Batch 157, Loss: 0.033567, Accuracy: 99.53%\n",
      "Batch 158, Loss: 0.004758, Accuracy: 99.54%\n",
      "Batch 159, Loss: 0.001310, Accuracy: 99.54%\n",
      "Batch 160, Loss: 0.016222, Accuracy: 99.53%\n",
      "Batch 161, Loss: 0.001826, Accuracy: 99.53%\n",
      "Batch 162, Loss: 0.000984, Accuracy: 99.54%\n",
      "Batch 163, Loss: 0.004368, Accuracy: 99.54%\n",
      "Batch 164, Loss: 0.001200, Accuracy: 99.54%\n",
      "Batch 165, Loss: 0.001312, Accuracy: 99.55%\n",
      "Batch 166, Loss: 0.002100, Accuracy: 99.55%\n",
      "Batch 167, Loss: 0.010859, Accuracy: 99.55%\n",
      "Batch 168, Loss: 0.005084, Accuracy: 99.55%\n",
      "Batch 169, Loss: 0.001721, Accuracy: 99.56%\n",
      "Batch 170, Loss: 0.003462, Accuracy: 99.56%\n",
      "Batch 171, Loss: 0.003192, Accuracy: 99.56%\n",
      "Batch 172, Loss: 0.004693, Accuracy: 99.56%\n",
      "Batch 173, Loss: 0.002324, Accuracy: 99.57%\n",
      "Batch 174, Loss: 0.002681, Accuracy: 99.57%\n",
      "Batch 175, Loss: 0.001856, Accuracy: 99.57%\n",
      "Batch 176, Loss: 0.004659, Accuracy: 99.57%\n",
      "Batch 177, Loss: 0.004452, Accuracy: 99.58%\n",
      "Batch 178, Loss: 0.004250, Accuracy: 99.58%\n",
      "Batch 179, Loss: 0.077042, Accuracy: 99.56%\n",
      "Batch 180, Loss: 0.001147, Accuracy: 99.57%\n",
      "Batch 181, Loss: 0.000967, Accuracy: 99.57%\n",
      "Batch 182, Loss: 0.005409, Accuracy: 99.57%\n",
      "Batch 183, Loss: 0.000893, Accuracy: 99.57%\n",
      "Batch 184, Loss: 0.002367, Accuracy: 99.58%\n",
      "Batch 185, Loss: 0.001578, Accuracy: 99.58%\n",
      "Batch 186, Loss: 0.015989, Accuracy: 99.57%\n",
      "Batch 187, Loss: 0.002856, Accuracy: 99.57%\n",
      "Batch 188, Loss: 0.099928, Accuracy: 99.57%\n",
      "Batch 189, Loss: 0.000730, Accuracy: 99.57%\n",
      "Batch 190, Loss: 0.001090, Accuracy: 99.57%\n",
      "Batch 191, Loss: 0.001655, Accuracy: 99.57%\n",
      "Batch 192, Loss: 0.004348, Accuracy: 99.58%\n",
      "Batch 193, Loss: 0.000872, Accuracy: 99.58%\n",
      "Batch 194, Loss: 0.002616, Accuracy: 99.58%\n",
      "Batch 195, Loss: 0.003064, Accuracy: 99.58%\n",
      "Batch 196, Loss: 0.001196, Accuracy: 99.59%\n",
      "Batch 197, Loss: 0.001122, Accuracy: 99.59%\n",
      "Batch 198, Loss: 0.000876, Accuracy: 99.59%\n",
      "Batch 199, Loss: 0.001407, Accuracy: 99.59%\n",
      "Batch 200, Loss: 0.002633, Accuracy: 99.59%\n",
      "Batch 201, Loss: 0.003070, Accuracy: 99.60%\n",
      "Batch 202, Loss: 0.000910, Accuracy: 99.60%\n",
      "Batch 203, Loss: 0.034517, Accuracy: 99.59%\n",
      "Batch 204, Loss: 0.001235, Accuracy: 99.59%\n",
      "Batch 205, Loss: 0.004183, Accuracy: 99.60%\n",
      "Batch 206, Loss: 0.007706, Accuracy: 99.60%\n",
      "Batch 207, Loss: 0.000714, Accuracy: 99.60%\n",
      "Batch 208, Loss: 0.001086, Accuracy: 99.60%\n",
      "Batch 209, Loss: 0.001283, Accuracy: 99.60%\n",
      "Batch 210, Loss: 0.000766, Accuracy: 99.61%\n",
      "Batch 211, Loss: 0.002154, Accuracy: 99.61%\n",
      "Batch 212, Loss: 0.001833, Accuracy: 99.61%\n",
      "Batch 213, Loss: 0.081039, Accuracy: 99.60%\n",
      "Training - Epoch 35, Loss: 0.012743, Accuracy: 99.60%\n",
      "Validation Batch 1, Loss: 0.003863, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.043804, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.000833, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.001545, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.010354, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.003524, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.001153, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.007315, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.006799, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.013465, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.006166, Accuracy: 99.72%\n",
      "Validation Batch 12, Loss: 0.005900, Accuracy: 99.74%\n",
      "Validation Batch 13, Loss: 0.048888, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.011538, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.006077, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.085005, Accuracy: 99.61%\n",
      "Validation Batch 17, Loss: 0.001703, Accuracy: 99.63%\n",
      "Validation Batch 18, Loss: 0.006859, Accuracy: 99.65%\n",
      "Validation Batch 19, Loss: 0.013860, Accuracy: 99.59%\n",
      "Validation Batch 20, Loss: 0.052035, Accuracy: 99.45%\n",
      "Validation Batch 21, Loss: 0.001272, Accuracy: 99.48%\n",
      "Validation Batch 22, Loss: 0.001096, Accuracy: 99.50%\n",
      "Validation Batch 23, Loss: 0.010439, Accuracy: 99.52%\n",
      "Validation Batch 24, Loss: 0.096519, Accuracy: 99.48%\n",
      "Validation Batch 25, Loss: 0.000742, Accuracy: 99.50%\n",
      "Validation Batch 26, Loss: 0.002143, Accuracy: 99.52%\n",
      "Validation Batch 27, Loss: 0.016256, Accuracy: 99.53%\n",
      "Validation - Epoch 35, Loss: 0.017006, Accuracy: 99.53%\n",
      "Patience—8\n",
      "Epoch 36\n",
      "Batch 1, Loss: 0.000962, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000722, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000727, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.016495, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.001131, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.003170, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.000811, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.047667, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.001114, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.016538, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.000979, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.041207, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.002384, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.001350, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.000825, Accuracy: 99.58%\n",
      "Batch 16, Loss: 0.001200, Accuracy: 99.61%\n",
      "Batch 17, Loss: 0.012564, Accuracy: 99.63%\n",
      "Batch 18, Loss: 0.001165, Accuracy: 99.65%\n",
      "Batch 19, Loss: 0.000975, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.008762, Accuracy: 99.69%\n",
      "Batch 21, Loss: 0.007603, Accuracy: 99.70%\n",
      "Batch 22, Loss: 0.000694, Accuracy: 99.72%\n",
      "Batch 23, Loss: 0.001270, Accuracy: 99.73%\n",
      "Batch 24, Loss: 0.002036, Accuracy: 99.74%\n",
      "Batch 25, Loss: 0.003827, Accuracy: 99.75%\n",
      "Batch 26, Loss: 0.001336, Accuracy: 99.76%\n",
      "Batch 27, Loss: 0.001012, Accuracy: 99.77%\n",
      "Batch 28, Loss: 0.002599, Accuracy: 99.78%\n",
      "Batch 29, Loss: 0.000684, Accuracy: 99.78%\n",
      "Batch 30, Loss: 0.001298, Accuracy: 99.79%\n",
      "Batch 31, Loss: 0.004594, Accuracy: 99.80%\n",
      "Batch 32, Loss: 0.000900, Accuracy: 99.80%\n",
      "Batch 33, Loss: 0.001052, Accuracy: 99.81%\n",
      "Batch 34, Loss: 0.012899, Accuracy: 99.77%\n",
      "Batch 35, Loss: 0.001613, Accuracy: 99.78%\n",
      "Batch 36, Loss: 0.001631, Accuracy: 99.78%\n",
      "Batch 37, Loss: 0.000919, Accuracy: 99.79%\n",
      "Batch 38, Loss: 0.000780, Accuracy: 99.79%\n",
      "Batch 39, Loss: 0.002419, Accuracy: 99.80%\n",
      "Batch 40, Loss: 0.000853, Accuracy: 99.80%\n",
      "Batch 41, Loss: 0.006157, Accuracy: 99.81%\n",
      "Batch 42, Loss: 0.002503, Accuracy: 99.81%\n",
      "Batch 43, Loss: 0.000663, Accuracy: 99.82%\n",
      "Batch 44, Loss: 0.000942, Accuracy: 99.82%\n",
      "Batch 45, Loss: 0.001711, Accuracy: 99.83%\n",
      "Batch 46, Loss: 0.001383, Accuracy: 99.83%\n",
      "Batch 47, Loss: 0.001751, Accuracy: 99.83%\n",
      "Batch 48, Loss: 0.021364, Accuracy: 99.80%\n",
      "Batch 49, Loss: 0.036771, Accuracy: 99.78%\n",
      "Batch 50, Loss: 0.003632, Accuracy: 99.78%\n",
      "Batch 51, Loss: 0.000838, Accuracy: 99.79%\n",
      "Batch 52, Loss: 0.001575, Accuracy: 99.79%\n",
      "Batch 53, Loss: 0.002114, Accuracy: 99.79%\n",
      "Batch 54, Loss: 0.003121, Accuracy: 99.80%\n",
      "Batch 55, Loss: 0.000763, Accuracy: 99.80%\n",
      "Batch 56, Loss: 0.001890, Accuracy: 99.80%\n",
      "Batch 57, Loss: 0.001188, Accuracy: 99.81%\n",
      "Batch 58, Loss: 0.009481, Accuracy: 99.81%\n",
      "Batch 59, Loss: 0.002231, Accuracy: 99.81%\n",
      "Batch 60, Loss: 0.000740, Accuracy: 99.82%\n",
      "Batch 61, Loss: 0.000994, Accuracy: 99.82%\n",
      "Batch 62, Loss: 0.019672, Accuracy: 99.80%\n",
      "Batch 63, Loss: 0.001451, Accuracy: 99.80%\n",
      "Batch 64, Loss: 0.001702, Accuracy: 99.80%\n",
      "Batch 65, Loss: 0.008149, Accuracy: 99.81%\n",
      "Batch 66, Loss: 0.001032, Accuracy: 99.81%\n",
      "Batch 67, Loss: 0.006810, Accuracy: 99.81%\n",
      "Batch 68, Loss: 0.002687, Accuracy: 99.82%\n",
      "Batch 69, Loss: 0.001424, Accuracy: 99.82%\n",
      "Batch 70, Loss: 0.000778, Accuracy: 99.82%\n",
      "Batch 71, Loss: 0.001292, Accuracy: 99.82%\n",
      "Batch 72, Loss: 0.001102, Accuracy: 99.83%\n",
      "Batch 73, Loss: 0.028444, Accuracy: 99.81%\n",
      "Batch 74, Loss: 0.003134, Accuracy: 99.81%\n",
      "Batch 75, Loss: 0.003367, Accuracy: 99.81%\n",
      "Batch 76, Loss: 0.001026, Accuracy: 99.81%\n",
      "Batch 77, Loss: 0.001823, Accuracy: 99.82%\n",
      "Batch 78, Loss: 0.001640, Accuracy: 99.82%\n",
      "Batch 79, Loss: 0.001888, Accuracy: 99.82%\n",
      "Batch 80, Loss: 0.000634, Accuracy: 99.82%\n",
      "Batch 81, Loss: 0.000915, Accuracy: 99.83%\n",
      "Batch 82, Loss: 0.005371, Accuracy: 99.83%\n",
      "Batch 83, Loss: 0.000697, Accuracy: 99.83%\n",
      "Batch 84, Loss: 0.001540, Accuracy: 99.83%\n",
      "Batch 85, Loss: 0.000800, Accuracy: 99.83%\n",
      "Batch 86, Loss: 0.005335, Accuracy: 99.84%\n",
      "Batch 87, Loss: 0.000683, Accuracy: 99.84%\n",
      "Batch 88, Loss: 0.000620, Accuracy: 99.84%\n",
      "Batch 89, Loss: 0.000838, Accuracy: 99.84%\n",
      "Batch 90, Loss: 0.001833, Accuracy: 99.84%\n",
      "Batch 91, Loss: 0.000968, Accuracy: 99.85%\n",
      "Batch 92, Loss: 0.000803, Accuracy: 99.85%\n",
      "Batch 93, Loss: 0.000971, Accuracy: 99.85%\n",
      "Batch 94, Loss: 0.001066, Accuracy: 99.85%\n",
      "Batch 95, Loss: 0.000770, Accuracy: 99.85%\n",
      "Batch 96, Loss: 0.000748, Accuracy: 99.85%\n",
      "Batch 97, Loss: 0.012042, Accuracy: 99.86%\n",
      "Batch 98, Loss: 0.001233, Accuracy: 99.86%\n",
      "Batch 99, Loss: 0.000752, Accuracy: 99.86%\n",
      "Batch 100, Loss: 0.001128, Accuracy: 99.86%\n",
      "Batch 101, Loss: 0.001009, Accuracy: 99.86%\n",
      "Batch 102, Loss: 0.001512, Accuracy: 99.86%\n",
      "Batch 103, Loss: 0.000913, Accuracy: 99.86%\n",
      "Batch 104, Loss: 0.000588, Accuracy: 99.86%\n",
      "Batch 105, Loss: 0.000777, Accuracy: 99.87%\n",
      "Batch 106, Loss: 0.001847, Accuracy: 99.87%\n",
      "Batch 107, Loss: 0.006263, Accuracy: 99.87%\n",
      "Batch 108, Loss: 0.001576, Accuracy: 99.87%\n",
      "Batch 109, Loss: 0.001290, Accuracy: 99.87%\n",
      "Batch 110, Loss: 0.003236, Accuracy: 99.87%\n",
      "Batch 111, Loss: 0.051477, Accuracy: 99.86%\n",
      "Batch 112, Loss: 0.001466, Accuracy: 99.86%\n",
      "Batch 113, Loss: 0.000609, Accuracy: 99.86%\n",
      "Batch 114, Loss: 0.001106, Accuracy: 99.86%\n",
      "Batch 115, Loss: 0.001061, Accuracy: 99.86%\n",
      "Batch 116, Loss: 0.000720, Accuracy: 99.87%\n",
      "Batch 117, Loss: 0.001062, Accuracy: 99.87%\n",
      "Batch 118, Loss: 0.001412, Accuracy: 99.87%\n",
      "Batch 119, Loss: 0.005034, Accuracy: 99.87%\n",
      "Batch 120, Loss: 0.001229, Accuracy: 99.87%\n",
      "Batch 121, Loss: 0.000731, Accuracy: 99.87%\n",
      "Batch 122, Loss: 0.000783, Accuracy: 99.87%\n",
      "Batch 123, Loss: 0.002085, Accuracy: 99.87%\n",
      "Batch 124, Loss: 0.002403, Accuracy: 99.87%\n",
      "Batch 125, Loss: 0.000940, Accuracy: 99.88%\n",
      "Batch 126, Loss: 0.002138, Accuracy: 99.88%\n",
      "Batch 127, Loss: 0.001175, Accuracy: 99.88%\n",
      "Batch 128, Loss: 0.005510, Accuracy: 99.88%\n",
      "Batch 129, Loss: 0.000904, Accuracy: 99.88%\n",
      "Batch 130, Loss: 0.000664, Accuracy: 99.88%\n",
      "Batch 131, Loss: 0.000812, Accuracy: 99.88%\n",
      "Batch 132, Loss: 0.003474, Accuracy: 99.88%\n",
      "Batch 133, Loss: 0.001328, Accuracy: 99.88%\n",
      "Batch 134, Loss: 0.007171, Accuracy: 99.88%\n",
      "Batch 135, Loss: 0.007314, Accuracy: 99.88%\n",
      "Batch 136, Loss: 0.000639, Accuracy: 99.89%\n",
      "Batch 137, Loss: 0.000568, Accuracy: 99.89%\n",
      "Batch 138, Loss: 0.001117, Accuracy: 99.89%\n",
      "Batch 139, Loss: 0.000757, Accuracy: 99.89%\n",
      "Batch 140, Loss: 0.000649, Accuracy: 99.89%\n",
      "Batch 141, Loss: 0.000535, Accuracy: 99.89%\n",
      "Batch 142, Loss: 0.000758, Accuracy: 99.89%\n",
      "Batch 143, Loss: 0.007670, Accuracy: 99.89%\n",
      "Batch 144, Loss: 0.000722, Accuracy: 99.89%\n",
      "Batch 145, Loss: 0.000665, Accuracy: 99.89%\n",
      "Batch 146, Loss: 0.000675, Accuracy: 99.89%\n",
      "Batch 147, Loss: 0.000947, Accuracy: 99.89%\n",
      "Batch 148, Loss: 0.000634, Accuracy: 99.89%\n",
      "Batch 149, Loss: 0.000793, Accuracy: 99.90%\n",
      "Batch 150, Loss: 0.000613, Accuracy: 99.90%\n",
      "Batch 151, Loss: 0.000508, Accuracy: 99.90%\n",
      "Batch 152, Loss: 0.000631, Accuracy: 99.90%\n",
      "Batch 153, Loss: 0.001384, Accuracy: 99.90%\n",
      "Batch 154, Loss: 0.000593, Accuracy: 99.90%\n",
      "Batch 155, Loss: 0.000774, Accuracy: 99.90%\n",
      "Batch 156, Loss: 0.000496, Accuracy: 99.90%\n",
      "Batch 157, Loss: 0.000521, Accuracy: 99.90%\n",
      "Batch 158, Loss: 0.000827, Accuracy: 99.90%\n",
      "Batch 159, Loss: 0.001853, Accuracy: 99.90%\n",
      "Batch 160, Loss: 0.000824, Accuracy: 99.90%\n",
      "Batch 161, Loss: 0.000811, Accuracy: 99.90%\n",
      "Batch 162, Loss: 0.000726, Accuracy: 99.90%\n",
      "Batch 163, Loss: 0.000538, Accuracy: 99.90%\n",
      "Batch 164, Loss: 0.000629, Accuracy: 99.90%\n",
      "Batch 165, Loss: 0.000623, Accuracy: 99.91%\n",
      "Batch 166, Loss: 0.001025, Accuracy: 99.91%\n",
      "Batch 167, Loss: 0.000584, Accuracy: 99.91%\n",
      "Batch 168, Loss: 0.000708, Accuracy: 99.91%\n",
      "Batch 169, Loss: 0.013924, Accuracy: 99.90%\n",
      "Batch 170, Loss: 0.000778, Accuracy: 99.90%\n",
      "Batch 171, Loss: 0.001218, Accuracy: 99.90%\n",
      "Batch 172, Loss: 0.000521, Accuracy: 99.90%\n",
      "Batch 173, Loss: 0.000488, Accuracy: 99.90%\n",
      "Batch 174, Loss: 0.000764, Accuracy: 99.90%\n",
      "Batch 175, Loss: 0.000921, Accuracy: 99.90%\n",
      "Batch 176, Loss: 0.005942, Accuracy: 99.90%\n",
      "Batch 177, Loss: 0.001315, Accuracy: 99.90%\n",
      "Batch 178, Loss: 0.004810, Accuracy: 99.90%\n",
      "Batch 179, Loss: 0.000584, Accuracy: 99.90%\n",
      "Batch 180, Loss: 0.090240, Accuracy: 99.90%\n",
      "Batch 181, Loss: 0.000627, Accuracy: 99.90%\n",
      "Batch 182, Loss: 0.000917, Accuracy: 99.90%\n",
      "Batch 183, Loss: 0.003327, Accuracy: 99.90%\n",
      "Batch 184, Loss: 0.000921, Accuracy: 99.90%\n",
      "Batch 185, Loss: 0.000605, Accuracy: 99.90%\n",
      "Batch 186, Loss: 0.000632, Accuracy: 99.90%\n",
      "Batch 187, Loss: 0.000588, Accuracy: 99.90%\n",
      "Batch 188, Loss: 0.000825, Accuracy: 99.90%\n",
      "Batch 189, Loss: 0.000580, Accuracy: 99.90%\n",
      "Batch 190, Loss: 0.000626, Accuracy: 99.90%\n",
      "Batch 191, Loss: 0.000521, Accuracy: 99.90%\n",
      "Batch 192, Loss: 0.003033, Accuracy: 99.90%\n",
      "Batch 193, Loss: 0.001151, Accuracy: 99.90%\n",
      "Batch 194, Loss: 0.000648, Accuracy: 99.90%\n",
      "Batch 195, Loss: 0.001028, Accuracy: 99.90%\n",
      "Batch 196, Loss: 0.001658, Accuracy: 99.90%\n",
      "Batch 197, Loss: 0.000765, Accuracy: 99.90%\n",
      "Batch 198, Loss: 0.001409, Accuracy: 99.91%\n",
      "Batch 199, Loss: 0.000951, Accuracy: 99.91%\n",
      "Batch 200, Loss: 0.000572, Accuracy: 99.91%\n",
      "Batch 201, Loss: 0.000662, Accuracy: 99.91%\n",
      "Batch 202, Loss: 0.000974, Accuracy: 99.91%\n",
      "Batch 203, Loss: 0.001546, Accuracy: 99.91%\n",
      "Batch 204, Loss: 0.000815, Accuracy: 99.91%\n",
      "Batch 205, Loss: 0.000690, Accuracy: 99.91%\n",
      "Batch 206, Loss: 0.000820, Accuracy: 99.91%\n",
      "Batch 207, Loss: 0.000834, Accuracy: 99.91%\n",
      "Batch 208, Loss: 0.001189, Accuracy: 99.91%\n",
      "Batch 209, Loss: 0.000568, Accuracy: 99.91%\n",
      "Batch 210, Loss: 0.000704, Accuracy: 99.91%\n",
      "Batch 211, Loss: 0.000670, Accuracy: 99.91%\n",
      "Batch 212, Loss: 0.001242, Accuracy: 99.91%\n",
      "Batch 213, Loss: 0.000620, Accuracy: 99.91%\n",
      "Training - Epoch 36, Loss: 0.003509, Accuracy: 99.91%\n",
      "Validation Batch 1, Loss: 0.001005, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001188, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.001023, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.001027, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.001850, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000862, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000801, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.003024, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.016294, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.002175, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000690, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.073716, Accuracy: 99.87%\n",
      "Validation Batch 13, Loss: 0.001084, Accuracy: 99.88%\n",
      "Validation Batch 14, Loss: 0.018133, Accuracy: 99.78%\n",
      "Validation Batch 15, Loss: 0.001100, Accuracy: 99.79%\n",
      "Validation Batch 16, Loss: 0.002158, Accuracy: 99.80%\n",
      "Validation Batch 17, Loss: 0.000944, Accuracy: 99.82%\n",
      "Validation Batch 18, Loss: 0.004681, Accuracy: 99.83%\n",
      "Validation Batch 19, Loss: 0.001293, Accuracy: 99.84%\n",
      "Validation Batch 20, Loss: 0.000647, Accuracy: 99.84%\n",
      "Validation Batch 21, Loss: 0.000836, Accuracy: 99.85%\n",
      "Validation Batch 22, Loss: 0.000707, Accuracy: 99.86%\n",
      "Validation Batch 23, Loss: 0.000630, Accuracy: 99.86%\n",
      "Validation Batch 24, Loss: 0.141102, Accuracy: 99.80%\n",
      "Validation Batch 25, Loss: 0.002676, Accuracy: 99.81%\n",
      "Validation Batch 26, Loss: 0.000885, Accuracy: 99.82%\n",
      "Validation Batch 27, Loss: 0.001064, Accuracy: 99.82%\n",
      "Validation - Epoch 36, Loss: 0.010430, Accuracy: 99.82%\n",
      "Patience—0\n",
      "Epoch 37\n",
      "Batch 1, Loss: 0.000611, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000512, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000788, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.001413, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001015, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000529, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000598, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000584, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000841, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000603, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.020949, Accuracy: 99.86%\n",
      "Batch 12, Loss: 0.000509, Accuracy: 99.87%\n",
      "Batch 13, Loss: 0.001824, Accuracy: 99.88%\n",
      "Batch 14, Loss: 0.000552, Accuracy: 99.89%\n",
      "Batch 15, Loss: 0.000590, Accuracy: 99.90%\n",
      "Batch 16, Loss: 0.000597, Accuracy: 99.90%\n",
      "Batch 17, Loss: 0.001679, Accuracy: 99.91%\n",
      "Batch 18, Loss: 0.002722, Accuracy: 99.91%\n",
      "Batch 19, Loss: 0.247672, Accuracy: 99.67%\n",
      "Batch 20, Loss: 0.002856, Accuracy: 99.69%\n",
      "Batch 21, Loss: 0.016712, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.005615, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.002301, Accuracy: 99.66%\n",
      "Batch 24, Loss: 0.039597, Accuracy: 99.61%\n",
      "Batch 25, Loss: 0.000702, Accuracy: 99.62%\n",
      "Batch 26, Loss: 0.000627, Accuracy: 99.64%\n",
      "Batch 27, Loss: 0.076029, Accuracy: 99.59%\n",
      "Batch 28, Loss: 0.001810, Accuracy: 99.61%\n",
      "Batch 29, Loss: 0.001027, Accuracy: 99.62%\n",
      "Batch 30, Loss: 0.000878, Accuracy: 99.64%\n",
      "Batch 31, Loss: 0.011459, Accuracy: 99.65%\n",
      "Batch 32, Loss: 0.002632, Accuracy: 99.66%\n",
      "Batch 33, Loss: 0.004009, Accuracy: 99.67%\n",
      "Batch 34, Loss: 0.003912, Accuracy: 99.68%\n",
      "Batch 35, Loss: 0.000667, Accuracy: 99.69%\n",
      "Batch 36, Loss: 0.001446, Accuracy: 99.70%\n",
      "Batch 37, Loss: 0.001556, Accuracy: 99.70%\n",
      "Batch 38, Loss: 0.066097, Accuracy: 99.63%\n",
      "Batch 39, Loss: 0.004552, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.110836, Accuracy: 99.53%\n",
      "Batch 41, Loss: 0.001208, Accuracy: 99.54%\n",
      "Batch 42, Loss: 0.000981, Accuracy: 99.55%\n",
      "Batch 43, Loss: 0.001577, Accuracy: 99.56%\n",
      "Batch 44, Loss: 0.000926, Accuracy: 99.57%\n",
      "Batch 45, Loss: 0.001323, Accuracy: 99.58%\n",
      "Batch 46, Loss: 0.003736, Accuracy: 99.59%\n",
      "Batch 47, Loss: 0.002622, Accuracy: 99.60%\n",
      "Batch 48, Loss: 0.010175, Accuracy: 99.61%\n",
      "Batch 49, Loss: 0.043528, Accuracy: 99.59%\n",
      "Batch 50, Loss: 0.002337, Accuracy: 99.59%\n",
      "Batch 51, Loss: 0.003452, Accuracy: 99.60%\n",
      "Batch 52, Loss: 0.001811, Accuracy: 99.61%\n",
      "Batch 53, Loss: 0.012376, Accuracy: 99.62%\n",
      "Batch 54, Loss: 0.002539, Accuracy: 99.62%\n",
      "Batch 55, Loss: 0.026167, Accuracy: 99.60%\n",
      "Batch 56, Loss: 0.007478, Accuracy: 99.61%\n",
      "Batch 57, Loss: 0.001833, Accuracy: 99.62%\n",
      "Batch 58, Loss: 0.101353, Accuracy: 99.57%\n",
      "Batch 59, Loss: 0.001288, Accuracy: 99.58%\n",
      "Batch 60, Loss: 0.002228, Accuracy: 99.58%\n",
      "Batch 61, Loss: 0.000933, Accuracy: 99.59%\n",
      "Batch 62, Loss: 0.069160, Accuracy: 99.57%\n",
      "Batch 63, Loss: 0.002890, Accuracy: 99.58%\n",
      "Batch 64, Loss: 0.004588, Accuracy: 99.58%\n",
      "Batch 65, Loss: 0.001924, Accuracy: 99.59%\n",
      "Batch 66, Loss: 0.017127, Accuracy: 99.57%\n",
      "Batch 67, Loss: 0.000848, Accuracy: 99.58%\n",
      "Batch 68, Loss: 0.002947, Accuracy: 99.59%\n",
      "Batch 69, Loss: 0.001256, Accuracy: 99.59%\n",
      "Batch 70, Loss: 0.002606, Accuracy: 99.60%\n",
      "Batch 71, Loss: 0.008848, Accuracy: 99.60%\n",
      "Batch 72, Loss: 0.007884, Accuracy: 99.61%\n",
      "Batch 73, Loss: 0.003068, Accuracy: 99.61%\n",
      "Batch 74, Loss: 0.012579, Accuracy: 99.62%\n",
      "Batch 75, Loss: 0.001475, Accuracy: 99.62%\n",
      "Batch 76, Loss: 0.020865, Accuracy: 99.61%\n",
      "Batch 77, Loss: 0.000832, Accuracy: 99.61%\n",
      "Batch 78, Loss: 0.001877, Accuracy: 99.62%\n",
      "Batch 79, Loss: 0.003994, Accuracy: 99.62%\n",
      "Batch 80, Loss: 0.006812, Accuracy: 99.63%\n",
      "Batch 81, Loss: 0.005340, Accuracy: 99.63%\n",
      "Batch 82, Loss: 0.001890, Accuracy: 99.64%\n",
      "Batch 83, Loss: 0.001074, Accuracy: 99.64%\n",
      "Batch 84, Loss: 0.002552, Accuracy: 99.65%\n",
      "Batch 85, Loss: 0.001187, Accuracy: 99.65%\n",
      "Batch 86, Loss: 0.000778, Accuracy: 99.65%\n",
      "Batch 87, Loss: 0.011009, Accuracy: 99.66%\n",
      "Batch 88, Loss: 0.003357, Accuracy: 99.66%\n",
      "Batch 89, Loss: 0.001195, Accuracy: 99.67%\n",
      "Batch 90, Loss: 0.005165, Accuracy: 99.67%\n",
      "Batch 91, Loss: 0.001863, Accuracy: 99.67%\n",
      "Batch 92, Loss: 0.001463, Accuracy: 99.68%\n",
      "Batch 93, Loss: 0.000888, Accuracy: 99.68%\n",
      "Batch 94, Loss: 0.000825, Accuracy: 99.68%\n",
      "Batch 95, Loss: 0.000871, Accuracy: 99.69%\n",
      "Batch 96, Loss: 0.004208, Accuracy: 99.69%\n",
      "Batch 97, Loss: 0.000975, Accuracy: 99.69%\n",
      "Batch 98, Loss: 0.007454, Accuracy: 99.70%\n",
      "Batch 99, Loss: 0.001390, Accuracy: 99.70%\n",
      "Batch 100, Loss: 0.006767, Accuracy: 99.70%\n",
      "Batch 101, Loss: 0.000801, Accuracy: 99.71%\n",
      "Batch 102, Loss: 0.000729, Accuracy: 99.71%\n",
      "Batch 103, Loss: 0.002556, Accuracy: 99.71%\n",
      "Batch 104, Loss: 0.006206, Accuracy: 99.71%\n",
      "Batch 105, Loss: 0.023527, Accuracy: 99.70%\n",
      "Batch 106, Loss: 0.000642, Accuracy: 99.71%\n",
      "Batch 107, Loss: 0.000656, Accuracy: 99.71%\n",
      "Batch 108, Loss: 0.004933, Accuracy: 99.71%\n",
      "Batch 109, Loss: 0.002542, Accuracy: 99.71%\n",
      "Batch 110, Loss: 0.001067, Accuracy: 99.72%\n",
      "Batch 111, Loss: 0.002762, Accuracy: 99.72%\n",
      "Batch 112, Loss: 0.004282, Accuracy: 99.72%\n",
      "Batch 113, Loss: 0.012384, Accuracy: 99.72%\n",
      "Batch 114, Loss: 0.001226, Accuracy: 99.73%\n",
      "Batch 115, Loss: 0.000683, Accuracy: 99.73%\n",
      "Batch 116, Loss: 0.001030, Accuracy: 99.73%\n",
      "Batch 117, Loss: 0.000728, Accuracy: 99.73%\n",
      "Batch 118, Loss: 0.000734, Accuracy: 99.74%\n",
      "Batch 119, Loss: 0.001425, Accuracy: 99.74%\n",
      "Batch 120, Loss: 0.000954, Accuracy: 99.74%\n",
      "Batch 121, Loss: 0.003429, Accuracy: 99.74%\n",
      "Batch 122, Loss: 0.000816, Accuracy: 99.74%\n",
      "Batch 123, Loss: 0.000860, Accuracy: 99.75%\n",
      "Batch 124, Loss: 0.000619, Accuracy: 99.75%\n",
      "Batch 125, Loss: 0.000843, Accuracy: 99.75%\n",
      "Batch 126, Loss: 0.000617, Accuracy: 99.75%\n",
      "Batch 127, Loss: 0.001143, Accuracy: 99.75%\n",
      "Batch 128, Loss: 0.000936, Accuracy: 99.76%\n",
      "Batch 129, Loss: 0.011896, Accuracy: 99.76%\n",
      "Batch 130, Loss: 0.001225, Accuracy: 99.76%\n",
      "Batch 131, Loss: 0.000781, Accuracy: 99.76%\n",
      "Batch 132, Loss: 0.000629, Accuracy: 99.76%\n",
      "Batch 133, Loss: 0.000613, Accuracy: 99.77%\n",
      "Batch 134, Loss: 0.003971, Accuracy: 99.77%\n",
      "Batch 135, Loss: 0.001082, Accuracy: 99.77%\n",
      "Batch 136, Loss: 0.007315, Accuracy: 99.77%\n",
      "Batch 137, Loss: 0.000610, Accuracy: 99.77%\n",
      "Batch 138, Loss: 0.001033, Accuracy: 99.77%\n",
      "Batch 139, Loss: 0.000551, Accuracy: 99.78%\n",
      "Batch 140, Loss: 0.001018, Accuracy: 99.78%\n",
      "Batch 141, Loss: 0.002591, Accuracy: 99.78%\n",
      "Batch 142, Loss: 0.000757, Accuracy: 99.78%\n",
      "Batch 143, Loss: 0.002206, Accuracy: 99.78%\n",
      "Batch 144, Loss: 0.000818, Accuracy: 99.78%\n",
      "Batch 145, Loss: 0.000937, Accuracy: 99.78%\n",
      "Batch 146, Loss: 0.020623, Accuracy: 99.78%\n",
      "Batch 147, Loss: 0.000635, Accuracy: 99.78%\n",
      "Batch 148, Loss: 0.000691, Accuracy: 99.78%\n",
      "Batch 149, Loss: 0.000621, Accuracy: 99.78%\n",
      "Batch 150, Loss: 0.001413, Accuracy: 99.78%\n",
      "Batch 151, Loss: 0.000582, Accuracy: 99.78%\n",
      "Batch 152, Loss: 0.001109, Accuracy: 99.78%\n",
      "Batch 153, Loss: 0.001209, Accuracy: 99.79%\n",
      "Batch 154, Loss: 0.001424, Accuracy: 99.79%\n",
      "Batch 155, Loss: 0.022152, Accuracy: 99.78%\n",
      "Batch 156, Loss: 0.001980, Accuracy: 99.78%\n",
      "Batch 157, Loss: 0.000972, Accuracy: 99.78%\n",
      "Batch 158, Loss: 0.001484, Accuracy: 99.78%\n",
      "Batch 159, Loss: 0.003063, Accuracy: 99.78%\n",
      "Batch 160, Loss: 0.001524, Accuracy: 99.79%\n",
      "Batch 161, Loss: 0.003260, Accuracy: 99.79%\n",
      "Batch 162, Loss: 0.006701, Accuracy: 99.79%\n",
      "Batch 163, Loss: 0.000804, Accuracy: 99.79%\n",
      "Batch 164, Loss: 0.001071, Accuracy: 99.79%\n",
      "Batch 165, Loss: 0.000653, Accuracy: 99.79%\n",
      "Batch 166, Loss: 0.000759, Accuracy: 99.79%\n",
      "Batch 167, Loss: 0.000636, Accuracy: 99.79%\n",
      "Batch 168, Loss: 0.001516, Accuracy: 99.80%\n",
      "Batch 169, Loss: 0.007959, Accuracy: 99.80%\n",
      "Batch 170, Loss: 0.038428, Accuracy: 99.79%\n",
      "Batch 171, Loss: 0.002216, Accuracy: 99.79%\n",
      "Batch 172, Loss: 0.056423, Accuracy: 99.78%\n",
      "Batch 173, Loss: 0.003533, Accuracy: 99.78%\n",
      "Batch 174, Loss: 0.009176, Accuracy: 99.78%\n",
      "Batch 175, Loss: 0.009131, Accuracy: 99.79%\n",
      "Batch 176, Loss: 0.002743, Accuracy: 99.79%\n",
      "Batch 177, Loss: 0.008004, Accuracy: 99.79%\n",
      "Batch 178, Loss: 0.013638, Accuracy: 99.78%\n",
      "Batch 179, Loss: 0.043541, Accuracy: 99.77%\n",
      "Batch 180, Loss: 0.006645, Accuracy: 99.77%\n",
      "Batch 181, Loss: 0.004082, Accuracy: 99.78%\n",
      "Batch 182, Loss: 0.011216, Accuracy: 99.78%\n",
      "Batch 183, Loss: 0.019632, Accuracy: 99.77%\n",
      "Batch 184, Loss: 0.001005, Accuracy: 99.77%\n",
      "Batch 185, Loss: 0.006746, Accuracy: 99.77%\n",
      "Batch 186, Loss: 0.051802, Accuracy: 99.76%\n",
      "Batch 187, Loss: 0.069849, Accuracy: 99.76%\n",
      "Batch 188, Loss: 0.047774, Accuracy: 99.75%\n",
      "Batch 189, Loss: 0.006190, Accuracy: 99.75%\n",
      "Batch 190, Loss: 0.009240, Accuracy: 99.75%\n",
      "Batch 191, Loss: 0.020477, Accuracy: 99.75%\n",
      "Batch 192, Loss: 0.004958, Accuracy: 99.75%\n",
      "Batch 193, Loss: 0.026346, Accuracy: 99.74%\n",
      "Batch 194, Loss: 0.003944, Accuracy: 99.74%\n",
      "Batch 195, Loss: 0.006928, Accuracy: 99.74%\n",
      "Batch 196, Loss: 0.001772, Accuracy: 99.74%\n",
      "Batch 197, Loss: 0.055670, Accuracy: 99.73%\n",
      "Batch 198, Loss: 0.002981, Accuracy: 99.73%\n",
      "Batch 199, Loss: 0.010210, Accuracy: 99.73%\n",
      "Batch 200, Loss: 0.006633, Accuracy: 99.73%\n",
      "Batch 201, Loss: 0.022309, Accuracy: 99.73%\n",
      "Batch 202, Loss: 0.010035, Accuracy: 99.73%\n",
      "Batch 203, Loss: 0.002310, Accuracy: 99.73%\n",
      "Batch 204, Loss: 0.063093, Accuracy: 99.72%\n",
      "Batch 205, Loss: 0.032044, Accuracy: 99.72%\n",
      "Batch 206, Loss: 0.023675, Accuracy: 99.71%\n",
      "Batch 207, Loss: 0.002307, Accuracy: 99.71%\n",
      "Batch 208, Loss: 0.002081, Accuracy: 99.71%\n",
      "Batch 209, Loss: 0.001495, Accuracy: 99.72%\n",
      "Batch 210, Loss: 0.008759, Accuracy: 99.72%\n",
      "Batch 211, Loss: 0.040940, Accuracy: 99.71%\n",
      "Batch 212, Loss: 0.001562, Accuracy: 99.71%\n",
      "Batch 213, Loss: 0.005540, Accuracy: 99.71%\n",
      "Training - Epoch 37, Loss: 0.009759, Accuracy: 99.71%\n",
      "Validation Batch 1, Loss: 0.001989, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.007883, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.007559, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.002196, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.009685, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.002957, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.011094, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.018250, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.144108, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.001611, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.067507, Accuracy: 99.43%\n",
      "Validation Batch 12, Loss: 0.027269, Accuracy: 99.35%\n",
      "Validation Batch 13, Loss: 0.027037, Accuracy: 99.28%\n",
      "Validation Batch 14, Loss: 0.032869, Accuracy: 99.22%\n",
      "Validation Batch 15, Loss: 0.032526, Accuracy: 99.17%\n",
      "Validation Batch 16, Loss: 0.004124, Accuracy: 99.22%\n",
      "Validation Batch 17, Loss: 0.016771, Accuracy: 99.26%\n",
      "Validation Batch 18, Loss: 0.017626, Accuracy: 99.31%\n",
      "Validation Batch 19, Loss: 0.035611, Accuracy: 99.18%\n",
      "Validation Batch 20, Loss: 0.007323, Accuracy: 99.22%\n",
      "Validation Batch 21, Loss: 0.058425, Accuracy: 99.18%\n",
      "Validation Batch 22, Loss: 0.003881, Accuracy: 99.22%\n",
      "Validation Batch 23, Loss: 0.039536, Accuracy: 99.18%\n",
      "Validation Batch 24, Loss: 0.161170, Accuracy: 99.02%\n",
      "Validation Batch 25, Loss: 0.001153, Accuracy: 99.06%\n",
      "Validation Batch 26, Loss: 0.016596, Accuracy: 99.10%\n",
      "Validation Batch 27, Loss: 0.072952, Accuracy: 99.00%\n",
      "Validation - Epoch 37, Loss: 0.030730, Accuracy: 99.00%\n",
      "Patience—1\n",
      "Epoch 38\n",
      "Batch 1, Loss: 0.002897, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.072229, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.005234, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.004152, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.002707, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.001190, Accuracy: 99.74%\n",
      "Batch 7, Loss: 0.001314, Accuracy: 99.78%\n",
      "Batch 8, Loss: 0.015703, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.009780, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.008173, Accuracy: 99.69%\n",
      "Batch 11, Loss: 0.017115, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.003264, Accuracy: 99.61%\n",
      "Batch 13, Loss: 0.003394, Accuracy: 99.64%\n",
      "Batch 14, Loss: 0.049477, Accuracy: 99.44%\n",
      "Batch 15, Loss: 0.141822, Accuracy: 99.17%\n",
      "Batch 16, Loss: 0.001294, Accuracy: 99.22%\n",
      "Batch 17, Loss: 0.066168, Accuracy: 99.17%\n",
      "Batch 18, Loss: 0.015802, Accuracy: 99.13%\n",
      "Batch 19, Loss: 0.028293, Accuracy: 99.10%\n",
      "Batch 20, Loss: 0.025805, Accuracy: 99.06%\n",
      "Batch 21, Loss: 0.060503, Accuracy: 98.96%\n",
      "Batch 22, Loss: 0.024398, Accuracy: 98.93%\n",
      "Batch 23, Loss: 0.012770, Accuracy: 98.98%\n",
      "Batch 24, Loss: 0.019898, Accuracy: 98.96%\n",
      "Batch 25, Loss: 0.203897, Accuracy: 98.75%\n",
      "Batch 26, Loss: 0.008205, Accuracy: 98.80%\n",
      "Batch 27, Loss: 0.073689, Accuracy: 98.73%\n",
      "Batch 28, Loss: 0.007753, Accuracy: 98.77%\n",
      "Batch 29, Loss: 0.008243, Accuracy: 98.81%\n",
      "Batch 30, Loss: 0.019716, Accuracy: 98.80%\n",
      "Batch 31, Loss: 0.120743, Accuracy: 98.74%\n",
      "Batch 32, Loss: 0.407810, Accuracy: 98.54%\n",
      "Batch 33, Loss: 0.122441, Accuracy: 98.39%\n",
      "Batch 34, Loss: 0.013771, Accuracy: 98.44%\n",
      "Batch 35, Loss: 0.118504, Accuracy: 98.26%\n",
      "Batch 36, Loss: 0.210837, Accuracy: 98.18%\n",
      "Batch 37, Loss: 0.180472, Accuracy: 98.14%\n",
      "Batch 38, Loss: 0.105157, Accuracy: 98.15%\n",
      "Batch 39, Loss: 0.179626, Accuracy: 98.04%\n",
      "Batch 40, Loss: 0.027440, Accuracy: 98.05%\n",
      "Batch 41, Loss: 0.051707, Accuracy: 97.98%\n",
      "Batch 42, Loss: 0.016125, Accuracy: 98.03%\n",
      "Batch 43, Loss: 0.003025, Accuracy: 98.07%\n",
      "Batch 44, Loss: 0.108883, Accuracy: 98.05%\n",
      "Batch 45, Loss: 0.023571, Accuracy: 98.06%\n",
      "Batch 46, Loss: 0.059422, Accuracy: 98.00%\n",
      "Batch 47, Loss: 0.122736, Accuracy: 97.97%\n",
      "Batch 48, Loss: 0.091432, Accuracy: 97.95%\n",
      "Batch 49, Loss: 0.172256, Accuracy: 97.90%\n",
      "Batch 50, Loss: 0.080208, Accuracy: 97.88%\n",
      "Batch 51, Loss: 0.095794, Accuracy: 97.86%\n",
      "Batch 52, Loss: 0.122313, Accuracy: 97.81%\n",
      "Batch 53, Loss: 0.021916, Accuracy: 97.82%\n",
      "Batch 54, Loss: 0.063033, Accuracy: 97.80%\n",
      "Batch 55, Loss: 0.003007, Accuracy: 97.84%\n",
      "Batch 56, Loss: 0.166667, Accuracy: 97.77%\n",
      "Batch 57, Loss: 0.082684, Accuracy: 97.72%\n",
      "Batch 58, Loss: 0.015193, Accuracy: 97.76%\n",
      "Batch 59, Loss: 0.037109, Accuracy: 97.78%\n",
      "Batch 60, Loss: 0.010753, Accuracy: 97.81%\n",
      "Batch 61, Loss: 0.011833, Accuracy: 97.85%\n",
      "Batch 62, Loss: 0.012721, Accuracy: 97.88%\n",
      "Batch 63, Loss: 0.009172, Accuracy: 97.92%\n",
      "Batch 64, Loss: 0.102895, Accuracy: 97.90%\n",
      "Batch 65, Loss: 0.008166, Accuracy: 97.93%\n",
      "Batch 66, Loss: 0.100728, Accuracy: 97.94%\n",
      "Batch 67, Loss: 0.129762, Accuracy: 97.92%\n",
      "Batch 68, Loss: 0.115609, Accuracy: 97.93%\n",
      "Batch 69, Loss: 0.046464, Accuracy: 97.92%\n",
      "Batch 70, Loss: 0.047194, Accuracy: 97.90%\n",
      "Batch 71, Loss: 0.043894, Accuracy: 97.91%\n",
      "Batch 72, Loss: 0.039767, Accuracy: 97.92%\n",
      "Batch 73, Loss: 0.062165, Accuracy: 97.90%\n",
      "Batch 74, Loss: 0.004049, Accuracy: 97.93%\n",
      "Batch 75, Loss: 0.043870, Accuracy: 97.94%\n",
      "Batch 76, Loss: 0.052976, Accuracy: 97.94%\n",
      "Batch 77, Loss: 0.010791, Accuracy: 97.97%\n",
      "Batch 78, Loss: 0.018362, Accuracy: 98.00%\n",
      "Batch 79, Loss: 0.047304, Accuracy: 97.98%\n",
      "Batch 80, Loss: 0.003825, Accuracy: 98.01%\n",
      "Batch 81, Loss: 0.012342, Accuracy: 98.03%\n",
      "Batch 82, Loss: 0.009683, Accuracy: 98.06%\n",
      "Batch 83, Loss: 0.019151, Accuracy: 98.06%\n",
      "Batch 84, Loss: 0.009480, Accuracy: 98.08%\n",
      "Batch 85, Loss: 0.007179, Accuracy: 98.11%\n",
      "Batch 86, Loss: 0.005898, Accuracy: 98.13%\n",
      "Batch 87, Loss: 0.043171, Accuracy: 98.11%\n",
      "Batch 88, Loss: 0.021267, Accuracy: 98.14%\n",
      "Batch 89, Loss: 0.006655, Accuracy: 98.16%\n",
      "Batch 90, Loss: 0.001970, Accuracy: 98.18%\n",
      "Batch 91, Loss: 0.028076, Accuracy: 98.16%\n",
      "Batch 92, Loss: 0.005802, Accuracy: 98.18%\n",
      "Batch 93, Loss: 0.019682, Accuracy: 98.20%\n",
      "Batch 94, Loss: 0.001816, Accuracy: 98.22%\n",
      "Batch 95, Loss: 0.012937, Accuracy: 98.24%\n",
      "Batch 96, Loss: 0.002151, Accuracy: 98.26%\n",
      "Batch 97, Loss: 0.005058, Accuracy: 98.28%\n",
      "Batch 98, Loss: 0.002934, Accuracy: 98.29%\n",
      "Batch 99, Loss: 0.007774, Accuracy: 98.31%\n",
      "Batch 100, Loss: 0.002768, Accuracy: 98.33%\n",
      "Batch 101, Loss: 0.020834, Accuracy: 98.33%\n",
      "Batch 102, Loss: 0.002901, Accuracy: 98.35%\n",
      "Batch 103, Loss: 0.079671, Accuracy: 98.35%\n",
      "Batch 104, Loss: 0.001651, Accuracy: 98.36%\n",
      "Batch 105, Loss: 0.002486, Accuracy: 98.38%\n",
      "Batch 106, Loss: 0.005513, Accuracy: 98.39%\n",
      "Batch 107, Loss: 0.041935, Accuracy: 98.39%\n",
      "Batch 108, Loss: 0.001594, Accuracy: 98.41%\n",
      "Batch 109, Loss: 0.009842, Accuracy: 98.42%\n",
      "Batch 110, Loss: 0.005372, Accuracy: 98.44%\n",
      "Batch 111, Loss: 0.008307, Accuracy: 98.45%\n",
      "Batch 112, Loss: 0.042004, Accuracy: 98.45%\n",
      "Batch 113, Loss: 0.010507, Accuracy: 98.47%\n",
      "Batch 114, Loss: 0.007223, Accuracy: 98.48%\n",
      "Batch 115, Loss: 0.027794, Accuracy: 98.48%\n",
      "Batch 116, Loss: 0.009119, Accuracy: 98.49%\n",
      "Batch 117, Loss: 0.005735, Accuracy: 98.50%\n",
      "Batch 118, Loss: 0.097679, Accuracy: 98.50%\n",
      "Batch 119, Loss: 0.003694, Accuracy: 98.52%\n",
      "Batch 120, Loss: 0.005857, Accuracy: 98.53%\n",
      "Batch 121, Loss: 0.007370, Accuracy: 98.54%\n",
      "Batch 122, Loss: 0.041508, Accuracy: 98.53%\n",
      "Batch 123, Loss: 0.003208, Accuracy: 98.54%\n",
      "Batch 124, Loss: 0.001898, Accuracy: 98.55%\n",
      "Batch 125, Loss: 0.007246, Accuracy: 98.56%\n",
      "Batch 126, Loss: 0.015169, Accuracy: 98.56%\n",
      "Batch 127, Loss: 0.011613, Accuracy: 98.57%\n",
      "Batch 128, Loss: 0.001348, Accuracy: 98.58%\n",
      "Batch 129, Loss: 0.007995, Accuracy: 98.59%\n",
      "Batch 130, Loss: 0.079415, Accuracy: 98.59%\n",
      "Batch 131, Loss: 0.001281, Accuracy: 98.60%\n",
      "Batch 132, Loss: 0.002300, Accuracy: 98.62%\n",
      "Batch 133, Loss: 0.007797, Accuracy: 98.63%\n",
      "Batch 134, Loss: 0.001524, Accuracy: 98.64%\n",
      "Batch 135, Loss: 0.169063, Accuracy: 98.62%\n",
      "Batch 136, Loss: 0.007963, Accuracy: 98.63%\n",
      "Batch 137, Loss: 0.013134, Accuracy: 98.64%\n",
      "Batch 138, Loss: 0.001608, Accuracy: 98.65%\n",
      "Batch 139, Loss: 0.001273, Accuracy: 98.66%\n",
      "Batch 140, Loss: 0.050672, Accuracy: 98.66%\n",
      "Batch 141, Loss: 0.011950, Accuracy: 98.67%\n",
      "Batch 142, Loss: 0.001124, Accuracy: 98.68%\n",
      "Batch 143, Loss: 0.001954, Accuracy: 98.69%\n",
      "Batch 144, Loss: 0.007013, Accuracy: 98.70%\n",
      "Batch 145, Loss: 0.002773, Accuracy: 98.71%\n",
      "Batch 146, Loss: 0.005868, Accuracy: 98.72%\n",
      "Batch 147, Loss: 0.003489, Accuracy: 98.72%\n",
      "Batch 148, Loss: 0.002504, Accuracy: 98.73%\n",
      "Batch 149, Loss: 0.000830, Accuracy: 98.74%\n",
      "Batch 150, Loss: 0.002083, Accuracy: 98.75%\n",
      "Batch 151, Loss: 0.011776, Accuracy: 98.76%\n",
      "Batch 152, Loss: 0.002276, Accuracy: 98.77%\n",
      "Batch 153, Loss: 0.008215, Accuracy: 98.77%\n",
      "Batch 154, Loss: 0.004727, Accuracy: 98.78%\n",
      "Batch 155, Loss: 0.005480, Accuracy: 98.79%\n",
      "Batch 156, Loss: 0.067483, Accuracy: 98.79%\n",
      "Batch 157, Loss: 0.025745, Accuracy: 98.79%\n",
      "Batch 158, Loss: 0.001163, Accuracy: 98.79%\n",
      "Batch 159, Loss: 0.004186, Accuracy: 98.80%\n",
      "Batch 160, Loss: 0.001695, Accuracy: 98.81%\n",
      "Batch 161, Loss: 0.118219, Accuracy: 98.80%\n",
      "Batch 162, Loss: 0.056816, Accuracy: 98.79%\n",
      "Batch 163, Loss: 0.004532, Accuracy: 98.80%\n",
      "Batch 164, Loss: 0.002468, Accuracy: 98.81%\n",
      "Batch 165, Loss: 0.024261, Accuracy: 98.81%\n",
      "Batch 166, Loss: 0.054001, Accuracy: 98.80%\n",
      "Batch 167, Loss: 0.002250, Accuracy: 98.80%\n",
      "Batch 168, Loss: 0.026246, Accuracy: 98.80%\n",
      "Batch 169, Loss: 0.003451, Accuracy: 98.81%\n",
      "Batch 170, Loss: 0.017721, Accuracy: 98.81%\n",
      "Batch 171, Loss: 0.011144, Accuracy: 98.81%\n",
      "Batch 172, Loss: 0.034058, Accuracy: 98.81%\n",
      "Batch 173, Loss: 0.021895, Accuracy: 98.81%\n",
      "Batch 174, Loss: 0.009597, Accuracy: 98.81%\n",
      "Batch 175, Loss: 0.021563, Accuracy: 98.82%\n",
      "Batch 176, Loss: 0.002800, Accuracy: 98.83%\n",
      "Batch 177, Loss: 0.055966, Accuracy: 98.83%\n",
      "Batch 178, Loss: 0.224877, Accuracy: 98.80%\n",
      "Batch 179, Loss: 0.056476, Accuracy: 98.79%\n",
      "Batch 180, Loss: 0.155373, Accuracy: 98.78%\n",
      "Batch 181, Loss: 0.002708, Accuracy: 98.78%\n",
      "Batch 182, Loss: 0.060421, Accuracy: 98.78%\n",
      "Batch 183, Loss: 0.031306, Accuracy: 98.78%\n",
      "Batch 184, Loss: 0.221054, Accuracy: 98.75%\n",
      "Batch 185, Loss: 0.040041, Accuracy: 98.75%\n",
      "Batch 186, Loss: 0.008541, Accuracy: 98.76%\n",
      "Batch 187, Loss: 0.016799, Accuracy: 98.76%\n",
      "Batch 188, Loss: 0.044873, Accuracy: 98.75%\n",
      "Batch 189, Loss: 0.041692, Accuracy: 98.74%\n",
      "Batch 190, Loss: 0.001993, Accuracy: 98.75%\n",
      "Batch 191, Loss: 0.116969, Accuracy: 98.74%\n",
      "Batch 192, Loss: 0.092561, Accuracy: 98.73%\n",
      "Batch 193, Loss: 0.010493, Accuracy: 98.74%\n",
      "Batch 194, Loss: 0.010694, Accuracy: 98.74%\n",
      "Batch 195, Loss: 0.073876, Accuracy: 98.73%\n",
      "Batch 196, Loss: 0.003520, Accuracy: 98.73%\n",
      "Batch 197, Loss: 0.007615, Accuracy: 98.74%\n",
      "Batch 198, Loss: 0.053956, Accuracy: 98.74%\n",
      "Batch 199, Loss: 0.003591, Accuracy: 98.74%\n",
      "Batch 200, Loss: 0.012424, Accuracy: 98.75%\n",
      "Batch 201, Loss: 0.132022, Accuracy: 98.74%\n",
      "Batch 202, Loss: 0.050888, Accuracy: 98.74%\n",
      "Batch 203, Loss: 0.090706, Accuracy: 98.73%\n",
      "Batch 204, Loss: 0.002362, Accuracy: 98.74%\n",
      "Batch 205, Loss: 0.121921, Accuracy: 98.73%\n",
      "Batch 206, Loss: 0.147580, Accuracy: 98.71%\n",
      "Batch 207, Loss: 0.080295, Accuracy: 98.70%\n",
      "Batch 208, Loss: 0.159174, Accuracy: 98.69%\n",
      "Batch 209, Loss: 0.068410, Accuracy: 98.69%\n",
      "Batch 210, Loss: 0.062099, Accuracy: 98.68%\n",
      "Batch 211, Loss: 0.066129, Accuracy: 98.68%\n",
      "Batch 212, Loss: 0.073960, Accuracy: 98.68%\n",
      "Batch 213, Loss: 0.032157, Accuracy: 98.68%\n",
      "Training - Epoch 38, Loss: 0.040981, Accuracy: 98.68%\n",
      "Validation Batch 1, Loss: 0.004475, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.070004, Accuracy: 97.66%\n",
      "Validation Batch 3, Loss: 0.012170, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.053804, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.034521, Accuracy: 98.44%\n",
      "Validation Batch 6, Loss: 0.002937, Accuracy: 98.70%\n",
      "Validation Batch 7, Loss: 0.004671, Accuracy: 98.88%\n",
      "Validation Batch 8, Loss: 0.076200, Accuracy: 98.63%\n",
      "Validation Batch 9, Loss: 0.008096, Accuracy: 98.78%\n",
      "Validation Batch 10, Loss: 0.002607, Accuracy: 98.91%\n",
      "Validation Batch 11, Loss: 0.030415, Accuracy: 98.86%\n",
      "Validation Batch 12, Loss: 0.003073, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.089404, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.176358, Accuracy: 98.66%\n",
      "Validation Batch 15, Loss: 0.020485, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.035882, Accuracy: 98.63%\n",
      "Validation Batch 17, Loss: 0.002422, Accuracy: 98.71%\n",
      "Validation Batch 18, Loss: 0.006542, Accuracy: 98.78%\n",
      "Validation Batch 19, Loss: 0.055442, Accuracy: 98.77%\n",
      "Validation Batch 20, Loss: 0.053188, Accuracy: 98.75%\n",
      "Validation Batch 21, Loss: 0.033878, Accuracy: 98.74%\n",
      "Validation Batch 22, Loss: 0.006443, Accuracy: 98.79%\n",
      "Validation Batch 23, Loss: 0.037326, Accuracy: 98.78%\n",
      "Validation Batch 24, Loss: 0.093746, Accuracy: 98.76%\n",
      "Validation Batch 25, Loss: 0.045894, Accuracy: 98.75%\n",
      "Validation Batch 26, Loss: 0.113944, Accuracy: 98.68%\n",
      "Validation Batch 27, Loss: 0.003957, Accuracy: 98.71%\n",
      "Validation - Epoch 38, Loss: 0.039922, Accuracy: 98.71%\n",
      "Patience—2\n",
      "Epoch 39\n",
      "Batch 1, Loss: 0.025856, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.010349, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.005417, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.010907, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.050828, Accuracy: 99.06%\n",
      "Batch 6, Loss: 0.003349, Accuracy: 99.22%\n",
      "Batch 7, Loss: 0.016025, Accuracy: 99.11%\n",
      "Batch 8, Loss: 0.119511, Accuracy: 99.02%\n",
      "Batch 9, Loss: 0.116898, Accuracy: 98.61%\n",
      "Batch 10, Loss: 0.002428, Accuracy: 98.75%\n",
      "Batch 11, Loss: 0.002839, Accuracy: 98.86%\n",
      "Batch 12, Loss: 0.004933, Accuracy: 98.96%\n",
      "Batch 13, Loss: 0.003351, Accuracy: 99.04%\n",
      "Batch 14, Loss: 0.021808, Accuracy: 99.00%\n",
      "Batch 15, Loss: 0.028444, Accuracy: 99.06%\n",
      "Batch 16, Loss: 0.014646, Accuracy: 99.12%\n",
      "Batch 17, Loss: 0.017884, Accuracy: 99.08%\n",
      "Batch 18, Loss: 0.004296, Accuracy: 99.13%\n",
      "Batch 19, Loss: 0.029696, Accuracy: 99.10%\n",
      "Batch 20, Loss: 0.007853, Accuracy: 99.14%\n",
      "Batch 21, Loss: 0.002131, Accuracy: 99.18%\n",
      "Batch 22, Loss: 0.005317, Accuracy: 99.22%\n",
      "Batch 23, Loss: 0.002293, Accuracy: 99.25%\n",
      "Batch 24, Loss: 0.003629, Accuracy: 99.28%\n",
      "Batch 25, Loss: 0.020511, Accuracy: 99.25%\n",
      "Batch 26, Loss: 0.004991, Accuracy: 99.28%\n",
      "Batch 27, Loss: 0.067573, Accuracy: 99.25%\n",
      "Batch 28, Loss: 0.002838, Accuracy: 99.27%\n",
      "Batch 29, Loss: 0.005380, Accuracy: 99.30%\n",
      "Batch 30, Loss: 0.027224, Accuracy: 99.27%\n",
      "Batch 31, Loss: 0.002340, Accuracy: 99.29%\n",
      "Batch 32, Loss: 0.002374, Accuracy: 99.32%\n",
      "Batch 33, Loss: 0.041238, Accuracy: 99.29%\n",
      "Batch 34, Loss: 0.005358, Accuracy: 99.31%\n",
      "Batch 35, Loss: 0.002500, Accuracy: 99.33%\n",
      "Batch 36, Loss: 0.006546, Accuracy: 99.35%\n",
      "Batch 37, Loss: 0.001973, Accuracy: 99.37%\n",
      "Batch 38, Loss: 0.039990, Accuracy: 99.34%\n",
      "Batch 39, Loss: 0.010526, Accuracy: 99.36%\n",
      "Batch 40, Loss: 0.016225, Accuracy: 99.38%\n",
      "Batch 41, Loss: 0.003072, Accuracy: 99.39%\n",
      "Batch 42, Loss: 0.002365, Accuracy: 99.40%\n",
      "Batch 43, Loss: 0.017968, Accuracy: 99.42%\n",
      "Batch 44, Loss: 0.003608, Accuracy: 99.43%\n",
      "Batch 45, Loss: 0.040520, Accuracy: 99.38%\n",
      "Batch 46, Loss: 0.014589, Accuracy: 99.39%\n",
      "Batch 47, Loss: 0.006105, Accuracy: 99.40%\n",
      "Batch 48, Loss: 0.001041, Accuracy: 99.41%\n",
      "Batch 49, Loss: 0.002214, Accuracy: 99.43%\n",
      "Batch 50, Loss: 0.002451, Accuracy: 99.44%\n",
      "Batch 51, Loss: 0.003328, Accuracy: 99.45%\n",
      "Batch 52, Loss: 0.044980, Accuracy: 99.43%\n",
      "Batch 53, Loss: 0.006380, Accuracy: 99.44%\n",
      "Batch 54, Loss: 0.031488, Accuracy: 99.42%\n",
      "Batch 55, Loss: 0.001058, Accuracy: 99.43%\n",
      "Batch 56, Loss: 0.001867, Accuracy: 99.44%\n",
      "Batch 57, Loss: 0.003062, Accuracy: 99.45%\n",
      "Batch 58, Loss: 0.005537, Accuracy: 99.46%\n",
      "Batch 59, Loss: 0.002228, Accuracy: 99.47%\n",
      "Batch 60, Loss: 0.004082, Accuracy: 99.48%\n",
      "Batch 61, Loss: 0.002059, Accuracy: 99.49%\n",
      "Batch 62, Loss: 0.037903, Accuracy: 99.47%\n",
      "Batch 63, Loss: 0.002392, Accuracy: 99.48%\n",
      "Batch 64, Loss: 0.013945, Accuracy: 99.46%\n",
      "Batch 65, Loss: 0.016064, Accuracy: 99.47%\n",
      "Batch 66, Loss: 0.014849, Accuracy: 99.48%\n",
      "Batch 67, Loss: 0.021548, Accuracy: 99.46%\n",
      "Batch 68, Loss: 0.006283, Accuracy: 99.47%\n",
      "Batch 69, Loss: 0.010895, Accuracy: 99.48%\n",
      "Batch 70, Loss: 0.005616, Accuracy: 99.49%\n",
      "Batch 71, Loss: 0.001153, Accuracy: 99.49%\n",
      "Batch 72, Loss: 0.001165, Accuracy: 99.50%\n",
      "Batch 73, Loss: 0.001601, Accuracy: 99.51%\n",
      "Batch 74, Loss: 0.006886, Accuracy: 99.51%\n",
      "Batch 75, Loss: 0.006035, Accuracy: 99.52%\n",
      "Batch 76, Loss: 0.018764, Accuracy: 99.51%\n",
      "Batch 77, Loss: 0.001033, Accuracy: 99.51%\n",
      "Batch 78, Loss: 0.001161, Accuracy: 99.52%\n",
      "Batch 79, Loss: 0.001887, Accuracy: 99.53%\n",
      "Batch 80, Loss: 0.001068, Accuracy: 99.53%\n",
      "Batch 81, Loss: 0.002804, Accuracy: 99.54%\n",
      "Batch 82, Loss: 0.005191, Accuracy: 99.54%\n",
      "Batch 83, Loss: 0.001449, Accuracy: 99.55%\n",
      "Batch 84, Loss: 0.002879, Accuracy: 99.55%\n",
      "Batch 85, Loss: 0.003370, Accuracy: 99.56%\n",
      "Batch 86, Loss: 0.003433, Accuracy: 99.56%\n",
      "Batch 87, Loss: 0.001902, Accuracy: 99.57%\n",
      "Batch 88, Loss: 0.008255, Accuracy: 99.57%\n",
      "Batch 89, Loss: 0.046562, Accuracy: 99.56%\n",
      "Batch 90, Loss: 0.001866, Accuracy: 99.57%\n",
      "Batch 91, Loss: 0.002651, Accuracy: 99.57%\n",
      "Batch 92, Loss: 0.001980, Accuracy: 99.58%\n",
      "Batch 93, Loss: 0.001184, Accuracy: 99.58%\n",
      "Batch 94, Loss: 0.044868, Accuracy: 99.57%\n",
      "Batch 95, Loss: 0.001522, Accuracy: 99.57%\n",
      "Batch 96, Loss: 0.004529, Accuracy: 99.58%\n",
      "Batch 97, Loss: 0.002140, Accuracy: 99.58%\n",
      "Batch 98, Loss: 0.001419, Accuracy: 99.59%\n",
      "Batch 99, Loss: 0.002668, Accuracy: 99.59%\n",
      "Batch 100, Loss: 0.032634, Accuracy: 99.58%\n",
      "Batch 101, Loss: 0.000926, Accuracy: 99.58%\n",
      "Batch 102, Loss: 0.002876, Accuracy: 99.59%\n",
      "Batch 103, Loss: 0.018580, Accuracy: 99.58%\n",
      "Batch 104, Loss: 0.002392, Accuracy: 99.58%\n",
      "Batch 105, Loss: 0.002546, Accuracy: 99.58%\n",
      "Batch 106, Loss: 0.000825, Accuracy: 99.59%\n",
      "Batch 107, Loss: 0.001104, Accuracy: 99.59%\n",
      "Batch 108, Loss: 0.000921, Accuracy: 99.59%\n",
      "Batch 109, Loss: 0.004335, Accuracy: 99.60%\n",
      "Batch 110, Loss: 0.001049, Accuracy: 99.60%\n",
      "Batch 111, Loss: 0.006901, Accuracy: 99.61%\n",
      "Batch 112, Loss: 0.000807, Accuracy: 99.61%\n",
      "Batch 113, Loss: 0.000877, Accuracy: 99.61%\n",
      "Batch 114, Loss: 0.001216, Accuracy: 99.62%\n",
      "Batch 115, Loss: 0.001155, Accuracy: 99.62%\n",
      "Batch 116, Loss: 0.002994, Accuracy: 99.62%\n",
      "Batch 117, Loss: 0.006452, Accuracy: 99.63%\n",
      "Batch 118, Loss: 0.003782, Accuracy: 99.63%\n",
      "Batch 119, Loss: 0.005790, Accuracy: 99.63%\n",
      "Batch 120, Loss: 0.010727, Accuracy: 99.64%\n",
      "Batch 121, Loss: 0.001753, Accuracy: 99.64%\n",
      "Batch 122, Loss: 0.002393, Accuracy: 99.64%\n",
      "Batch 123, Loss: 0.000990, Accuracy: 99.64%\n",
      "Batch 124, Loss: 0.001163, Accuracy: 99.65%\n",
      "Batch 125, Loss: 0.004732, Accuracy: 99.65%\n",
      "Batch 126, Loss: 0.000845, Accuracy: 99.65%\n",
      "Batch 127, Loss: 0.001080, Accuracy: 99.66%\n",
      "Batch 128, Loss: 0.001295, Accuracy: 99.66%\n",
      "Batch 129, Loss: 0.002512, Accuracy: 99.66%\n",
      "Batch 130, Loss: 0.001077, Accuracy: 99.66%\n",
      "Batch 131, Loss: 0.000735, Accuracy: 99.67%\n",
      "Batch 132, Loss: 0.003351, Accuracy: 99.67%\n",
      "Batch 133, Loss: 0.001574, Accuracy: 99.67%\n",
      "Batch 134, Loss: 0.036810, Accuracy: 99.66%\n",
      "Batch 135, Loss: 0.007097, Accuracy: 99.66%\n",
      "Batch 136, Loss: 0.001013, Accuracy: 99.67%\n",
      "Batch 137, Loss: 0.001419, Accuracy: 99.67%\n",
      "Batch 138, Loss: 0.002073, Accuracy: 99.67%\n",
      "Batch 139, Loss: 0.001734, Accuracy: 99.67%\n",
      "Batch 140, Loss: 0.005896, Accuracy: 99.68%\n",
      "Batch 141, Loss: 0.002019, Accuracy: 99.68%\n",
      "Batch 142, Loss: 0.001767, Accuracy: 99.68%\n",
      "Batch 143, Loss: 0.005819, Accuracy: 99.68%\n",
      "Batch 144, Loss: 0.001438, Accuracy: 99.69%\n",
      "Batch 145, Loss: 0.001797, Accuracy: 99.69%\n",
      "Batch 146, Loss: 0.001102, Accuracy: 99.69%\n",
      "Batch 147, Loss: 0.001114, Accuracy: 99.69%\n",
      "Batch 148, Loss: 0.030924, Accuracy: 99.67%\n",
      "Batch 149, Loss: 0.001651, Accuracy: 99.67%\n",
      "Batch 150, Loss: 0.004039, Accuracy: 99.68%\n",
      "Batch 151, Loss: 0.000754, Accuracy: 99.68%\n",
      "Batch 152, Loss: 0.000935, Accuracy: 99.68%\n",
      "Batch 153, Loss: 0.022547, Accuracy: 99.67%\n",
      "Batch 154, Loss: 0.000714, Accuracy: 99.68%\n",
      "Batch 155, Loss: 0.000731, Accuracy: 99.68%\n",
      "Batch 156, Loss: 0.001090, Accuracy: 99.68%\n",
      "Batch 157, Loss: 0.001008, Accuracy: 99.68%\n",
      "Batch 158, Loss: 0.004780, Accuracy: 99.68%\n",
      "Batch 159, Loss: 0.008554, Accuracy: 99.69%\n",
      "Batch 160, Loss: 0.002572, Accuracy: 99.69%\n",
      "Batch 161, Loss: 0.002299, Accuracy: 99.69%\n",
      "Batch 162, Loss: 0.019232, Accuracy: 99.68%\n",
      "Batch 163, Loss: 0.009770, Accuracy: 99.68%\n",
      "Batch 164, Loss: 0.001107, Accuracy: 99.69%\n",
      "Batch 165, Loss: 0.001053, Accuracy: 99.69%\n",
      "Batch 166, Loss: 0.000711, Accuracy: 99.69%\n",
      "Batch 167, Loss: 0.001043, Accuracy: 99.69%\n",
      "Batch 168, Loss: 0.001395, Accuracy: 99.69%\n",
      "Batch 169, Loss: 0.009373, Accuracy: 99.69%\n",
      "Batch 170, Loss: 0.003159, Accuracy: 99.70%\n",
      "Batch 171, Loss: 0.004303, Accuracy: 99.70%\n",
      "Batch 172, Loss: 0.001773, Accuracy: 99.70%\n",
      "Batch 173, Loss: 0.001535, Accuracy: 99.70%\n",
      "Batch 174, Loss: 0.002755, Accuracy: 99.70%\n",
      "Batch 175, Loss: 0.064460, Accuracy: 99.70%\n",
      "Batch 176, Loss: 0.000976, Accuracy: 99.70%\n",
      "Batch 177, Loss: 0.022879, Accuracy: 99.69%\n",
      "Batch 178, Loss: 0.002215, Accuracy: 99.69%\n",
      "Batch 179, Loss: 0.003724, Accuracy: 99.69%\n",
      "Batch 180, Loss: 0.014441, Accuracy: 99.69%\n",
      "Batch 181, Loss: 0.002111, Accuracy: 99.69%\n",
      "Batch 182, Loss: 0.007630, Accuracy: 99.69%\n",
      "Batch 183, Loss: 0.001788, Accuracy: 99.69%\n",
      "Batch 184, Loss: 0.000803, Accuracy: 99.69%\n",
      "Batch 185, Loss: 0.001374, Accuracy: 99.70%\n",
      "Batch 186, Loss: 0.007301, Accuracy: 99.70%\n",
      "Batch 187, Loss: 0.001718, Accuracy: 99.70%\n",
      "Batch 188, Loss: 0.001162, Accuracy: 99.70%\n",
      "Batch 189, Loss: 0.000959, Accuracy: 99.70%\n",
      "Batch 190, Loss: 0.001253, Accuracy: 99.70%\n",
      "Batch 191, Loss: 0.001062, Accuracy: 99.71%\n",
      "Batch 192, Loss: 0.000693, Accuracy: 99.71%\n",
      "Batch 193, Loss: 0.001601, Accuracy: 99.71%\n",
      "Batch 194, Loss: 0.001056, Accuracy: 99.71%\n",
      "Batch 195, Loss: 0.000794, Accuracy: 99.71%\n",
      "Batch 196, Loss: 0.000972, Accuracy: 99.71%\n",
      "Batch 197, Loss: 0.001211, Accuracy: 99.71%\n",
      "Batch 198, Loss: 0.002374, Accuracy: 99.72%\n",
      "Batch 199, Loss: 0.002060, Accuracy: 99.72%\n",
      "Batch 200, Loss: 0.004058, Accuracy: 99.72%\n",
      "Batch 201, Loss: 0.001205, Accuracy: 99.72%\n",
      "Batch 202, Loss: 0.001167, Accuracy: 99.72%\n",
      "Batch 203, Loss: 0.006819, Accuracy: 99.72%\n",
      "Batch 204, Loss: 0.012372, Accuracy: 99.72%\n",
      "Batch 205, Loss: 0.000747, Accuracy: 99.72%\n",
      "Batch 206, Loss: 0.000745, Accuracy: 99.72%\n",
      "Batch 207, Loss: 0.000607, Accuracy: 99.72%\n",
      "Batch 208, Loss: 0.001174, Accuracy: 99.72%\n",
      "Batch 209, Loss: 0.000688, Accuracy: 99.72%\n",
      "Batch 210, Loss: 0.008523, Accuracy: 99.72%\n",
      "Batch 211, Loss: 0.000829, Accuracy: 99.73%\n",
      "Batch 212, Loss: 0.000773, Accuracy: 99.73%\n",
      "Batch 213, Loss: 0.000952, Accuracy: 99.73%\n",
      "Training - Epoch 39, Loss: 0.008497, Accuracy: 99.73%\n",
      "Validation Batch 1, Loss: 0.013058, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.001353, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.003690, Accuracy: 99.48%\n",
      "Validation Batch 4, Loss: 0.000925, Accuracy: 99.61%\n",
      "Validation Batch 5, Loss: 0.001659, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.000571, Accuracy: 99.74%\n",
      "Validation Batch 7, Loss: 0.000848, Accuracy: 99.78%\n",
      "Validation Batch 8, Loss: 0.014734, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.001167, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.000658, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.054082, Accuracy: 99.57%\n",
      "Validation Batch 12, Loss: 0.001379, Accuracy: 99.61%\n",
      "Validation Batch 13, Loss: 0.001484, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.005740, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.000844, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.041630, Accuracy: 99.61%\n",
      "Validation Batch 17, Loss: 0.002656, Accuracy: 99.63%\n",
      "Validation Batch 18, Loss: 0.001092, Accuracy: 99.65%\n",
      "Validation Batch 19, Loss: 0.002793, Accuracy: 99.67%\n",
      "Validation Batch 20, Loss: 0.001194, Accuracy: 99.69%\n",
      "Validation Batch 21, Loss: 0.002002, Accuracy: 99.70%\n",
      "Validation Batch 22, Loss: 0.007531, Accuracy: 99.72%\n",
      "Validation Batch 23, Loss: 0.006400, Accuracy: 99.73%\n",
      "Validation Batch 24, Loss: 0.064941, Accuracy: 99.67%\n",
      "Validation Batch 25, Loss: 0.000638, Accuracy: 99.69%\n",
      "Validation Batch 26, Loss: 0.054955, Accuracy: 99.64%\n",
      "Validation Batch 27, Loss: 0.003186, Accuracy: 99.65%\n",
      "Validation - Epoch 39, Loss: 0.010785, Accuracy: 99.65%\n",
      "Patience—3\n",
      "Epoch 40\n",
      "Batch 1, Loss: 0.000753, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000575, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000640, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000808, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000716, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000958, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000701, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000664, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000558, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.015245, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000870, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000648, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000594, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.001082, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000750, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000805, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000584, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.001460, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.001743, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000645, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000549, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000603, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000544, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.002733, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000810, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000886, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000629, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000450, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000859, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000656, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.001435, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000540, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000523, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000591, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000537, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000705, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000859, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000633, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000574, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.001191, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000619, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000825, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000580, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000621, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000547, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.001069, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.001207, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000585, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000759, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000713, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000529, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000396, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000397, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000781, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000599, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000623, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000888, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000497, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000764, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000560, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000702, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000626, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.001188, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000636, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.001093, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000873, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.001002, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000630, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.001442, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000717, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.001246, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000562, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000616, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000431, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000476, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000484, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.001271, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000600, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000706, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.002475, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000597, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000722, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000597, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000620, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000658, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000629, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000811, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000488, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000988, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000491, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.001582, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.001796, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.001855, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000675, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000535, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000453, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000509, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000479, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000563, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000684, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.003315, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000733, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000533, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000947, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000508, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.001312, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000704, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000433, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000530, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000595, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000700, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.035143, Accuracy: 99.99%\n",
      "Batch 114, Loss: 0.000459, Accuracy: 99.99%\n",
      "Batch 115, Loss: 0.000565, Accuracy: 99.99%\n",
      "Batch 116, Loss: 0.000522, Accuracy: 99.99%\n",
      "Batch 117, Loss: 0.000440, Accuracy: 99.99%\n",
      "Batch 118, Loss: 0.000474, Accuracy: 99.99%\n",
      "Batch 119, Loss: 0.001199, Accuracy: 99.99%\n",
      "Batch 120, Loss: 0.000606, Accuracy: 99.99%\n",
      "Batch 121, Loss: 0.000476, Accuracy: 99.99%\n",
      "Batch 122, Loss: 0.000671, Accuracy: 99.99%\n",
      "Batch 123, Loss: 0.000844, Accuracy: 99.99%\n",
      "Batch 124, Loss: 0.001883, Accuracy: 99.99%\n",
      "Batch 125, Loss: 0.002050, Accuracy: 99.99%\n",
      "Batch 126, Loss: 0.000646, Accuracy: 99.99%\n",
      "Batch 127, Loss: 0.000603, Accuracy: 99.99%\n",
      "Batch 128, Loss: 0.000929, Accuracy: 99.99%\n",
      "Batch 129, Loss: 0.005941, Accuracy: 99.99%\n",
      "Batch 130, Loss: 0.018093, Accuracy: 99.99%\n",
      "Batch 131, Loss: 0.003427, Accuracy: 99.99%\n",
      "Batch 132, Loss: 0.001017, Accuracy: 99.99%\n",
      "Batch 133, Loss: 0.002497, Accuracy: 99.99%\n",
      "Batch 134, Loss: 0.014939, Accuracy: 99.98%\n",
      "Batch 135, Loss: 0.005890, Accuracy: 99.98%\n",
      "Batch 136, Loss: 0.003651, Accuracy: 99.98%\n",
      "Batch 137, Loss: 0.005997, Accuracy: 99.98%\n",
      "Batch 138, Loss: 0.001072, Accuracy: 99.98%\n",
      "Batch 139, Loss: 0.004551, Accuracy: 99.98%\n",
      "Batch 140, Loss: 0.005839, Accuracy: 99.98%\n",
      "Batch 141, Loss: 0.000903, Accuracy: 99.98%\n",
      "Batch 142, Loss: 0.001243, Accuracy: 99.98%\n",
      "Batch 143, Loss: 0.001509, Accuracy: 99.98%\n",
      "Batch 144, Loss: 0.001394, Accuracy: 99.98%\n",
      "Batch 145, Loss: 0.012438, Accuracy: 99.97%\n",
      "Batch 146, Loss: 0.022635, Accuracy: 99.96%\n",
      "Batch 147, Loss: 0.000778, Accuracy: 99.96%\n",
      "Batch 148, Loss: 0.050451, Accuracy: 99.95%\n",
      "Batch 149, Loss: 0.000670, Accuracy: 99.95%\n",
      "Batch 150, Loss: 0.005268, Accuracy: 99.95%\n",
      "Batch 151, Loss: 0.001183, Accuracy: 99.95%\n",
      "Batch 152, Loss: 0.000959, Accuracy: 99.95%\n",
      "Batch 153, Loss: 0.000883, Accuracy: 99.95%\n",
      "Batch 154, Loss: 0.000591, Accuracy: 99.95%\n",
      "Batch 155, Loss: 0.001226, Accuracy: 99.95%\n",
      "Batch 156, Loss: 0.000908, Accuracy: 99.95%\n",
      "Batch 157, Loss: 0.000952, Accuracy: 99.95%\n",
      "Batch 158, Loss: 0.000914, Accuracy: 99.95%\n",
      "Batch 159, Loss: 0.000829, Accuracy: 99.95%\n",
      "Batch 160, Loss: 0.038945, Accuracy: 99.94%\n",
      "Batch 161, Loss: 0.002380, Accuracy: 99.94%\n",
      "Batch 162, Loss: 0.004536, Accuracy: 99.94%\n",
      "Batch 163, Loss: 0.004008, Accuracy: 99.94%\n",
      "Batch 164, Loss: 0.002103, Accuracy: 99.94%\n",
      "Batch 165, Loss: 0.000624, Accuracy: 99.94%\n",
      "Batch 166, Loss: 0.003162, Accuracy: 99.94%\n",
      "Batch 167, Loss: 0.000603, Accuracy: 99.94%\n",
      "Batch 168, Loss: 0.001083, Accuracy: 99.94%\n",
      "Batch 169, Loss: 0.000693, Accuracy: 99.94%\n",
      "Batch 170, Loss: 0.021544, Accuracy: 99.94%\n",
      "Batch 171, Loss: 0.000505, Accuracy: 99.94%\n",
      "Batch 172, Loss: 0.000629, Accuracy: 99.94%\n",
      "Batch 173, Loss: 0.002189, Accuracy: 99.94%\n",
      "Batch 174, Loss: 0.001893, Accuracy: 99.94%\n",
      "Batch 175, Loss: 0.001482, Accuracy: 99.94%\n",
      "Batch 176, Loss: 0.001082, Accuracy: 99.94%\n",
      "Batch 177, Loss: 0.000928, Accuracy: 99.94%\n",
      "Batch 178, Loss: 0.001252, Accuracy: 99.94%\n",
      "Batch 179, Loss: 0.013828, Accuracy: 99.93%\n",
      "Batch 180, Loss: 0.000802, Accuracy: 99.93%\n",
      "Batch 181, Loss: 0.002998, Accuracy: 99.93%\n",
      "Batch 182, Loss: 0.004791, Accuracy: 99.93%\n",
      "Batch 183, Loss: 0.020031, Accuracy: 99.92%\n",
      "Batch 184, Loss: 0.001060, Accuracy: 99.92%\n",
      "Batch 185, Loss: 0.001334, Accuracy: 99.92%\n",
      "Batch 186, Loss: 0.000510, Accuracy: 99.92%\n",
      "Batch 187, Loss: 0.000474, Accuracy: 99.92%\n",
      "Batch 188, Loss: 0.000603, Accuracy: 99.93%\n",
      "Batch 189, Loss: 0.001366, Accuracy: 99.93%\n",
      "Batch 190, Loss: 0.002927, Accuracy: 99.93%\n",
      "Batch 191, Loss: 0.007173, Accuracy: 99.93%\n",
      "Batch 192, Loss: 0.000579, Accuracy: 99.93%\n",
      "Batch 193, Loss: 0.007061, Accuracy: 99.93%\n",
      "Batch 194, Loss: 0.000608, Accuracy: 99.93%\n",
      "Batch 195, Loss: 0.004315, Accuracy: 99.93%\n",
      "Batch 196, Loss: 0.000462, Accuracy: 99.93%\n",
      "Batch 197, Loss: 0.000469, Accuracy: 99.93%\n",
      "Batch 198, Loss: 0.002696, Accuracy: 99.93%\n",
      "Batch 199, Loss: 0.000732, Accuracy: 99.93%\n",
      "Batch 200, Loss: 0.000560, Accuracy: 99.93%\n",
      "Batch 201, Loss: 0.000888, Accuracy: 99.93%\n",
      "Batch 202, Loss: 0.000643, Accuracy: 99.93%\n",
      "Batch 203, Loss: 0.000929, Accuracy: 99.93%\n",
      "Batch 204, Loss: 0.000631, Accuracy: 99.93%\n",
      "Batch 205, Loss: 0.000652, Accuracy: 99.93%\n",
      "Batch 206, Loss: 0.038861, Accuracy: 99.92%\n",
      "Batch 207, Loss: 0.001609, Accuracy: 99.92%\n",
      "Batch 208, Loss: 0.000514, Accuracy: 99.92%\n",
      "Batch 209, Loss: 0.001034, Accuracy: 99.93%\n",
      "Batch 210, Loss: 0.000997, Accuracy: 99.93%\n",
      "Batch 211, Loss: 0.000997, Accuracy: 99.93%\n",
      "Batch 212, Loss: 0.000654, Accuracy: 99.93%\n",
      "Batch 213, Loss: 0.000964, Accuracy: 99.93%\n",
      "Training - Epoch 40, Loss: 0.002561, Accuracy: 99.93%\n",
      "Validation Batch 1, Loss: 0.001148, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.045982, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.134045, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.005126, Accuracy: 98.83%\n",
      "Validation Batch 5, Loss: 0.127284, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.001324, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.000800, Accuracy: 99.11%\n",
      "Validation Batch 8, Loss: 0.024751, Accuracy: 99.02%\n",
      "Validation Batch 9, Loss: 0.019510, Accuracy: 98.96%\n",
      "Validation Batch 10, Loss: 0.001353, Accuracy: 99.06%\n",
      "Validation Batch 11, Loss: 0.183641, Accuracy: 98.86%\n",
      "Validation Batch 12, Loss: 0.050522, Accuracy: 98.83%\n",
      "Validation Batch 13, Loss: 0.094584, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.062562, Accuracy: 98.55%\n",
      "Validation Batch 15, Loss: 0.076799, Accuracy: 98.54%\n",
      "Validation Batch 16, Loss: 0.038344, Accuracy: 98.54%\n",
      "Validation Batch 17, Loss: 0.002093, Accuracy: 98.62%\n",
      "Validation Batch 18, Loss: 0.019829, Accuracy: 98.61%\n",
      "Validation Batch 19, Loss: 0.107555, Accuracy: 98.60%\n",
      "Validation Batch 20, Loss: 0.070435, Accuracy: 98.59%\n",
      "Validation Batch 21, Loss: 0.044315, Accuracy: 98.59%\n",
      "Validation Batch 22, Loss: 0.005329, Accuracy: 98.65%\n",
      "Validation Batch 23, Loss: 0.119777, Accuracy: 98.57%\n",
      "Validation Batch 24, Loss: 0.084788, Accuracy: 98.57%\n",
      "Validation Batch 25, Loss: 0.001358, Accuracy: 98.62%\n",
      "Validation Batch 26, Loss: 0.002500, Accuracy: 98.68%\n",
      "Validation Batch 27, Loss: 0.000680, Accuracy: 98.71%\n",
      "Validation - Epoch 40, Loss: 0.049127, Accuracy: 98.71%\n",
      "Patience—4\n",
      "Epoch 41\n",
      "Batch 1, Loss: 0.000698, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000987, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.074513, Accuracy: 98.96%\n",
      "Batch 4, Loss: 0.151894, Accuracy: 98.05%\n",
      "Batch 5, Loss: 0.001021, Accuracy: 98.44%\n",
      "Batch 6, Loss: 0.005164, Accuracy: 98.70%\n",
      "Batch 7, Loss: 0.000830, Accuracy: 98.88%\n",
      "Batch 8, Loss: 0.007047, Accuracy: 99.02%\n",
      "Batch 9, Loss: 0.025569, Accuracy: 98.96%\n",
      "Batch 10, Loss: 0.167024, Accuracy: 98.28%\n",
      "Batch 11, Loss: 0.001682, Accuracy: 98.44%\n",
      "Batch 12, Loss: 0.003545, Accuracy: 98.57%\n",
      "Batch 13, Loss: 0.007490, Accuracy: 98.68%\n",
      "Batch 14, Loss: 0.051678, Accuracy: 98.66%\n",
      "Batch 15, Loss: 0.119495, Accuracy: 98.54%\n",
      "Batch 16, Loss: 0.035005, Accuracy: 98.44%\n",
      "Batch 17, Loss: 0.015923, Accuracy: 98.44%\n",
      "Batch 18, Loss: 0.083377, Accuracy: 98.44%\n",
      "Batch 19, Loss: 0.184640, Accuracy: 98.11%\n",
      "Batch 20, Loss: 0.034959, Accuracy: 98.12%\n",
      "Batch 21, Loss: 0.001691, Accuracy: 98.21%\n",
      "Batch 22, Loss: 0.002864, Accuracy: 98.30%\n",
      "Batch 23, Loss: 0.057807, Accuracy: 98.30%\n",
      "Batch 24, Loss: 0.009775, Accuracy: 98.37%\n",
      "Batch 25, Loss: 0.289900, Accuracy: 97.94%\n",
      "Batch 26, Loss: 0.079728, Accuracy: 97.84%\n",
      "Batch 27, Loss: 0.062068, Accuracy: 97.80%\n",
      "Batch 28, Loss: 0.016722, Accuracy: 97.88%\n",
      "Batch 29, Loss: 0.127686, Accuracy: 97.79%\n",
      "Batch 30, Loss: 0.016527, Accuracy: 97.86%\n",
      "Batch 31, Loss: 0.012785, Accuracy: 97.93%\n",
      "Batch 32, Loss: 0.039892, Accuracy: 97.95%\n",
      "Batch 33, Loss: 0.065634, Accuracy: 97.92%\n",
      "Batch 34, Loss: 0.102971, Accuracy: 97.84%\n",
      "Batch 35, Loss: 0.120119, Accuracy: 97.72%\n",
      "Batch 36, Loss: 0.096624, Accuracy: 97.70%\n",
      "Batch 37, Loss: 0.132731, Accuracy: 97.72%\n",
      "Batch 38, Loss: 0.148694, Accuracy: 97.70%\n",
      "Batch 39, Loss: 0.119336, Accuracy: 97.72%\n",
      "Batch 40, Loss: 0.147626, Accuracy: 97.70%\n",
      "Batch 41, Loss: 0.037734, Accuracy: 97.71%\n",
      "Batch 42, Loss: 0.001796, Accuracy: 97.77%\n",
      "Batch 43, Loss: 0.005848, Accuracy: 97.82%\n",
      "Batch 44, Loss: 0.079570, Accuracy: 97.80%\n",
      "Batch 45, Loss: 0.007740, Accuracy: 97.85%\n",
      "Batch 46, Loss: 0.031611, Accuracy: 97.86%\n",
      "Batch 47, Loss: 0.063636, Accuracy: 97.87%\n",
      "Batch 48, Loss: 0.082672, Accuracy: 97.85%\n",
      "Batch 49, Loss: 0.005254, Accuracy: 97.90%\n",
      "Batch 50, Loss: 0.087796, Accuracy: 97.91%\n",
      "Batch 51, Loss: 0.158920, Accuracy: 97.82%\n",
      "Batch 52, Loss: 0.008607, Accuracy: 97.87%\n",
      "Batch 53, Loss: 0.025609, Accuracy: 97.88%\n",
      "Batch 54, Loss: 0.020029, Accuracy: 97.92%\n",
      "Batch 55, Loss: 0.018482, Accuracy: 97.95%\n",
      "Batch 56, Loss: 0.104666, Accuracy: 97.94%\n",
      "Batch 57, Loss: 0.021221, Accuracy: 97.97%\n",
      "Batch 58, Loss: 0.019626, Accuracy: 98.01%\n",
      "Batch 59, Loss: 0.054089, Accuracy: 97.99%\n",
      "Batch 60, Loss: 0.006157, Accuracy: 98.02%\n",
      "Batch 61, Loss: 0.005672, Accuracy: 98.05%\n",
      "Batch 62, Loss: 0.034324, Accuracy: 98.06%\n",
      "Batch 63, Loss: 0.074008, Accuracy: 98.02%\n",
      "Batch 64, Loss: 0.011701, Accuracy: 98.05%\n",
      "Batch 65, Loss: 0.007142, Accuracy: 98.08%\n",
      "Batch 66, Loss: 0.036428, Accuracy: 98.08%\n",
      "Batch 67, Loss: 0.071368, Accuracy: 98.09%\n",
      "Batch 68, Loss: 0.016639, Accuracy: 98.12%\n",
      "Batch 69, Loss: 0.006615, Accuracy: 98.14%\n",
      "Batch 70, Loss: 0.124448, Accuracy: 98.12%\n",
      "Batch 71, Loss: 0.024719, Accuracy: 98.13%\n",
      "Batch 72, Loss: 0.006360, Accuracy: 98.16%\n",
      "Batch 73, Loss: 0.006046, Accuracy: 98.18%\n",
      "Batch 74, Loss: 0.002424, Accuracy: 98.21%\n",
      "Batch 75, Loss: 0.045582, Accuracy: 98.21%\n",
      "Batch 76, Loss: 0.015213, Accuracy: 98.21%\n",
      "Batch 77, Loss: 0.049222, Accuracy: 98.21%\n",
      "Batch 78, Loss: 0.006351, Accuracy: 98.24%\n",
      "Batch 79, Loss: 0.067292, Accuracy: 98.22%\n",
      "Batch 80, Loss: 0.044545, Accuracy: 98.22%\n",
      "Batch 81, Loss: 0.064187, Accuracy: 98.23%\n",
      "Batch 82, Loss: 0.002376, Accuracy: 98.25%\n",
      "Batch 83, Loss: 0.012214, Accuracy: 98.27%\n",
      "Batch 84, Loss: 0.020705, Accuracy: 98.27%\n",
      "Batch 85, Loss: 0.016733, Accuracy: 98.27%\n",
      "Batch 86, Loss: 0.003814, Accuracy: 98.29%\n",
      "Batch 87, Loss: 0.029018, Accuracy: 98.29%\n",
      "Batch 88, Loss: 0.010350, Accuracy: 98.31%\n",
      "Batch 89, Loss: 0.009946, Accuracy: 98.33%\n",
      "Batch 90, Loss: 0.009284, Accuracy: 98.35%\n",
      "Batch 91, Loss: 0.026210, Accuracy: 98.35%\n",
      "Batch 92, Loss: 0.035273, Accuracy: 98.35%\n",
      "Batch 93, Loss: 0.011264, Accuracy: 98.37%\n",
      "Batch 94, Loss: 0.001872, Accuracy: 98.39%\n",
      "Batch 95, Loss: 0.002028, Accuracy: 98.40%\n",
      "Batch 96, Loss: 0.096840, Accuracy: 98.39%\n",
      "Batch 97, Loss: 0.003959, Accuracy: 98.41%\n",
      "Batch 98, Loss: 0.003868, Accuracy: 98.42%\n",
      "Batch 99, Loss: 0.003784, Accuracy: 98.44%\n",
      "Batch 100, Loss: 0.033644, Accuracy: 98.44%\n",
      "Batch 101, Loss: 0.009625, Accuracy: 98.45%\n",
      "Batch 102, Loss: 0.079695, Accuracy: 98.45%\n",
      "Batch 103, Loss: 0.090859, Accuracy: 98.41%\n",
      "Batch 104, Loss: 0.041184, Accuracy: 98.39%\n",
      "Batch 105, Loss: 0.021778, Accuracy: 98.39%\n",
      "Batch 106, Loss: 0.004333, Accuracy: 98.41%\n",
      "Batch 107, Loss: 0.077734, Accuracy: 98.39%\n",
      "Batch 108, Loss: 0.061227, Accuracy: 98.39%\n",
      "Batch 109, Loss: 0.066618, Accuracy: 98.39%\n",
      "Batch 110, Loss: 0.058634, Accuracy: 98.38%\n",
      "Batch 111, Loss: 0.002408, Accuracy: 98.40%\n",
      "Batch 112, Loss: 0.005561, Accuracy: 98.41%\n",
      "Batch 113, Loss: 0.014217, Accuracy: 98.42%\n",
      "Batch 114, Loss: 0.006432, Accuracy: 98.44%\n",
      "Batch 115, Loss: 0.081438, Accuracy: 98.42%\n",
      "Batch 116, Loss: 0.018652, Accuracy: 98.42%\n",
      "Batch 117, Loss: 0.001600, Accuracy: 98.44%\n",
      "Batch 118, Loss: 0.002587, Accuracy: 98.45%\n",
      "Batch 119, Loss: 0.013232, Accuracy: 98.46%\n",
      "Batch 120, Loss: 0.009507, Accuracy: 98.48%\n",
      "Batch 121, Loss: 0.006889, Accuracy: 98.49%\n",
      "Batch 122, Loss: 0.019617, Accuracy: 98.49%\n",
      "Batch 123, Loss: 0.019885, Accuracy: 98.49%\n",
      "Batch 124, Loss: 0.053447, Accuracy: 98.48%\n",
      "Batch 125, Loss: 0.004021, Accuracy: 98.49%\n",
      "Batch 126, Loss: 0.014848, Accuracy: 98.49%\n",
      "Batch 127, Loss: 0.003421, Accuracy: 98.50%\n",
      "Batch 128, Loss: 0.003250, Accuracy: 98.51%\n",
      "Batch 129, Loss: 0.002480, Accuracy: 98.52%\n",
      "Batch 130, Loss: 0.003417, Accuracy: 98.53%\n",
      "Batch 131, Loss: 0.001804, Accuracy: 98.54%\n",
      "Batch 132, Loss: 0.003514, Accuracy: 98.56%\n",
      "Batch 133, Loss: 0.001217, Accuracy: 98.57%\n",
      "Batch 134, Loss: 0.020479, Accuracy: 98.57%\n",
      "Batch 135, Loss: 0.003484, Accuracy: 98.58%\n",
      "Batch 136, Loss: 0.008894, Accuracy: 98.59%\n",
      "Batch 137, Loss: 0.005494, Accuracy: 98.60%\n",
      "Batch 138, Loss: 0.004027, Accuracy: 98.61%\n",
      "Batch 139, Loss: 0.002497, Accuracy: 98.62%\n",
      "Batch 140, Loss: 0.003248, Accuracy: 98.63%\n",
      "Batch 141, Loss: 0.005909, Accuracy: 98.64%\n",
      "Batch 142, Loss: 0.000965, Accuracy: 98.65%\n",
      "Batch 143, Loss: 0.112450, Accuracy: 98.63%\n",
      "Batch 144, Loss: 0.041987, Accuracy: 98.63%\n",
      "Batch 145, Loss: 0.037984, Accuracy: 98.63%\n",
      "Batch 146, Loss: 0.003189, Accuracy: 98.64%\n",
      "Batch 147, Loss: 0.025094, Accuracy: 98.64%\n",
      "Batch 148, Loss: 0.007240, Accuracy: 98.65%\n",
      "Batch 149, Loss: 0.002177, Accuracy: 98.66%\n",
      "Batch 150, Loss: 0.008988, Accuracy: 98.67%\n",
      "Batch 151, Loss: 0.002610, Accuracy: 98.68%\n",
      "Batch 152, Loss: 0.015243, Accuracy: 98.67%\n",
      "Batch 153, Loss: 0.006970, Accuracy: 98.68%\n",
      "Batch 154, Loss: 0.012232, Accuracy: 98.69%\n",
      "Batch 155, Loss: 0.001906, Accuracy: 98.70%\n",
      "Batch 156, Loss: 0.066101, Accuracy: 98.69%\n",
      "Batch 157, Loss: 0.001955, Accuracy: 98.70%\n",
      "Batch 158, Loss: 0.004795, Accuracy: 98.70%\n",
      "Batch 159, Loss: 0.004163, Accuracy: 98.71%\n",
      "Batch 160, Loss: 0.002155, Accuracy: 98.72%\n",
      "Batch 161, Loss: 0.004508, Accuracy: 98.73%\n",
      "Batch 162, Loss: 0.013292, Accuracy: 98.74%\n",
      "Batch 163, Loss: 0.011675, Accuracy: 98.74%\n",
      "Batch 164, Loss: 0.004947, Accuracy: 98.75%\n",
      "Batch 165, Loss: 0.000878, Accuracy: 98.76%\n",
      "Batch 166, Loss: 0.005752, Accuracy: 98.77%\n",
      "Batch 167, Loss: 0.001917, Accuracy: 98.77%\n",
      "Batch 168, Loss: 0.001457, Accuracy: 98.78%\n",
      "Batch 169, Loss: 0.000952, Accuracy: 98.79%\n",
      "Batch 170, Loss: 0.002854, Accuracy: 98.80%\n",
      "Batch 171, Loss: 0.000939, Accuracy: 98.80%\n",
      "Batch 172, Loss: 0.003602, Accuracy: 98.81%\n",
      "Batch 173, Loss: 0.001642, Accuracy: 98.82%\n",
      "Batch 174, Loss: 0.002534, Accuracy: 98.82%\n",
      "Batch 175, Loss: 0.002395, Accuracy: 98.83%\n",
      "Batch 176, Loss: 0.002585, Accuracy: 98.84%\n",
      "Batch 177, Loss: 0.004092, Accuracy: 98.84%\n",
      "Batch 178, Loss: 0.002598, Accuracy: 98.85%\n",
      "Batch 179, Loss: 0.048278, Accuracy: 98.85%\n",
      "Batch 180, Loss: 0.002003, Accuracy: 98.85%\n",
      "Batch 181, Loss: 0.004114, Accuracy: 98.86%\n",
      "Batch 182, Loss: 0.003516, Accuracy: 98.87%\n",
      "Batch 183, Loss: 0.011029, Accuracy: 98.87%\n",
      "Batch 184, Loss: 0.048598, Accuracy: 98.87%\n",
      "Batch 185, Loss: 0.001073, Accuracy: 98.88%\n",
      "Batch 186, Loss: 0.005214, Accuracy: 98.88%\n",
      "Batch 187, Loss: 0.000848, Accuracy: 98.89%\n",
      "Batch 188, Loss: 0.043420, Accuracy: 98.89%\n",
      "Batch 189, Loss: 0.001975, Accuracy: 98.89%\n",
      "Batch 190, Loss: 0.004564, Accuracy: 98.90%\n",
      "Batch 191, Loss: 0.002338, Accuracy: 98.90%\n",
      "Batch 192, Loss: 0.002358, Accuracy: 98.91%\n",
      "Batch 193, Loss: 0.011306, Accuracy: 98.92%\n",
      "Batch 194, Loss: 0.041783, Accuracy: 98.91%\n",
      "Batch 195, Loss: 0.001646, Accuracy: 98.92%\n",
      "Batch 196, Loss: 0.003018, Accuracy: 98.92%\n",
      "Batch 197, Loss: 0.003484, Accuracy: 98.93%\n",
      "Batch 198, Loss: 0.007927, Accuracy: 98.93%\n",
      "Batch 199, Loss: 0.008712, Accuracy: 98.94%\n",
      "Batch 200, Loss: 0.005348, Accuracy: 98.95%\n",
      "Batch 201, Loss: 0.001866, Accuracy: 98.95%\n",
      "Batch 202, Loss: 0.047495, Accuracy: 98.95%\n",
      "Batch 203, Loss: 0.001692, Accuracy: 98.95%\n",
      "Batch 204, Loss: 0.011801, Accuracy: 98.96%\n",
      "Batch 205, Loss: 0.005868, Accuracy: 98.96%\n",
      "Batch 206, Loss: 0.004732, Accuracy: 98.97%\n",
      "Batch 207, Loss: 0.007541, Accuracy: 98.97%\n",
      "Batch 208, Loss: 0.008666, Accuracy: 98.98%\n",
      "Batch 209, Loss: 0.001532, Accuracy: 98.98%\n",
      "Batch 210, Loss: 0.002293, Accuracy: 98.99%\n",
      "Batch 211, Loss: 0.002097, Accuracy: 98.99%\n",
      "Batch 212, Loss: 0.002205, Accuracy: 99.00%\n",
      "Batch 213, Loss: 0.001802, Accuracy: 99.00%\n",
      "Training - Epoch 41, Loss: 0.028950, Accuracy: 99.00%\n",
      "Validation Batch 1, Loss: 0.001913, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.012940, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.002408, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.007343, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.029906, Accuracy: 99.69%\n",
      "Validation Batch 6, Loss: 0.022718, Accuracy: 99.48%\n",
      "Validation Batch 7, Loss: 0.001008, Accuracy: 99.55%\n",
      "Validation Batch 8, Loss: 0.001673, Accuracy: 99.61%\n",
      "Validation Batch 9, Loss: 0.007504, Accuracy: 99.65%\n",
      "Validation Batch 10, Loss: 0.000925, Accuracy: 99.69%\n",
      "Validation Batch 11, Loss: 0.002872, Accuracy: 99.72%\n",
      "Validation Batch 12, Loss: 0.001916, Accuracy: 99.74%\n",
      "Validation Batch 13, Loss: 0.023343, Accuracy: 99.64%\n",
      "Validation Batch 14, Loss: 0.013895, Accuracy: 99.67%\n",
      "Validation Batch 15, Loss: 0.010494, Accuracy: 99.69%\n",
      "Validation Batch 16, Loss: 0.003405, Accuracy: 99.71%\n",
      "Validation Batch 17, Loss: 0.004918, Accuracy: 99.72%\n",
      "Validation Batch 18, Loss: 0.002817, Accuracy: 99.74%\n",
      "Validation Batch 19, Loss: 0.001673, Accuracy: 99.75%\n",
      "Validation Batch 20, Loss: 0.010238, Accuracy: 99.77%\n",
      "Validation Batch 21, Loss: 0.011798, Accuracy: 99.78%\n",
      "Validation Batch 22, Loss: 0.036702, Accuracy: 99.72%\n",
      "Validation Batch 23, Loss: 0.012655, Accuracy: 99.73%\n",
      "Validation Batch 24, Loss: 0.076642, Accuracy: 99.67%\n",
      "Validation Batch 25, Loss: 0.082455, Accuracy: 99.56%\n",
      "Validation Batch 26, Loss: 0.023887, Accuracy: 99.52%\n",
      "Validation Batch 27, Loss: 0.006388, Accuracy: 99.53%\n",
      "Validation - Epoch 41, Loss: 0.015349, Accuracy: 99.53%\n",
      "Patience—5\n",
      "Epoch 42\n",
      "Batch 1, Loss: 0.001489, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000809, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.006014, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.001237, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.001664, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.001750, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.001650, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.009660, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.004606, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.005159, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000949, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000548, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000987, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.001811, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000773, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.001914, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.012424, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.001246, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.001170, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.001089, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.001532, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000906, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.001814, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.002234, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.001252, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.002244, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.003052, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.015171, Accuracy: 99.94%\n",
      "Batch 29, Loss: 0.007772, Accuracy: 99.95%\n",
      "Batch 30, Loss: 0.000784, Accuracy: 99.95%\n",
      "Batch 31, Loss: 0.004588, Accuracy: 99.95%\n",
      "Batch 32, Loss: 0.000986, Accuracy: 99.95%\n",
      "Batch 33, Loss: 0.073161, Accuracy: 99.91%\n",
      "Batch 34, Loss: 0.002356, Accuracy: 99.91%\n",
      "Batch 35, Loss: 0.002405, Accuracy: 99.91%\n",
      "Batch 36, Loss: 0.001059, Accuracy: 99.91%\n",
      "Batch 37, Loss: 0.001813, Accuracy: 99.92%\n",
      "Batch 38, Loss: 0.141268, Accuracy: 99.88%\n",
      "Batch 39, Loss: 0.001744, Accuracy: 99.88%\n",
      "Batch 40, Loss: 0.020432, Accuracy: 99.84%\n",
      "Batch 41, Loss: 0.001074, Accuracy: 99.85%\n",
      "Batch 42, Loss: 0.000663, Accuracy: 99.85%\n",
      "Batch 43, Loss: 0.001757, Accuracy: 99.85%\n",
      "Batch 44, Loss: 0.001143, Accuracy: 99.86%\n",
      "Batch 45, Loss: 0.007043, Accuracy: 99.86%\n",
      "Batch 46, Loss: 0.000773, Accuracy: 99.86%\n",
      "Batch 47, Loss: 0.000944, Accuracy: 99.87%\n",
      "Batch 48, Loss: 0.002082, Accuracy: 99.87%\n",
      "Batch 49, Loss: 0.001721, Accuracy: 99.87%\n",
      "Batch 50, Loss: 0.003202, Accuracy: 99.88%\n",
      "Batch 51, Loss: 0.001538, Accuracy: 99.88%\n",
      "Batch 52, Loss: 0.002869, Accuracy: 99.88%\n",
      "Batch 53, Loss: 0.033658, Accuracy: 99.85%\n",
      "Batch 54, Loss: 0.043561, Accuracy: 99.83%\n",
      "Batch 55, Loss: 0.017001, Accuracy: 99.80%\n",
      "Batch 56, Loss: 0.038757, Accuracy: 99.78%\n",
      "Batch 57, Loss: 0.000785, Accuracy: 99.78%\n",
      "Batch 58, Loss: 0.003016, Accuracy: 99.78%\n",
      "Batch 59, Loss: 0.009765, Accuracy: 99.79%\n",
      "Batch 60, Loss: 0.028833, Accuracy: 99.77%\n",
      "Batch 61, Loss: 0.001162, Accuracy: 99.77%\n",
      "Batch 62, Loss: 0.043278, Accuracy: 99.75%\n",
      "Batch 63, Loss: 0.008070, Accuracy: 99.75%\n",
      "Batch 64, Loss: 0.008839, Accuracy: 99.76%\n",
      "Batch 65, Loss: 0.012769, Accuracy: 99.76%\n",
      "Batch 66, Loss: 0.016964, Accuracy: 99.76%\n",
      "Batch 67, Loss: 0.005543, Accuracy: 99.77%\n",
      "Batch 68, Loss: 0.003622, Accuracy: 99.77%\n",
      "Batch 69, Loss: 0.015948, Accuracy: 99.75%\n",
      "Batch 70, Loss: 0.004273, Accuracy: 99.75%\n",
      "Batch 71, Loss: 0.044349, Accuracy: 99.71%\n",
      "Batch 72, Loss: 0.002653, Accuracy: 99.72%\n",
      "Batch 73, Loss: 0.001455, Accuracy: 99.72%\n",
      "Batch 74, Loss: 0.006234, Accuracy: 99.73%\n",
      "Batch 75, Loss: 0.004617, Accuracy: 99.73%\n",
      "Batch 76, Loss: 0.008984, Accuracy: 99.73%\n",
      "Batch 77, Loss: 0.053963, Accuracy: 99.72%\n",
      "Batch 78, Loss: 0.002690, Accuracy: 99.72%\n",
      "Batch 79, Loss: 0.008352, Accuracy: 99.72%\n",
      "Batch 80, Loss: 0.009474, Accuracy: 99.73%\n",
      "Batch 81, Loss: 0.001955, Accuracy: 99.73%\n",
      "Batch 82, Loss: 0.001204, Accuracy: 99.73%\n",
      "Batch 83, Loss: 0.001503, Accuracy: 99.74%\n",
      "Batch 84, Loss: 0.060330, Accuracy: 99.72%\n",
      "Batch 85, Loss: 0.001006, Accuracy: 99.72%\n",
      "Batch 86, Loss: 0.002591, Accuracy: 99.73%\n",
      "Batch 87, Loss: 0.001133, Accuracy: 99.73%\n",
      "Batch 88, Loss: 0.007522, Accuracy: 99.73%\n",
      "Batch 89, Loss: 0.005676, Accuracy: 99.74%\n",
      "Batch 90, Loss: 0.002966, Accuracy: 99.74%\n",
      "Batch 91, Loss: 0.000746, Accuracy: 99.74%\n",
      "Batch 92, Loss: 0.001722, Accuracy: 99.75%\n",
      "Batch 93, Loss: 0.007321, Accuracy: 99.75%\n",
      "Batch 94, Loss: 0.006249, Accuracy: 99.75%\n",
      "Batch 95, Loss: 0.002683, Accuracy: 99.75%\n",
      "Batch 96, Loss: 0.009857, Accuracy: 99.76%\n",
      "Batch 97, Loss: 0.001599, Accuracy: 99.76%\n",
      "Batch 98, Loss: 0.000835, Accuracy: 99.76%\n",
      "Batch 99, Loss: 0.005997, Accuracy: 99.76%\n",
      "Batch 100, Loss: 0.034715, Accuracy: 99.75%\n",
      "Batch 101, Loss: 0.063189, Accuracy: 99.74%\n",
      "Batch 102, Loss: 0.002040, Accuracy: 99.74%\n",
      "Batch 103, Loss: 0.001031, Accuracy: 99.74%\n",
      "Batch 104, Loss: 0.001408, Accuracy: 99.74%\n",
      "Batch 105, Loss: 0.001508, Accuracy: 99.75%\n",
      "Batch 106, Loss: 0.010364, Accuracy: 99.75%\n",
      "Batch 107, Loss: 0.002135, Accuracy: 99.75%\n",
      "Batch 108, Loss: 0.002883, Accuracy: 99.75%\n",
      "Batch 109, Loss: 0.040957, Accuracy: 99.71%\n",
      "Batch 110, Loss: 0.015194, Accuracy: 99.70%\n",
      "Batch 111, Loss: 0.002231, Accuracy: 99.70%\n",
      "Batch 112, Loss: 0.000681, Accuracy: 99.71%\n",
      "Batch 113, Loss: 0.027672, Accuracy: 99.70%\n",
      "Batch 114, Loss: 0.002634, Accuracy: 99.70%\n",
      "Batch 115, Loss: 0.002771, Accuracy: 99.70%\n",
      "Batch 116, Loss: 0.038321, Accuracy: 99.69%\n",
      "Batch 117, Loss: 0.011675, Accuracy: 99.69%\n",
      "Batch 118, Loss: 0.050668, Accuracy: 99.68%\n",
      "Batch 119, Loss: 0.006489, Accuracy: 99.68%\n",
      "Batch 120, Loss: 0.001289, Accuracy: 99.69%\n",
      "Batch 121, Loss: 0.001425, Accuracy: 99.69%\n",
      "Batch 122, Loss: 0.000941, Accuracy: 99.69%\n",
      "Batch 123, Loss: 0.015975, Accuracy: 99.68%\n",
      "Batch 124, Loss: 0.001568, Accuracy: 99.68%\n",
      "Batch 125, Loss: 0.001332, Accuracy: 99.69%\n",
      "Batch 126, Loss: 0.001918, Accuracy: 99.69%\n",
      "Batch 127, Loss: 0.063838, Accuracy: 99.68%\n",
      "Batch 128, Loss: 0.030360, Accuracy: 99.67%\n",
      "Batch 129, Loss: 0.008302, Accuracy: 99.67%\n",
      "Batch 130, Loss: 0.036979, Accuracy: 99.66%\n",
      "Batch 131, Loss: 0.002261, Accuracy: 99.67%\n",
      "Batch 132, Loss: 0.062678, Accuracy: 99.66%\n",
      "Batch 133, Loss: 0.002333, Accuracy: 99.66%\n",
      "Batch 134, Loss: 0.006750, Accuracy: 99.66%\n",
      "Batch 135, Loss: 0.011884, Accuracy: 99.66%\n",
      "Batch 136, Loss: 0.003432, Accuracy: 99.67%\n",
      "Batch 137, Loss: 0.006230, Accuracy: 99.67%\n",
      "Batch 138, Loss: 0.002526, Accuracy: 99.67%\n",
      "Batch 139, Loss: 0.005552, Accuracy: 99.67%\n",
      "Batch 140, Loss: 0.105197, Accuracy: 99.65%\n",
      "Batch 141, Loss: 0.001437, Accuracy: 99.66%\n",
      "Batch 142, Loss: 0.001365, Accuracy: 99.66%\n",
      "Batch 143, Loss: 0.002092, Accuracy: 99.66%\n",
      "Batch 144, Loss: 0.012556, Accuracy: 99.65%\n",
      "Batch 145, Loss: 0.002567, Accuracy: 99.66%\n",
      "Batch 146, Loss: 0.015406, Accuracy: 99.65%\n",
      "Batch 147, Loss: 0.041408, Accuracy: 99.64%\n",
      "Batch 148, Loss: 0.005637, Accuracy: 99.64%\n",
      "Batch 149, Loss: 0.002194, Accuracy: 99.64%\n",
      "Batch 150, Loss: 0.046155, Accuracy: 99.64%\n",
      "Batch 151, Loss: 0.012175, Accuracy: 99.63%\n",
      "Batch 152, Loss: 0.006855, Accuracy: 99.63%\n",
      "Batch 153, Loss: 0.008044, Accuracy: 99.63%\n",
      "Batch 154, Loss: 0.001430, Accuracy: 99.63%\n",
      "Batch 155, Loss: 0.004126, Accuracy: 99.64%\n",
      "Batch 156, Loss: 0.034977, Accuracy: 99.63%\n",
      "Batch 157, Loss: 0.020861, Accuracy: 99.63%\n",
      "Batch 158, Loss: 0.099881, Accuracy: 99.61%\n",
      "Batch 159, Loss: 0.025784, Accuracy: 99.61%\n",
      "Batch 160, Loss: 0.104564, Accuracy: 99.59%\n",
      "Batch 161, Loss: 0.001765, Accuracy: 99.59%\n",
      "Batch 162, Loss: 0.000860, Accuracy: 99.59%\n",
      "Batch 163, Loss: 0.005472, Accuracy: 99.60%\n",
      "Batch 164, Loss: 0.058687, Accuracy: 99.59%\n",
      "Batch 165, Loss: 0.006669, Accuracy: 99.59%\n",
      "Batch 166, Loss: 0.145417, Accuracy: 99.58%\n",
      "Batch 167, Loss: 0.003180, Accuracy: 99.58%\n",
      "Batch 168, Loss: 0.006797, Accuracy: 99.58%\n",
      "Batch 169, Loss: 0.044304, Accuracy: 99.57%\n",
      "Batch 170, Loss: 0.009331, Accuracy: 99.57%\n",
      "Batch 171, Loss: 0.008341, Accuracy: 99.57%\n",
      "Batch 172, Loss: 0.004616, Accuracy: 99.57%\n",
      "Batch 173, Loss: 0.068931, Accuracy: 99.56%\n",
      "Batch 174, Loss: 0.004434, Accuracy: 99.56%\n",
      "Batch 175, Loss: 0.022402, Accuracy: 99.56%\n",
      "Batch 176, Loss: 0.017432, Accuracy: 99.56%\n",
      "Batch 177, Loss: 0.049119, Accuracy: 99.55%\n",
      "Batch 178, Loss: 0.005263, Accuracy: 99.55%\n",
      "Batch 179, Loss: 0.003116, Accuracy: 99.55%\n",
      "Batch 180, Loss: 0.001660, Accuracy: 99.56%\n",
      "Batch 181, Loss: 0.017133, Accuracy: 99.55%\n",
      "Batch 182, Loss: 0.001818, Accuracy: 99.55%\n",
      "Batch 183, Loss: 0.045098, Accuracy: 99.55%\n",
      "Batch 184, Loss: 0.066955, Accuracy: 99.54%\n",
      "Batch 185, Loss: 0.016720, Accuracy: 99.54%\n",
      "Batch 186, Loss: 0.008341, Accuracy: 99.55%\n",
      "Batch 187, Loss: 0.002240, Accuracy: 99.55%\n",
      "Batch 188, Loss: 0.001608, Accuracy: 99.55%\n",
      "Batch 189, Loss: 0.053392, Accuracy: 99.55%\n",
      "Batch 190, Loss: 0.001846, Accuracy: 99.55%\n",
      "Batch 191, Loss: 0.067856, Accuracy: 99.54%\n",
      "Batch 192, Loss: 0.048151, Accuracy: 99.54%\n",
      "Batch 193, Loss: 0.019335, Accuracy: 99.53%\n",
      "Batch 194, Loss: 0.002908, Accuracy: 99.53%\n",
      "Batch 195, Loss: 0.011847, Accuracy: 99.54%\n",
      "Batch 196, Loss: 0.012888, Accuracy: 99.54%\n",
      "Batch 197, Loss: 0.001362, Accuracy: 99.54%\n",
      "Batch 198, Loss: 0.005581, Accuracy: 99.54%\n",
      "Batch 199, Loss: 0.022067, Accuracy: 99.54%\n",
      "Batch 200, Loss: 0.034454, Accuracy: 99.53%\n",
      "Batch 201, Loss: 0.137933, Accuracy: 99.51%\n",
      "Batch 202, Loss: 0.001895, Accuracy: 99.51%\n",
      "Batch 203, Loss: 0.021270, Accuracy: 99.51%\n",
      "Batch 204, Loss: 0.001780, Accuracy: 99.51%\n",
      "Batch 205, Loss: 0.002316, Accuracy: 99.51%\n",
      "Batch 206, Loss: 0.002036, Accuracy: 99.51%\n",
      "Batch 207, Loss: 0.009702, Accuracy: 99.52%\n",
      "Batch 208, Loss: 0.007032, Accuracy: 99.52%\n",
      "Batch 209, Loss: 0.001776, Accuracy: 99.52%\n",
      "Batch 210, Loss: 0.005082, Accuracy: 99.52%\n",
      "Batch 211, Loss: 0.004842, Accuracy: 99.53%\n",
      "Batch 212, Loss: 0.004057, Accuracy: 99.53%\n",
      "Batch 213, Loss: 0.064775, Accuracy: 99.52%\n",
      "Training - Epoch 42, Loss: 0.015233, Accuracy: 99.52%\n",
      "Validation Batch 1, Loss: 0.134203, Accuracy: 96.88%\n",
      "Validation Batch 2, Loss: 0.003969, Accuracy: 98.44%\n",
      "Validation Batch 3, Loss: 0.052872, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.018286, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.055847, Accuracy: 98.44%\n",
      "Validation Batch 6, Loss: 0.012568, Accuracy: 98.70%\n",
      "Validation Batch 7, Loss: 0.006428, Accuracy: 98.88%\n",
      "Validation Batch 8, Loss: 0.035739, Accuracy: 98.83%\n",
      "Validation Batch 9, Loss: 0.011848, Accuracy: 98.96%\n",
      "Validation Batch 10, Loss: 0.134154, Accuracy: 98.75%\n",
      "Validation Batch 11, Loss: 0.013266, Accuracy: 98.86%\n",
      "Validation Batch 12, Loss: 0.005836, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.102080, Accuracy: 98.68%\n",
      "Validation Batch 14, Loss: 0.062916, Accuracy: 98.55%\n",
      "Validation Batch 15, Loss: 0.008452, Accuracy: 98.65%\n",
      "Validation Batch 16, Loss: 0.013386, Accuracy: 98.73%\n",
      "Validation Batch 17, Loss: 0.002750, Accuracy: 98.81%\n",
      "Validation Batch 18, Loss: 0.141399, Accuracy: 98.78%\n",
      "Validation Batch 19, Loss: 0.009005, Accuracy: 98.85%\n",
      "Validation Batch 20, Loss: 0.034842, Accuracy: 98.83%\n",
      "Validation Batch 21, Loss: 0.113285, Accuracy: 98.66%\n",
      "Validation Batch 22, Loss: 0.012312, Accuracy: 98.72%\n",
      "Validation Batch 23, Loss: 0.010737, Accuracy: 98.78%\n",
      "Validation Batch 24, Loss: 0.113290, Accuracy: 98.70%\n",
      "Validation Batch 25, Loss: 0.011431, Accuracy: 98.75%\n",
      "Validation Batch 26, Loss: 0.005092, Accuracy: 98.80%\n",
      "Validation Batch 27, Loss: 0.092358, Accuracy: 98.77%\n",
      "Validation - Epoch 42, Loss: 0.045124, Accuracy: 98.77%\n",
      "Patience—6\n",
      "Epoch 43\n",
      "Batch 1, Loss: 0.004702, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.044732, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.007195, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.004081, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.029635, Accuracy: 99.38%\n",
      "Batch 6, Loss: 0.001601, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.004807, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.001461, Accuracy: 99.61%\n",
      "Batch 9, Loss: 0.014213, Accuracy: 99.65%\n",
      "Batch 10, Loss: 0.055630, Accuracy: 99.38%\n",
      "Batch 11, Loss: 0.102001, Accuracy: 99.15%\n",
      "Batch 12, Loss: 0.009839, Accuracy: 99.22%\n",
      "Batch 13, Loss: 0.003618, Accuracy: 99.28%\n",
      "Batch 14, Loss: 0.010912, Accuracy: 99.33%\n",
      "Batch 15, Loss: 0.002726, Accuracy: 99.38%\n",
      "Batch 16, Loss: 0.059812, Accuracy: 99.22%\n",
      "Batch 17, Loss: 0.002405, Accuracy: 99.26%\n",
      "Batch 18, Loss: 0.006311, Accuracy: 99.31%\n",
      "Batch 19, Loss: 0.023743, Accuracy: 99.26%\n",
      "Batch 20, Loss: 0.004718, Accuracy: 99.30%\n",
      "Batch 21, Loss: 0.004111, Accuracy: 99.33%\n",
      "Batch 22, Loss: 0.018383, Accuracy: 99.29%\n",
      "Batch 23, Loss: 0.001194, Accuracy: 99.32%\n",
      "Batch 24, Loss: 0.009584, Accuracy: 99.35%\n",
      "Batch 25, Loss: 0.059772, Accuracy: 99.31%\n",
      "Batch 26, Loss: 0.019839, Accuracy: 99.28%\n",
      "Batch 27, Loss: 0.003673, Accuracy: 99.31%\n",
      "Batch 28, Loss: 0.001751, Accuracy: 99.33%\n",
      "Batch 29, Loss: 0.004423, Accuracy: 99.35%\n",
      "Batch 30, Loss: 0.006017, Accuracy: 99.38%\n",
      "Batch 31, Loss: 0.002944, Accuracy: 99.40%\n",
      "Batch 32, Loss: 0.009465, Accuracy: 99.41%\n",
      "Batch 33, Loss: 0.004063, Accuracy: 99.43%\n",
      "Batch 34, Loss: 0.001086, Accuracy: 99.45%\n",
      "Batch 35, Loss: 0.029870, Accuracy: 99.42%\n",
      "Batch 36, Loss: 0.019588, Accuracy: 99.39%\n",
      "Batch 37, Loss: 0.000944, Accuracy: 99.41%\n",
      "Batch 38, Loss: 0.006426, Accuracy: 99.42%\n",
      "Batch 39, Loss: 0.003651, Accuracy: 99.44%\n",
      "Batch 40, Loss: 0.072677, Accuracy: 99.41%\n",
      "Batch 41, Loss: 0.012762, Accuracy: 99.43%\n",
      "Batch 42, Loss: 0.013946, Accuracy: 99.40%\n",
      "Batch 43, Loss: 0.002079, Accuracy: 99.42%\n",
      "Batch 44, Loss: 0.077705, Accuracy: 99.40%\n",
      "Batch 45, Loss: 0.002929, Accuracy: 99.41%\n",
      "Batch 46, Loss: 0.021045, Accuracy: 99.39%\n",
      "Batch 47, Loss: 0.001366, Accuracy: 99.40%\n",
      "Batch 48, Loss: 0.018290, Accuracy: 99.41%\n",
      "Batch 49, Loss: 0.014717, Accuracy: 99.39%\n",
      "Batch 50, Loss: 0.003365, Accuracy: 99.41%\n",
      "Batch 51, Loss: 0.005709, Accuracy: 99.42%\n",
      "Batch 52, Loss: 0.030864, Accuracy: 99.40%\n",
      "Batch 53, Loss: 0.007470, Accuracy: 99.41%\n",
      "Batch 54, Loss: 0.005067, Accuracy: 99.42%\n",
      "Batch 55, Loss: 0.009274, Accuracy: 99.43%\n",
      "Batch 56, Loss: 0.009454, Accuracy: 99.44%\n",
      "Batch 57, Loss: 0.015316, Accuracy: 99.42%\n",
      "Batch 58, Loss: 0.042590, Accuracy: 99.41%\n",
      "Batch 59, Loss: 0.083870, Accuracy: 99.34%\n",
      "Batch 60, Loss: 0.011843, Accuracy: 99.35%\n",
      "Batch 61, Loss: 0.002359, Accuracy: 99.36%\n",
      "Batch 62, Loss: 0.002716, Accuracy: 99.37%\n",
      "Batch 63, Loss: 0.003304, Accuracy: 99.38%\n",
      "Batch 64, Loss: 0.008457, Accuracy: 99.39%\n",
      "Batch 65, Loss: 0.125714, Accuracy: 99.35%\n",
      "Batch 66, Loss: 0.090378, Accuracy: 99.31%\n",
      "Batch 67, Loss: 0.002673, Accuracy: 99.32%\n",
      "Batch 68, Loss: 0.009974, Accuracy: 99.33%\n",
      "Batch 69, Loss: 0.005095, Accuracy: 99.34%\n",
      "Batch 70, Loss: 0.013067, Accuracy: 99.35%\n",
      "Batch 71, Loss: 0.110911, Accuracy: 99.32%\n",
      "Batch 72, Loss: 0.007769, Accuracy: 99.33%\n",
      "Batch 73, Loss: 0.006201, Accuracy: 99.34%\n",
      "Batch 74, Loss: 0.012907, Accuracy: 99.35%\n",
      "Batch 75, Loss: 0.006477, Accuracy: 99.35%\n",
      "Batch 76, Loss: 0.002369, Accuracy: 99.36%\n",
      "Batch 77, Loss: 0.088741, Accuracy: 99.35%\n",
      "Batch 78, Loss: 0.028661, Accuracy: 99.34%\n",
      "Batch 79, Loss: 0.003956, Accuracy: 99.35%\n",
      "Batch 80, Loss: 0.028516, Accuracy: 99.36%\n",
      "Batch 81, Loss: 0.007086, Accuracy: 99.36%\n",
      "Batch 82, Loss: 0.016974, Accuracy: 99.37%\n",
      "Batch 83, Loss: 0.004694, Accuracy: 99.38%\n",
      "Batch 84, Loss: 0.003814, Accuracy: 99.39%\n",
      "Batch 85, Loss: 0.000895, Accuracy: 99.39%\n",
      "Batch 86, Loss: 0.011600, Accuracy: 99.40%\n",
      "Batch 87, Loss: 0.027813, Accuracy: 99.39%\n",
      "Batch 88, Loss: 0.002845, Accuracy: 99.40%\n",
      "Batch 89, Loss: 0.019399, Accuracy: 99.39%\n",
      "Batch 90, Loss: 0.001073, Accuracy: 99.39%\n",
      "Batch 91, Loss: 0.001713, Accuracy: 99.40%\n",
      "Batch 92, Loss: 0.006210, Accuracy: 99.41%\n",
      "Batch 93, Loss: 0.057677, Accuracy: 99.40%\n",
      "Batch 94, Loss: 0.023552, Accuracy: 99.38%\n",
      "Batch 95, Loss: 0.055585, Accuracy: 99.38%\n",
      "Batch 96, Loss: 0.050696, Accuracy: 99.37%\n",
      "Batch 97, Loss: 0.021903, Accuracy: 99.36%\n",
      "Batch 98, Loss: 0.027958, Accuracy: 99.35%\n",
      "Batch 99, Loss: 0.001440, Accuracy: 99.35%\n",
      "Batch 100, Loss: 0.003108, Accuracy: 99.36%\n",
      "Batch 101, Loss: 0.001842, Accuracy: 99.37%\n",
      "Batch 102, Loss: 0.005522, Accuracy: 99.37%\n",
      "Batch 103, Loss: 0.036201, Accuracy: 99.36%\n",
      "Batch 104, Loss: 0.004313, Accuracy: 99.37%\n",
      "Batch 105, Loss: 0.068308, Accuracy: 99.36%\n",
      "Batch 106, Loss: 0.012492, Accuracy: 99.37%\n",
      "Batch 107, Loss: 0.014799, Accuracy: 99.37%\n",
      "Batch 108, Loss: 0.039752, Accuracy: 99.35%\n",
      "Batch 109, Loss: 0.068716, Accuracy: 99.33%\n",
      "Batch 110, Loss: 0.015915, Accuracy: 99.33%\n",
      "Batch 111, Loss: 0.004138, Accuracy: 99.34%\n",
      "Batch 112, Loss: 0.025986, Accuracy: 99.33%\n",
      "Batch 113, Loss: 0.028693, Accuracy: 99.32%\n",
      "Batch 114, Loss: 0.030638, Accuracy: 99.31%\n",
      "Batch 115, Loss: 0.007419, Accuracy: 99.32%\n",
      "Batch 116, Loss: 0.111176, Accuracy: 99.31%\n",
      "Batch 117, Loss: 0.005964, Accuracy: 99.32%\n",
      "Batch 118, Loss: 0.060278, Accuracy: 99.31%\n",
      "Batch 119, Loss: 0.001203, Accuracy: 99.32%\n",
      "Batch 120, Loss: 0.085133, Accuracy: 99.31%\n",
      "Batch 121, Loss: 0.098393, Accuracy: 99.29%\n",
      "Batch 122, Loss: 0.001356, Accuracy: 99.30%\n",
      "Batch 123, Loss: 0.002032, Accuracy: 99.30%\n",
      "Batch 124, Loss: 0.076875, Accuracy: 99.28%\n",
      "Batch 125, Loss: 0.032296, Accuracy: 99.26%\n",
      "Batch 126, Loss: 0.189131, Accuracy: 99.23%\n",
      "Batch 127, Loss: 0.010186, Accuracy: 99.24%\n",
      "Batch 128, Loss: 0.162277, Accuracy: 99.22%\n",
      "Batch 129, Loss: 0.046270, Accuracy: 99.20%\n",
      "Batch 130, Loss: 0.073686, Accuracy: 99.19%\n",
      "Batch 131, Loss: 0.008768, Accuracy: 99.20%\n",
      "Batch 132, Loss: 0.005346, Accuracy: 99.21%\n",
      "Batch 133, Loss: 0.098367, Accuracy: 99.19%\n",
      "Batch 134, Loss: 0.028119, Accuracy: 99.20%\n",
      "Batch 135, Loss: 0.036134, Accuracy: 99.19%\n",
      "Batch 136, Loss: 0.002043, Accuracy: 99.20%\n",
      "Batch 137, Loss: 0.050883, Accuracy: 99.18%\n",
      "Batch 138, Loss: 0.090029, Accuracy: 99.15%\n",
      "Batch 139, Loss: 0.085691, Accuracy: 99.15%\n",
      "Batch 140, Loss: 0.045873, Accuracy: 99.13%\n",
      "Batch 141, Loss: 0.098163, Accuracy: 99.12%\n",
      "Batch 142, Loss: 0.013547, Accuracy: 99.13%\n",
      "Batch 143, Loss: 0.012362, Accuracy: 99.14%\n",
      "Batch 144, Loss: 0.024604, Accuracy: 99.13%\n",
      "Batch 145, Loss: 0.099497, Accuracy: 99.12%\n",
      "Batch 146, Loss: 0.006261, Accuracy: 99.12%\n",
      "Batch 147, Loss: 0.043298, Accuracy: 99.11%\n",
      "Batch 148, Loss: 0.023768, Accuracy: 99.10%\n",
      "Batch 149, Loss: 0.003567, Accuracy: 99.11%\n",
      "Batch 150, Loss: 0.002481, Accuracy: 99.11%\n",
      "Batch 151, Loss: 0.065910, Accuracy: 99.11%\n",
      "Batch 152, Loss: 0.004606, Accuracy: 99.12%\n",
      "Batch 153, Loss: 0.001844, Accuracy: 99.12%\n",
      "Batch 154, Loss: 0.046662, Accuracy: 99.11%\n",
      "Batch 155, Loss: 0.019045, Accuracy: 99.11%\n",
      "Batch 156, Loss: 0.003584, Accuracy: 99.12%\n",
      "Batch 157, Loss: 0.005885, Accuracy: 99.12%\n",
      "Batch 158, Loss: 0.002785, Accuracy: 99.13%\n",
      "Batch 159, Loss: 0.002322, Accuracy: 99.14%\n",
      "Batch 160, Loss: 0.009385, Accuracy: 99.14%\n",
      "Batch 161, Loss: 0.016339, Accuracy: 99.14%\n",
      "Batch 162, Loss: 0.005816, Accuracy: 99.14%\n",
      "Batch 163, Loss: 0.044648, Accuracy: 99.14%\n",
      "Batch 164, Loss: 0.021040, Accuracy: 99.13%\n",
      "Batch 165, Loss: 0.024857, Accuracy: 99.13%\n",
      "Batch 166, Loss: 0.005113, Accuracy: 99.13%\n",
      "Batch 167, Loss: 0.008564, Accuracy: 99.14%\n",
      "Batch 168, Loss: 0.011335, Accuracy: 99.14%\n",
      "Batch 169, Loss: 0.103255, Accuracy: 99.14%\n",
      "Batch 170, Loss: 0.001710, Accuracy: 99.15%\n",
      "Batch 171, Loss: 0.001560, Accuracy: 99.15%\n",
      "Batch 172, Loss: 0.068138, Accuracy: 99.14%\n",
      "Batch 173, Loss: 0.008885, Accuracy: 99.14%\n",
      "Batch 174, Loss: 0.002843, Accuracy: 99.15%\n",
      "Batch 175, Loss: 0.011844, Accuracy: 99.15%\n",
      "Batch 176, Loss: 0.001222, Accuracy: 99.16%\n",
      "Batch 177, Loss: 0.001435, Accuracy: 99.16%\n",
      "Batch 178, Loss: 0.226048, Accuracy: 99.14%\n",
      "Batch 179, Loss: 0.047551, Accuracy: 99.14%\n",
      "Batch 180, Loss: 0.088540, Accuracy: 99.12%\n",
      "Batch 181, Loss: 0.002642, Accuracy: 99.13%\n",
      "Batch 182, Loss: 0.055396, Accuracy: 99.12%\n",
      "Batch 183, Loss: 0.007323, Accuracy: 99.13%\n",
      "Batch 184, Loss: 0.113893, Accuracy: 99.12%\n",
      "Batch 185, Loss: 0.044461, Accuracy: 99.11%\n",
      "Batch 186, Loss: 0.059322, Accuracy: 99.11%\n",
      "Batch 187, Loss: 0.009117, Accuracy: 99.11%\n",
      "Batch 188, Loss: 0.005675, Accuracy: 99.12%\n",
      "Batch 189, Loss: 0.003652, Accuracy: 99.12%\n",
      "Batch 190, Loss: 0.002135, Accuracy: 99.13%\n",
      "Batch 191, Loss: 0.017716, Accuracy: 99.12%\n",
      "Batch 192, Loss: 0.002503, Accuracy: 99.13%\n",
      "Batch 193, Loss: 0.017496, Accuracy: 99.13%\n",
      "Batch 194, Loss: 0.039736, Accuracy: 99.13%\n",
      "Batch 195, Loss: 0.019093, Accuracy: 99.13%\n",
      "Batch 196, Loss: 0.024801, Accuracy: 99.13%\n",
      "Batch 197, Loss: 0.036031, Accuracy: 99.12%\n",
      "Batch 198, Loss: 0.012760, Accuracy: 99.12%\n",
      "Batch 199, Loss: 0.014106, Accuracy: 99.13%\n",
      "Batch 200, Loss: 0.003129, Accuracy: 99.13%\n",
      "Batch 201, Loss: 0.001897, Accuracy: 99.14%\n",
      "Batch 202, Loss: 0.025184, Accuracy: 99.13%\n",
      "Batch 203, Loss: 0.236333, Accuracy: 99.11%\n",
      "Batch 204, Loss: 0.002528, Accuracy: 99.12%\n",
      "Batch 205, Loss: 0.003472, Accuracy: 99.12%\n",
      "Batch 206, Loss: 0.052683, Accuracy: 99.12%\n",
      "Batch 207, Loss: 0.025501, Accuracy: 99.12%\n",
      "Batch 208, Loss: 0.001477, Accuracy: 99.12%\n",
      "Batch 209, Loss: 0.004084, Accuracy: 99.13%\n",
      "Batch 210, Loss: 0.009578, Accuracy: 99.13%\n",
      "Batch 211, Loss: 0.002321, Accuracy: 99.13%\n",
      "Batch 212, Loss: 0.035891, Accuracy: 99.12%\n",
      "Batch 213, Loss: 0.009360, Accuracy: 99.13%\n",
      "Training - Epoch 43, Loss: 0.027387, Accuracy: 99.13%\n",
      "Validation Batch 1, Loss: 0.103678, Accuracy: 98.44%\n",
      "Validation Batch 2, Loss: 0.006681, Accuracy: 99.22%\n",
      "Validation Batch 3, Loss: 0.066410, Accuracy: 98.44%\n",
      "Validation Batch 4, Loss: 0.081094, Accuracy: 98.44%\n",
      "Validation Batch 5, Loss: 0.004968, Accuracy: 98.75%\n",
      "Validation Batch 6, Loss: 0.002818, Accuracy: 98.96%\n",
      "Validation Batch 7, Loss: 0.094669, Accuracy: 98.88%\n",
      "Validation Batch 8, Loss: 0.010898, Accuracy: 99.02%\n",
      "Validation Batch 9, Loss: 0.069090, Accuracy: 98.78%\n",
      "Validation Batch 10, Loss: 0.014568, Accuracy: 98.91%\n",
      "Validation Batch 11, Loss: 0.003568, Accuracy: 99.01%\n",
      "Validation Batch 12, Loss: 0.017813, Accuracy: 98.96%\n",
      "Validation Batch 13, Loss: 0.061001, Accuracy: 98.92%\n",
      "Validation Batch 14, Loss: 0.052363, Accuracy: 98.88%\n",
      "Validation Batch 15, Loss: 0.009848, Accuracy: 98.96%\n",
      "Validation Batch 16, Loss: 0.026065, Accuracy: 98.93%\n",
      "Validation Batch 17, Loss: 0.037581, Accuracy: 98.90%\n",
      "Validation Batch 18, Loss: 0.011119, Accuracy: 98.96%\n",
      "Validation Batch 19, Loss: 0.021320, Accuracy: 99.01%\n",
      "Validation Batch 20, Loss: 0.012141, Accuracy: 99.06%\n",
      "Validation Batch 21, Loss: 0.067777, Accuracy: 99.03%\n",
      "Validation Batch 22, Loss: 0.010539, Accuracy: 99.08%\n",
      "Validation Batch 23, Loss: 0.013733, Accuracy: 99.12%\n",
      "Validation Batch 24, Loss: 0.100517, Accuracy: 99.09%\n",
      "Validation Batch 25, Loss: 0.001686, Accuracy: 99.12%\n",
      "Validation Batch 26, Loss: 0.014253, Accuracy: 99.10%\n",
      "Validation Batch 27, Loss: 0.004564, Accuracy: 99.12%\n",
      "Validation - Epoch 43, Loss: 0.034102, Accuracy: 99.12%\n",
      "Patience—7\n",
      "Epoch 44\n",
      "Batch 1, Loss: 0.117098, Accuracy: 98.44%\n",
      "Batch 2, Loss: 0.001347, Accuracy: 99.22%\n",
      "Batch 3, Loss: 0.008148, Accuracy: 99.48%\n",
      "Batch 4, Loss: 0.002163, Accuracy: 99.61%\n",
      "Batch 5, Loss: 0.004539, Accuracy: 99.69%\n",
      "Batch 6, Loss: 0.036997, Accuracy: 99.48%\n",
      "Batch 7, Loss: 0.001860, Accuracy: 99.55%\n",
      "Batch 8, Loss: 0.051013, Accuracy: 99.41%\n",
      "Batch 9, Loss: 0.005807, Accuracy: 99.48%\n",
      "Batch 10, Loss: 0.002219, Accuracy: 99.53%\n",
      "Batch 11, Loss: 0.004501, Accuracy: 99.57%\n",
      "Batch 12, Loss: 0.023194, Accuracy: 99.48%\n",
      "Batch 13, Loss: 0.002433, Accuracy: 99.52%\n",
      "Batch 14, Loss: 0.005811, Accuracy: 99.55%\n",
      "Batch 15, Loss: 0.001818, Accuracy: 99.58%\n",
      "Batch 16, Loss: 0.002654, Accuracy: 99.61%\n",
      "Batch 17, Loss: 0.039750, Accuracy: 99.54%\n",
      "Batch 18, Loss: 0.003531, Accuracy: 99.57%\n",
      "Batch 19, Loss: 0.001304, Accuracy: 99.59%\n",
      "Batch 20, Loss: 0.002325, Accuracy: 99.61%\n",
      "Batch 21, Loss: 0.001576, Accuracy: 99.63%\n",
      "Batch 22, Loss: 0.003885, Accuracy: 99.64%\n",
      "Batch 23, Loss: 0.057725, Accuracy: 99.59%\n",
      "Batch 24, Loss: 0.003541, Accuracy: 99.61%\n",
      "Batch 25, Loss: 0.002713, Accuracy: 99.62%\n",
      "Batch 26, Loss: 0.005096, Accuracy: 99.64%\n",
      "Batch 27, Loss: 0.005143, Accuracy: 99.65%\n",
      "Batch 28, Loss: 0.003925, Accuracy: 99.67%\n",
      "Batch 29, Loss: 0.047039, Accuracy: 99.62%\n",
      "Batch 30, Loss: 0.007280, Accuracy: 99.64%\n",
      "Batch 31, Loss: 0.001783, Accuracy: 99.65%\n",
      "Batch 32, Loss: 0.002014, Accuracy: 99.66%\n",
      "Batch 33, Loss: 0.003286, Accuracy: 99.67%\n",
      "Batch 34, Loss: 0.015716, Accuracy: 99.63%\n",
      "Batch 35, Loss: 0.003189, Accuracy: 99.64%\n",
      "Batch 36, Loss: 0.001885, Accuracy: 99.65%\n",
      "Batch 37, Loss: 0.003072, Accuracy: 99.66%\n",
      "Batch 38, Loss: 0.008532, Accuracy: 99.67%\n",
      "Batch 39, Loss: 0.059043, Accuracy: 99.64%\n",
      "Batch 40, Loss: 0.013474, Accuracy: 99.61%\n",
      "Batch 41, Loss: 0.001020, Accuracy: 99.62%\n",
      "Batch 42, Loss: 0.001157, Accuracy: 99.63%\n",
      "Batch 43, Loss: 0.005008, Accuracy: 99.64%\n",
      "Batch 44, Loss: 0.001451, Accuracy: 99.64%\n",
      "Batch 45, Loss: 0.011394, Accuracy: 99.65%\n",
      "Batch 46, Loss: 0.002823, Accuracy: 99.66%\n",
      "Batch 47, Loss: 0.001516, Accuracy: 99.67%\n",
      "Batch 48, Loss: 0.001805, Accuracy: 99.67%\n",
      "Batch 49, Loss: 0.004823, Accuracy: 99.68%\n",
      "Batch 50, Loss: 0.001925, Accuracy: 99.69%\n",
      "Batch 51, Loss: 0.001857, Accuracy: 99.69%\n",
      "Batch 52, Loss: 0.004843, Accuracy: 99.70%\n",
      "Batch 53, Loss: 0.006393, Accuracy: 99.71%\n",
      "Batch 54, Loss: 0.005448, Accuracy: 99.71%\n",
      "Batch 55, Loss: 0.005549, Accuracy: 99.72%\n",
      "Batch 56, Loss: 0.011054, Accuracy: 99.72%\n",
      "Batch 57, Loss: 0.040850, Accuracy: 99.67%\n",
      "Batch 58, Loss: 0.001451, Accuracy: 99.68%\n",
      "Batch 59, Loss: 0.003963, Accuracy: 99.68%\n",
      "Batch 60, Loss: 0.001267, Accuracy: 99.69%\n",
      "Batch 61, Loss: 0.002547, Accuracy: 99.69%\n",
      "Batch 62, Loss: 0.001559, Accuracy: 99.70%\n",
      "Batch 63, Loss: 0.001013, Accuracy: 99.70%\n",
      "Batch 64, Loss: 0.001182, Accuracy: 99.71%\n",
      "Batch 65, Loss: 0.002937, Accuracy: 99.71%\n",
      "Batch 66, Loss: 0.017266, Accuracy: 99.69%\n",
      "Batch 67, Loss: 0.003118, Accuracy: 99.70%\n",
      "Batch 68, Loss: 0.004540, Accuracy: 99.70%\n",
      "Batch 69, Loss: 0.010098, Accuracy: 99.71%\n",
      "Batch 70, Loss: 0.002836, Accuracy: 99.71%\n",
      "Batch 71, Loss: 0.003260, Accuracy: 99.71%\n",
      "Batch 72, Loss: 0.001863, Accuracy: 99.72%\n",
      "Batch 73, Loss: 0.000919, Accuracy: 99.72%\n",
      "Batch 74, Loss: 0.001647, Accuracy: 99.73%\n",
      "Batch 75, Loss: 0.002857, Accuracy: 99.73%\n",
      "Batch 76, Loss: 0.006619, Accuracy: 99.73%\n",
      "Batch 77, Loss: 0.000935, Accuracy: 99.74%\n",
      "Batch 78, Loss: 0.001074, Accuracy: 99.74%\n",
      "Batch 79, Loss: 0.022474, Accuracy: 99.72%\n",
      "Batch 80, Loss: 0.003380, Accuracy: 99.73%\n",
      "Batch 81, Loss: 0.002583, Accuracy: 99.73%\n",
      "Batch 82, Loss: 0.001276, Accuracy: 99.73%\n",
      "Batch 83, Loss: 0.001680, Accuracy: 99.74%\n",
      "Batch 84, Loss: 0.006591, Accuracy: 99.74%\n",
      "Batch 85, Loss: 0.001923, Accuracy: 99.74%\n",
      "Batch 86, Loss: 0.045188, Accuracy: 99.71%\n",
      "Batch 87, Loss: 0.003559, Accuracy: 99.71%\n",
      "Batch 88, Loss: 0.002162, Accuracy: 99.72%\n",
      "Batch 89, Loss: 0.001172, Accuracy: 99.72%\n",
      "Batch 90, Loss: 0.003946, Accuracy: 99.72%\n",
      "Batch 91, Loss: 0.000626, Accuracy: 99.73%\n",
      "Batch 92, Loss: 0.000630, Accuracy: 99.73%\n",
      "Batch 93, Loss: 0.002815, Accuracy: 99.73%\n",
      "Batch 94, Loss: 0.002944, Accuracy: 99.73%\n",
      "Batch 95, Loss: 0.002121, Accuracy: 99.74%\n",
      "Batch 96, Loss: 0.006324, Accuracy: 99.74%\n",
      "Batch 97, Loss: 0.008025, Accuracy: 99.74%\n",
      "Batch 98, Loss: 0.009715, Accuracy: 99.74%\n",
      "Batch 99, Loss: 0.018019, Accuracy: 99.73%\n",
      "Batch 100, Loss: 0.075095, Accuracy: 99.72%\n",
      "Batch 101, Loss: 0.005876, Accuracy: 99.72%\n",
      "Batch 102, Loss: 0.006811, Accuracy: 99.72%\n",
      "Batch 103, Loss: 0.002915, Accuracy: 99.73%\n",
      "Batch 104, Loss: 0.001021, Accuracy: 99.73%\n",
      "Batch 105, Loss: 0.054394, Accuracy: 99.70%\n",
      "Batch 106, Loss: 0.016107, Accuracy: 99.69%\n",
      "Batch 107, Loss: 0.002339, Accuracy: 99.69%\n",
      "Batch 108, Loss: 0.001897, Accuracy: 99.70%\n",
      "Batch 109, Loss: 0.009111, Accuracy: 99.70%\n",
      "Batch 110, Loss: 0.001799, Accuracy: 99.70%\n",
      "Batch 111, Loss: 0.001101, Accuracy: 99.70%\n",
      "Batch 112, Loss: 0.002270, Accuracy: 99.71%\n",
      "Batch 113, Loss: 0.000922, Accuracy: 99.71%\n",
      "Batch 114, Loss: 0.001638, Accuracy: 99.71%\n",
      "Batch 115, Loss: 0.004576, Accuracy: 99.71%\n",
      "Batch 116, Loss: 0.002373, Accuracy: 99.72%\n",
      "Batch 117, Loss: 0.001760, Accuracy: 99.72%\n",
      "Batch 118, Loss: 0.017784, Accuracy: 99.71%\n",
      "Batch 119, Loss: 0.064489, Accuracy: 99.70%\n",
      "Batch 120, Loss: 0.001729, Accuracy: 99.70%\n",
      "Batch 121, Loss: 0.011273, Accuracy: 99.70%\n",
      "Batch 122, Loss: 0.032325, Accuracy: 99.69%\n",
      "Batch 123, Loss: 0.038381, Accuracy: 99.68%\n",
      "Batch 124, Loss: 0.001078, Accuracy: 99.68%\n",
      "Batch 125, Loss: 0.001457, Accuracy: 99.69%\n",
      "Batch 126, Loss: 0.003761, Accuracy: 99.69%\n",
      "Batch 127, Loss: 0.005507, Accuracy: 99.69%\n",
      "Batch 128, Loss: 0.009260, Accuracy: 99.69%\n",
      "Batch 129, Loss: 0.030426, Accuracy: 99.69%\n",
      "Batch 130, Loss: 0.002224, Accuracy: 99.69%\n",
      "Batch 131, Loss: 0.002630, Accuracy: 99.69%\n",
      "Batch 132, Loss: 0.011035, Accuracy: 99.69%\n",
      "Batch 133, Loss: 0.001406, Accuracy: 99.69%\n",
      "Batch 134, Loss: 0.007869, Accuracy: 99.70%\n",
      "Batch 135, Loss: 0.006325, Accuracy: 99.70%\n",
      "Batch 136, Loss: 0.006019, Accuracy: 99.70%\n",
      "Batch 137, Loss: 0.002510, Accuracy: 99.70%\n",
      "Batch 138, Loss: 0.001985, Accuracy: 99.71%\n",
      "Batch 139, Loss: 0.012947, Accuracy: 99.71%\n",
      "Batch 140, Loss: 0.001210, Accuracy: 99.71%\n",
      "Batch 141, Loss: 0.002028, Accuracy: 99.71%\n",
      "Batch 142, Loss: 0.034968, Accuracy: 99.70%\n",
      "Batch 143, Loss: 0.003616, Accuracy: 99.70%\n",
      "Batch 144, Loss: 0.000914, Accuracy: 99.71%\n",
      "Batch 145, Loss: 0.008027, Accuracy: 99.71%\n",
      "Batch 146, Loss: 0.030740, Accuracy: 99.70%\n",
      "Batch 147, Loss: 0.000907, Accuracy: 99.70%\n",
      "Batch 148, Loss: 0.005789, Accuracy: 99.70%\n",
      "Batch 149, Loss: 0.001148, Accuracy: 99.71%\n",
      "Batch 150, Loss: 0.001091, Accuracy: 99.71%\n",
      "Batch 151, Loss: 0.003774, Accuracy: 99.71%\n",
      "Batch 152, Loss: 0.001008, Accuracy: 99.71%\n",
      "Batch 153, Loss: 0.000713, Accuracy: 99.71%\n",
      "Batch 154, Loss: 0.001163, Accuracy: 99.72%\n",
      "Batch 155, Loss: 0.000840, Accuracy: 99.72%\n",
      "Batch 156, Loss: 0.001712, Accuracy: 99.72%\n",
      "Batch 157, Loss: 0.011720, Accuracy: 99.72%\n",
      "Batch 158, Loss: 0.001574, Accuracy: 99.72%\n",
      "Batch 159, Loss: 0.001157, Accuracy: 99.72%\n",
      "Batch 160, Loss: 0.001081, Accuracy: 99.73%\n",
      "Batch 161, Loss: 0.018471, Accuracy: 99.72%\n",
      "Batch 162, Loss: 0.000926, Accuracy: 99.72%\n",
      "Batch 163, Loss: 0.001649, Accuracy: 99.72%\n",
      "Batch 164, Loss: 0.016112, Accuracy: 99.71%\n",
      "Batch 165, Loss: 0.001336, Accuracy: 99.72%\n",
      "Batch 166, Loss: 0.001182, Accuracy: 99.72%\n",
      "Batch 167, Loss: 0.045337, Accuracy: 99.71%\n",
      "Batch 168, Loss: 0.000768, Accuracy: 99.71%\n",
      "Batch 169, Loss: 0.001383, Accuracy: 99.71%\n",
      "Batch 170, Loss: 0.001030, Accuracy: 99.72%\n",
      "Batch 171, Loss: 0.000880, Accuracy: 99.72%\n",
      "Batch 172, Loss: 0.017384, Accuracy: 99.71%\n",
      "Batch 173, Loss: 0.033391, Accuracy: 99.70%\n",
      "Batch 174, Loss: 0.004624, Accuracy: 99.70%\n",
      "Batch 175, Loss: 0.002165, Accuracy: 99.71%\n",
      "Batch 176, Loss: 0.001697, Accuracy: 99.71%\n",
      "Batch 177, Loss: 0.001488, Accuracy: 99.71%\n",
      "Batch 178, Loss: 0.003090, Accuracy: 99.71%\n",
      "Batch 179, Loss: 0.001884, Accuracy: 99.71%\n",
      "Batch 180, Loss: 0.001484, Accuracy: 99.71%\n",
      "Batch 181, Loss: 0.001531, Accuracy: 99.72%\n",
      "Batch 182, Loss: 0.001864, Accuracy: 99.72%\n",
      "Batch 183, Loss: 0.000935, Accuracy: 99.72%\n",
      "Batch 184, Loss: 0.002545, Accuracy: 99.72%\n",
      "Batch 185, Loss: 0.034184, Accuracy: 99.71%\n",
      "Batch 186, Loss: 0.004108, Accuracy: 99.71%\n",
      "Batch 187, Loss: 0.002092, Accuracy: 99.72%\n",
      "Batch 188, Loss: 0.005683, Accuracy: 99.72%\n",
      "Batch 189, Loss: 0.001632, Accuracy: 99.72%\n",
      "Batch 190, Loss: 0.003080, Accuracy: 99.72%\n",
      "Batch 191, Loss: 0.001576, Accuracy: 99.72%\n",
      "Batch 192, Loss: 0.001168, Accuracy: 99.72%\n",
      "Batch 193, Loss: 0.006698, Accuracy: 99.72%\n",
      "Batch 194, Loss: 0.008284, Accuracy: 99.73%\n",
      "Batch 195, Loss: 0.000932, Accuracy: 99.73%\n",
      "Batch 196, Loss: 0.001848, Accuracy: 99.73%\n",
      "Batch 197, Loss: 0.004354, Accuracy: 99.73%\n",
      "Batch 198, Loss: 0.001026, Accuracy: 99.73%\n",
      "Batch 199, Loss: 0.000944, Accuracy: 99.73%\n",
      "Batch 200, Loss: 0.010984, Accuracy: 99.73%\n",
      "Batch 201, Loss: 0.000794, Accuracy: 99.74%\n",
      "Batch 202, Loss: 0.000789, Accuracy: 99.74%\n",
      "Batch 203, Loss: 0.002969, Accuracy: 99.74%\n",
      "Batch 204, Loss: 0.002776, Accuracy: 99.74%\n",
      "Batch 205, Loss: 0.000716, Accuracy: 99.74%\n",
      "Batch 206, Loss: 0.000632, Accuracy: 99.74%\n",
      "Batch 207, Loss: 0.002595, Accuracy: 99.74%\n",
      "Batch 208, Loss: 0.001511, Accuracy: 99.74%\n",
      "Batch 209, Loss: 0.002999, Accuracy: 99.75%\n",
      "Batch 210, Loss: 0.001330, Accuracy: 99.75%\n",
      "Batch 211, Loss: 0.001785, Accuracy: 99.75%\n",
      "Batch 212, Loss: 0.004200, Accuracy: 99.75%\n",
      "Batch 213, Loss: 0.000576, Accuracy: 99.75%\n",
      "Training - Epoch 44, Loss: 0.008228, Accuracy: 99.75%\n",
      "Validation Batch 1, Loss: 0.000730, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001922, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000801, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000668, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.001516, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000696, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000695, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.038766, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.003876, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.003005, Accuracy: 99.84%\n",
      "Validation Batch 11, Loss: 0.045411, Accuracy: 99.72%\n",
      "Validation Batch 12, Loss: 0.001215, Accuracy: 99.74%\n",
      "Validation Batch 13, Loss: 0.001901, Accuracy: 99.76%\n",
      "Validation Batch 14, Loss: 0.001130, Accuracy: 99.78%\n",
      "Validation Batch 15, Loss: 0.000682, Accuracy: 99.79%\n",
      "Validation Batch 16, Loss: 0.004269, Accuracy: 99.80%\n",
      "Validation Batch 17, Loss: 0.004725, Accuracy: 99.82%\n",
      "Validation Batch 18, Loss: 0.000864, Accuracy: 99.83%\n",
      "Validation Batch 19, Loss: 0.000843, Accuracy: 99.84%\n",
      "Validation Batch 20, Loss: 0.037689, Accuracy: 99.77%\n",
      "Validation Batch 21, Loss: 0.001450, Accuracy: 99.78%\n",
      "Validation Batch 22, Loss: 0.001414, Accuracy: 99.79%\n",
      "Validation Batch 23, Loss: 0.002673, Accuracy: 99.80%\n",
      "Validation Batch 24, Loss: 0.127776, Accuracy: 99.74%\n",
      "Validation Batch 25, Loss: 0.000761, Accuracy: 99.75%\n",
      "Validation Batch 26, Loss: 0.000883, Accuracy: 99.76%\n",
      "Validation Batch 27, Loss: 0.002473, Accuracy: 99.77%\n",
      "Validation - Epoch 44, Loss: 0.010697, Accuracy: 99.77%\n",
      "Patience—8\n",
      "Epoch 45\n",
      "Batch 1, Loss: 0.000900, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000526, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000992, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.001768, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000530, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000723, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.001061, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000662, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.001387, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.001749, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000675, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.001164, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.001352, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000608, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.002253, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000461, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.008992, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000777, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000536, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000654, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.001251, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.001153, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.001620, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000657, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000543, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000909, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.001121, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.001599, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.001411, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000967, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.002683, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000696, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.004901, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000732, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000881, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.001028, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000642, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000493, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.001235, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000428, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.001080, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000669, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000553, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000670, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000785, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.001356, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000588, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000426, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000791, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000615, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000492, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000731, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.001591, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.001432, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000892, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000669, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000798, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000478, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000469, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.001013, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.001159, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000829, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000806, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000638, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.001858, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.003282, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000467, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000788, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000713, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.001113, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000480, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000429, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000925, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000920, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000627, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000382, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000543, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000383, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000522, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000420, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000477, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000874, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.006472, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.001131, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.001056, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.001338, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000528, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000687, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.001357, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000740, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000922, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000541, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000688, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000899, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000511, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000698, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000847, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000600, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000672, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.001033, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000648, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000508, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000642, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.001294, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.002469, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000494, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000561, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000461, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000673, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000820, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000429, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000577, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000564, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000725, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000598, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000618, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000429, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000915, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.001040, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000796, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000598, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000527, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000572, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000614, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000545, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000616, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000572, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000638, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000791, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000610, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000780, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000612, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000703, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000571, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000508, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000472, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000780, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000675, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000641, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000611, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000833, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000510, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000559, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000480, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000573, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000464, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000552, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000717, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000556, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000579, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000489, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000990, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000708, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000459, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000644, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000598, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000482, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000714, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000420, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000627, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000494, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000481, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000472, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000762, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000398, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000385, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000714, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000530, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000355, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000606, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000589, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000442, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000442, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000623, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000466, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.001310, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000440, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000507, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000479, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000587, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000440, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.001403, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000477, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000462, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000419, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000459, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000575, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000440, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000473, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000507, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000611, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.002915, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.001489, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000395, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000576, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000480, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.001582, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000584, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000840, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000410, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000657, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000464, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000480, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000439, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000543, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000359, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000588, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000422, Accuracy: 100.00%\n",
      "Training - Epoch 45, Loss: 0.000848, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000514, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.001040, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000513, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000419, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000596, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000368, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000425, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.009779, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.001195, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000570, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000798, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000730, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000537, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000610, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000946, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.014318, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.002335, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000399, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000539, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000802, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000521, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000504, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000600, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.128575, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000397, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000600, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000472, Accuracy: 99.88%\n",
      "Validation - Epoch 45, Loss: 0.006263, Accuracy: 99.88%\n",
      "Patience—0\n",
      "Epoch 46\n",
      "Batch 1, Loss: 0.000454, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000623, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000375, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000498, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000546, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000410, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000503, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000513, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000439, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000411, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000475, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000407, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000368, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000724, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000443, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000533, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000567, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000896, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000374, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000515, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000555, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000424, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000502, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000578, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000377, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000604, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000524, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000310, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000411, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000575, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000353, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000443, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000409, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000379, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000450, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000451, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000394, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000670, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000506, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000594, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000461, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000370, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000489, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000426, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000371, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000618, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000414, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000490, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000774, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000510, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000442, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000392, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000363, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000410, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000373, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000416, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000386, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000372, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000412, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000576, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000453, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000501, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000515, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000411, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000412, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000497, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000402, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000431, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000493, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000437, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000404, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000451, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000389, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000454, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000429, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000406, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000632, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000546, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000436, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000542, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000651, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000363, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000403, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000486, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000458, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000408, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000400, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000536, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000405, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000432, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000426, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000382, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000594, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000432, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000452, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000537, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000399, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000423, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000747, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000400, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000615, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000364, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000467, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000373, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000424, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000399, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000570, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000375, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000349, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000448, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000412, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000374, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000372, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000618, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000355, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000434, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000464, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000714, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000352, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000430, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000394, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000466, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000420, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000329, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000412, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000426, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000413, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000463, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000558, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000418, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000382, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000444, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000449, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000378, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000380, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000481, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000450, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000422, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000365, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000333, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000470, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000385, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000364, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000349, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000334, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000342, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000587, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000454, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000377, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000342, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000506, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000377, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000352, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000472, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000416, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000374, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000509, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000439, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000422, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000390, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000372, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000443, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000358, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000353, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000451, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000439, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000372, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000415, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000533, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000369, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000442, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000375, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000388, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000449, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000371, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000397, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000358, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000314, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000350, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000335, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000383, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000407, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000332, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000431, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000347, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000430, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000356, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000369, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000354, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000340, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000322, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000360, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000359, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000494, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000387, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000434, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000349, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000288, Accuracy: 100.00%\n",
      "Training - Epoch 46, Loss: 0.000437, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000356, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000645, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000404, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000343, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000477, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000313, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000344, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.015196, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.000826, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.000404, Accuracy: 99.84%\n",
      "Validation Batch 11, Loss: 0.000610, Accuracy: 99.86%\n",
      "Validation Batch 12, Loss: 0.000441, Accuracy: 99.87%\n",
      "Validation Batch 13, Loss: 0.000408, Accuracy: 99.88%\n",
      "Validation Batch 14, Loss: 0.000496, Accuracy: 99.89%\n",
      "Validation Batch 15, Loss: 0.000576, Accuracy: 99.90%\n",
      "Validation Batch 16, Loss: 0.039976, Accuracy: 99.80%\n",
      "Validation Batch 17, Loss: 0.002642, Accuracy: 99.82%\n",
      "Validation Batch 18, Loss: 0.000341, Accuracy: 99.83%\n",
      "Validation Batch 19, Loss: 0.000452, Accuracy: 99.84%\n",
      "Validation Batch 20, Loss: 0.000570, Accuracy: 99.84%\n",
      "Validation Batch 21, Loss: 0.000421, Accuracy: 99.85%\n",
      "Validation Batch 22, Loss: 0.000421, Accuracy: 99.86%\n",
      "Validation Batch 23, Loss: 0.000446, Accuracy: 99.86%\n",
      "Validation Batch 24, Loss: 0.129580, Accuracy: 99.80%\n",
      "Validation Batch 25, Loss: 0.000353, Accuracy: 99.81%\n",
      "Validation Batch 26, Loss: 0.000520, Accuracy: 99.82%\n",
      "Validation Batch 27, Loss: 0.000389, Accuracy: 99.82%\n",
      "Validation - Epoch 46, Loss: 0.007331, Accuracy: 99.82%\n",
      "Patience—1\n",
      "Epoch 47\n",
      "Batch 1, Loss: 0.000314, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000459, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000496, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000378, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000381, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000365, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000386, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000422, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000461, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000464, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000386, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000353, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000343, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000383, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000516, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000412, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000403, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000418, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000357, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000425, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000505, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000404, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000318, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000484, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000420, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000369, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000338, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000428, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000343, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000344, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000460, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000509, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000394, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000415, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000418, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000392, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000391, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000389, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000333, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000541, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000432, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000374, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000398, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000350, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000370, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000350, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000435, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000360, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000354, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000351, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000369, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000370, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000348, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000423, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000344, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000403, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000383, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000330, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000385, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000391, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000417, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000411, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000332, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000403, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000361, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000395, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000364, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000407, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000398, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000348, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000437, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000544, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000396, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000340, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000396, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000417, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000438, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000348, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000455, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000395, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000372, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000310, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000383, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000349, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000310, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000605, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000312, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000342, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000326, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000365, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000450, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000381, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000409, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000392, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000340, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000499, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000537, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000398, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000367, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000389, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000387, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000314, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000403, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000344, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000372, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000475, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000290, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000397, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000420, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000348, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000316, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000397, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000345, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000357, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000432, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000387, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000464, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000446, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000453, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000316, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000377, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000325, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000340, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000418, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000389, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000408, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000299, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000350, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000348, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000299, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000306, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000325, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000270, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000323, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000325, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000328, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000378, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000290, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000432, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000388, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000391, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000398, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000378, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000323, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000347, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000328, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000358, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000343, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000335, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000342, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000438, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000286, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000364, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000333, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000312, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000370, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000374, Accuracy: 100.00%\n",
      "Training - Epoch 47, Loss: 0.000365, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000301, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000565, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000356, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000302, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000422, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000282, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000302, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.013316, Accuracy: 99.80%\n",
      "Validation Batch 9, Loss: 0.000648, Accuracy: 99.83%\n",
      "Validation Batch 10, Loss: 0.000347, Accuracy: 99.84%\n",
      "Validation Batch 11, Loss: 0.000513, Accuracy: 99.86%\n",
      "Validation Batch 12, Loss: 0.000365, Accuracy: 99.87%\n",
      "Validation Batch 13, Loss: 0.000352, Accuracy: 99.88%\n",
      "Validation Batch 14, Loss: 0.000424, Accuracy: 99.89%\n",
      "Validation Batch 15, Loss: 0.000512, Accuracy: 99.90%\n",
      "Validation Batch 16, Loss: 0.046615, Accuracy: 99.80%\n",
      "Validation Batch 17, Loss: 0.001819, Accuracy: 99.82%\n",
      "Validation Batch 18, Loss: 0.000306, Accuracy: 99.83%\n",
      "Validation Batch 19, Loss: 0.000394, Accuracy: 99.84%\n",
      "Validation Batch 20, Loss: 0.000449, Accuracy: 99.84%\n",
      "Validation Batch 21, Loss: 0.000368, Accuracy: 99.85%\n",
      "Validation Batch 22, Loss: 0.000366, Accuracy: 99.86%\n",
      "Validation Batch 23, Loss: 0.000386, Accuracy: 99.86%\n",
      "Validation Batch 24, Loss: 0.132601, Accuracy: 99.80%\n",
      "Validation Batch 25, Loss: 0.000314, Accuracy: 99.81%\n",
      "Validation Batch 26, Loss: 0.000467, Accuracy: 99.82%\n",
      "Validation Batch 27, Loss: 0.000339, Accuracy: 99.82%\n",
      "Validation - Epoch 47, Loss: 0.007535, Accuracy: 99.82%\n",
      "Patience—2\n",
      "Epoch 48\n",
      "Batch 1, Loss: 0.000323, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000279, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000337, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000321, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000364, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000395, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000338, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000318, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000306, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000468, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000302, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000360, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000374, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000353, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000447, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000335, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000402, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000392, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000384, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000291, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000322, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000366, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000332, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000358, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000310, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000352, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000412, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000269, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000292, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000405, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000425, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000381, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000328, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000359, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000340, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000313, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000334, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000388, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000338, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000343, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000302, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000373, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000313, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000355, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000419, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000302, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000446, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000373, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000344, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000306, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000529, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000331, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000362, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000318, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000280, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000330, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000328, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000321, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000306, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000289, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000327, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000408, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000381, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000338, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000383, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000306, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000386, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000267, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000364, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000321, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000338, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000328, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000318, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000325, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000286, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000361, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000297, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000306, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000323, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000316, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000325, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000289, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000366, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000290, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000430, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000310, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000362, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000329, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000361, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000351, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000381, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000362, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000279, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000322, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000352, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000288, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000304, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000288, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000368, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000304, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000365, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000401, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000354, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000367, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000292, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000316, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000357, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000358, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000357, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000280, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000280, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000265, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000414, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000280, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000270, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000267, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000330, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000356, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000322, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000381, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000400, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000302, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000408, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000256, Accuracy: 100.00%\n",
      "Training - Epoch 48, Loss: 0.000321, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000266, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000508, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000320, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000272, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000374, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000256, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000271, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.010517, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000545, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000306, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000451, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000319, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000312, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000372, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000461, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.050643, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.001553, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000277, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000351, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000384, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000324, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000325, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000343, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.135523, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000281, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000418, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000300, Accuracy: 99.88%\n",
      "Validation - Epoch 48, Loss: 0.007640, Accuracy: 99.88%\n",
      "Patience—3\n",
      "Epoch 49\n",
      "Batch 1, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000313, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000335, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000279, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000397, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000311, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000358, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000340, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000334, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000319, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000325, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000352, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000313, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000365, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000277, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000318, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000236, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000333, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000279, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000243, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000335, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000321, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000304, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000387, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000338, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000376, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000265, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000354, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000316, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000378, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000342, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000347, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000291, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000297, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000274, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000253, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000321, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000393, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000341, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000313, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000308, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000328, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000297, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000359, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000346, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000332, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000269, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000389, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000289, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000254, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000312, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000289, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000253, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000299, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000291, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000353, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000246, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000269, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000253, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000326, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000388, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000339, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000299, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000265, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000270, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000304, Accuracy: 100.00%\n",
      "Training - Epoch 49, Loss: 0.000287, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000238, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000462, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000289, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000246, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000335, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000234, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000245, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.008464, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000465, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000274, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000400, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000283, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000279, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000329, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000422, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.053067, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.001240, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000251, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000315, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000337, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000290, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000291, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000307, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.138294, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000254, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000373, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000269, Accuracy: 99.88%\n",
      "Validation - Epoch 49, Loss: 0.007713, Accuracy: 99.88%\n",
      "Patience—4\n",
      "Epoch 50\n",
      "Batch 1, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000286, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000330, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000246, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000254, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000291, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000265, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000254, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000324, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000254, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000267, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000322, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000286, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000320, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000309, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000423, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000267, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000289, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000243, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000349, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000273, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000253, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000236, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000336, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000353, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000301, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000243, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000329, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000249, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000303, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000297, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000236, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000300, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000249, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000253, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000246, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000274, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000288, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000288, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000315, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000272, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000269, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000298, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000295, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000284, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000304, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000292, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000236, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000355, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000226, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000274, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000281, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000269, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000253, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000323, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000282, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000285, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000299, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000266, Accuracy: 100.00%\n",
      "Training - Epoch 50, Loss: 0.000258, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000215, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000422, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000262, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000225, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000301, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000214, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000223, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.006108, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000411, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000247, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000358, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000256, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000253, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000294, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000385, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.054557, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.001062, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000229, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000284, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000305, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000261, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000263, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000278, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.140791, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000228, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000331, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000241, Accuracy: 99.88%\n",
      "Validation - Epoch 50, Loss: 0.007741, Accuracy: 99.88%\n",
      "Patience—5\n",
      "Epoch 51\n",
      "Batch 1, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000216, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000276, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000270, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000261, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000291, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000287, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000250, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000293, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000277, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000367, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000226, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000317, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000213, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000254, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000249, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000211, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000255, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000290, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000236, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000296, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000294, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000297, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000248, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000279, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000260, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000226, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000237, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000305, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000268, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000316, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000216, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000213, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000266, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000216, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000259, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000256, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000283, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000209, Accuracy: 100.00%\n",
      "Training - Epoch 51, Loss: 0.000234, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000196, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000384, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000238, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000206, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000272, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000197, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000204, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.004676, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000372, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000224, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000323, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000232, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000229, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000264, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000352, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.055590, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.000942, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000209, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000257, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000279, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000236, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000239, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000252, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.143339, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000207, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000296, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000219, Accuracy: 99.88%\n",
      "Validation - Epoch 51, Loss: 0.007794, Accuracy: 99.88%\n",
      "Patience—6\n",
      "Epoch 52\n",
      "Batch 1, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000271, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000211, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000243, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000263, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000278, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000236, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000213, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000211, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000205, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000226, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000247, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000257, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000252, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000211, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000307, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000251, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000205, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000224, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000213, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000279, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000186, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000275, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000234, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000246, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000222, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000264, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000226, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000290, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000243, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000231, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000270, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000227, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000230, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000243, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000240, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000274, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000249, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000211, Accuracy: 100.00%\n",
      "Training - Epoch 52, Loss: 0.000212, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000178, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000353, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000218, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000188, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000246, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000181, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000186, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.003846, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000328, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000203, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000293, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000211, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000207, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000238, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000324, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.056939, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.000829, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000191, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000233, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000249, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000214, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000217, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000229, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.145692, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000188, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000267, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000199, Accuracy: 99.88%\n",
      "Validation - Epoch 52, Loss: 0.007876, Accuracy: 99.88%\n",
      "Patience—7\n",
      "Epoch 53\n",
      "Batch 1, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000244, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000226, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000245, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000241, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000220, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000258, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000211, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000216, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000214, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000219, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000242, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000239, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000229, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000205, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000183, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000238, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000221, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000209, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000195, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000183, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000262, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000232, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000228, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000147, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000179, Accuracy: 100.00%\n",
      "Training - Epoch 53, Loss: 0.000193, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000163, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000325, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000199, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000173, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000224, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000166, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000171, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.003127, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000291, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000185, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000266, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000191, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000189, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000215, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000300, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.057297, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.000735, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000175, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000212, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000225, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000194, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000197, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000208, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.148025, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000171, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000241, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000181, Accuracy: 99.88%\n",
      "Validation - Epoch 53, Loss: 0.007928, Accuracy: 99.88%\n",
      "Patience—8\n",
      "Epoch 54\n",
      "Batch 1, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000197, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000233, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000186, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000205, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000183, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000213, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000212, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000186, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000144, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000213, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000235, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000194, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000183, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000204, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000215, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000205, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000223, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000153, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000188, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000199, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000205, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000201, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000216, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000171, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000198, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000200, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000147, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000152, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000133, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000141, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000137, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000198, Accuracy: 100.00%\n",
      "Training - Epoch 54, Loss: 0.000176, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000149, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000294, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000182, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000158, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000204, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000152, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000156, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.002582, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000264, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000168, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000243, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000174, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000171, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000195, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000272, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.059174, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.000663, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000160, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000193, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000206, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000176, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000180, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000190, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.150155, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000156, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000218, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000165, Accuracy: 99.88%\n",
      "Validation - Epoch 54, Loss: 0.008037, Accuracy: 99.88%\n",
      "Patience—9\n",
      "Epoch 55\n",
      "Batch 1, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 2, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 3, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 4, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 5, Loss: 0.000140, Accuracy: 100.00%\n",
      "Batch 6, Loss: 0.000207, Accuracy: 100.00%\n",
      "Batch 7, Loss: 0.000152, Accuracy: 100.00%\n",
      "Batch 8, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 9, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 10, Loss: 0.000153, Accuracy: 100.00%\n",
      "Batch 11, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 12, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 13, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 14, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 15, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 16, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 17, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 18, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 19, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 20, Loss: 0.000190, Accuracy: 100.00%\n",
      "Batch 21, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 22, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 23, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 24, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 25, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 26, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 27, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 28, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 29, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 30, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 31, Loss: 0.000176, Accuracy: 100.00%\n",
      "Batch 32, Loss: 0.000202, Accuracy: 100.00%\n",
      "Batch 33, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 34, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 35, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 36, Loss: 0.000139, Accuracy: 100.00%\n",
      "Batch 37, Loss: 0.000189, Accuracy: 100.00%\n",
      "Batch 38, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 39, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 40, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 41, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 42, Loss: 0.000210, Accuracy: 100.00%\n",
      "Batch 43, Loss: 0.000140, Accuracy: 100.00%\n",
      "Batch 44, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 45, Loss: 0.000138, Accuracy: 100.00%\n",
      "Batch 46, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 47, Loss: 0.000141, Accuracy: 100.00%\n",
      "Batch 48, Loss: 0.000143, Accuracy: 100.00%\n",
      "Batch 49, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 50, Loss: 0.000152, Accuracy: 100.00%\n",
      "Batch 51, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 52, Loss: 0.000143, Accuracy: 100.00%\n",
      "Batch 53, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 54, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 55, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 56, Loss: 0.000135, Accuracy: 100.00%\n",
      "Batch 57, Loss: 0.000206, Accuracy: 100.00%\n",
      "Batch 58, Loss: 0.000138, Accuracy: 100.00%\n",
      "Batch 59, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 60, Loss: 0.000193, Accuracy: 100.00%\n",
      "Batch 61, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 62, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 63, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 64, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 65, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 66, Loss: 0.000175, Accuracy: 100.00%\n",
      "Batch 67, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 68, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 69, Loss: 0.000182, Accuracy: 100.00%\n",
      "Batch 70, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 71, Loss: 0.000146, Accuracy: 100.00%\n",
      "Batch 72, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 73, Loss: 0.000178, Accuracy: 100.00%\n",
      "Batch 74, Loss: 0.000137, Accuracy: 100.00%\n",
      "Batch 75, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 76, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 77, Loss: 0.000225, Accuracy: 100.00%\n",
      "Batch 78, Loss: 0.000141, Accuracy: 100.00%\n",
      "Batch 79, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 80, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 81, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 82, Loss: 0.000167, Accuracy: 100.00%\n",
      "Batch 83, Loss: 0.000158, Accuracy: 100.00%\n",
      "Batch 84, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 85, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 86, Loss: 0.000187, Accuracy: 100.00%\n",
      "Batch 87, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 88, Loss: 0.000163, Accuracy: 100.00%\n",
      "Batch 89, Loss: 0.000186, Accuracy: 100.00%\n",
      "Batch 90, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 91, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 92, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 93, Loss: 0.000138, Accuracy: 100.00%\n",
      "Batch 94, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 95, Loss: 0.000135, Accuracy: 100.00%\n",
      "Batch 96, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 97, Loss: 0.000134, Accuracy: 100.00%\n",
      "Batch 98, Loss: 0.000196, Accuracy: 100.00%\n",
      "Batch 99, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 100, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 101, Loss: 0.000137, Accuracy: 100.00%\n",
      "Batch 102, Loss: 0.000147, Accuracy: 100.00%\n",
      "Batch 103, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 104, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 105, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 106, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 107, Loss: 0.000147, Accuracy: 100.00%\n",
      "Batch 108, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 109, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 110, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 111, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 112, Loss: 0.000156, Accuracy: 100.00%\n",
      "Batch 113, Loss: 0.000146, Accuracy: 100.00%\n",
      "Batch 114, Loss: 0.000150, Accuracy: 100.00%\n",
      "Batch 115, Loss: 0.000186, Accuracy: 100.00%\n",
      "Batch 116, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 117, Loss: 0.000173, Accuracy: 100.00%\n",
      "Batch 118, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 119, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 120, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 121, Loss: 0.000185, Accuracy: 100.00%\n",
      "Batch 122, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 123, Loss: 0.000140, Accuracy: 100.00%\n",
      "Batch 124, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 125, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 126, Loss: 0.000184, Accuracy: 100.00%\n",
      "Batch 127, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 128, Loss: 0.000143, Accuracy: 100.00%\n",
      "Batch 129, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 130, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 131, Loss: 0.000174, Accuracy: 100.00%\n",
      "Batch 132, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 133, Loss: 0.000128, Accuracy: 100.00%\n",
      "Batch 134, Loss: 0.000132, Accuracy: 100.00%\n",
      "Batch 135, Loss: 0.000170, Accuracy: 100.00%\n",
      "Batch 136, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 137, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 138, Loss: 0.000139, Accuracy: 100.00%\n",
      "Batch 139, Loss: 0.000150, Accuracy: 100.00%\n",
      "Batch 140, Loss: 0.000146, Accuracy: 100.00%\n",
      "Batch 141, Loss: 0.000181, Accuracy: 100.00%\n",
      "Batch 142, Loss: 0.000150, Accuracy: 100.00%\n",
      "Batch 143, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 144, Loss: 0.000153, Accuracy: 100.00%\n",
      "Batch 145, Loss: 0.000141, Accuracy: 100.00%\n",
      "Batch 146, Loss: 0.000165, Accuracy: 100.00%\n",
      "Batch 147, Loss: 0.000140, Accuracy: 100.00%\n",
      "Batch 148, Loss: 0.000138, Accuracy: 100.00%\n",
      "Batch 149, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 150, Loss: 0.000135, Accuracy: 100.00%\n",
      "Batch 151, Loss: 0.000138, Accuracy: 100.00%\n",
      "Batch 152, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 153, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 154, Loss: 0.000191, Accuracy: 100.00%\n",
      "Batch 155, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 156, Loss: 0.000179, Accuracy: 100.00%\n",
      "Batch 157, Loss: 0.000141, Accuracy: 100.00%\n",
      "Batch 158, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 159, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 160, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 161, Loss: 0.000162, Accuracy: 100.00%\n",
      "Batch 162, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 163, Loss: 0.000147, Accuracy: 100.00%\n",
      "Batch 164, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 165, Loss: 0.000146, Accuracy: 100.00%\n",
      "Batch 166, Loss: 0.000218, Accuracy: 100.00%\n",
      "Batch 167, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 168, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 169, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 170, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 171, Loss: 0.000203, Accuracy: 100.00%\n",
      "Batch 172, Loss: 0.000142, Accuracy: 100.00%\n",
      "Batch 173, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 174, Loss: 0.000148, Accuracy: 100.00%\n",
      "Batch 175, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 176, Loss: 0.000192, Accuracy: 100.00%\n",
      "Batch 177, Loss: 0.000161, Accuracy: 100.00%\n",
      "Batch 178, Loss: 0.000143, Accuracy: 100.00%\n",
      "Batch 179, Loss: 0.000138, Accuracy: 100.00%\n",
      "Batch 180, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 181, Loss: 0.000137, Accuracy: 100.00%\n",
      "Batch 182, Loss: 0.000159, Accuracy: 100.00%\n",
      "Batch 183, Loss: 0.000164, Accuracy: 100.00%\n",
      "Batch 184, Loss: 0.000131, Accuracy: 100.00%\n",
      "Batch 185, Loss: 0.000177, Accuracy: 100.00%\n",
      "Batch 186, Loss: 0.000155, Accuracy: 100.00%\n",
      "Batch 187, Loss: 0.000154, Accuracy: 100.00%\n",
      "Batch 188, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 189, Loss: 0.000172, Accuracy: 100.00%\n",
      "Batch 190, Loss: 0.000143, Accuracy: 100.00%\n",
      "Batch 191, Loss: 0.000180, Accuracy: 100.00%\n",
      "Batch 192, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 193, Loss: 0.000153, Accuracy: 100.00%\n",
      "Batch 194, Loss: 0.000157, Accuracy: 100.00%\n",
      "Batch 195, Loss: 0.000143, Accuracy: 100.00%\n",
      "Batch 196, Loss: 0.000217, Accuracy: 100.00%\n",
      "Batch 197, Loss: 0.000133, Accuracy: 100.00%\n",
      "Batch 198, Loss: 0.000208, Accuracy: 100.00%\n",
      "Batch 199, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 200, Loss: 0.000151, Accuracy: 100.00%\n",
      "Batch 201, Loss: 0.000149, Accuracy: 100.00%\n",
      "Batch 202, Loss: 0.000134, Accuracy: 100.00%\n",
      "Batch 203, Loss: 0.000128, Accuracy: 100.00%\n",
      "Batch 204, Loss: 0.000144, Accuracy: 100.00%\n",
      "Batch 205, Loss: 0.000166, Accuracy: 100.00%\n",
      "Batch 206, Loss: 0.000144, Accuracy: 100.00%\n",
      "Batch 207, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 208, Loss: 0.000152, Accuracy: 100.00%\n",
      "Batch 209, Loss: 0.000169, Accuracy: 100.00%\n",
      "Batch 210, Loss: 0.000168, Accuracy: 100.00%\n",
      "Batch 211, Loss: 0.000160, Accuracy: 100.00%\n",
      "Batch 212, Loss: 0.000145, Accuracy: 100.00%\n",
      "Batch 213, Loss: 0.000147, Accuracy: 100.00%\n",
      "Training - Epoch 55, Loss: 0.000160, Accuracy: 100.00%\n",
      "Validation Batch 1, Loss: 0.000136, Accuracy: 100.00%\n",
      "Validation Batch 2, Loss: 0.000264, Accuracy: 100.00%\n",
      "Validation Batch 3, Loss: 0.000166, Accuracy: 100.00%\n",
      "Validation Batch 4, Loss: 0.000145, Accuracy: 100.00%\n",
      "Validation Batch 5, Loss: 0.000184, Accuracy: 100.00%\n",
      "Validation Batch 6, Loss: 0.000140, Accuracy: 100.00%\n",
      "Validation Batch 7, Loss: 0.000144, Accuracy: 100.00%\n",
      "Validation Batch 8, Loss: 0.002192, Accuracy: 100.00%\n",
      "Validation Batch 9, Loss: 0.000238, Accuracy: 100.00%\n",
      "Validation Batch 10, Loss: 0.000153, Accuracy: 100.00%\n",
      "Validation Batch 11, Loss: 0.000223, Accuracy: 100.00%\n",
      "Validation Batch 12, Loss: 0.000159, Accuracy: 100.00%\n",
      "Validation Batch 13, Loss: 0.000156, Accuracy: 100.00%\n",
      "Validation Batch 14, Loss: 0.000177, Accuracy: 100.00%\n",
      "Validation Batch 15, Loss: 0.000243, Accuracy: 100.00%\n",
      "Validation Batch 16, Loss: 0.061474, Accuracy: 99.90%\n",
      "Validation Batch 17, Loss: 0.000640, Accuracy: 99.91%\n",
      "Validation Batch 18, Loss: 0.000146, Accuracy: 99.91%\n",
      "Validation Batch 19, Loss: 0.000176, Accuracy: 99.92%\n",
      "Validation Batch 20, Loss: 0.000190, Accuracy: 99.92%\n",
      "Validation Batch 21, Loss: 0.000161, Accuracy: 99.93%\n",
      "Validation Batch 22, Loss: 0.000164, Accuracy: 99.93%\n",
      "Validation Batch 23, Loss: 0.000173, Accuracy: 99.93%\n",
      "Validation Batch 24, Loss: 0.152161, Accuracy: 99.87%\n",
      "Validation Batch 25, Loss: 0.000142, Accuracy: 99.88%\n",
      "Validation Batch 26, Loss: 0.000196, Accuracy: 99.88%\n",
      "Validation Batch 27, Loss: 0.000151, Accuracy: 99.88%\n",
      "Validation - Epoch 55, Loss: 0.008166, Accuracy: 99.88%\n",
      "Patience—10\n",
      "Early stopping at epoch 55\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 130  \n",
    "patience = 20  \n",
    "best_val_loss = float('inf')  \n",
    "best_model = None  \n",
    "\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "train_accuracy_list = list()\n",
    "val_accuracy_list = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Batch {batch_idx+1}, Loss: {loss.item():.6f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Training - Epoch {epoch+1}, Loss: {train_loss:.6f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()  \n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "            outputs = model(images) \n",
    "            loss = criterion(outputs, labels) \n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print(f\"Validation Batch {batch_idx+1}, Loss: {loss.item():.6f}, Accuracy: {100 * val_correct / val_total:.2f}%\")\n",
    "\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Validation - Epoch {epoch+1}, Loss: {val_loss:.6f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    print(f'Patience—{patience_counter}')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "model = best_model\n",
    "torch.save(model.state_dict(), f'{experiment}-{model_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracy_list, label='Train Accuracy')\n",
    "\n",
    "# Plotting the second graph\n",
    "plt.plot(val_accuracy_list, label='Val Accuracy')\n",
    "\n",
    "# Adding labels and a legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train vs Val Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "\n",
    "# Plotting the second graph\n",
    "plt.plot(val_loss_list, label='Val Loss')\n",
    "\n",
    "# Adding labels and a legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Val Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch 1, Loss: 0.000794, Accuracy: 100.00%\n",
      "Test Batch 2, Loss: 0.001584, Accuracy: 100.00%\n",
      "Test Batch 3, Loss: 0.000500, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Batch 4, Loss: 0.000658, Accuracy: 100.00%\n",
      "Test Batch 5, Loss: 0.000561, Accuracy: 100.00%\n",
      "Test Batch 6, Loss: 0.079773, Accuracy: 99.74%\n",
      "Test Batch 7, Loss: 0.000403, Accuracy: 99.78%\n",
      "Test Batch 8, Loss: 0.000527, Accuracy: 99.80%\n",
      "Test Batch 9, Loss: 0.001967, Accuracy: 99.83%\n",
      "Test Batch 10, Loss: 0.000567, Accuracy: 99.84%\n",
      "Test Batch 11, Loss: 0.008066, Accuracy: 99.86%\n",
      "Test Batch 12, Loss: 0.039644, Accuracy: 99.74%\n",
      "Test Batch 13, Loss: 0.001194, Accuracy: 99.76%\n",
      "Test Batch 14, Loss: 0.000630, Accuracy: 99.78%\n",
      "Test Batch 15, Loss: 0.000483, Accuracy: 99.79%\n",
      "Test Batch 16, Loss: 0.000680, Accuracy: 99.80%\n",
      "Test Batch 17, Loss: 0.002303, Accuracy: 99.82%\n",
      "Test Batch 18, Loss: 0.000535, Accuracy: 99.83%\n",
      "Test Batch 19, Loss: 0.000507, Accuracy: 99.84%\n",
      "Test Batch 20, Loss: 0.000484, Accuracy: 99.84%\n",
      "Test Batch 21, Loss: 0.000678, Accuracy: 99.85%\n",
      "Test Batch 22, Loss: 0.000489, Accuracy: 99.86%\n",
      "Test Batch 23, Loss: 0.153426, Accuracy: 99.80%\n",
      "Test Batch 24, Loss: 0.137874, Accuracy: 99.74%\n",
      "Test Batch 25, Loss: 0.001149, Accuracy: 99.75%\n",
      "Test Batch 26, Loss: 0.090500, Accuracy: 99.70%\n",
      "Test Batch 27, Loss: 0.000777, Accuracy: 99.71%\n",
      "Test Set - Loss: 0.019509, Accuracy: 99.71%\n",
      "Confusion Matrix:\n",
      "[[118   0   0   0]\n",
      " [  0 436   2   1]\n",
      " [  0   0 578   1]\n",
      " [  0   0   1 568]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        print(f\"Test Batch {batch_idx+1}, Loss: {loss.item():.6f}, Accuracy: {100 * test_correct / test_total:.2f}%\")\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "\n",
    "print(f\"Test Set - Loss: {test_loss:.6f}, Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "# Calculate percentages for each element\n",
    "cm_percentage = (cm / np.sum(cm)) * 100\n",
    "\n",
    "# Plot confusion matrix with count and percentages\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=['MILD', 'MODERATE', 'NORMAL', 'SEVERE'],\n",
    "            yticklabels=['MILD', 'MODERATE', 'NORMAL', 'SEVERE'],\n",
    "            ax=ax)\n",
    "\n",
    "# Annotate each box with count and percentage\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm[0])):\n",
    "        ax.text(j + 0.5, i + 0.5, f'\\n\\n{cm_percentage[i, j]:.2f}%',\n",
    "                ha='center', va='center', color='black')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping at Epoch 55\n",
    "Test Accuracy — 99.71%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
